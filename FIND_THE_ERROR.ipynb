{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten, LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "import tqdm\n",
    "from numpy import loadtxt\n",
    "from os import *\n",
    "from sklearn.utils import class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(true,preds):\n",
    "    conf_matx = confusion_matrix(true, preds)\n",
    "    sns.heatmap(conf_matx, annot=True,annot_kws={\"size\": 12},fmt='g', cbar=False, cmap=plt.cm.Blues) #'viridis'\n",
    "    #plt.savefig('/home/jovyan/conf_matrix.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return conf_matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(model_history, model_name):\n",
    "    fig = plt.figure(figsize=(15,5), facecolor='w')\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.plot(model_history.history['loss'])\n",
    "    ax.plot(model_history.history['val_loss'])\n",
    "    ax.set(title=model_name + ': Model loss', ylabel='Loss', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Val'], loc='upper left')\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.plot(model_history.history['accuracy'])\n",
    "    ax.plot(model_history.history['val_accuracy'])\n",
    "    ax.set(title=model_name + ': Model Accuracy; test='+ str(np.round(model_history.history['val_accuracy'][-1], 3)),\n",
    "           ylabel='Accuracy', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Val'], loc='upper left')\n",
    "    #plt.savefig('/home/jovyan/curve.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(x):\n",
    "    rescaled = []\n",
    "\n",
    "    for i in x:\n",
    "\n",
    "        scale_percent = 140 # percent of original size\n",
    "        width = int(i.shape[1] / (scale_percent / 100))\n",
    "        height = int(i.shape[0] / (scale_percent / 100))\n",
    "        dim = (width, height)\n",
    "        resized = cv2.resize(i, dim, interpolation = cv2.INTER_LANCZOS4)\n",
    "        rescaled.append(resized)\n",
    "\n",
    "    x_orig = np.reshape( rescaled, (len( rescaled), resized.shape[1], resized.shape[1], 3))\n",
    "\n",
    "    return x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(path_data):\n",
    "    \n",
    "    p = '/home/jovyan/DATA_MASTER_PROJECT/IMG_A549_high_con/'\n",
    "    \n",
    "    \n",
    "    \n",
    "    pa_adr = p + 'ADR_tile/'\n",
    "    \n",
    "    pa_control = p + 'CONTROL_cropped/'\n",
    "    \n",
    "    pa_hrh = p + 'HRH_tile/'\n",
    "    \n",
    "    pa_dmso = p + 'DMSO_tile/'\n",
    "    \n",
    "    image_list = []\n",
    "    \n",
    "    \n",
    "       \n",
    "\n",
    "\n",
    "    for filename in sorted(path_data, key=natural_keys): \n",
    "        \n",
    "        if 'adr' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_adr + filename,1)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "            \n",
    "\n",
    "            image_list.append(imarray)\n",
    "        \n",
    "            \n",
    "        if 'hrh' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_hrh + filename,1)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "            \n",
    "\n",
    "            image_list.append(imarray)\n",
    "            \n",
    "        if 'dmso' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_dmso + filename,1)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "            \n",
    "\n",
    "            image_list.append(imarray)\n",
    "\n",
    "\n",
    "\n",
    "    x_orig = np.reshape(image_list, (len(image_list), 256, 256, 3))\n",
    "\n",
    "    return x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Images_path(path_data):\n",
    "    \n",
    "    p = '/scratch-shared/victor/IMG_A549/'\n",
    "    \n",
    "    \n",
    "    \n",
    "    pa_adr = p + 'ADR_tile/'\n",
    "    pa_hrh = p + 'HRH_tile/'\n",
    "    pa_dmso = p + 'DMSO_tile/'\n",
    "    \n",
    "    image_list = []\n",
    "    \n",
    "    \n",
    "       \n",
    "\n",
    "\n",
    "    for filename in path_data: \n",
    "        \n",
    "        if 'adr' in filename:\n",
    "            \n",
    "\n",
    "            image_list.append(pa_adr + filename)\n",
    "        \n",
    "            \n",
    "        if 'hrh' in filename:\n",
    "\n",
    "            image_list.append(pa_hrh + filename)\n",
    "            \n",
    "        if 'dmso' in filename:\n",
    "            \n",
    "\n",
    "            image_list.append(pa_dmso + filename)\n",
    "\n",
    "    return image_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(y):\n",
    "    lab = []\n",
    "    for i in y:\n",
    "        if 'adr' in i:\n",
    "            lab.append(0)\n",
    "        if 'hrh' in i:\n",
    "            lab.append(1)\n",
    "        if 'dmso' in i:\n",
    "            lab.append(2)\n",
    "    return lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_count(x):\n",
    "    name_wel = []\n",
    "    for i in sorted(x, key = natural_keys):\n",
    "        name_wel.append(i.split('_')[0])\n",
    "\n",
    "    z = sorted(list(set(name_wel)))\n",
    "    r = list(range(len(z)))\n",
    "\n",
    "    num = []\n",
    "    for iz in range(len(z)):\n",
    "        count = 0\n",
    "        for i in sorted(x, key=natural_keys):\n",
    "            if z[iz] in i:\n",
    "                count += 1\n",
    "        num.append(count)\n",
    "    return list(zip(z, r, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages_LSTM(path_data,len_t_points):\n",
    "    \n",
    "\n",
    "    feat_list = []\n",
    "\n",
    "\n",
    "    for filename in sorted(glob.glob(path_data), key=natural_keys): \n",
    "        feat_list.append(np.load(filename))\n",
    "\n",
    "    x_orig = np.reshape(feat_list, (len(feat_list),len_t_points, 64))\n",
    "\n",
    "    return x_orig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(data_set):\n",
    "    fe = return_count(data_set)\n",
    "    leb = creat_label(fe)\n",
    "    y = np.array(list(leb))\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels_LSTM(data_set):\n",
    "    fe = return_count_LSTM(data_set)\n",
    "    leb = creat_label(fe)\n",
    "    y = np.array(list(leb))\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_count_LSTM(x):\n",
    "    name_wel = []\n",
    "    for _,_,i in os.walk(x):\n",
    "        for f in i:\n",
    "            name_wel.append(f.split('_')[2])\n",
    "\n",
    "    z = sorted(list(set(name_wel)), key=natural_keys)\n",
    "    r = list(range(len(z)))\n",
    "\n",
    "    num = []\n",
    "    for iz in range(len(z)):\n",
    "        count = 0\n",
    "        for i in sorted(name_wel, key=natural_keys):\n",
    "            if z[iz] in i:\n",
    "                count += 1\n",
    "        num.append(count)\n",
    "    return list(zip(z, r, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_label(y):\n",
    "    labels = []\n",
    "    for ix, _ in enumerate(y):\n",
    "        \n",
    "        if y[ix][0] == 'adr':\n",
    "        \n",
    "            labels.append([[y[ix][0],0]] * y[ix][2])\n",
    "        \n",
    "        if y[ix][0] == 'hrh':\n",
    "            \n",
    "            labels.append([[y[ix][0],1]] * y[ix][2])\n",
    "        \n",
    "            \n",
    "        if y[ix][0] == 'dmso':\n",
    "            \n",
    "            labels.append([[y[ix][0],2]] * y[ix][2])\n",
    "    \n",
    "    ler = [i for sub in labels for i in sub ]\n",
    "    \n",
    "    _, lab= zip(*ler)\n",
    "\n",
    "    \n",
    "    return lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_step_acc(tes_data, x):\n",
    "\n",
    "    results = []            \n",
    "\n",
    "    x_test = loadImages(tes_data)\n",
    "    y_test = make_labels(tes_data)\n",
    "    \n",
    "    y_test_1 = keras.utils.to_categorical(y_test,num_classes=3)\n",
    "    \n",
    "    #x_test = resize(x_test)\n",
    "    x_test = preprocess_input(x_test)\n",
    "\n",
    "    scores = x.evaluate(x_test, y_test_1, verbose = 1)\n",
    "    results.append(scores[1]*100)\n",
    "    \n",
    "    test_preds = m4.predict(x_test)\n",
    "\n",
    "    preds_df = pd.DataFrame(test_preds)\n",
    "    predicted_labels = preds_df.idxmax(axis=1)\n",
    "    draw_confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_mean_acc(result_cv, string_well):\n",
    "    \n",
    "    l_drug = string_well*3\n",
    "\n",
    "    acc_mean_cv = []\n",
    "\n",
    "    for i in result_cv:\n",
    "        acc_mean_cv.append(np.mean(i))\n",
    "        \n",
    "    cv_drug = list(zip(acc_mean_cv, l_drug))\n",
    "    \n",
    "    res = sorted(cv_drug, key = lambda x: x[1])\n",
    "    a , b = zip(*res)\n",
    "    \n",
    "    a = list(a)\n",
    "    \n",
    "    s = list(np.array_split(a, len(string_well)))\n",
    "    \n",
    "    cv_score_acc = []\n",
    "    \n",
    "    for ix, i in enumerate(s):\n",
    "        s1 = list(s[ix])\n",
    "        \n",
    "        cv_score_acc.append(np.mean(s1))\n",
    "        \n",
    "    return list(zip(cv_score_acc, string_well))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA FOR LSTM PART\n",
    "\n",
    "p_feat = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/'\n",
    "train_data = p_feat + 'features_train/*.npy'\n",
    "val_data = p_feat + 'features_validation/*.npy'\n",
    "tes_data= p_feat + 'features_test/*.npy'\n",
    "\n",
    "y_tra_path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/features_train/'\n",
    "y_tes_path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/features_test/'\n",
    "y_val_path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/features_validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met = ['F10']\n",
    "mid = ['D5']\n",
    "oxy = ['F6']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cycl = ['C4']\n",
    "dime =  ['F7']\n",
    "cypr  = ['G9']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_well_adr = [met,mid,oxy]\n",
    "\n",
    "tot_well_hrh = [cycl, dime, cypr]\n",
    "\n",
    "string_well_adr = ['met', 'mid', 'oxy']\n",
    "\n",
    "string_well_hrh = ['cycl', 'dime', 'cypr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_well = []\n",
    "string_well = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'ADR' # FOR TEST SET\n",
    "b = 'HRH' # FOR REST\n",
    "\n",
    "\n",
    "if a == 'HRH':\n",
    "    tot_well = tot_well_hrh\n",
    "    string_well = string_well_hrh\n",
    "    \n",
    "if a == 'ADR':\n",
    "    tot_well = tot_well_adr\n",
    "    string_well = string_well_adr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_results_accuracy = []\n",
    "\n",
    "results_lstm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_points = list(map(str, range(0,34)))\n",
    "\n",
    "new_time = []\n",
    "for i in time_points:\n",
    "    r = '_' + i + '.'\n",
    "    new_time.append(r)\n",
    "\n",
    "\n",
    "\n",
    "path_test = '/scratch-shared/victor/IMG_A549/{}_tile/'.format(a)\n",
    "\n",
    "# NAME OF THE WELLS CORRESPONDING TO THE DRUG THAT YOU WANT IN THE TEST SET \n",
    "\n",
    "wells_drug = [tot_well[0][0]] \n",
    "\n",
    "test = []\n",
    "\n",
    "for _,_, filenames in os.walk(path_test):\n",
    "\n",
    "    for filename in sorted(filenames, key = natural_keys):\n",
    "\n",
    "        for w in wells_drug:\n",
    "            for t in new_time:\n",
    "                if '{}'.format(w) in filename and '{}tiff'.format(t) in filename:\n",
    "                    test.append(filename)\n",
    "\n",
    "groups_list = ['{}'.format(a), '{}'.format(b)]\n",
    "\n",
    "fileds_of_view = ['1','2','3','4','5']\n",
    "\n",
    "field_train, field_val = train_test_split(fileds_of_view, test_size=0.4, random_state=8)\n",
    "\n",
    "\n",
    "train = []\n",
    "\n",
    "validation = []\n",
    "\n",
    "group_compounds = []\n",
    "\n",
    "all_wells = tot_well_adr + tot_well_hrh\n",
    "all_wells.remove(wells_drug)\n",
    "allw = [j for i in all_wells for j in i]\n",
    "\n",
    "for group in tqdm.tqdm(groups_list):\n",
    "\n",
    "    pa = '/scratch-shared/victor/IMG_A549/{}_tile/'.format(group)\n",
    "\n",
    "    for _,_, filenames in os.walk(pa):\n",
    "\n",
    "        for filename in sorted(filenames, key = natural_keys):\n",
    "\n",
    "            for t in new_time:\n",
    "\n",
    "                for al in allw:\n",
    "\n",
    "                    if '_{}-'.format(al) in filename  and '{}tiff'.format(t) in filename:\n",
    "\n",
    "                        group_compounds.append(filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pp = '/scratch-shared/victor/IMG_A549/DMSO_tile/'\n",
    "\n",
    "dm = []\n",
    "for _,_, filenames in os.walk(pp): \n",
    "\n",
    "    for f in filenames:\n",
    "        dm.append(f)\n",
    "\n",
    "\n",
    "group_compounds = group_compounds + dm\n",
    "\n",
    "for i in group_compounds:\n",
    "\n",
    "    for f in field_train:\n",
    "        if '-{}_'.format(f) in i:\n",
    "            train.append(i)\n",
    "\n",
    "\n",
    "    for v in field_val:\n",
    "        if '-{}_'.format(v) in i:\n",
    "            validation.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_leb = label(train)\n",
    "val_leb = label(validation)\n",
    "test_leb = label(test)\n",
    "train_cnn = Images_path(train)\n",
    "validation_cnn = Images_path(validation)\n",
    "\n",
    "\n",
    "data_train = {'id': train_cnn, 'labels':train_leb}\n",
    "data_val = {'id': validation_cnn, 'labels':val_leb}\n",
    "\n",
    "df_train = pd.DataFrame(data_train, columns = ['id', 'labels'])\n",
    "df_val = pd.DataFrame(data_val, columns = ['id', 'labels'])\n",
    "\n",
    "df_train['labels'] = df_train['labels'].astype(str)\n",
    "df_val['labels'] = df_val['labels'].astype(str)\n",
    "\n",
    "datagen=ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory = None , x_col=\"id\", y_col=\"labels\",color_mode=\"rgb\", \n",
    "                                            class_mode=\"categorical\", target_size=(256, 256), batch_size=256)\n",
    "\n",
    "val_generator=datagen.flow_from_dataframe(dataframe=df_val, directory = None , x_col=\"id\", y_col=\"labels\",color_mode=\"rgb\", \n",
    "                                            class_mode=\"categorical\", target_size=(256, 256), batch_size=256)\n",
    "\n",
    "\n",
    "weights = class_weight.compute_class_weight('balanced', np.unique(train_leb), train_leb)\n",
    "\n",
    "weights = dict(enumerate(weights))\n",
    "\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=1)\n",
    "\n",
    "pretrained_model = VGG16(weights='imagenet',include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "base_model = Model(inputs=pretrained_model.input, outputs=pretrained_model.get_layer('block3_pool').output)\n",
    "\n",
    "print('Model_loaded')\n",
    "\n",
    "m4 = Sequential()\n",
    "m4.add(base_model)\n",
    "\n",
    "\n",
    "m4.add(BatchNormalization())\n",
    "m4.add(GlobalAveragePooling2D())\n",
    "m4.add(Dense(128, activation='relu'))\n",
    "m4.add(BatchNormalization())\n",
    "m4.add(Dense(64, activation='relu'))\n",
    "m4.add(BatchNormalization())\n",
    "m4.add(Activation('relu'))\n",
    "m4.add(Dense(3,activation='softmax'))\n",
    "\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=1e-3)\n",
    "\n",
    "m4.compile(loss= keras.losses.categorical_crossentropy, optimizer=opt, metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
    "\n",
    "m4_h = m4.fit(train_generator, steps_per_epoch = STEP_SIZE_TRAIN, validation_data = val_generator, \n",
    "              validation_steps = STEP_SIZE_VALID , callbacks = [es],\n",
    "              class_weight = weights, epochs=epochs, verbose = 1)\n",
    "\n",
    "\n",
    "#         base_model.trainable = True\n",
    "\n",
    "#         opt = keras.optimizers.Adam(lr=1e-4)\n",
    "\n",
    "#         m4.compile(loss= keras.losses.categorical_crossentropy, optimizer=opt, metrics = ['accuracy'])\n",
    "\n",
    "#         epochs = 300\n",
    "\n",
    "#         m4_h = m4.fit(train_generator, steps_per_epoch = STEP_SIZE_TRAIN, validation_data = val_generator, \n",
    "#                       validation_steps = STEP_SIZE_VALID , callbacks = [es],\n",
    "#                       class_weight = weights, epochs=epochs, verbose = 1)\n",
    "\n",
    "l = []\n",
    "for t in new_time:\n",
    "    for i in test:\n",
    "        if t in i:\n",
    "            l.append((i))\n",
    "\n",
    "\n",
    "grouped = {}\n",
    "for elem in l:\n",
    "    key = elem.split('.tiff')[0].split('_')[5]\n",
    "    grouped.setdefault(key, []).append(elem)\n",
    "grouped = grouped.values()\n",
    "\n",
    "test_data = list(grouped)\n",
    "\n",
    "r = []\n",
    "\n",
    "for ix ,_ in enumerate(test_data):\n",
    "    r.append(time_step_acc(test_data[ix],m4))\n",
    "\n",
    "plt.plot(time_points,r)\n",
    "#plt.savefig('/home/jovyan/IMG_CNN_FINAL/{}_accuracy.png'.format(string_well[index_t_well]))\n",
    "\n",
    "tot_results_accuracy.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(m4.layers):\n",
    "    layer._name = 'layer_' + str(i)\n",
    "\n",
    "\n",
    "\n",
    "lstm_model = Model(inputs=m4.input, outputs=m4.get_layer('layer_6').output)\n",
    "\n",
    "del m4\n",
    "K.clear_session()\n",
    "\n",
    "data_name = [train,test,validation]\n",
    "\n",
    "feat_name = ['train', 'test', 'validation']\n",
    "\n",
    "for index_name, _ in enumerate(data_name):\n",
    "\n",
    "    path =  data_name[index_name]\n",
    "\n",
    "    name_well = []\n",
    "\n",
    "    for i in path:\n",
    "        name_well.append(i.split('_id')[0])\n",
    "\n",
    "    wells = list(set(name_well))\n",
    "    wells\n",
    "\n",
    "    for w in wells:\n",
    "\n",
    "        time = []\n",
    "\n",
    "\n",
    "        for filename in sorted(path, key = natural_keys):\n",
    "            if w in filename: #PAY ATTENTION ID THE IMAGE IS A TIFF OR PNG IMAGE #########\n",
    "                time.append(filename)\n",
    "\n",
    "        data_id = {}\n",
    "        n_id = []\n",
    "        w_n = []\n",
    "\n",
    "        for i in time:\n",
    "            t = i.split('_id_')[1].split('time_')[0]\n",
    "            f = i.split('_id_')[0].split('time_')[0]\n",
    "            n_id.append(t)\n",
    "            w_n.append(f)\n",
    "\n",
    "        id_cell = set(n_id)\n",
    "\n",
    "\n",
    "        for ix, i in enumerate(sorted(id_cell, key = natural_keys)):\n",
    "\n",
    "            id_name = []\n",
    "            dict_1 = {}\n",
    "\n",
    "            for t in time:\n",
    "                if 'id_{}'.format(i) in t:\n",
    "                    id_name.append(t)\n",
    "\n",
    "            d = {'id':id_name}\n",
    "            data = pd.DataFrame(d)\n",
    "\n",
    "            dict_1[ix]=data \n",
    "            data_id.update(dict_1) \n",
    "\n",
    "\n",
    "        len_id = [i for i, j in data_id.items()]\n",
    "\n",
    "        for le in len_id:    \n",
    "\n",
    "\n",
    "            e = pd.DataFrame(data_id[le])\n",
    "\n",
    "            coords = e.values.tolist()\n",
    "            id_cells = []\n",
    "            for i in coords:\n",
    "                for j in i:\n",
    "                    id_cells.append(j)\n",
    "            \n",
    "            print(len(id_cells))\n",
    "\n",
    "            x_orig = loadImages(id_cells)\n",
    "\n",
    "            x_orig = preprocess_input(x_orig)\n",
    "            output = lstm_model.predict(x_orig)\n",
    "            np.save('/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/features_{}/features_well_{}_id_{}.npy'.format(feat_name[index_name],w_n[0], le), output)\n",
    "    print('Saved_feature_{}'.format(feat_name[index_name]))\n",
    "\n",
    "\n",
    "x_train_lstm = loadImages_LSTM(train_data, len(time_points))\n",
    "y_train_lstm = make_labels_LSTM(y_tra_path)\n",
    "\n",
    "x_test_lstm = loadImages_LSTM(tes_data, len(time_points))\n",
    "y_test_lstm = make_labels_LSTM(y_tes_path)\n",
    "\n",
    "x_val_lstm = loadImages_LSTM(val_data, len(time_points))\n",
    "y_val_lstm = make_labels_LSTM(y_val_path)\n",
    "\n",
    "weights_lstm = class_weight.compute_class_weight('balanced', np.unique(y_train_lstm),y_train_lstm)\n",
    "\n",
    "weights_lstm = dict(enumerate(weights_lstm))\n",
    "\n",
    "y_train_lstm = keras.utils.to_categorical(y_train_lstm, num_classes = 3)\n",
    "y_test_1_lstm = keras.utils.to_categorical(y_test_lstm, num_classes= 3)\n",
    "y_val_lstm = keras.utils.to_categorical(y_val_lstm, num_classes = 3)\n",
    "\n",
    "\n",
    "m = Sequential()\n",
    "m.add(LSTM(32, input_shape = (x_train_lstm.shape[1],x_train_lstm.shape[2])))\n",
    "m.add(Dropout(0.2))\n",
    "m.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "opt_lstm = keras.optimizers.Adam(lr=1e-4)\n",
    "\n",
    "m.compile(loss= keras.losses.categorical_crossentropy, optimizer=opt, metrics = ['accuracy'])\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "m_h = m.fit(x_train_lstm,y_train_lstm,\n",
    "\n",
    "                 callbacks = [es],\n",
    "\n",
    "                epochs=epochs,\n",
    "                validation_data = (x_val_lstm,y_val_lstm), \n",
    "\n",
    "                class_weight = weights_lstm)\n",
    "\n",
    "\n",
    "scores_lstm = m.evaluate(x_test_lstm, y_test_1_lstm)\n",
    "results_lstm.append([scores_lstm[1]*100, string_well[index_t_well]])\n",
    "\n",
    "del m\n",
    "K.clear_session()\n",
    "\n",
    "# DELITE FILES IN FEATURE VECTOR FOLDERS\n",
    "\n",
    "folders = glob.glob('/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/*')\n",
    "\n",
    "for fo in folders:\n",
    "    file = glob.glob(f'{fo}/*')\n",
    "    for f in file:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ACCURACY SCORE AVERAGE FOR CNN\n",
    "cv_s = cv_mean_acc(tot_results_accuracy, string_well)\n",
    "cv_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_s_mean,_ = zip(*cv_s)\n",
    "\n",
    "m_cv = np.mean(list(cv_s_mean))\n",
    "m_cv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT OF MEAN ACCURACY FOR EVERY TIME POINT CNN\n",
    "\n",
    "l_drug = string_well*3\n",
    "\n",
    "acc_plot = []\n",
    "\n",
    "for i in tot_results_accuracy:\n",
    "    acc_plot.append(i)\n",
    "\n",
    "cv_plot = list(zip(acc_plot, l_drug))\n",
    "\n",
    "res_plot = sorted(cv_plot, key = lambda x: x[1])\n",
    "\n",
    "a , b = zip(*res_plot)\n",
    "    \n",
    "a = list(a)\n",
    "\n",
    "s = list(np.array_split(a, len(string_well)))\n",
    "\n",
    "cv_plot = []\n",
    "\n",
    "for ix, i in enumerate(s):\n",
    "    s1 = list(s[ix])\n",
    "    \n",
    "    cv_plot.append(np.average(s1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i in cv_plot:\n",
    "    \n",
    "    plt.plot(time_points, i)\n",
    "    plt.show\n",
    "    plt.savefig('/home/jovyan/cv_score.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lstm = sorted(results_lstm, key=lambda x: x[1])\n",
    "r_lstm , _ = zip(*results_lstm)\n",
    "    \n",
    "r_lstm = list(r_lstm)\n",
    "\n",
    "re_lstm = list(np.array_split(r_lstm, len(string_well)))\n",
    "\n",
    "cv_lstm = []\n",
    "\n",
    "for ix, i in enumerate(re_lstm):\n",
    "    r1 = list(re_lstm[ix])\n",
    "    cv_lstm.append(np.mean(r1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_lstm = list(zip(cv_lstm, string_well))\n",
    "cv_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_l_mean,_ = zip(*cv_lstm)\n",
    "\n",
    "m_cv_l = np.mean(list(cv_l_mean))\n",
    "m_cv_l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE RUNNING AGAIN\n",
    "\n",
    "folders = glob.glob('/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/*')\n",
    "\n",
    "for fo in folders:\n",
    "    file = glob.glob(f'{fo}/*')\n",
    "    for f in file:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_l_mean,_ = zip(*cv_lstm)\n",
    "\n",
    "m_cv_l = np.mean(list(cv_l_mean))\n",
    "m_cv_l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_cv_l =  np.std(list(cv_l_mean))\n",
    "sd_cv_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = np.mean(cv_plot, axis = 0)\n",
    "me = me.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = np.std(cv_plot, axis = 0)\n",
    "sd = sd.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('ytick', labelsize=18)\n",
    "ax = plt.figure(figsize=(13,8), facecolor='w').gca()\n",
    "ax.plot(me)\n",
    "ax.fill_between(time_points, me - sd, me + sd, alpha = 0.5)\n",
    "\n",
    "plt.errorbar(31.5, m_cv_l, sd_cv_l, linestyle='None', marker='^', markersize=12)\n",
    "\n",
    "plt.savefig('/home/jovyan/md_sd_score.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_stat = [i for i in cv_s_mean]\n",
    "lstm_stat = [i for i in cv_l_mean]\n",
    "\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "stat, p = wilcoxon(cnn_stat, lstm_stat)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
