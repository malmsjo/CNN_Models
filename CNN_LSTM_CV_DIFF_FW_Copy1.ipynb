{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten, LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "import tqdm\n",
    "from numpy import loadtxt\n",
    "from os import *\n",
    "from sklearn.utils import class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(true,preds):\n",
    "    conf_matx = confusion_matrix(true, preds)\n",
    "    sns.heatmap(conf_matx, annot=True,annot_kws={\"size\": 12},fmt='g', cbar=False, cmap=plt.cm.Blues) #'viridis'\n",
    "    #plt.savefig('/home/jovyan/conf_matrix.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return conf_matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(model_history, model_name):\n",
    "    fig = plt.figure(figsize=(15,5), facecolor='w')\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.plot(model_history.history['loss'])\n",
    "    ax.plot(model_history.history['val_loss'])\n",
    "    ax.set(title=model_name + ': Model loss', ylabel='Loss', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Val'], loc='upper left')\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.plot(model_history.history['accuracy'])\n",
    "    ax.plot(model_history.history['val_accuracy'])\n",
    "    ax.set(title=model_name + ': Model Accuracy; test='+ str(np.round(model_history.history['val_accuracy'][-1], 3)),\n",
    "           ylabel='Accuracy', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Val'], loc='upper left')\n",
    "    #plt.savefig('/home/jovyan/curve.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(x):\n",
    "    rescaled = []\n",
    "\n",
    "    for i in x:\n",
    "\n",
    "        scale_percent = 140 # percent of original size\n",
    "        width = int(i.shape[1] / (scale_percent / 100))\n",
    "        height = int(i.shape[0] / (scale_percent / 100))\n",
    "        dim = (width, height)\n",
    "        resized = cv2.resize(i, dim, interpolation = cv2.INTER_LANCZOS4)\n",
    "        rescaled.append(resized)\n",
    "\n",
    "    x_orig = np.reshape( rescaled, (len( rescaled), resized.shape[1], resized.shape[1], 3))\n",
    "\n",
    "    return x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(path_data):\n",
    "    \n",
    "    p = '/home/jovyan/DATA_MASTER_PROJECT/IMG_A549_high_con/'\n",
    "    \n",
    "    \n",
    "    \n",
    "    pa_adr = p + 'ADR_cropped/'\n",
    "    \n",
    "    pa_control = p + 'CONTROL_cropped/'\n",
    "    \n",
    "    pa_hrh = p + 'HRH_cropped/'\n",
    "    \n",
    "    pa_dmso = p + 'DMSO_cropped/'\n",
    "    \n",
    "    image_list = []\n",
    "    \n",
    "    \n",
    "       \n",
    "\n",
    "\n",
    "    for filename in sorted(path_data, key=natural_keys): \n",
    "        \n",
    "        if 'adr' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_adr + filename)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "            \n",
    "\n",
    "            image_list.append(imarray)\n",
    "            \n",
    "        if 'control' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_control + filename)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "            \n",
    "\n",
    "            image_list.append(imarray)\n",
    "            \n",
    "        if 'hrh' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_hrh + filename)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "            \n",
    "\n",
    "            image_list.append(imarray)\n",
    "            \n",
    "        if 'dmso' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_dmso + filename)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "            \n",
    "\n",
    "            image_list.append(imarray)\n",
    "\n",
    "\n",
    "\n",
    "    x_orig = np.reshape(image_list, (len(image_list), 90, 90, 3))\n",
    "\n",
    "    return x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_count(x):\n",
    "    name_wel = []\n",
    "    for i in sorted(x, key = natural_keys):\n",
    "        name_wel.append(i.split('_')[0])\n",
    "\n",
    "    z = sorted(list(set(name_wel)))\n",
    "    r = list(range(len(z)))\n",
    "\n",
    "    num = []\n",
    "    for iz in range(len(z)):\n",
    "        count = 0\n",
    "        for i in sorted(x, key=natural_keys):\n",
    "            if z[iz] in i:\n",
    "                count += 1\n",
    "        num.append(count)\n",
    "    return list(zip(z, r, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages_LSTM(path_data,len_t_points):\n",
    "    \n",
    "\n",
    "    feat_list = []\n",
    "\n",
    "\n",
    "    for filename in sorted(glob.glob(path_data), key=natural_keys): \n",
    "        feat_list.append(np.load(filename))\n",
    "\n",
    "    x_orig = np.reshape(feat_list, (len(feat_list),len_t_points, 64))\n",
    "\n",
    "    return x_orig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(data_set):\n",
    "    fe = return_count(data_set)\n",
    "    leb = creat_label(fe)\n",
    "    y = np.array(list(leb))\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels_LSTM(data_set):\n",
    "    fe = return_count_LSTM(data_set)\n",
    "    leb = creat_label(fe)\n",
    "    y = np.array(list(leb))\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_count_LSTM(x):\n",
    "    name_wel = []\n",
    "    for _,_,i in os.walk(x):\n",
    "        for f in i:\n",
    "            name_wel.append(f.split('_')[2])\n",
    "\n",
    "    z = sorted(list(set(name_wel)), key=natural_keys)\n",
    "    r = list(range(len(z)))\n",
    "\n",
    "    num = []\n",
    "    for iz in range(len(z)):\n",
    "        count = 0\n",
    "        for i in sorted(name_wel, key=natural_keys):\n",
    "            if z[iz] in i:\n",
    "                count += 1\n",
    "        num.append(count)\n",
    "    return list(zip(z, r, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_label(y):\n",
    "    labels = []\n",
    "    for ix, _ in enumerate(y):\n",
    "        \n",
    "        if y[ix][0] == 'adr':\n",
    "        \n",
    "            labels.append([[y[ix][0],0]] * y[ix][2])\n",
    "        \n",
    "        if y[ix][0] == 'hrh':\n",
    "            \n",
    "            labels.append([[y[ix][0],1]] * y[ix][2])\n",
    "        \n",
    "        if y[ix][0] == 'control':\n",
    "            \n",
    "            labels.append([[y[ix][0],1]] * y[ix][2])\n",
    "            \n",
    "        if y[ix][0] == 'dmso':\n",
    "            \n",
    "            labels.append([[y[ix][0],1]] * y[ix][2])\n",
    "    \n",
    "    ler = [i for sub in labels for i in sub ]\n",
    "    \n",
    "    _, lab= zip(*ler)\n",
    "\n",
    "    \n",
    "    return lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_step_acc(tes_data, x):\n",
    "\n",
    "    results = []            \n",
    "\n",
    "    x_test = loadImages(tes_data)\n",
    "    y_test = make_labels(tes_data)\n",
    "    x_test = resize(x_test)\n",
    "    x_test = preprocess_input(x_test)\n",
    "\n",
    "    scores = x.evaluate(x_test, y_test, verbose = 1)\n",
    "    results.append(scores[1]*100)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_mean_acc(result_cv, string_well):\n",
    "    \n",
    "    l_drug = string_well*3\n",
    "\n",
    "    acc_mean_cv = []\n",
    "\n",
    "    for i in result_cv:\n",
    "        acc_mean_cv.append(np.mean(i))\n",
    "        \n",
    "    cv_drug = list(zip(acc_mean_cv, l_drug))\n",
    "    \n",
    "    res = sorted(cv_drug, key = lambda x: x[1])\n",
    "    a , b = zip(*res)\n",
    "    \n",
    "    a = list(a)\n",
    "    \n",
    "    s = list(np.array_split(a, len(string_well)))\n",
    "    \n",
    "    cv_score_acc = []\n",
    "    \n",
    "    for ix, i in enumerate(s):\n",
    "        s1 = list(s[ix])\n",
    "        \n",
    "        cv_score_acc.append(np.mean(s1))\n",
    "        \n",
    "    return list(zip(cv_score_acc, string_well))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA FOR LSTM PART\n",
    "\n",
    "p_feat = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/'\n",
    "train_data = p_feat + 'features_train/*.npy'\n",
    "val_data = p_feat + 'features_validation/*.npy'\n",
    "tes_data= p_feat + 'features_test/*.npy'\n",
    "\n",
    "y_tra_path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/features_train/'\n",
    "y_tes_path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/features_test/'\n",
    "y_val_path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/features_validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "met = ['F10']\n",
    "mid = ['D5']\n",
    "oxy = ['F6']\n",
    "nap = ['B3']\n",
    "dip = ['F2']\n",
    "met_1 = ['B7']\n",
    "lab = ['D10']\n",
    "car = ['G2']\n",
    "mep = ['B11']\n",
    "nef = ['C10']\n",
    "tri = ['B2']\n",
    "dox = ['F8']\n",
    "\n",
    "\n",
    "cycl = ['C4']\n",
    "dime =  ['F7']\n",
    "cypr  = ['G9']\n",
    "lora = [ 'E5']\n",
    "doxy = ['D4']\n",
    "oloa = ['E2']\n",
    "hydr = ['F5']\n",
    "orph = ['E7']\n",
    "cinn = ['B10']\n",
    "desl = ['F3']\n",
    "chlo =  ['D2']\n",
    "trim = ['E9']\n",
    "mian= ['E8']\n",
    "fexo= ['B5']\n",
    "chlo_1 = ['E3']\n",
    "trip= ['C5']\n",
    "desi= ['E4']\n",
    "levo= ['C3']\n",
    "diphe_1= ['C7']\n",
    "diphe_2= ['F11']\n",
    "emed= ['G6']\n",
    "ceti= ['D11']\n",
    "trip_1= ['F9']\n",
    "doxe=['C2']\n",
    "chlo_2= ['D6']\n",
    "flun = ['C9']\n",
    "keto= ['D7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_results_accuracy = []\n",
    "\n",
    "results_lstm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_well_adr = [met,mid,oxy,nap,dip,met_1,lab,car,mep,nef,tri,dox]\n",
    "tot_well_hrh = [cycl, dime, cypr,lora,doxy,oloa,cinn,desl,chlo,trim,mian,fexo,chlo_1,trip,desi,levo,\n",
    "                \n",
    "                diphe_1,diphe_2,emed,ceti,trip_1,doxe,chlo_2,flun,keto]\n",
    "\n",
    "string_well_adr = ['met', 'mid', 'oxy', 'nap', 'dip','met_1','lab','car','mep','nef','tri','dox']\n",
    "string_well_hrh = ['cycl', 'dime', 'cypr', 'lora', 'doxy','oloa','cinn','desl','chlo','trim','mian','fexo','chlo_1','trip','desi',\n",
    "                  'levo','diphe_1','diphe_2','emed','ceti','trip_1','doxe','chlo_2','flun','keto']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_well = []\n",
    "string_well = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'HRH' # FOR TEST SET\n",
    "b = 'ADR' # FOR REST\n",
    "\n",
    "if a == 'HRH':\n",
    "    tot_well = tot_well_hrh\n",
    "    string_well = string_well_hrh\n",
    "    \n",
    "if a == 'ADR':\n",
    "    tot_well = tot_well_adr\n",
    "    string_well = string_well_adr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = list(np.random.randint(1,1000,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.65s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.60s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 240.337890625 steps, validate for 54.2109375 steps\n",
      "Epoch 1/300\n",
      "241/240 [==============================] - 29s 119ms/step - loss: 0.6391 - accuracy: 0.6514 - val_loss: 0.6606 - val_accuracy: 0.6646\n",
      "Epoch 2/300\n",
      "241/240 [==============================] - 24s 100ms/step - loss: 0.5661 - accuracy: 0.7082 - val_loss: 0.6554 - val_accuracy: 0.6471\n",
      "Epoch 3/300\n",
      "241/240 [==============================] - 25s 102ms/step - loss: 0.5443 - accuracy: 0.7240 - val_loss: 0.6770 - val_accuracy: 0.6290\n",
      "Epoch 4/300\n",
      "241/240 [==============================] - 24s 99ms/step - loss: 0.5247 - accuracy: 0.7369 - val_loss: 0.7018 - val_accuracy: 0.6231\n",
      "Epoch 5/300\n",
      "241/240 [==============================] - 24s 98ms/step - loss: 0.5082 - accuracy: 0.7489 - val_loss: 0.7054 - val_accuracy: 0.6172\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 240.337890625 steps, validate for 54.2109375 steps\n",
      "Epoch 1/300\n",
      "241/240 [==============================] - 63s 261ms/step - loss: 0.4886 - accuracy: 0.7611 - val_loss: 0.8846 - val_accuracy: 0.6567\n",
      "Epoch 2/300\n",
      "241/240 [==============================] - 59s 245ms/step - loss: 0.4338 - accuracy: 0.7989 - val_loss: 0.8076 - val_accuracy: 0.6229\n",
      "Epoch 3/300\n",
      "241/240 [==============================] - 59s 243ms/step - loss: 0.3919 - accuracy: 0.8250 - val_loss: 0.8561 - val_accuracy: 0.6336\n",
      "Epoch 4/300\n",
      "241/240 [==============================] - 59s 243ms/step - loss: 0.3511 - accuracy: 0.8488 - val_loss: 1.0436 - val_accuracy: 0.6613\n",
      "Epoch 5/300\n",
      "241/240 [==============================] - 59s 245ms/step - loss: 0.3173 - accuracy: 0.8678 - val_loss: 0.8524 - val_accuracy: 0.5949\n",
      "Epoch 00005: early stopping\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7046 - accuracy: 0.6980\n",
      "196/196 [==============================] - 0s 593us/sample - loss: 0.6867 - accuracy: 0.6837\n",
      "193/193 [==============================] - 0s 541us/sample - loss: 0.7666 - accuracy: 0.6425\n",
      "190/190 [==============================] - 0s 815us/sample - loss: 0.7659 - accuracy: 0.6632\n",
      "190/190 [==============================] - 0s 240us/sample - loss: 0.7080 - accuracy: 0.6789\n",
      "187/187 [==============================] - 0s 774us/sample - loss: 0.6943 - accuracy: 0.6364\n",
      "184/184 [==============================] - 0s 754us/sample - loss: 0.6052 - accuracy: 0.7174\n",
      "183/183 [==============================] - 0s 759us/sample - loss: 0.6702 - accuracy: 0.6831\n",
      "182/182 [==============================] - 0s 772us/sample - loss: 0.6919 - accuracy: 0.6484\n",
      "181/181 [==============================] - 0s 799us/sample - loss: 0.7297 - accuracy: 0.6685\n",
      "177/177 [==============================] - 0s 778us/sample - loss: 0.7810 - accuracy: 0.6497\n",
      "178/178 [==============================] - 0s 766us/sample - loss: 0.7226 - accuracy: 0.6742\n",
      "178/178 [==============================] - 0s 242us/sample - loss: 0.7441 - accuracy: 0.6742\n",
      "176/176 [==============================] - 0s 725us/sample - loss: 0.7633 - accuracy: 0.6364\n",
      "175/175 [==============================] - 0s 714us/sample - loss: 0.7096 - accuracy: 0.6629\n",
      "176/176 [==============================] - 0s 244us/sample - loss: 0.7422 - accuracy: 0.6193\n",
      "173/173 [==============================] - 0s 709us/sample - loss: 0.7525 - accuracy: 0.6416\n",
      "172/172 [==============================] - 0s 700us/sample - loss: 0.7808 - accuracy: 0.6453\n",
      "171/171 [==============================] - 0s 712us/sample - loss: 0.7143 - accuracy: 0.6667\n",
      "171/171 [==============================] - 0s 222us/sample - loss: 0.7792 - accuracy: 0.6784\n",
      "171/171 [==============================] - 0s 257us/sample - loss: 0.7494 - accuracy: 0.6667\n",
      "170/170 [==============================] - 0s 225us/sample - loss: 0.8228 - accuracy: 0.6588\n",
      "171/171 [==============================] - 0s 232us/sample - loss: 0.6340 - accuracy: 0.7427\n",
      "170/170 [==============================] - 0s 282us/sample - loss: 0.7017 - accuracy: 0.6706\n",
      "170/170 [==============================] - 0s 271us/sample - loss: 0.7217 - accuracy: 0.6471\n",
      "171/171 [==============================] - 0s 215us/sample - loss: 0.6946 - accuracy: 0.6608\n",
      "168/168 [==============================] - 0s 636us/sample - loss: 0.6314 - accuracy: 0.6964\n",
      "169/169 [==============================] - 0s 766us/sample - loss: 0.7667 - accuracy: 0.6686\n",
      "169/169 [==============================] - 0s 248us/sample - loss: 0.7087 - accuracy: 0.6805\n",
      "167/167 [==============================] - 0s 662us/sample - loss: 0.8282 - accuracy: 0.6407\n",
      "168/168 [==============================] - 0s 253us/sample - loss: 0.8375 - accuracy: 0.6369\n",
      "169/169 [==============================] - 0s 239us/sample - loss: 0.8510 - accuracy: 0.6272\n",
      "166/166 [==============================] - 0s 663us/sample - loss: 0.8508 - accuracy: 0.6084\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 3265 samples, validate on 736 samples\n",
      "Epoch 1/300\n",
      "3265/3265 [==============================] - 3s 854us/sample - loss: 0.5650 - accuracy: 0.7124 - val_loss: 0.6527 - val_accuracy: 0.6413\n",
      "Epoch 2/300\n",
      "3265/3265 [==============================] - 1s 243us/sample - loss: 0.4347 - accuracy: 0.8077 - val_loss: 0.6988 - val_accuracy: 0.6318\n",
      "Epoch 3/300\n",
      "3265/3265 [==============================] - 1s 224us/sample - loss: 0.3306 - accuracy: 0.8747 - val_loss: 0.7861 - val_accuracy: 0.6223\n",
      "Epoch 4/300\n",
      "3265/3265 [==============================] - 1s 222us/sample - loss: 0.2480 - accuracy: 0.9164 - val_loss: 0.8914 - val_accuracy: 0.6291\n",
      "Epoch 00004: early stopping\n",
      "159/159 [==============================] - 0s 3ms/sample - loss: 0.2724 - accuracy: 0.8616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [19:36, 1176.70s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.40s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.59s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 241.609375 steps, validate for 54.607421875 steps\n",
      "Epoch 1/300\n",
      "242/241 [==============================] - 25s 105ms/step - loss: 0.5991 - accuracy: 0.6835 - val_loss: 0.6391 - val_accuracy: 0.6654\n",
      "Epoch 2/300\n",
      "242/241 [==============================] - 24s 98ms/step - loss: 0.5585 - accuracy: 0.7151 - val_loss: 0.6581 - val_accuracy: 0.6513\n",
      "Epoch 3/300\n",
      "242/241 [==============================] - 23s 97ms/step - loss: 0.5358 - accuracy: 0.7291 - val_loss: 0.6871 - val_accuracy: 0.6290\n",
      "Epoch 4/300\n",
      "242/241 [==============================] - 23s 96ms/step - loss: 0.5171 - accuracy: 0.7419 - val_loss: 0.6944 - val_accuracy: 0.6292\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 241.609375 steps, validate for 54.607421875 steps\n",
      "Epoch 1/300\n",
      "242/241 [==============================] - 60s 247ms/step - loss: 0.4937 - accuracy: 0.7585 - val_loss: 1.1717 - val_accuracy: 0.5103\n",
      "Epoch 2/300\n",
      "242/241 [==============================] - 58s 239ms/step - loss: 0.4372 - accuracy: 0.7964 - val_loss: 0.9613 - val_accuracy: 0.5312\n",
      "Epoch 3/300\n",
      "242/241 [==============================] - 58s 241ms/step - loss: 0.3904 - accuracy: 0.8259 - val_loss: 0.8765 - val_accuracy: 0.5398\n",
      "Epoch 4/300\n",
      "242/241 [==============================] - 58s 238ms/step - loss: 0.3497 - accuracy: 0.8508 - val_loss: 0.8589 - val_accuracy: 0.5667\n",
      "Epoch 5/300\n",
      "242/241 [==============================] - 57s 237ms/step - loss: 0.3105 - accuracy: 0.8710 - val_loss: 0.8687 - val_accuracy: 0.5786\n",
      "Epoch 6/300\n",
      "242/241 [==============================] - 57s 238ms/step - loss: 0.2726 - accuracy: 0.8923 - val_loss: 0.8769 - val_accuracy: 0.6191\n",
      "Epoch 7/300\n",
      "242/241 [==============================] - 58s 238ms/step - loss: 0.2381 - accuracy: 0.9107 - val_loss: 0.9329 - val_accuracy: 0.6207\n",
      "Epoch 00007: early stopping\n",
      "167/167 [==============================] - 0s 1ms/sample - loss: 0.5457 - accuracy: 0.7365\n",
      "164/164 [==============================] - 0s 245us/sample - loss: 0.5693 - accuracy: 0.7378\n",
      "162/162 [==============================] - 0s 635us/sample - loss: 0.5374 - accuracy: 0.7654\n",
      "162/162 [==============================] - 0s 236us/sample - loss: 0.6149 - accuracy: 0.7407\n",
      "162/162 [==============================] - 0s 222us/sample - loss: 0.5132 - accuracy: 0.7716\n",
      "161/161 [==============================] - 0s 263us/sample - loss: 0.5574 - accuracy: 0.7888\n",
      "162/162 [==============================] - 0s 251us/sample - loss: 0.5198 - accuracy: 0.7716\n",
      "162/162 [==============================] - 0s 228us/sample - loss: 0.5417 - accuracy: 0.7469\n",
      "157/157 [==============================] - 0s 950us/sample - loss: 0.4703 - accuracy: 0.8153\n",
      "158/158 [==============================] - 0s 258us/sample - loss: 0.4631 - accuracy: 0.7848\n",
      "157/157 [==============================] - 0s 241us/sample - loss: 0.5225 - accuracy: 0.7643\n",
      "157/157 [==============================] - 0s 217us/sample - loss: 0.4889 - accuracy: 0.7452\n",
      "157/157 [==============================] - 0s 237us/sample - loss: 0.5161 - accuracy: 0.7707\n",
      "155/155 [==============================] - 0s 233us/sample - loss: 0.4812 - accuracy: 0.7742\n",
      "152/152 [==============================] - 0s 228us/sample - loss: 0.4057 - accuracy: 0.8092\n",
      "153/153 [==============================] - 0s 882us/sample - loss: 0.5403 - accuracy: 0.7712\n",
      "150/150 [==============================] - 0s 267us/sample - loss: 0.4150 - accuracy: 0.8200\n",
      "149/149 [==============================] - 0s 241us/sample - loss: 0.4871 - accuracy: 0.7852\n",
      "147/147 [==============================] - 0s 861us/sample - loss: 0.5453 - accuracy: 0.7279\n",
      "147/147 [==============================] - 0s 246us/sample - loss: 0.4609 - accuracy: 0.7755\n",
      "146/146 [==============================] - 0s 245us/sample - loss: 0.4859 - accuracy: 0.7671\n",
      "145/145 [==============================] - 0s 232us/sample - loss: 0.5324 - accuracy: 0.7517\n",
      "145/145 [==============================] - 0s 238us/sample - loss: 0.5148 - accuracy: 0.7655\n",
      "144/144 [==============================] - 0s 244us/sample - loss: 0.5272 - accuracy: 0.7639\n",
      "141/141 [==============================] - 0s 251us/sample - loss: 0.5391 - accuracy: 0.7447\n",
      "140/140 [==============================] - 0s 244us/sample - loss: 0.5030 - accuracy: 0.7857\n",
      "140/140 [==============================] - 0s 234us/sample - loss: 0.5562 - accuracy: 0.7714\n",
      "140/140 [==============================] - 0s 447us/sample - loss: 0.5416 - accuracy: 0.7786\n",
      "140/140 [==============================] - 0s 266us/sample - loss: 0.5668 - accuracy: 0.7357\n",
      "140/140 [==============================] - 0s 248us/sample - loss: 0.5720 - accuracy: 0.7643\n",
      "141/141 [==============================] - 0s 263us/sample - loss: 0.5004 - accuracy: 0.7660\n",
      "139/139 [==============================] - 0s 242us/sample - loss: 0.5521 - accuracy: 0.7554\n",
      "138/138 [==============================] - 0s 255us/sample - loss: 0.5422 - accuracy: 0.7391\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 3284 samples, validate on 742 samples\n",
      "Epoch 1/300\n",
      "3284/3284 [==============================] - 2s 761us/sample - loss: 0.4582 - accuracy: 0.8021 - val_loss: 0.7353 - val_accuracy: 0.6415\n",
      "Epoch 2/300\n",
      "3284/3284 [==============================] - 1s 203us/sample - loss: 0.2266 - accuracy: 0.9385 - val_loss: 0.8959 - val_accuracy: 0.6240\n",
      "Epoch 3/300\n",
      "3284/3284 [==============================] - 1s 220us/sample - loss: 0.1143 - accuracy: 0.9793 - val_loss: 1.0735 - val_accuracy: 0.5970\n",
      "Epoch 4/300\n",
      "3284/3284 [==============================] - 1s 218us/sample - loss: 0.0702 - accuracy: 0.9881 - val_loss: 1.2080 - val_accuracy: 0.5984\n",
      "Epoch 00004: early stopping\n",
      "134/134 [==============================] - 0s 137us/sample - loss: 0.6898 - accuracy: 0.7015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [40:32, 1200.38s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.61s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.72s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 245.265625 steps, validate for 55.02734375 steps\n",
      "Epoch 1/300\n",
      "246/245 [==============================] - 25s 101ms/step - loss: 0.6031 - accuracy: 0.6800 - val_loss: 0.6500 - val_accuracy: 0.6631\n",
      "Epoch 2/300\n",
      "246/245 [==============================] - 24s 96ms/step - loss: 0.5597 - accuracy: 0.7136 - val_loss: 0.6589 - val_accuracy: 0.6492\n",
      "Epoch 3/300\n",
      "246/245 [==============================] - 23s 95ms/step - loss: 0.5376 - accuracy: 0.7290 - val_loss: 0.6880 - val_accuracy: 0.6467\n",
      "Epoch 4/300\n",
      "246/245 [==============================] - 24s 98ms/step - loss: 0.5199 - accuracy: 0.7423 - val_loss: 0.7062 - val_accuracy: 0.6323\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 245.265625 steps, validate for 55.02734375 steps\n",
      "Epoch 1/300\n",
      "246/245 [==============================] - 61s 247ms/step - loss: 0.4963 - accuracy: 0.7572 - val_loss: 0.7881 - val_accuracy: 0.5963\n",
      "Epoch 2/300\n",
      "246/245 [==============================] - 58s 236ms/step - loss: 0.4387 - accuracy: 0.7954 - val_loss: 0.7850 - val_accuracy: 0.6450\n",
      "Epoch 3/300\n",
      "246/245 [==============================] - 58s 238ms/step - loss: 0.3919 - accuracy: 0.8237 - val_loss: 0.8286 - val_accuracy: 0.5726\n",
      "Epoch 4/300\n",
      "246/245 [==============================] - 60s 243ms/step - loss: 0.3499 - accuracy: 0.8490 - val_loss: 0.8594 - val_accuracy: 0.6562\n",
      "Epoch 5/300\n",
      "246/245 [==============================] - 59s 241ms/step - loss: 0.3109 - accuracy: 0.8700 - val_loss: 0.8848 - val_accuracy: 0.6020\n",
      "Epoch 00005: early stopping\n",
      "106/106 [==============================] - 0s 2ms/sample - loss: 0.7270 - accuracy: 0.6415\n",
      "107/107 [==============================] - 0s 249us/sample - loss: 0.7061 - accuracy: 0.6262\n",
      "106/106 [==============================] - 0s 256us/sample - loss: 0.6437 - accuracy: 0.6981\n",
      "104/104 [==============================] - 0s 257us/sample - loss: 0.6660 - accuracy: 0.6346\n",
      "103/103 [==============================] - 0s 379us/sample - loss: 0.7045 - accuracy: 0.6117\n",
      "102/102 [==============================] - 0s 244us/sample - loss: 0.8313 - accuracy: 0.6176\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.8509 - accuracy: 0.6300\n",
      "99/99 [==============================] - 0s 1ms/sample - loss: 0.7503 - accuracy: 0.5758\n",
      "97/97 [==============================] - 0s 257us/sample - loss: 0.8763 - accuracy: 0.5670\n",
      "98/98 [==============================] - 0s 444us/sample - loss: 0.9227 - accuracy: 0.5816\n",
      "98/98 [==============================] - 0s 252us/sample - loss: 0.8742 - accuracy: 0.6122\n",
      "92/92 [==============================] - 0s 1ms/sample - loss: 1.0092 - accuracy: 0.5435\n",
      "95/95 [==============================] - 0s 1ms/sample - loss: 0.9548 - accuracy: 0.5684\n",
      "94/94 [==============================] - 0s 244us/sample - loss: 1.0209 - accuracy: 0.4681\n",
      "90/90 [==============================] - 0s 1ms/sample - loss: 0.9852 - accuracy: 0.5333\n",
      "91/91 [==============================] - 0s 226us/sample - loss: 1.0294 - accuracy: 0.5275\n",
      "87/87 [==============================] - 0s 258us/sample - loss: 0.9136 - accuracy: 0.5862\n",
      "87/87 [==============================] - 0s 272us/sample - loss: 0.9999 - accuracy: 0.5632\n",
      "87/87 [==============================] - 0s 277us/sample - loss: 1.0788 - accuracy: 0.5402\n",
      "77/77 [==============================] - 0s 293us/sample - loss: 0.8240 - accuracy: 0.6234\n",
      "77/77 [==============================] - 0s 307us/sample - loss: 1.0226 - accuracy: 0.4675\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 1.0616 - accuracy: 0.5067\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 0.9901 - accuracy: 0.5600\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 1.1212 - accuracy: 0.4533\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 1.0944 - accuracy: 0.5467\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 1.0349 - accuracy: 0.5467\n",
      "75/75 [==============================] - 0s 258us/sample - loss: 1.1076 - accuracy: 0.5333\n",
      "75/75 [==============================] - 0s 251us/sample - loss: 1.1057 - accuracy: 0.5867\n",
      "74/74 [==============================] - 0s 335us/sample - loss: 0.9839 - accuracy: 0.5811\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 1.0398 - accuracy: 0.5067\n",
      "74/74 [==============================] - 0s 283us/sample - loss: 0.9108 - accuracy: 0.5676\n",
      "74/74 [==============================] - 0s 336us/sample - loss: 1.0408 - accuracy: 0.5946\n",
      "74/74 [==============================] - 0s 337us/sample - loss: 1.0291 - accuracy: 0.5135\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 3341 samples, validate on 752 samples\n",
      "Epoch 1/300\n",
      "3341/3341 [==============================] - 3s 750us/sample - loss: 0.5725 - accuracy: 0.6926 - val_loss: 0.6515 - val_accuracy: 0.6410\n",
      "Epoch 2/300\n",
      "3341/3341 [==============================] - 1s 231us/sample - loss: 0.4116 - accuracy: 0.8213 - val_loss: 0.6972 - val_accuracy: 0.6370\n",
      "Epoch 3/300\n",
      "3341/3341 [==============================] - 1s 217us/sample - loss: 0.3111 - accuracy: 0.8881 - val_loss: 0.7730 - val_accuracy: 0.6449\n",
      "Epoch 4/300\n",
      "3341/3341 [==============================] - 1s 234us/sample - loss: 0.2314 - accuracy: 0.9222 - val_loss: 0.8800 - val_accuracy: 0.6383\n",
      "Epoch 00004: early stopping\n",
      "67/67 [==============================] - 0s 161us/sample - loss: 0.5517 - accuracy: 0.7612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [59:32, 1182.17s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.33s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.51s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 239.427734375 steps, validate for 54.662109375 steps\n",
      "Epoch 1/300\n",
      "240/239 [==============================] - 25s 104ms/step - loss: 0.6054 - accuracy: 0.6781 - val_loss: 0.6464 - val_accuracy: 0.6608\n",
      "Epoch 2/300\n",
      "240/239 [==============================] - 23s 95ms/step - loss: 0.5641 - accuracy: 0.7073 - val_loss: 0.6480 - val_accuracy: 0.6424\n",
      "Epoch 3/300\n",
      "240/239 [==============================] - 24s 98ms/step - loss: 0.5433 - accuracy: 0.7248 - val_loss: 0.6779 - val_accuracy: 0.6360\n",
      "Epoch 4/300\n",
      "240/239 [==============================] - 23s 97ms/step - loss: 0.5259 - accuracy: 0.7365 - val_loss: 0.6828 - val_accuracy: 0.6204\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 239.427734375 steps, validate for 54.662109375 steps\n",
      "Epoch 1/300\n",
      "240/239 [==============================] - 59s 247ms/step - loss: 0.5020 - accuracy: 0.7519 - val_loss: 0.7401 - val_accuracy: 0.5761\n",
      "Epoch 2/300\n",
      "240/239 [==============================] - 57s 237ms/step - loss: 0.4437 - accuracy: 0.7925 - val_loss: 0.8454 - val_accuracy: 0.5504\n",
      "Epoch 3/300\n",
      "240/239 [==============================] - 57s 238ms/step - loss: 0.3974 - accuracy: 0.8216 - val_loss: 0.7379 - val_accuracy: 0.6365\n",
      "Epoch 4/300\n",
      "240/239 [==============================] - 56s 235ms/step - loss: 0.3557 - accuracy: 0.8448 - val_loss: 0.8277 - val_accuracy: 0.6241\n",
      "Epoch 5/300\n",
      "240/239 [==============================] - 56s 234ms/step - loss: 0.3158 - accuracy: 0.8692 - val_loss: 0.8953 - val_accuracy: 0.5684\n",
      "Epoch 6/300\n",
      "240/239 [==============================] - 57s 236ms/step - loss: 0.2785 - accuracy: 0.8883 - val_loss: 0.8774 - val_accuracy: 0.5789\n",
      "Epoch 00006: early stopping\n",
      "207/207 [==============================] - 0s 1ms/sample - loss: 0.8224 - accuracy: 0.5990\n",
      "204/204 [==============================] - 0s 219us/sample - loss: 0.8529 - accuracy: 0.5931\n",
      "205/205 [==============================] - 0s 212us/sample - loss: 0.9137 - accuracy: 0.5659\n",
      "202/202 [==============================] - 0s 333us/sample - loss: 0.7605 - accuracy: 0.6337\n",
      "201/201 [==============================] - 0s 225us/sample - loss: 0.8497 - accuracy: 0.5373\n",
      "200/200 [==============================] - 0s 209us/sample - loss: 0.7427 - accuracy: 0.5900\n",
      "196/196 [==============================] - 0s 215us/sample - loss: 0.7639 - accuracy: 0.6224\n",
      "195/195 [==============================] - 0s 231us/sample - loss: 0.7661 - accuracy: 0.6256\n",
      "193/193 [==============================] - 0s 251us/sample - loss: 0.8188 - accuracy: 0.6373\n",
      "189/189 [==============================] - 0s 253us/sample - loss: 0.7120 - accuracy: 0.6931\n",
      "186/186 [==============================] - 0s 221us/sample - loss: 0.6862 - accuracy: 0.6882\n",
      "187/187 [==============================] - 0s 223us/sample - loss: 0.7254 - accuracy: 0.6310\n",
      "185/185 [==============================] - 0s 242us/sample - loss: 0.7163 - accuracy: 0.6270\n",
      "184/184 [==============================] - 0s 240us/sample - loss: 0.7723 - accuracy: 0.6141\n",
      "182/182 [==============================] - 0s 251us/sample - loss: 0.7230 - accuracy: 0.6429\n",
      "183/183 [==============================] - 0s 230us/sample - loss: 0.6713 - accuracy: 0.6230\n",
      "182/182 [==============================] - 0s 242us/sample - loss: 0.6473 - accuracy: 0.6703\n",
      "181/181 [==============================] - 0s 227us/sample - loss: 0.6697 - accuracy: 0.6575\n",
      "182/182 [==============================] - 0s 233us/sample - loss: 0.6311 - accuracy: 0.6538\n",
      "180/180 [==============================] - 0s 798us/sample - loss: 0.6133 - accuracy: 0.6778\n",
      "179/179 [==============================] - 0s 235us/sample - loss: 0.5988 - accuracy: 0.7039\n",
      "176/176 [==============================] - 0s 219us/sample - loss: 0.7250 - accuracy: 0.6250\n",
      "174/174 [==============================] - 0s 245us/sample - loss: 0.7514 - accuracy: 0.6322\n",
      "174/174 [==============================] - 0s 229us/sample - loss: 0.7299 - accuracy: 0.6149\n",
      "174/174 [==============================] - 0s 233us/sample - loss: 0.7294 - accuracy: 0.6494\n",
      "172/172 [==============================] - 0s 240us/sample - loss: 0.7377 - accuracy: 0.6163\n",
      "174/174 [==============================] - 0s 244us/sample - loss: 0.7089 - accuracy: 0.6494\n",
      "172/172 [==============================] - 0s 237us/sample - loss: 0.5899 - accuracy: 0.6977\n",
      "171/171 [==============================] - 0s 225us/sample - loss: 0.6704 - accuracy: 0.6725\n",
      "171/171 [==============================] - 0s 224us/sample - loss: 0.5955 - accuracy: 0.6725\n",
      "170/170 [==============================] - 0s 251us/sample - loss: 0.6739 - accuracy: 0.6353\n",
      "169/169 [==============================] - 0s 246us/sample - loss: 0.6811 - accuracy: 0.7041\n",
      "169/169 [==============================] - 0s 223us/sample - loss: 0.7661 - accuracy: 0.6272\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 3255 samples, validate on 743 samples\n",
      "Epoch 1/300\n",
      "3255/3255 [==============================] - 2s 749us/sample - loss: 0.5321 - accuracy: 0.7364 - val_loss: 0.6808 - val_accuracy: 0.6460\n",
      "Epoch 2/300\n",
      "3255/3255 [==============================] - 1s 244us/sample - loss: 0.3372 - accuracy: 0.8805 - val_loss: 0.7867 - val_accuracy: 0.6406\n",
      "Epoch 3/300\n",
      "3255/3255 [==============================] - 1s 240us/sample - loss: 0.1809 - accuracy: 0.9521 - val_loss: 0.9747 - val_accuracy: 0.6433\n",
      "Epoch 4/300\n",
      "3255/3255 [==============================] - 1s 228us/sample - loss: 0.1175 - accuracy: 0.9705 - val_loss: 1.0587 - val_accuracy: 0.6218\n",
      "Epoch 00004: early stopping\n",
      "162/162 [==============================] - 0s 151us/sample - loss: 0.5276 - accuracy: 0.7469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [1:19:15, 1182.48s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.51s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.61s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 243.294921875 steps, validate for 54.861328125 steps\n",
      "Epoch 1/300\n",
      "244/243 [==============================] - 25s 102ms/step - loss: 0.6228 - accuracy: 0.6647 - val_loss: 0.6600 - val_accuracy: 0.6711\n",
      "Epoch 2/300\n",
      "244/243 [==============================] - 23s 93ms/step - loss: 0.5616 - accuracy: 0.7112 - val_loss: 0.6559 - val_accuracy: 0.6506\n",
      "Epoch 3/300\n",
      "244/243 [==============================] - 23s 94ms/step - loss: 0.5397 - accuracy: 0.7267 - val_loss: 0.6865 - val_accuracy: 0.6302\n",
      "Epoch 4/300\n",
      "244/243 [==============================] - 23s 94ms/step - loss: 0.5216 - accuracy: 0.7396 - val_loss: 0.7036 - val_accuracy: 0.6214\n",
      "Epoch 5/300\n",
      "244/243 [==============================] - 23s 96ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.7252 - val_accuracy: 0.6263\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 243.294921875 steps, validate for 54.861328125 steps\n",
      "Epoch 1/300\n",
      "244/243 [==============================] - 59s 242ms/step - loss: 0.4858 - accuracy: 0.7627 - val_loss: 0.8492 - val_accuracy: 0.6291\n",
      "Epoch 2/300\n",
      "244/243 [==============================] - 59s 240ms/step - loss: 0.4307 - accuracy: 0.7991 - val_loss: 0.9738 - val_accuracy: 0.5024\n",
      "Epoch 3/300\n",
      "244/243 [==============================] - 58s 238ms/step - loss: 0.3874 - accuracy: 0.8250 - val_loss: 0.9225 - val_accuracy: 0.6350\n",
      "Epoch 4/300\n",
      "244/243 [==============================] - 58s 239ms/step - loss: 0.3477 - accuracy: 0.8495 - val_loss: 1.0878 - val_accuracy: 0.6559\n",
      "Epoch 00004: early stopping\n",
      "139/139 [==============================] - 0s 2ms/sample - loss: 0.1105 - accuracy: 0.9784\n",
      "135/135 [==============================] - 0s 322us/sample - loss: 0.1083 - accuracy: 0.9778\n",
      "131/131 [==============================] - 0s 249us/sample - loss: 0.1256 - accuracy: 0.9695\n",
      "130/130 [==============================] - 0s 220us/sample - loss: 0.1420 - accuracy: 0.9769\n",
      "129/129 [==============================] - 0s 276us/sample - loss: 0.1270 - accuracy: 0.9845\n",
      "130/130 [==============================] - 0s 269us/sample - loss: 0.1075 - accuracy: 0.9846\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.1250 - accuracy: 0.9766\n",
      "128/128 [==============================] - 0s 222us/sample - loss: 0.1016 - accuracy: 0.9844\n",
      "126/126 [==============================] - 0s 211us/sample - loss: 0.1107 - accuracy: 0.9683\n",
      "128/128 [==============================] - 0s 216us/sample - loss: 0.0813 - accuracy: 0.9844\n",
      "127/127 [==============================] - 0s 225us/sample - loss: 0.0802 - accuracy: 0.9843\n",
      "126/126 [==============================] - 0s 228us/sample - loss: 0.0951 - accuracy: 0.9841\n",
      "125/125 [==============================] - 0s 244us/sample - loss: 0.0661 - accuracy: 0.9920\n",
      "126/126 [==============================] - 0s 240us/sample - loss: 0.0763 - accuracy: 0.9921\n",
      "124/124 [==============================] - 0s 246us/sample - loss: 0.0612 - accuracy: 0.9919\n",
      "123/123 [==============================] - 0s 303us/sample - loss: 0.0813 - accuracy: 0.9919\n",
      "121/121 [==============================] - 0s 243us/sample - loss: 0.0770 - accuracy: 0.9917\n",
      "119/119 [==============================] - 0s 253us/sample - loss: 0.1107 - accuracy: 0.9664\n",
      "121/121 [==============================] - 0s 239us/sample - loss: 0.1391 - accuracy: 0.9587\n",
      "118/118 [==============================] - 0s 247us/sample - loss: 0.1129 - accuracy: 0.9661\n",
      "117/117 [==============================] - 0s 247us/sample - loss: 0.1480 - accuracy: 0.9487\n",
      "117/117 [==============================] - 0s 258us/sample - loss: 0.1190 - accuracy: 0.9744\n",
      "114/114 [==============================] - 0s 242us/sample - loss: 0.1156 - accuracy: 0.9649\n",
      "113/113 [==============================] - 0s 251us/sample - loss: 0.1264 - accuracy: 0.9381\n",
      "113/113 [==============================] - 0s 284us/sample - loss: 0.0974 - accuracy: 0.9646\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.0959 - accuracy: 0.9554\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.1017 - accuracy: 0.9643\n",
      "110/110 [==============================] - 0s 271us/sample - loss: 0.0836 - accuracy: 0.9636\n",
      "110/110 [==============================] - 0s 241us/sample - loss: 0.0776 - accuracy: 0.9909\n",
      "109/109 [==============================] - 0s 240us/sample - loss: 0.0955 - accuracy: 0.9725\n",
      "110/110 [==============================] - 0s 230us/sample - loss: 0.1055 - accuracy: 0.9455\n",
      "109/109 [==============================] - 0s 234us/sample - loss: 0.1225 - accuracy: 0.9450\n",
      "107/107 [==============================] - 0s 240us/sample - loss: 0.1499 - accuracy: 0.9533\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 3309 samples, validate on 748 samples\n",
      "Epoch 1/300\n",
      "3309/3309 [==============================] - 2s 738us/sample - loss: 0.6003 - accuracy: 0.6733 - val_loss: 0.6467 - val_accuracy: 0.6551\n",
      "Epoch 2/300\n",
      "3309/3309 [==============================] - 1s 204us/sample - loss: 0.5014 - accuracy: 0.7613 - val_loss: 0.6627 - val_accuracy: 0.6364\n",
      "Epoch 3/300\n",
      "3309/3309 [==============================] - 1s 232us/sample - loss: 0.4347 - accuracy: 0.8117 - val_loss: 0.6997 - val_accuracy: 0.6364\n",
      "Epoch 4/300\n",
      "3309/3309 [==============================] - 1s 222us/sample - loss: 0.3730 - accuracy: 0.8480 - val_loss: 0.7528 - val_accuracy: 0.6310\n",
      "Epoch 00004: early stopping\n",
      "103/103 [==============================] - 0s 144us/sample - loss: 0.2643 - accuracy: 0.9029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [1:37:42, 1159.82s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.26s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.57s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 244.60546875 steps, validate for 55.50390625 steps\n",
      "Epoch 1/300\n",
      "245/244 [==============================] - 25s 103ms/step - loss: 0.5987 - accuracy: 0.6828 - val_loss: 0.6429 - val_accuracy: 0.6673\n",
      "Epoch 2/300\n",
      "245/244 [==============================] - 23s 94ms/step - loss: 0.5575 - accuracy: 0.7169 - val_loss: 0.6594 - val_accuracy: 0.6471\n",
      "Epoch 3/300\n",
      "245/244 [==============================] - 23s 95ms/step - loss: 0.5359 - accuracy: 0.7304 - val_loss: 0.6790 - val_accuracy: 0.6455\n",
      "Epoch 4/300\n",
      "245/244 [==============================] - 23s 95ms/step - loss: 0.5167 - accuracy: 0.7431 - val_loss: 0.6938 - val_accuracy: 0.6346\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 244.60546875 steps, validate for 55.50390625 steps\n",
      "Epoch 1/300\n",
      "245/244 [==============================] - 60s 247ms/step - loss: 0.4930 - accuracy: 0.7594 - val_loss: 0.8530 - val_accuracy: 0.6388\n",
      "Epoch 2/300\n",
      "245/244 [==============================] - 58s 239ms/step - loss: 0.4365 - accuracy: 0.7963 - val_loss: 0.7469 - val_accuracy: 0.6223\n",
      "Epoch 3/300\n",
      "245/244 [==============================] - 58s 237ms/step - loss: 0.3896 - accuracy: 0.8252 - val_loss: 0.8557 - val_accuracy: 0.5977\n",
      "Epoch 4/300\n",
      "245/244 [==============================] - 58s 236ms/step - loss: 0.3472 - accuracy: 0.8494 - val_loss: 0.8299 - val_accuracy: 0.6048\n",
      "Epoch 5/300\n",
      "245/244 [==============================] - 58s 239ms/step - loss: 0.3074 - accuracy: 0.8730 - val_loss: 0.8217 - val_accuracy: 0.6104\n",
      "Epoch 00005: early stopping\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.5107 - accuracy: 0.7500\n",
      "103/103 [==============================] - 0s 258us/sample - loss: 0.5034 - accuracy: 0.8058\n",
      "98/98 [==============================] - 0s 269us/sample - loss: 0.4884 - accuracy: 0.7857\n",
      "97/97 [==============================] - 0s 271us/sample - loss: 0.4869 - accuracy: 0.7938\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.6745 - accuracy: 0.6979\n",
      "96/96 [==============================] - 0s 328us/sample - loss: 0.6098 - accuracy: 0.7396\n",
      "96/96 [==============================] - 0s 248us/sample - loss: 0.5408 - accuracy: 0.7396\n",
      "92/92 [==============================] - 0s 258us/sample - loss: 0.5474 - accuracy: 0.7826\n",
      "91/91 [==============================] - 0s 236us/sample - loss: 0.4649 - accuracy: 0.7582\n",
      "92/92 [==============================] - 0s 241us/sample - loss: 0.5871 - accuracy: 0.6848\n",
      "91/91 [==============================] - 0s 287us/sample - loss: 0.5337 - accuracy: 0.7363\n",
      "90/90 [==============================] - 0s 260us/sample - loss: 0.6137 - accuracy: 0.7111\n",
      "90/90 [==============================] - 0s 243us/sample - loss: 0.5542 - accuracy: 0.7000\n",
      "89/89 [==============================] - 0s 251us/sample - loss: 0.5374 - accuracy: 0.7416\n",
      "89/89 [==============================] - 0s 277us/sample - loss: 0.6421 - accuracy: 0.7079\n",
      "88/88 [==============================] - 0s 344us/sample - loss: 0.5400 - accuracy: 0.7386\n",
      "88/88 [==============================] - 0s 278us/sample - loss: 0.5497 - accuracy: 0.7159\n",
      "88/88 [==============================] - 0s 264us/sample - loss: 0.4992 - accuracy: 0.7386\n",
      "89/89 [==============================] - 0s 241us/sample - loss: 0.5894 - accuracy: 0.7753\n",
      "87/87 [==============================] - 0s 258us/sample - loss: 0.5050 - accuracy: 0.7931\n",
      "88/88 [==============================] - 0s 265us/sample - loss: 0.4885 - accuracy: 0.7955\n",
      "88/88 [==============================] - 0s 274us/sample - loss: 0.5677 - accuracy: 0.7273\n",
      "86/86 [==============================] - 0s 269us/sample - loss: 0.4676 - accuracy: 0.8140\n",
      "86/86 [==============================] - 0s 257us/sample - loss: 0.5612 - accuracy: 0.7209\n",
      "87/87 [==============================] - 0s 246us/sample - loss: 0.5854 - accuracy: 0.7241\n",
      "87/87 [==============================] - 0s 281us/sample - loss: 0.5317 - accuracy: 0.7816\n",
      "86/86 [==============================] - 0s 255us/sample - loss: 0.5389 - accuracy: 0.7791\n",
      "87/87 [==============================] - 0s 294us/sample - loss: 0.5304 - accuracy: 0.7816\n",
      "85/85 [==============================] - 0s 304us/sample - loss: 0.5052 - accuracy: 0.8000\n",
      "87/87 [==============================] - 0s 347us/sample - loss: 0.5897 - accuracy: 0.7011\n",
      "86/86 [==============================] - 0s 281us/sample - loss: 0.5091 - accuracy: 0.7791\n",
      "86/86 [==============================] - 0s 276us/sample - loss: 0.5965 - accuracy: 0.7209\n",
      "86/86 [==============================] - 0s 283us/sample - loss: 0.5336 - accuracy: 0.7093\n"
     ]
    }
   ],
   "source": [
    "for num_ix, rand_num in enumerate(rand):\n",
    "    for index_t_well, _ in tqdm.tqdm(enumerate(tot_well)):\n",
    "\n",
    "        time_points = list(map(str, range(1,34)))\n",
    "\n",
    "        new_time = []\n",
    "        for i in time_points:\n",
    "            r = '_' + i + '.'\n",
    "            new_time.append(r)\n",
    "\n",
    "\n",
    "\n",
    "        path_test = '/home/jovyan/DATA_MASTER_PROJECT/IMG_A549_high_con/{}_cropped/'.format(a)\n",
    "\n",
    "        # NAME OF THE WELLS CORRESPONDING TO THE DRUG THAT YOU WANT IN THE TEST SET \n",
    "\n",
    "        wells_drug = [tot_well[index_t_well][0]] \n",
    "\n",
    "        test = []\n",
    "\n",
    "        for _,_, filenames in os.walk(path_test):\n",
    "\n",
    "            for filename in sorted(filenames, key = natural_keys):\n",
    "\n",
    "                for w in wells_drug:\n",
    "                    for t in new_time:\n",
    "                        if '{}'.format(w) in filename and '{}tiff'.format(t) in filename:\n",
    "                            test.append(filename)\n",
    "\n",
    "        groups_list = ['{}'.format(a), '{}'.format(b)]\n",
    "\n",
    "        fileds_of_view = ['1','2','3','4','5']\n",
    "\n",
    "        field_train, field_val = train_test_split(fileds_of_view, test_size=0.2, random_state=rand_num)\n",
    "\n",
    "\n",
    "        train = []\n",
    "\n",
    "        validation = []\n",
    "\n",
    "        group_compounds = []\n",
    "\n",
    "        for group in tqdm.tqdm(groups_list):\n",
    "\n",
    "            pa = '/home/jovyan/DATA_MASTER_PROJECT/IMG_A549_high_con/{}_cropped/'.format(group)\n",
    "\n",
    "            for _,_, filenames in os.walk(pa):\n",
    "\n",
    "                for filename in sorted(filenames, key = natural_keys):\n",
    "\n",
    "                    for t in new_time:\n",
    "\n",
    "                        if '_{}-'.format(wells_drug[0]) not in filename  and '{}tiff'.format(t) in filename:\n",
    "\n",
    "                            group_compounds.append(filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for i in group_compounds:\n",
    "\n",
    "            for f in field_train:\n",
    "                if '-{}_'.format(f) in i:\n",
    "                    train.append(i)\n",
    "\n",
    "\n",
    "            for v in field_val:\n",
    "                if '-{}_'.format(v) in i:\n",
    "                    validation.append(i)\n",
    "\n",
    "\n",
    "        x_train = loadImages(train)\n",
    "        y_train = make_labels(train)\n",
    "\n",
    "\n",
    "\n",
    "        x_val = loadImages(validation)\n",
    "        y_val = make_labels(validation)\n",
    "\n",
    "\n",
    "\n",
    "        x_train = resize(x_train)\n",
    "\n",
    "\n",
    "        x_val = resize(x_val)\n",
    "\n",
    "\n",
    "        weights = class_weight.compute_class_weight('balanced', np.unique(y_train),y_train)\n",
    "\n",
    "\n",
    "        x_train = preprocess_input(x_train)\n",
    "\n",
    "        x_val = preprocess_input(x_val)\n",
    "\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=3)\n",
    "\n",
    "        pretrained_model = VGG16(weights='imagenet',include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "        base_model = Model(inputs=pretrained_model.input, outputs=pretrained_model.get_layer('block3_pool').output)\n",
    "\n",
    "        batch_size = 128\n",
    "\n",
    "        datagen = ImageDataGenerator()\n",
    "\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "        train_gen = datagen.flow(x_train, y_train,batch_size=batch_size )\n",
    "\n",
    "        dat_val = ImageDataGenerator()\n",
    "\n",
    "        dat_val.fit(x_val)\n",
    "\n",
    "        val_gen = dat_val.flow(x_val, y_val,batch_size=batch_size)\n",
    "\n",
    "        m4 = Sequential()\n",
    "        m4.add(base_model)\n",
    "\n",
    "\n",
    "        m4.add(BatchNormalization())\n",
    "        m4.add(GlobalAveragePooling2D())\n",
    "        m4.add(Dense(64, activation='relu'))\n",
    "        m4.add(BatchNormalization())\n",
    "        m4.add(Activation('relu'))\n",
    "        m4.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "        base_model.trainable = False\n",
    "\n",
    "        opt = keras.optimizers.Adam(lr=1e-3)\n",
    "\n",
    "        m4.compile(loss= keras.losses.binary_crossentropy, optimizer=opt, metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "        epochs = 300\n",
    "\n",
    "        m4_h = m4.fit(train_gen,\n",
    "                        steps_per_epoch=(len(x_train)/batch_size),\n",
    "                        callbacks = [es],\n",
    "                        epochs=epochs,\n",
    "                        validation_data = (val_gen), \n",
    "                        validation_steps = (len(x_val)/batch_size),\n",
    "                        class_weight = weights,\n",
    "                         verbose = 1)\n",
    "\n",
    "        base_model.trainable = True\n",
    "\n",
    "        opt = keras.optimizers.Adam(lr=1e-4)\n",
    "\n",
    "        m4.compile(loss= keras.losses.binary_crossentropy, optimizer=opt, metrics = ['accuracy'])\n",
    "\n",
    "        epochs = 300\n",
    "\n",
    "        m4_h = m4.fit(train_gen,\n",
    "                        steps_per_epoch=(len(x_train)//batch_size),\n",
    "                        callbacks = [es],\n",
    "                        epochs=epochs,\n",
    "                        validation_data = val_gen, \n",
    "                        validation_steps = (len(x_val)//batch_size),\n",
    "                        class_weight = weights,\n",
    "                        verbose = 1)\n",
    "\n",
    "        l = []\n",
    "        for t in new_time:\n",
    "            for i in test:\n",
    "                if t in i:\n",
    "                    l.append((i))\n",
    "\n",
    "\n",
    "        grouped = {}\n",
    "        for elem in l:\n",
    "            key = elem.split('.tiff')[0].split('_')[5]\n",
    "            grouped.setdefault(key, []).append(elem)\n",
    "        grouped = grouped.values()\n",
    "\n",
    "        test_data = list(grouped)\n",
    "\n",
    "        r = []\n",
    "\n",
    "        for ix ,_ in enumerate(test_data):\n",
    "            r.append(time_step_acc(test_data[ix],m4))\n",
    "\n",
    "        plt.plot(time_points,r)\n",
    "        plt.savefig('/home/jovyan/IMG_CNN_FINAL/{}_accuracy.png'.format(string_well[index_t_well]))\n",
    "\n",
    "        tot_results_accuracy.append(r)\n",
    "        \n",
    "        for i, layer in enumerate(m4.layers):\n",
    "            layer._name = 'layer_' + str(i)\n",
    "\n",
    "\n",
    "\n",
    "        lstm_model = Model(inputs=m4.input, outputs=m4.get_layer('layer_4').output)\n",
    "\n",
    "        del m4\n",
    "        K.clear_session()\n",
    "        \n",
    "        data_name = [train,test,validation]\n",
    "\n",
    "        feat_name = ['train', 'test', 'validation']\n",
    "\n",
    "        for index_name, _ in enumerate(data_name):\n",
    "\n",
    "            path =  data_name[index_name]\n",
    "\n",
    "            name_well = []\n",
    "\n",
    "            for i in path:\n",
    "                name_well.append(i.split('_id')[0])\n",
    "\n",
    "            wells = list(set(name_well))\n",
    "            wells\n",
    "\n",
    "            for w in wells:\n",
    "\n",
    "                time = []\n",
    "\n",
    "\n",
    "                for filename in sorted(path, key = natural_keys):\n",
    "                    if w in filename: #PAY ATTENTION ID THE IMAGE IS A TIFF OR PNG IMAGE #########\n",
    "                        time.append(filename)\n",
    "\n",
    "                data_id = {}\n",
    "                n_id = []\n",
    "                w_n = []\n",
    "\n",
    "                for i in time:\n",
    "                    t = i.split('_id_')[1].split('time_')[0]\n",
    "                    f = i.split('_id_')[0].split('time_')[0]\n",
    "                    n_id.append(t)\n",
    "                    w_n.append(f)\n",
    "\n",
    "                id_cell = set(n_id)\n",
    "\n",
    "\n",
    "                for ix, i in enumerate(sorted(id_cell, key = natural_keys)):\n",
    "\n",
    "                    id_name = []\n",
    "                    dict_1 = {}\n",
    "\n",
    "                    for t in time:\n",
    "                        if 'id_{}'.format(i) in t:\n",
    "                            id_name.append(t)\n",
    "\n",
    "                    d = {'id':id_name}\n",
    "                    data = pd.DataFrame(d)\n",
    "\n",
    "                    dict_1[ix]=data \n",
    "                    data_id.update(dict_1) \n",
    "\n",
    "                delete = [i for i, j in data_id.items() if len(j) < len(time_points)] # 9 or the length of time span you are traning on \n",
    "                for i in delete : del data_id[i]\n",
    "\n",
    "                len_id = [i for i, j in data_id.items()]\n",
    "\n",
    "                for le in len_id:    \n",
    "\n",
    "\n",
    "                    e = pd.DataFrame(data_id[le])\n",
    "\n",
    "                    coords = e.values.tolist()\n",
    "                    id_cells = []\n",
    "                    for i in coords:\n",
    "                        for j in i:\n",
    "                            id_cells.append(j)\n",
    "\n",
    "                    x_orig = loadImages(id_cells)\n",
    "                    x_orig = resize(x_orig)\n",
    "\n",
    "                    x_orig = preprocess_input(x_orig)\n",
    "                    output = lstm_model.predict(x_orig)\n",
    "                    np.save('/home/jovyan/DATA_MASTER_PROJECT/LSTM//FEAT_FOLDERS/features_{}/features_well_{}_id_{}.npy'.format(feat_name[index_name],w_n[0], le), output)\n",
    "            print('Saved_feature_{}'.format(feat_name[index_name]))\n",
    "\n",
    "\n",
    "        x_train_lstm = loadImages_LSTM(train_data, len(time_points))\n",
    "        y_train_lstm = make_labels_LSTM(y_tra_path)\n",
    "\n",
    "        x_test_lstm = loadImages_LSTM(tes_data, len(time_points))\n",
    "        y_test_lstm = make_labels_LSTM(y_tes_path)\n",
    "\n",
    "        x_val_lstm = loadImages_LSTM(val_data, len(time_points))\n",
    "        y_val_lstm = make_labels_LSTM(y_val_path)\n",
    "\n",
    "        weights_lstm = class_weight.compute_class_weight('balanced', np.unique(y_train_lstm),y_train_lstm)\n",
    "\n",
    "\n",
    "        m = Sequential()\n",
    "        m.add(LSTM(32, input_shape = (x_train_lstm.shape[1],x_train_lstm.shape[2])))\n",
    "        m.add(Dropout(0.2))\n",
    "        m.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "        opt_lstm = keras.optimizers.Adam(lr=1e-4)\n",
    "\n",
    "        m.compile(loss= keras.losses.binary_crossentropy, optimizer=opt, metrics = ['accuracy'])\n",
    "\n",
    "        epochs = 300\n",
    "\n",
    "        m_h = m.fit(x_train_lstm,y_train_lstm,\n",
    "\n",
    "                         callbacks = [es],\n",
    "\n",
    "                        epochs=epochs,\n",
    "                        validation_data = (x_val_lstm,y_val_lstm), \n",
    "\n",
    "                        class_weight = weights_lstm)\n",
    "\n",
    "\n",
    "        scores_lstm = m.evaluate(x_test_lstm, y_test_lstm)\n",
    "        results_lstm.append([scores_lstm[1]*100, string_well[index_t_well]])\n",
    "        \n",
    "        del m\n",
    "        K.clear_session()\n",
    "\n",
    "        # DELITE FILES IN FEATURE VECTOR FOLDERS\n",
    "\n",
    "        folders = glob.glob('/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/*')\n",
    "\n",
    "        for fo in folders:\n",
    "            file = glob.glob(f'{fo}/*')\n",
    "            for f in file:\n",
    "                os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCURACY SCORE AVERAGE FOR CNN\n",
    "cv_s = cv_mean_acc(tot_results_accuracy, string_well)\n",
    "cv_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_s_mean,_ = zip(*cv_s)\n",
    "\n",
    "m_cv = np.mean(list(cv_s_mean))\n",
    "m_cv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT OF MEAN ACCURACY FOR EVERY TIME POINT CNN\n",
    "\n",
    "l_drug = string_well*3\n",
    "\n",
    "acc_plot = []\n",
    "\n",
    "for i in tot_results_accuracy:\n",
    "    acc_plot.append(i)\n",
    "\n",
    "cv_plot = list(zip(acc_plot, l_drug))\n",
    "\n",
    "res_plot = sorted(cv_plot, key = lambda x: x[1])\n",
    "\n",
    "a , b = zip(*res_plot)\n",
    "    \n",
    "a = list(a)\n",
    "\n",
    "s = list(np.array_split(a, len(string_well)))\n",
    "\n",
    "cv_plot = []\n",
    "\n",
    "for ix, i in enumerate(s):\n",
    "    s1 = list(s[ix])\n",
    "    \n",
    "    cv_plot.append(np.average(s1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i in cv_plot:\n",
    "    \n",
    "    plt.plot(time_points, i)\n",
    "    plt.show\n",
    "    plt.savefig('/home/jovyan/cv_score.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lstm = sorted(results_lstm, key=lambda x: x[1])\n",
    "r_lstm , _ = zip(*results_lstm)\n",
    "    \n",
    "r_lstm = list(r_lstm)\n",
    "\n",
    "re_lstm = list(np.array_split(r_lstm, len(string_well)))\n",
    "\n",
    "cv_lstm = []\n",
    "\n",
    "for ix, i in enumerate(re_lstm):\n",
    "    r1 = list(re_lstm[ix])\n",
    "    cv_lstm.append(np.mean(r1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_lstm = list(zip(cv_lstm, string_well))\n",
    "cv_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_l_mean,_ = zip(*cv_lstm)\n",
    "\n",
    "m_cv_l = np.mean(list(cv_l_mean))\n",
    "m_cv_l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE RUNNING AGAIN\n",
    "\n",
    "folders = glob.glob('/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/*')\n",
    "\n",
    "for fo in folders:\n",
    "    file = glob.glob(f'{fo}/*')\n",
    "    for f in file:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
