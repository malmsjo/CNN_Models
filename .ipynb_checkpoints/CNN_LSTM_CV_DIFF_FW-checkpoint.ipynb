{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten, LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "import tqdm\n",
    "from numpy import loadtxt\n",
    "from os import *\n",
    "from sklearn.utils import class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(true,preds):\n",
    "    conf_matx = confusion_matrix(true, preds)\n",
    "    sns.heatmap(conf_matx, annot=True,annot_kws={\"size\": 12},fmt='g', cbar=False, cmap=plt.cm.Blues) #'viridis'\n",
    "    #plt.savefig('/home/jovyan/conf_matrix.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return conf_matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(model_history, model_name):\n",
    "    fig = plt.figure(figsize=(15,5), facecolor='w')\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.plot(model_history.history['loss'])\n",
    "    ax.plot(model_history.history['val_loss'])\n",
    "    ax.set(title=model_name + ': Model loss', ylabel='Loss', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Val'], loc='upper left')\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.plot(model_history.history['accuracy'])\n",
    "    ax.plot(model_history.history['val_accuracy'])\n",
    "    ax.set(title=model_name + ': Model Accuracy; test='+ str(np.round(model_history.history['val_accuracy'][-1], 3)),\n",
    "           ylabel='Accuracy', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Val'], loc='upper left')\n",
    "    #plt.savefig('/home/jovyan/curve.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(x):\n",
    "    rescaled = []\n",
    "\n",
    "    for i in x:\n",
    "\n",
    "        scale_percent = 140 # percent of original size\n",
    "        width = int(i.shape[1] / (scale_percent / 100))\n",
    "        height = int(i.shape[0] / (scale_percent / 100))\n",
    "        dim = (width, height)\n",
    "        resized = cv2.resize(i, dim, interpolation = cv2.INTER_LANCZOS4)\n",
    "        rescaled.append(resized)\n",
    "\n",
    "    x_orig = np.reshape( rescaled, (len( rescaled), resized.shape[1], resized.shape[1], 3))\n",
    "\n",
    "    return x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(path_data):\n",
    "    \n",
    "    p = '/home/jovyan/DATA_MASTER_PROJECT/IMG_A549_high_con/'\n",
    "    \n",
    "    \n",
    "    \n",
    "    pa_adr = p + 'ADR_cropped/'\n",
    "    \n",
    "    pa_control = p + 'CONTROL_cropped/'\n",
    "    \n",
    "    pa_hrh = p + 'HRH_cropped/'\n",
    "    \n",
    "    pa_dmso = p + 'DMSO_cropped/'\n",
    "    \n",
    "    image_list = []\n",
    "    \n",
    "    \n",
    "       \n",
    "\n",
    "\n",
    "    for filename in sorted(path_data, key=natural_keys): \n",
    "        \n",
    "        if 'adr' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_adr + filename)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "            \n",
    "\n",
    "            image_list.append(imarray)\n",
    "            \n",
    "        if 'control' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_control + filename)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "            \n",
    "\n",
    "            image_list.append(imarray)\n",
    "            \n",
    "        if 'hrh' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_hrh + filename)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "            \n",
    "\n",
    "            image_list.append(imarray)\n",
    "            \n",
    "        if 'dmso' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_dmso + filename)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "            \n",
    "\n",
    "            image_list.append(imarray)\n",
    "\n",
    "\n",
    "\n",
    "    x_orig = np.reshape(image_list, (len(image_list), 90, 90, 3))\n",
    "\n",
    "    return x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_count(x):\n",
    "    name_wel = []\n",
    "    for i in sorted(x, key = natural_keys):\n",
    "        name_wel.append(i.split('_')[0])\n",
    "\n",
    "    z = sorted(list(set(name_wel)))\n",
    "    r = list(range(len(z)))\n",
    "\n",
    "    num = []\n",
    "    for iz in range(len(z)):\n",
    "        count = 0\n",
    "        for i in sorted(x, key=natural_keys):\n",
    "            if z[iz] in i:\n",
    "                count += 1\n",
    "        num.append(count)\n",
    "    return list(zip(z, r, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages_LSTM(path_data,len_t_points):\n",
    "    \n",
    "\n",
    "    feat_list = []\n",
    "\n",
    "\n",
    "    for filename in sorted(glob.glob(path_data), key=natural_keys): \n",
    "        feat_list.append(np.load(filename))\n",
    "\n",
    "    x_orig = np.reshape(feat_list, (len(feat_list),len_t_points, 64))\n",
    "\n",
    "    return x_orig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(data_set):\n",
    "    fe = return_count(data_set)\n",
    "    leb = creat_label(fe)\n",
    "    y = np.array(list(leb))\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels_LSTM(data_set):\n",
    "    fe = return_count_LSTM(data_set)\n",
    "    leb = creat_label(fe)\n",
    "    y = np.array(list(leb))\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_count_LSTM(x):\n",
    "    name_wel = []\n",
    "    for _,_,i in os.walk(x):\n",
    "        for f in i:\n",
    "            name_wel.append(f.split('_')[2])\n",
    "\n",
    "    z = sorted(list(set(name_wel)), key=natural_keys)\n",
    "    r = list(range(len(z)))\n",
    "\n",
    "    num = []\n",
    "    for iz in range(len(z)):\n",
    "        count = 0\n",
    "        for i in sorted(name_wel, key=natural_keys):\n",
    "            if z[iz] in i:\n",
    "                count += 1\n",
    "        num.append(count)\n",
    "    return list(zip(z, r, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_label(y):\n",
    "    labels = []\n",
    "    for ix, _ in enumerate(y):\n",
    "        \n",
    "        if y[ix][0] == 'adr':\n",
    "        \n",
    "            labels.append([[y[ix][0],0]] * y[ix][2])\n",
    "        \n",
    "        if y[ix][0] == 'hrh':\n",
    "            \n",
    "            labels.append([[y[ix][0],0]] * y[ix][2])\n",
    "        \n",
    "        if y[ix][0] == 'control':\n",
    "            \n",
    "            labels.append([[y[ix][0],1]] * y[ix][2])\n",
    "            \n",
    "        if y[ix][0] == 'dmso':\n",
    "            \n",
    "            labels.append([[y[ix][0],1]] * y[ix][2])\n",
    "    \n",
    "    ler = [i for sub in labels for i in sub ]\n",
    "    \n",
    "    _, lab= zip(*ler)\n",
    "\n",
    "    \n",
    "    return lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_step_acc(tes_data, x):\n",
    "\n",
    "    results = []            \n",
    "\n",
    "    x_test = loadImages(tes_data)\n",
    "    y_test = make_labels(tes_data)\n",
    "    x_test = resize(x_test)\n",
    "    x_test = preprocess_input(x_test)\n",
    "\n",
    "    scores = x.evaluate(x_test, y_test, verbose = 1)\n",
    "    results.append(scores[1]*100)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_mean_acc(result_cv, string_well):\n",
    "    \n",
    "    l_drug = string_well*3\n",
    "\n",
    "    acc_mean_cv = []\n",
    "\n",
    "    for i in result_cv:\n",
    "        acc_mean_cv.append(np.mean(i))\n",
    "        \n",
    "    cv_drug = list(zip(acc_mean_cv, l_drug))\n",
    "    \n",
    "    res = sorted(cv_drug, key = lambda x: x[1])\n",
    "    a , b = zip(*res)\n",
    "    \n",
    "    a = list(a)\n",
    "    \n",
    "    s = list(np.array_split(a, len(string_well)))\n",
    "    \n",
    "    cv_score_acc = []\n",
    "    \n",
    "    for ix, i in enumerate(s):\n",
    "        s1 = list(s[ix])\n",
    "        \n",
    "        cv_score_acc.append(np.mean(s1))\n",
    "        \n",
    "    return list(zip(cv_score_acc, string_well))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA FOR LSTM PART\n",
    "\n",
    "p_feat = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/'\n",
    "train_data = p_feat + 'features_train/*.npy'\n",
    "val_data = p_feat + 'features_validation/*.npy'\n",
    "tes_data= p_feat + 'features_test/*.npy'\n",
    "\n",
    "y_tra_path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/features_train/'\n",
    "y_tes_path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/features_test/'\n",
    "y_val_path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/features_validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "met = ['F10']\n",
    "mid = ['D5']\n",
    "oxy = ['F6']\n",
    "nap = ['B3']\n",
    "dip = ['F2']\n",
    "met_1 = ['B7']\n",
    "lab = ['D10']\n",
    "car = ['G2']\n",
    "mep = ['B11']\n",
    "nef = ['C10']\n",
    "tri = ['B2']\n",
    "dox = ['F8']\n",
    "\n",
    "\n",
    "cycl = ['C4']\n",
    "dime =  ['F7']\n",
    "cypr  = ['G9']\n",
    "lora = [ 'E5']\n",
    "doxy = ['D4']\n",
    "oloa = ['E2']\n",
    "hydr = ['F5']\n",
    "orph = ['E7']\n",
    "cinn = ['B10']\n",
    "desl = ['F3']\n",
    "chlo =  ['D2']\n",
    "trim = ['E9']\n",
    "mian= ['E8']\n",
    "fexo= ['B5']\n",
    "chlo_1 = ['E3']\n",
    "trip= ['C5']\n",
    "desi= ['E4']\n",
    "levo= ['C3']\n",
    "diphe_1= ['C7']\n",
    "diphe_2= ['F11']\n",
    "emed= ['G6']\n",
    "ceti= ['D11']\n",
    "trip_1= ['F9']\n",
    "doxe=['C2']\n",
    "chlo_2= ['D6']\n",
    "flun = ['C9']\n",
    "keto= ['D7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_results_accuracy = []\n",
    "\n",
    "results_lstm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_well_adr = [met,mid,oxy,nap,dip,met_1,lab,car,mep,nef,tri,dox]\n",
    "tot_well_hrh = [cycl, dime, cypr,lora,doxy,oloa,cinn,desl,chlo,trim,mian,fexo,chlo_1,trip,desi,levo,\n",
    "                \n",
    "                diphe_1,diphe_2,emed,ceti,trip_1,doxe,chlo_2,flun,keto]\n",
    "\n",
    "string_well_adr = ['met', 'mid', 'oxy', 'nap', 'dip','met_1','lab','car','mep','nef','tri','dox']\n",
    "string_well_hrh = ['cycl', 'dime', 'cypr', 'lora', 'doxy','oloa','cinn','desl','chlo','trim','mian','fexo','chlo_1','trip','desi',\n",
    "                  'levo','diphe_1','diphe_2','emed','ceti','trip_1','doxe','chlo_2','flun','keto']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_well = []\n",
    "string_well = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'HRH' # FOR TEST SET\n",
    "b = 'DMSO' # FOR REST\n",
    "\n",
    "if a == 'HRH':\n",
    "    tot_well = tot_well_hrh\n",
    "    string_well = string_well_hrh\n",
    "    \n",
    "if a == 'ADR':\n",
    "    tot_well = tot_well_adr\n",
    "    string_well = string_well_adr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = list(np.random.randint(1,1000,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.53s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.29s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 832.3671875 steps, validate for 198.4453125 steps\n",
      "Epoch 1/300\n",
      "833/832 [==============================] - 28s 33ms/step - loss: 0.5544 - accuracy: 0.7435 - val_loss: 0.6233 - val_accuracy: 0.7184\n",
      "Epoch 2/300\n",
      "833/832 [==============================] - 24s 28ms/step - loss: 0.5025 - accuracy: 0.7803 - val_loss: 0.6194 - val_accuracy: 0.7183\n",
      "Epoch 3/300\n",
      "833/832 [==============================] - 24s 29ms/step - loss: 0.4883 - accuracy: 0.7850 - val_loss: 0.6188 - val_accuracy: 0.7192\n",
      "Epoch 4/300\n",
      "833/832 [==============================] - 24s 29ms/step - loss: 0.4774 - accuracy: 0.7891 - val_loss: 0.6242 - val_accuracy: 0.7185\n",
      "Epoch 5/300\n",
      "833/832 [==============================] - 24s 29ms/step - loss: 0.4681 - accuracy: 0.7929 - val_loss: 0.6306 - val_accuracy: 0.7214\n",
      "Epoch 6/300\n",
      "833/832 [==============================] - 24s 29ms/step - loss: 0.4597 - accuracy: 0.7964 - val_loss: 0.6297 - val_accuracy: 0.7203\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 832.3671875 steps, validate for 198.4453125 steps\n",
      "Epoch 1/300\n",
      "833/832 [==============================] - 56s 67ms/step - loss: 0.4438 - accuracy: 0.8045 - val_loss: 0.6601 - val_accuracy: 0.7252\n",
      "Epoch 2/300\n",
      "833/832 [==============================] - 54s 65ms/step - loss: 0.4174 - accuracy: 0.8182 - val_loss: 0.6270 - val_accuracy: 0.7178\n",
      "Epoch 3/300\n",
      "833/832 [==============================] - 55s 66ms/step - loss: 0.3954 - accuracy: 0.8301 - val_loss: 0.6439 - val_accuracy: 0.7146\n",
      "Epoch 4/300\n",
      "833/832 [==============================] - 55s 66ms/step - loss: 0.3761 - accuracy: 0.8414 - val_loss: 0.6545 - val_accuracy: 0.7247\n",
      "Epoch 5/300\n",
      "833/832 [==============================] - 54s 65ms/step - loss: 0.3573 - accuracy: 0.8508 - val_loss: 0.6689 - val_accuracy: 0.7105\n",
      "Epoch 00005: early stopping\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.3285 - accuracy: 0.9257\n",
      "196/196 [==============================] - 0s 624us/sample - loss: 0.2854 - accuracy: 0.9337\n",
      "193/193 [==============================] - 0s 561us/sample - loss: 0.2982 - accuracy: 0.9275\n",
      "190/190 [==============================] - 0s 802us/sample - loss: 0.3025 - accuracy: 0.9053\n",
      "190/190 [==============================] - 0s 240us/sample - loss: 0.3034 - accuracy: 0.9158\n",
      "187/187 [==============================] - 0s 777us/sample - loss: 0.2937 - accuracy: 0.9144\n",
      "184/184 [==============================] - 0s 744us/sample - loss: 0.2959 - accuracy: 0.9185\n",
      "183/183 [==============================] - 0s 757us/sample - loss: 0.3004 - accuracy: 0.9071\n",
      "182/182 [==============================] - 0s 720us/sample - loss: 0.2854 - accuracy: 0.9011\n",
      "181/181 [==============================] - 0s 727us/sample - loss: 0.2531 - accuracy: 0.9171\n",
      "177/177 [==============================] - 0s 740us/sample - loss: 0.2587 - accuracy: 0.9322\n",
      "178/178 [==============================] - 0s 720us/sample - loss: 0.2670 - accuracy: 0.9157\n",
      "178/178 [==============================] - 0s 244us/sample - loss: 0.2807 - accuracy: 0.9101\n",
      "176/176 [==============================] - 0s 728us/sample - loss: 0.2480 - accuracy: 0.9489\n",
      "175/175 [==============================] - 0s 737us/sample - loss: 0.2986 - accuracy: 0.8800\n",
      "176/176 [==============================] - 0s 245us/sample - loss: 0.2492 - accuracy: 0.9318\n",
      "173/173 [==============================] - 0s 701us/sample - loss: 0.2836 - accuracy: 0.8902\n",
      "172/172 [==============================] - 0s 677us/sample - loss: 0.2831 - accuracy: 0.9360\n",
      "171/171 [==============================] - 0s 700us/sample - loss: 0.2784 - accuracy: 0.9298\n",
      "171/171 [==============================] - 0s 229us/sample - loss: 0.2947 - accuracy: 0.9006\n",
      "171/171 [==============================] - 0s 240us/sample - loss: 0.2742 - accuracy: 0.9123\n",
      "170/170 [==============================] - 0s 215us/sample - loss: 0.2713 - accuracy: 0.9294\n",
      "171/171 [==============================] - 0s 241us/sample - loss: 0.2880 - accuracy: 0.9240\n",
      "170/170 [==============================] - 0s 241us/sample - loss: 0.2723 - accuracy: 0.9176\n",
      "170/170 [==============================] - 0s 235us/sample - loss: 0.3169 - accuracy: 0.8941\n",
      "171/171 [==============================] - 0s 245us/sample - loss: 0.2887 - accuracy: 0.8830\n",
      "168/168 [==============================] - 0s 631us/sample - loss: 0.3164 - accuracy: 0.8988\n",
      "169/169 [==============================] - 0s 671us/sample - loss: 0.2800 - accuracy: 0.9349\n",
      "169/169 [==============================] - 0s 249us/sample - loss: 0.2693 - accuracy: 0.9349\n",
      "167/167 [==============================] - 0s 667us/sample - loss: 0.2562 - accuracy: 0.9401\n",
      "168/168 [==============================] - 0s 275us/sample - loss: 0.2848 - accuracy: 0.9345\n",
      "169/169 [==============================] - 0s 266us/sample - loss: 0.2994 - accuracy: 0.9172\n",
      "166/166 [==============================] - 0s 723us/sample - loss: 0.3297 - accuracy: 0.8855\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2823 samples, validate on 667 samples\n",
      "Epoch 1/300\n",
      "2823/2823 [==============================] - 3s 919us/sample - loss: 0.7160 - accuracy: 0.5172 - val_loss: 0.6888 - val_accuracy: 0.5697\n",
      "Epoch 2/300\n",
      "2823/2823 [==============================] - 1s 235us/sample - loss: 0.6758 - accuracy: 0.5753 - val_loss: 0.6709 - val_accuracy: 0.5952\n",
      "Epoch 3/300\n",
      "2823/2823 [==============================] - 1s 253us/sample - loss: 0.6506 - accuracy: 0.6128 - val_loss: 0.6587 - val_accuracy: 0.6222\n",
      "Epoch 4/300\n",
      "2823/2823 [==============================] - 1s 221us/sample - loss: 0.6336 - accuracy: 0.6373 - val_loss: 0.6493 - val_accuracy: 0.6252\n",
      "Epoch 5/300\n",
      "2823/2823 [==============================] - 1s 233us/sample - loss: 0.6198 - accuracy: 0.6525 - val_loss: 0.6415 - val_accuracy: 0.6387\n",
      "Epoch 6/300\n",
      "2823/2823 [==============================] - 1s 244us/sample - loss: 0.6080 - accuracy: 0.6674 - val_loss: 0.6349 - val_accuracy: 0.6447\n",
      "Epoch 7/300\n",
      "2823/2823 [==============================] - 1s 249us/sample - loss: 0.5959 - accuracy: 0.6954 - val_loss: 0.6292 - val_accuracy: 0.6522\n",
      "Epoch 8/300\n",
      "2823/2823 [==============================] - 1s 217us/sample - loss: 0.5869 - accuracy: 0.7042 - val_loss: 0.6241 - val_accuracy: 0.6687\n",
      "Epoch 9/300\n",
      "2823/2823 [==============================] - 1s 223us/sample - loss: 0.5774 - accuracy: 0.7180 - val_loss: 0.6195 - val_accuracy: 0.6732\n",
      "Epoch 10/300\n",
      "2823/2823 [==============================] - 1s 215us/sample - loss: 0.5706 - accuracy: 0.7297 - val_loss: 0.6155 - val_accuracy: 0.6837\n",
      "Epoch 11/300\n",
      "2823/2823 [==============================] - 1s 213us/sample - loss: 0.5590 - accuracy: 0.7418 - val_loss: 0.6117 - val_accuracy: 0.6822\n",
      "Epoch 12/300\n",
      "2823/2823 [==============================] - 1s 197us/sample - loss: 0.5559 - accuracy: 0.7471 - val_loss: 0.6085 - val_accuracy: 0.6837\n",
      "Epoch 13/300\n",
      "2823/2823 [==============================] - 1s 216us/sample - loss: 0.5455 - accuracy: 0.7545 - val_loss: 0.6055 - val_accuracy: 0.6837\n",
      "Epoch 14/300\n",
      "2823/2823 [==============================] - 1s 211us/sample - loss: 0.5387 - accuracy: 0.7673 - val_loss: 0.6028 - val_accuracy: 0.6927\n",
      "Epoch 15/300\n",
      "2823/2823 [==============================] - 1s 224us/sample - loss: 0.5312 - accuracy: 0.7744 - val_loss: 0.6004 - val_accuracy: 0.6972\n",
      "Epoch 16/300\n",
      "2823/2823 [==============================] - 1s 207us/sample - loss: 0.5279 - accuracy: 0.7736 - val_loss: 0.5982 - val_accuracy: 0.6987\n",
      "Epoch 17/300\n",
      "2823/2823 [==============================] - 1s 231us/sample - loss: 0.5226 - accuracy: 0.7740 - val_loss: 0.5961 - val_accuracy: 0.6987\n",
      "Epoch 18/300\n",
      "2823/2823 [==============================] - 1s 230us/sample - loss: 0.5133 - accuracy: 0.7885 - val_loss: 0.5943 - val_accuracy: 0.7031\n",
      "Epoch 19/300\n",
      "2823/2823 [==============================] - 1s 238us/sample - loss: 0.5107 - accuracy: 0.7839 - val_loss: 0.5927 - val_accuracy: 0.7076\n",
      "Epoch 20/300\n",
      "2823/2823 [==============================] - 1s 237us/sample - loss: 0.5047 - accuracy: 0.7914 - val_loss: 0.5913 - val_accuracy: 0.7046\n",
      "Epoch 21/300\n",
      "2823/2823 [==============================] - 1s 257us/sample - loss: 0.4976 - accuracy: 0.7906 - val_loss: 0.5901 - val_accuracy: 0.7061\n",
      "Epoch 22/300\n",
      "2823/2823 [==============================] - 1s 265us/sample - loss: 0.4973 - accuracy: 0.7924 - val_loss: 0.5890 - val_accuracy: 0.7091\n",
      "Epoch 23/300\n",
      "2823/2823 [==============================] - 1s 252us/sample - loss: 0.4913 - accuracy: 0.7988 - val_loss: 0.5880 - val_accuracy: 0.7106\n",
      "Epoch 24/300\n",
      "2823/2823 [==============================] - 1s 250us/sample - loss: 0.4867 - accuracy: 0.8038 - val_loss: 0.5872 - val_accuracy: 0.7091\n",
      "Epoch 25/300\n",
      "2823/2823 [==============================] - 1s 252us/sample - loss: 0.4801 - accuracy: 0.8062 - val_loss: 0.5865 - val_accuracy: 0.7076\n",
      "Epoch 26/300\n",
      "2823/2823 [==============================] - 1s 242us/sample - loss: 0.4790 - accuracy: 0.8080 - val_loss: 0.5860 - val_accuracy: 0.7061\n",
      "Epoch 27/300\n",
      "2823/2823 [==============================] - 1s 237us/sample - loss: 0.4706 - accuracy: 0.8073 - val_loss: 0.5856 - val_accuracy: 0.7091\n",
      "Epoch 28/300\n",
      "2823/2823 [==============================] - 1s 231us/sample - loss: 0.4684 - accuracy: 0.8055 - val_loss: 0.5853 - val_accuracy: 0.7121\n",
      "Epoch 29/300\n",
      "2823/2823 [==============================] - 1s 236us/sample - loss: 0.4623 - accuracy: 0.8101 - val_loss: 0.5850 - val_accuracy: 0.7136\n",
      "Epoch 30/300\n",
      "2823/2823 [==============================] - 1s 240us/sample - loss: 0.4589 - accuracy: 0.8119 - val_loss: 0.5849 - val_accuracy: 0.7166\n",
      "Epoch 31/300\n",
      "2823/2823 [==============================] - 1s 241us/sample - loss: 0.4578 - accuracy: 0.8140 - val_loss: 0.5848 - val_accuracy: 0.7151\n",
      "Epoch 32/300\n",
      "2823/2823 [==============================] - 1s 208us/sample - loss: 0.4523 - accuracy: 0.8165 - val_loss: 0.5848 - val_accuracy: 0.7151\n",
      "Epoch 33/300\n",
      "2823/2823 [==============================] - 1s 241us/sample - loss: 0.4492 - accuracy: 0.8172 - val_loss: 0.5850 - val_accuracy: 0.7166\n",
      "Epoch 34/300\n",
      "2823/2823 [==============================] - 1s 239us/sample - loss: 0.4476 - accuracy: 0.8183 - val_loss: 0.5851 - val_accuracy: 0.7181\n",
      "Epoch 35/300\n",
      "2823/2823 [==============================] - 1s 214us/sample - loss: 0.4447 - accuracy: 0.8162 - val_loss: 0.5853 - val_accuracy: 0.7181\n",
      "Epoch 00035: early stopping\n",
      "159/159 [==============================] - 0s 125us/sample - loss: 0.3340 - accuracy: 0.9623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [18:15, 1095.14s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:04<00:04,  4.26s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.74s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 837.453125 steps, validate for 200.03125 steps\n",
      "Epoch 1/300\n",
      "838/837 [==============================] - 25s 29ms/step - loss: 0.6222 - accuracy: 0.6700 - val_loss: 0.6238 - val_accuracy: 0.7207\n",
      "Epoch 2/300\n",
      "838/837 [==============================] - 24s 28ms/step - loss: 0.5074 - accuracy: 0.7799 - val_loss: 0.6303 - val_accuracy: 0.7206\n",
      "Epoch 3/300\n",
      "838/837 [==============================] - 23s 28ms/step - loss: 0.4912 - accuracy: 0.7846 - val_loss: 0.6316 - val_accuracy: 0.7222\n",
      "Epoch 4/300\n",
      "838/837 [==============================] - 24s 28ms/step - loss: 0.4802 - accuracy: 0.7894 - val_loss: 0.6294 - val_accuracy: 0.7235\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 837.453125 steps, validate for 200.03125 steps\n",
      "Epoch 1/300\n",
      "838/837 [==============================] - 55s 66ms/step - loss: 0.4619 - accuracy: 0.7963 - val_loss: 0.6534 - val_accuracy: 0.7214\n",
      "Epoch 2/300\n",
      "838/837 [==============================] - 54s 64ms/step - loss: 0.4341 - accuracy: 0.8103 - val_loss: 0.6368 - val_accuracy: 0.7255\n",
      "Epoch 3/300\n",
      "838/837 [==============================] - 54s 64ms/step - loss: 0.4108 - accuracy: 0.8223 - val_loss: 0.6451 - val_accuracy: 0.7269\n",
      "Epoch 4/300\n",
      "838/837 [==============================] - 54s 64ms/step - loss: 0.3896 - accuracy: 0.8337 - val_loss: 0.6740 - val_accuracy: 0.7225\n",
      "Epoch 5/300\n",
      "838/837 [==============================] - 54s 65ms/step - loss: 0.3696 - accuracy: 0.8447 - val_loss: 0.6454 - val_accuracy: 0.7116\n",
      "Epoch 00005: early stopping\n",
      "167/167 [==============================] - 0s 1ms/sample - loss: 0.2852 - accuracy: 0.9401\n",
      "164/164 [==============================] - 0s 239us/sample - loss: 0.3181 - accuracy: 0.8780\n",
      "162/162 [==============================] - 0s 668us/sample - loss: 0.3238 - accuracy: 0.8951\n",
      "162/162 [==============================] - 0s 237us/sample - loss: 0.3056 - accuracy: 0.9074\n",
      "162/162 [==============================] - 0s 243us/sample - loss: 0.3146 - accuracy: 0.9012\n",
      "161/161 [==============================] - 0s 240us/sample - loss: 0.3051 - accuracy: 0.9068\n",
      "162/162 [==============================] - 0s 254us/sample - loss: 0.2719 - accuracy: 0.9444\n",
      "162/162 [==============================] - 0s 264us/sample - loss: 0.2964 - accuracy: 0.9136\n",
      "157/157 [==============================] - 0s 898us/sample - loss: 0.2831 - accuracy: 0.9299\n",
      "158/158 [==============================] - 0s 230us/sample - loss: 0.2874 - accuracy: 0.9241\n",
      "157/157 [==============================] - 0s 215us/sample - loss: 0.3035 - accuracy: 0.9236\n",
      "157/157 [==============================] - 0s 223us/sample - loss: 0.3158 - accuracy: 0.9172\n",
      "157/157 [==============================] - 0s 223us/sample - loss: 0.2881 - accuracy: 0.9236\n",
      "155/155 [==============================] - 0s 234us/sample - loss: 0.3024 - accuracy: 0.8903\n",
      "152/152 [==============================] - 0s 285us/sample - loss: 0.3075 - accuracy: 0.9013\n",
      "153/153 [==============================] - 0s 856us/sample - loss: 0.3108 - accuracy: 0.9020\n",
      "150/150 [==============================] - 0s 229us/sample - loss: 0.3006 - accuracy: 0.9200\n",
      "149/149 [==============================] - 0s 210us/sample - loss: 0.3134 - accuracy: 0.8926\n",
      "147/147 [==============================] - 0s 847us/sample - loss: 0.3626 - accuracy: 0.8707\n",
      "147/147 [==============================] - 0s 262us/sample - loss: 0.3240 - accuracy: 0.9048\n",
      "146/146 [==============================] - 0s 231us/sample - loss: 0.3133 - accuracy: 0.8904\n",
      "145/145 [==============================] - 0s 222us/sample - loss: 0.3356 - accuracy: 0.8759\n",
      "145/145 [==============================] - 0s 240us/sample - loss: 0.3231 - accuracy: 0.8897\n",
      "144/144 [==============================] - 0s 239us/sample - loss: 0.3221 - accuracy: 0.9028\n",
      "141/141 [==============================] - 0s 257us/sample - loss: 0.3602 - accuracy: 0.8936\n",
      "140/140 [==============================] - 0s 250us/sample - loss: 0.3272 - accuracy: 0.8857\n",
      "140/140 [==============================] - 0s 243us/sample - loss: 0.3403 - accuracy: 0.8643\n",
      "140/140 [==============================] - 0s 269us/sample - loss: 0.3208 - accuracy: 0.8786\n",
      "140/140 [==============================] - 0s 307us/sample - loss: 0.3378 - accuracy: 0.8571\n",
      "140/140 [==============================] - 0s 279us/sample - loss: 0.3139 - accuracy: 0.8929\n",
      "141/141 [==============================] - 0s 250us/sample - loss: 0.3116 - accuracy: 0.9220\n",
      "139/139 [==============================] - 0s 262us/sample - loss: 0.3060 - accuracy: 0.8777\n",
      "138/138 [==============================] - 0s 265us/sample - loss: 0.3198 - accuracy: 0.8841\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2842 samples, validate on 673 samples\n",
      "Epoch 1/300\n",
      "2842/2842 [==============================] - 3s 946us/sample - loss: 0.6595 - accuracy: 0.6122 - val_loss: 0.6775 - val_accuracy: 0.5527\n",
      "Epoch 2/300\n",
      "2842/2842 [==============================] - 1s 221us/sample - loss: 0.6272 - accuracy: 0.6816 - val_loss: 0.6630 - val_accuracy: 0.5825\n",
      "Epoch 3/300\n",
      "2842/2842 [==============================] - 1s 228us/sample - loss: 0.6078 - accuracy: 0.6999 - val_loss: 0.6534 - val_accuracy: 0.6048\n",
      "Epoch 4/300\n",
      "2842/2842 [==============================] - 1s 238us/sample - loss: 0.5904 - accuracy: 0.7291 - val_loss: 0.6462 - val_accuracy: 0.6211\n",
      "Epoch 5/300\n",
      "2842/2842 [==============================] - 1s 253us/sample - loss: 0.5831 - accuracy: 0.7368 - val_loss: 0.6405 - val_accuracy: 0.6360\n",
      "Epoch 6/300\n",
      "2842/2842 [==============================] - 1s 247us/sample - loss: 0.5679 - accuracy: 0.7505 - val_loss: 0.6357 - val_accuracy: 0.6478\n",
      "Epoch 7/300\n",
      "2842/2842 [==============================] - 1s 257us/sample - loss: 0.5603 - accuracy: 0.7653 - val_loss: 0.6317 - val_accuracy: 0.6464\n",
      "Epoch 8/300\n",
      "2842/2842 [==============================] - 1s 228us/sample - loss: 0.5509 - accuracy: 0.7635 - val_loss: 0.6282 - val_accuracy: 0.6508\n",
      "Epoch 9/300\n",
      "2842/2842 [==============================] - 1s 231us/sample - loss: 0.5437 - accuracy: 0.7780 - val_loss: 0.6253 - val_accuracy: 0.6568\n",
      "Epoch 10/300\n",
      "2842/2842 [==============================] - 1s 251us/sample - loss: 0.5358 - accuracy: 0.7776 - val_loss: 0.6227 - val_accuracy: 0.6627\n",
      "Epoch 11/300\n",
      "2842/2842 [==============================] - 1s 232us/sample - loss: 0.5317 - accuracy: 0.7783 - val_loss: 0.6204 - val_accuracy: 0.6686\n",
      "Epoch 12/300\n",
      "2842/2842 [==============================] - 1s 242us/sample - loss: 0.5221 - accuracy: 0.7875 - val_loss: 0.6185 - val_accuracy: 0.6701\n",
      "Epoch 13/300\n",
      "2842/2842 [==============================] - 1s 236us/sample - loss: 0.5175 - accuracy: 0.7822 - val_loss: 0.6168 - val_accuracy: 0.6701\n",
      "Epoch 14/300\n",
      "2842/2842 [==============================] - 1s 226us/sample - loss: 0.5105 - accuracy: 0.7928 - val_loss: 0.6153 - val_accuracy: 0.6731\n",
      "Epoch 15/300\n",
      "2842/2842 [==============================] - 1s 225us/sample - loss: 0.5050 - accuracy: 0.7980 - val_loss: 0.6140 - val_accuracy: 0.6746\n",
      "Epoch 16/300\n",
      "2842/2842 [==============================] - 1s 200us/sample - loss: 0.5005 - accuracy: 0.7970 - val_loss: 0.6128 - val_accuracy: 0.6776\n",
      "Epoch 17/300\n",
      "2842/2842 [==============================] - 1s 228us/sample - loss: 0.4936 - accuracy: 0.8033 - val_loss: 0.6119 - val_accuracy: 0.6790\n",
      "Epoch 18/300\n",
      "2842/2842 [==============================] - 1s 226us/sample - loss: 0.4936 - accuracy: 0.7970 - val_loss: 0.6111 - val_accuracy: 0.6805\n",
      "Epoch 19/300\n",
      "2842/2842 [==============================] - 1s 243us/sample - loss: 0.4883 - accuracy: 0.8040 - val_loss: 0.6104 - val_accuracy: 0.6820\n",
      "Epoch 20/300\n",
      "2842/2842 [==============================] - 1s 250us/sample - loss: 0.4838 - accuracy: 0.8054 - val_loss: 0.6098 - val_accuracy: 0.6880\n",
      "Epoch 21/300\n",
      "2842/2842 [==============================] - 1s 227us/sample - loss: 0.4774 - accuracy: 0.8068 - val_loss: 0.6094 - val_accuracy: 0.6880\n",
      "Epoch 22/300\n",
      "2842/2842 [==============================] - 1s 212us/sample - loss: 0.4759 - accuracy: 0.8096 - val_loss: 0.6090 - val_accuracy: 0.6895\n",
      "Epoch 23/300\n",
      "2842/2842 [==============================] - 1s 200us/sample - loss: 0.4711 - accuracy: 0.8107 - val_loss: 0.6087 - val_accuracy: 0.6895\n",
      "Epoch 24/300\n",
      "2842/2842 [==============================] - 1s 220us/sample - loss: 0.4714 - accuracy: 0.8114 - val_loss: 0.6085 - val_accuracy: 0.6909\n",
      "Epoch 25/300\n",
      "2842/2842 [==============================] - 1s 221us/sample - loss: 0.4643 - accuracy: 0.8198 - val_loss: 0.6084 - val_accuracy: 0.6939\n",
      "Epoch 26/300\n",
      "2842/2842 [==============================] - 1s 215us/sample - loss: 0.4617 - accuracy: 0.8142 - val_loss: 0.6084 - val_accuracy: 0.6954\n",
      "Epoch 27/300\n",
      "2842/2842 [==============================] - 1s 244us/sample - loss: 0.4560 - accuracy: 0.8156 - val_loss: 0.6083 - val_accuracy: 0.6969\n",
      "Epoch 28/300\n",
      "2842/2842 [==============================] - 1s 235us/sample - loss: 0.4555 - accuracy: 0.8125 - val_loss: 0.6084 - val_accuracy: 0.6969\n",
      "Epoch 29/300\n",
      "2842/2842 [==============================] - 1s 248us/sample - loss: 0.4521 - accuracy: 0.8209 - val_loss: 0.6085 - val_accuracy: 0.6984\n",
      "Epoch 30/300\n",
      "2842/2842 [==============================] - 1s 258us/sample - loss: 0.4506 - accuracy: 0.8170 - val_loss: 0.6087 - val_accuracy: 0.6999\n",
      "Epoch 00030: early stopping\n",
      "134/134 [==============================] - 0s 210us/sample - loss: 0.3344 - accuracy: 0.9179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [35:54, 1084.40s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.66s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.43s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 852.078125 steps, validate for 201.7109375 steps\n",
      "Epoch 1/300\n",
      "853/852 [==============================] - 25s 29ms/step - loss: 0.5629 - accuracy: 0.7353 - val_loss: 0.6091 - val_accuracy: 0.7259\n",
      "Epoch 2/300\n",
      "853/852 [==============================] - 24s 28ms/step - loss: 0.5009 - accuracy: 0.7839 - val_loss: 0.6147 - val_accuracy: 0.7221\n",
      "Epoch 3/300\n",
      "853/852 [==============================] - 24s 28ms/step - loss: 0.4872 - accuracy: 0.7881 - val_loss: 0.6182 - val_accuracy: 0.7195\n",
      "Epoch 4/300\n",
      "853/852 [==============================] - 24s 28ms/step - loss: 0.4763 - accuracy: 0.7917 - val_loss: 0.6197 - val_accuracy: 0.7177\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 852.078125 steps, validate for 201.7109375 steps\n",
      "Epoch 1/300\n",
      "853/852 [==============================] - 56s 66ms/step - loss: 0.4584 - accuracy: 0.7991 - val_loss: 0.6474 - val_accuracy: 0.7232\n",
      "Epoch 2/300\n",
      "853/852 [==============================] - 54s 64ms/step - loss: 0.4315 - accuracy: 0.8123 - val_loss: 0.6239 - val_accuracy: 0.7054\n",
      "Epoch 3/300\n",
      "853/852 [==============================] - 54s 64ms/step - loss: 0.4086 - accuracy: 0.8245 - val_loss: 0.6616 - val_accuracy: 0.7072\n",
      "Epoch 4/300\n",
      "853/852 [==============================] - 54s 64ms/step - loss: 0.3875 - accuracy: 0.8361 - val_loss: 0.6711 - val_accuracy: 0.7125\n",
      "Epoch 5/300\n",
      "853/852 [==============================] - 55s 64ms/step - loss: 0.3673 - accuracy: 0.8466 - val_loss: 0.7163 - val_accuracy: 0.6620\n",
      "Epoch 00005: early stopping\n",
      "106/106 [==============================] - 0s 2ms/sample - loss: 0.3730 - accuracy: 0.8774\n",
      "107/107 [==============================] - 0s 251us/sample - loss: 0.3480 - accuracy: 0.8879\n",
      "106/106 [==============================] - 0s 283us/sample - loss: 0.3923 - accuracy: 0.8585\n",
      "104/104 [==============================] - 0s 253us/sample - loss: 0.3431 - accuracy: 0.9135\n",
      "103/103 [==============================] - 0s 253us/sample - loss: 0.3728 - accuracy: 0.8641\n",
      "102/102 [==============================] - 0s 286us/sample - loss: 0.3298 - accuracy: 0.9216\n",
      "100/100 [==============================] - 0s 254us/sample - loss: 0.3420 - accuracy: 0.8800\n",
      "99/99 [==============================] - 0s 957us/sample - loss: 0.3628 - accuracy: 0.9091\n",
      "97/97 [==============================] - 0s 278us/sample - loss: 0.3588 - accuracy: 0.8866\n",
      "98/98 [==============================] - 0s 279us/sample - loss: 0.3379 - accuracy: 0.9082\n",
      "98/98 [==============================] - 0s 314us/sample - loss: 0.3500 - accuracy: 0.8878\n",
      "92/92 [==============================] - 0s 1ms/sample - loss: 0.3276 - accuracy: 0.9239\n",
      "95/95 [==============================] - 0s 1ms/sample - loss: 0.3212 - accuracy: 0.9053\n",
      "94/94 [==============================] - 0s 260us/sample - loss: 0.3398 - accuracy: 0.8830\n",
      "90/90 [==============================] - 0s 1ms/sample - loss: 0.3267 - accuracy: 0.8889\n",
      "91/91 [==============================] - 0s 238us/sample - loss: 0.3290 - accuracy: 0.9121\n",
      "87/87 [==============================] - 0s 272us/sample - loss: 0.3567 - accuracy: 0.8736\n",
      "87/87 [==============================] - 0s 229us/sample - loss: 0.3139 - accuracy: 0.9310\n",
      "87/87 [==============================] - 0s 223us/sample - loss: 0.3263 - accuracy: 0.8851\n",
      "77/77 [==============================] - 0s 361us/sample - loss: 0.3252 - accuracy: 0.8961\n",
      "77/77 [==============================] - 0s 243us/sample - loss: 0.3229 - accuracy: 0.8961\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.3657 - accuracy: 0.8667\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.3740 - accuracy: 0.8667\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.3312 - accuracy: 0.9067\n",
      "75/75 [==============================] - 0s 252us/sample - loss: 0.3345 - accuracy: 0.9200\n",
      "75/75 [==============================] - 0s 296us/sample - loss: 0.3583 - accuracy: 0.8800\n",
      "75/75 [==============================] - 0s 279us/sample - loss: 0.3621 - accuracy: 0.8667\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.3638 - accuracy: 0.8533\n",
      "74/74 [==============================] - 0s 267us/sample - loss: 0.4257 - accuracy: 0.8243\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 0.3849 - accuracy: 0.8533\n",
      "74/74 [==============================] - 0s 309us/sample - loss: 0.3582 - accuracy: 0.8784\n",
      "74/74 [==============================] - 0s 281us/sample - loss: 0.3956 - accuracy: 0.8514\n",
      "74/74 [==============================] - 0s 281us/sample - loss: 0.3631 - accuracy: 0.8784\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2899 samples, validate on 683 samples\n",
      "Epoch 1/300\n",
      "2899/2899 [==============================] - 3s 1ms/sample - loss: 0.6344 - accuracy: 0.6561 - val_loss: 0.6468 - val_accuracy: 0.6384\n",
      "Epoch 2/300\n",
      "2899/2899 [==============================] - 1s 238us/sample - loss: 0.5926 - accuracy: 0.7237 - val_loss: 0.6301 - val_accuracy: 0.6735\n",
      "Epoch 3/300\n",
      "2899/2899 [==============================] - 1s 231us/sample - loss: 0.5646 - accuracy: 0.7534 - val_loss: 0.6212 - val_accuracy: 0.6823\n",
      "Epoch 4/300\n",
      "2899/2899 [==============================] - 1s 243us/sample - loss: 0.5496 - accuracy: 0.7592 - val_loss: 0.6161 - val_accuracy: 0.6925\n",
      "Epoch 5/300\n",
      "2899/2899 [==============================] - 1s 240us/sample - loss: 0.5354 - accuracy: 0.7654 - val_loss: 0.6130 - val_accuracy: 0.6969\n",
      "Epoch 6/300\n",
      "2899/2899 [==============================] - 1s 214us/sample - loss: 0.5251 - accuracy: 0.7779 - val_loss: 0.6109 - val_accuracy: 0.6984\n",
      "Epoch 7/300\n",
      "2899/2899 [==============================] - 1s 234us/sample - loss: 0.5166 - accuracy: 0.7806 - val_loss: 0.6096 - val_accuracy: 0.7028\n",
      "Epoch 8/300\n",
      "2899/2899 [==============================] - 1s 241us/sample - loss: 0.5110 - accuracy: 0.7830 - val_loss: 0.6088 - val_accuracy: 0.7057\n",
      "Epoch 9/300\n",
      "2899/2899 [==============================] - 1s 188us/sample - loss: 0.5030 - accuracy: 0.7830 - val_loss: 0.6084 - val_accuracy: 0.7057\n",
      "Epoch 10/300\n",
      "2899/2899 [==============================] - 1s 203us/sample - loss: 0.4962 - accuracy: 0.7851 - val_loss: 0.6082 - val_accuracy: 0.7072\n",
      "Epoch 11/300\n",
      "2899/2899 [==============================] - 1s 220us/sample - loss: 0.4916 - accuracy: 0.7930 - val_loss: 0.6083 - val_accuracy: 0.7086\n",
      "Epoch 12/300\n",
      "2899/2899 [==============================] - 1s 247us/sample - loss: 0.4894 - accuracy: 0.7917 - val_loss: 0.6085 - val_accuracy: 0.7086\n",
      "Epoch 13/300\n",
      "2899/2899 [==============================] - 1s 230us/sample - loss: 0.4850 - accuracy: 0.7982 - val_loss: 0.6088 - val_accuracy: 0.7101\n",
      "Epoch 00013: early stopping\n",
      "67/67 [==============================] - 0s 183us/sample - loss: 0.2931 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [53:32, 1076.49s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.50s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.24s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 828.7265625 steps, validate for 200.25 steps\n",
      "Epoch 1/300\n",
      "829/828 [==============================] - 25s 30ms/step - loss: 0.5938 - accuracy: 0.7017 - val_loss: 0.6239 - val_accuracy: 0.7207\n",
      "Epoch 2/300\n",
      "829/828 [==============================] - 23s 28ms/step - loss: 0.5110 - accuracy: 0.7777 - val_loss: 0.6185 - val_accuracy: 0.7224\n",
      "Epoch 3/300\n",
      "829/828 [==============================] - 23s 28ms/step - loss: 0.4962 - accuracy: 0.7819 - val_loss: 0.6248 - val_accuracy: 0.7225\n",
      "Epoch 4/300\n",
      "829/828 [==============================] - 24s 28ms/step - loss: 0.4858 - accuracy: 0.7858 - val_loss: 0.6218 - val_accuracy: 0.7239\n",
      "Epoch 5/300\n",
      "829/828 [==============================] - 23s 28ms/step - loss: 0.4769 - accuracy: 0.7896 - val_loss: 0.6251 - val_accuracy: 0.7236\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 828.7265625 steps, validate for 200.25 steps\n",
      "Epoch 1/300\n",
      "829/828 [==============================] - 54s 66ms/step - loss: 0.4599 - accuracy: 0.7972 - val_loss: 0.6134 - val_accuracy: 0.7229\n",
      "Epoch 2/300\n",
      "829/828 [==============================] - 53s 65ms/step - loss: 0.4329 - accuracy: 0.8104 - val_loss: 0.6363 - val_accuracy: 0.7297\n",
      "Epoch 3/300\n",
      "829/828 [==============================] - 53s 64ms/step - loss: 0.4089 - accuracy: 0.8232 - val_loss: 0.6524 - val_accuracy: 0.6940\n",
      "Epoch 4/300\n",
      "829/828 [==============================] - 53s 64ms/step - loss: 0.3876 - accuracy: 0.8353 - val_loss: 0.6532 - val_accuracy: 0.7065\n",
      "Epoch 00004: early stopping\n",
      "207/207 [==============================] - 0s 1ms/sample - loss: 0.2505 - accuracy: 0.9614\n",
      "204/204 [==============================] - 0s 223us/sample - loss: 0.2531 - accuracy: 0.9559\n",
      "205/205 [==============================] - 0s 209us/sample - loss: 0.2556 - accuracy: 0.9659\n",
      "202/202 [==============================] - 0s 222us/sample - loss: 0.2652 - accuracy: 0.9505\n",
      "201/201 [==============================] - 0s 245us/sample - loss: 0.2758 - accuracy: 0.9353\n",
      "200/200 [==============================] - 0s 230us/sample - loss: 0.2661 - accuracy: 0.9550\n",
      "196/196 [==============================] - 0s 221us/sample - loss: 0.2684 - accuracy: 0.9439\n",
      "195/195 [==============================] - 0s 250us/sample - loss: 0.2579 - accuracy: 0.9385\n",
      "193/193 [==============================] - 0s 299us/sample - loss: 0.2554 - accuracy: 0.9689\n",
      "189/189 [==============================] - 0s 263us/sample - loss: 0.2547 - accuracy: 0.9471\n",
      "186/186 [==============================] - 0s 233us/sample - loss: 0.2521 - accuracy: 0.9570\n",
      "187/187 [==============================] - 0s 240us/sample - loss: 0.2525 - accuracy: 0.9626\n",
      "185/185 [==============================] - 0s 247us/sample - loss: 0.2866 - accuracy: 0.9189\n",
      "184/184 [==============================] - 0s 252us/sample - loss: 0.2934 - accuracy: 0.9239\n",
      "182/182 [==============================] - 0s 239us/sample - loss: 0.2718 - accuracy: 0.9396\n",
      "183/183 [==============================] - 0s 246us/sample - loss: 0.2736 - accuracy: 0.9290\n",
      "182/182 [==============================] - 0s 268us/sample - loss: 0.2764 - accuracy: 0.9451\n",
      "181/181 [==============================] - 0s 229us/sample - loss: 0.3086 - accuracy: 0.9282\n",
      "182/182 [==============================] - 0s 240us/sample - loss: 0.2946 - accuracy: 0.9066\n",
      "180/180 [==============================] - 0s 829us/sample - loss: 0.3014 - accuracy: 0.9222\n",
      "179/179 [==============================] - 0s 247us/sample - loss: 0.2760 - accuracy: 0.9385\n",
      "176/176 [==============================] - 0s 231us/sample - loss: 0.2638 - accuracy: 0.9261\n",
      "174/174 [==============================] - 0s 699us/sample - loss: 0.2778 - accuracy: 0.9368\n",
      "174/174 [==============================] - 0s 272us/sample - loss: 0.2382 - accuracy: 0.9598\n",
      "174/174 [==============================] - 0s 244us/sample - loss: 0.2619 - accuracy: 0.9540\n",
      "172/172 [==============================] - 0s 234us/sample - loss: 0.2532 - accuracy: 0.9651\n",
      "174/174 [==============================] - 0s 244us/sample - loss: 0.2491 - accuracy: 0.9598\n",
      "172/172 [==============================] - 0s 281us/sample - loss: 0.2474 - accuracy: 0.9709\n",
      "171/171 [==============================] - 0s 249us/sample - loss: 0.2412 - accuracy: 0.9591\n",
      "171/171 [==============================] - 0s 232us/sample - loss: 0.2612 - accuracy: 0.9532\n",
      "170/170 [==============================] - 0s 215us/sample - loss: 0.2452 - accuracy: 0.9706\n",
      "169/169 [==============================] - 0s 235us/sample - loss: 0.2506 - accuracy: 0.9704\n",
      "169/169 [==============================] - 0s 227us/sample - loss: 0.2699 - accuracy: 0.9586\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2813 samples, validate on 674 samples\n",
      "Epoch 1/300\n",
      "2813/2813 [==============================] - 3s 931us/sample - loss: 0.7403 - accuracy: 0.4671 - val_loss: 0.6950 - val_accuracy: 0.5504\n",
      "Epoch 2/300\n",
      "2813/2813 [==============================] - 1s 205us/sample - loss: 0.6987 - accuracy: 0.5322 - val_loss: 0.6759 - val_accuracy: 0.5786\n",
      "Epoch 3/300\n",
      "2813/2813 [==============================] - 1s 210us/sample - loss: 0.6714 - accuracy: 0.5887 - val_loss: 0.6626 - val_accuracy: 0.6172\n",
      "Epoch 4/300\n",
      "2813/2813 [==============================] - 1s 215us/sample - loss: 0.6556 - accuracy: 0.6253 - val_loss: 0.6526 - val_accuracy: 0.6202\n",
      "Epoch 5/300\n",
      "2813/2813 [==============================] - 1s 228us/sample - loss: 0.6329 - accuracy: 0.6502 - val_loss: 0.6446 - val_accuracy: 0.6335\n",
      "Epoch 6/300\n",
      "2813/2813 [==============================] - 1s 200us/sample - loss: 0.6233 - accuracy: 0.6722 - val_loss: 0.6380 - val_accuracy: 0.6617\n",
      "Epoch 7/300\n",
      "2813/2813 [==============================] - 1s 215us/sample - loss: 0.6139 - accuracy: 0.6776 - val_loss: 0.6323 - val_accuracy: 0.6662\n",
      "Epoch 8/300\n",
      "2813/2813 [==============================] - 1s 181us/sample - loss: 0.6062 - accuracy: 0.6889 - val_loss: 0.6275 - val_accuracy: 0.6751\n",
      "Epoch 9/300\n",
      "2813/2813 [==============================] - 1s 183us/sample - loss: 0.5957 - accuracy: 0.7057 - val_loss: 0.6231 - val_accuracy: 0.6751\n",
      "Epoch 10/300\n",
      "2813/2813 [==============================] - 1s 201us/sample - loss: 0.5848 - accuracy: 0.7192 - val_loss: 0.6194 - val_accuracy: 0.6780\n",
      "Epoch 11/300\n",
      "2813/2813 [==============================] - 1s 190us/sample - loss: 0.5791 - accuracy: 0.7273 - val_loss: 0.6161 - val_accuracy: 0.6810\n",
      "Epoch 12/300\n",
      "2813/2813 [==============================] - 1s 203us/sample - loss: 0.5705 - accuracy: 0.7344 - val_loss: 0.6131 - val_accuracy: 0.6810\n",
      "Epoch 13/300\n",
      "2813/2813 [==============================] - 1s 198us/sample - loss: 0.5633 - accuracy: 0.7401 - val_loss: 0.6104 - val_accuracy: 0.6825\n",
      "Epoch 14/300\n",
      "2813/2813 [==============================] - 1s 241us/sample - loss: 0.5569 - accuracy: 0.7501 - val_loss: 0.6080 - val_accuracy: 0.6899\n",
      "Epoch 15/300\n",
      "2813/2813 [==============================] - 1s 255us/sample - loss: 0.5534 - accuracy: 0.7597 - val_loss: 0.6059 - val_accuracy: 0.6929\n",
      "Epoch 16/300\n",
      "2813/2813 [==============================] - 1s 213us/sample - loss: 0.5475 - accuracy: 0.7597 - val_loss: 0.6040 - val_accuracy: 0.7033\n",
      "Epoch 17/300\n",
      "2813/2813 [==============================] - 1s 246us/sample - loss: 0.5433 - accuracy: 0.7597 - val_loss: 0.6022 - val_accuracy: 0.7047\n",
      "Epoch 18/300\n",
      "2813/2813 [==============================] - 1s 225us/sample - loss: 0.5373 - accuracy: 0.7622 - val_loss: 0.6008 - val_accuracy: 0.7092\n",
      "Epoch 19/300\n",
      "2813/2813 [==============================] - 1s 223us/sample - loss: 0.5338 - accuracy: 0.7622 - val_loss: 0.5994 - val_accuracy: 0.7107\n",
      "Epoch 20/300\n",
      "2813/2813 [==============================] - 1s 233us/sample - loss: 0.5281 - accuracy: 0.7693 - val_loss: 0.5982 - val_accuracy: 0.7136\n",
      "Epoch 21/300\n",
      "2813/2813 [==============================] - 1s 239us/sample - loss: 0.5227 - accuracy: 0.7768 - val_loss: 0.5972 - val_accuracy: 0.7166\n",
      "Epoch 22/300\n",
      "2813/2813 [==============================] - 1s 231us/sample - loss: 0.5204 - accuracy: 0.7796 - val_loss: 0.5963 - val_accuracy: 0.7181\n",
      "Epoch 23/300\n",
      "2813/2813 [==============================] - 1s 249us/sample - loss: 0.5171 - accuracy: 0.7800 - val_loss: 0.5955 - val_accuracy: 0.7196\n",
      "Epoch 24/300\n",
      "2813/2813 [==============================] - 1s 195us/sample - loss: 0.5135 - accuracy: 0.7853 - val_loss: 0.5948 - val_accuracy: 0.7196\n",
      "Epoch 25/300\n",
      "2813/2813 [==============================] - 0s 176us/sample - loss: 0.5067 - accuracy: 0.7871 - val_loss: 0.5942 - val_accuracy: 0.7226\n",
      "Epoch 26/300\n",
      "2813/2813 [==============================] - 1s 192us/sample - loss: 0.5054 - accuracy: 0.7892 - val_loss: 0.5938 - val_accuracy: 0.7211\n",
      "Epoch 27/300\n",
      "2813/2813 [==============================] - 1s 199us/sample - loss: 0.5001 - accuracy: 0.7910 - val_loss: 0.5934 - val_accuracy: 0.7211\n",
      "Epoch 28/300\n",
      "2813/2813 [==============================] - 1s 200us/sample - loss: 0.4989 - accuracy: 0.7924 - val_loss: 0.5931 - val_accuracy: 0.7211\n",
      "Epoch 29/300\n",
      "2813/2813 [==============================] - 1s 196us/sample - loss: 0.4943 - accuracy: 0.7895 - val_loss: 0.5929 - val_accuracy: 0.7226\n",
      "Epoch 30/300\n",
      "2813/2813 [==============================] - 1s 197us/sample - loss: 0.4899 - accuracy: 0.7959 - val_loss: 0.5927 - val_accuracy: 0.7270\n",
      "Epoch 31/300\n",
      "2813/2813 [==============================] - 1s 204us/sample - loss: 0.4865 - accuracy: 0.7988 - val_loss: 0.5926 - val_accuracy: 0.7285\n",
      "Epoch 32/300\n",
      "2813/2813 [==============================] - 1s 202us/sample - loss: 0.4869 - accuracy: 0.7938 - val_loss: 0.5925 - val_accuracy: 0.7285\n",
      "Epoch 33/300\n",
      "2813/2813 [==============================] - 1s 207us/sample - loss: 0.4811 - accuracy: 0.7956 - val_loss: 0.5925 - val_accuracy: 0.7270\n",
      "Epoch 34/300\n",
      "2813/2813 [==============================] - 1s 201us/sample - loss: 0.4798 - accuracy: 0.8013 - val_loss: 0.5925 - val_accuracy: 0.7270\n",
      "Epoch 35/300\n",
      "2813/2813 [==============================] - 1s 211us/sample - loss: 0.4763 - accuracy: 0.8013 - val_loss: 0.5925 - val_accuracy: 0.7270\n",
      "Epoch 00035: early stopping\n",
      "162/162 [==============================] - 0s 154us/sample - loss: 0.3001 - accuracy: 0.9815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [1:10:38, 1061.27s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.54s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.27s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 844.1953125 steps, validate for 201.046875 steps\n",
      "Epoch 1/300\n",
      "845/844 [==============================] - 24s 29ms/step - loss: 0.5466 - accuracy: 0.7565 - val_loss: 0.6308 - val_accuracy: 0.7222\n",
      "Epoch 2/300\n",
      "845/844 [==============================] - 23s 27ms/step - loss: 0.5024 - accuracy: 0.7824 - val_loss: 0.6229 - val_accuracy: 0.7227\n",
      "Epoch 3/300\n",
      "845/844 [==============================] - 23s 28ms/step - loss: 0.4884 - accuracy: 0.7871 - val_loss: 0.6292 - val_accuracy: 0.7202\n",
      "Epoch 4/300\n",
      "845/844 [==============================] - 23s 28ms/step - loss: 0.4785 - accuracy: 0.7909 - val_loss: 0.6344 - val_accuracy: 0.7210\n",
      "Epoch 5/300\n",
      "845/844 [==============================] - 23s 28ms/step - loss: 0.4701 - accuracy: 0.7940 - val_loss: 0.6403 - val_accuracy: 0.7201\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 844.1953125 steps, validate for 201.046875 steps\n",
      "Epoch 1/300\n",
      "845/844 [==============================] - 55s 65ms/step - loss: 0.4539 - accuracy: 0.8017 - val_loss: 0.6360 - val_accuracy: 0.7055\n",
      "Epoch 2/300\n",
      "845/844 [==============================] - 53s 63ms/step - loss: 0.4270 - accuracy: 0.8145 - val_loss: 0.6456 - val_accuracy: 0.7010\n",
      "Epoch 3/300\n",
      "845/844 [==============================] - 54s 64ms/step - loss: 0.4042 - accuracy: 0.8264 - val_loss: 0.6610 - val_accuracy: 0.7008\n",
      "Epoch 4/300\n",
      "845/844 [==============================] - 54s 63ms/step - loss: 0.3823 - accuracy: 0.8382 - val_loss: 0.6398 - val_accuracy: 0.7151\n",
      "Epoch 00004: early stopping\n",
      "139/139 [==============================] - 0s 1ms/sample - loss: 0.2677 - accuracy: 0.9424\n",
      "135/135 [==============================] - 0s 244us/sample - loss: 0.2364 - accuracy: 0.9704\n",
      "131/131 [==============================] - 0s 259us/sample - loss: 0.2405 - accuracy: 0.9466\n",
      "130/130 [==============================] - 0s 325us/sample - loss: 0.2308 - accuracy: 0.9769\n",
      "129/129 [==============================] - 0s 328us/sample - loss: 0.2816 - accuracy: 0.9457\n",
      "130/130 [==============================] - 0s 251us/sample - loss: 0.2251 - accuracy: 0.9769\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.2558 - accuracy: 0.9531\n",
      "128/128 [==============================] - 0s 206us/sample - loss: 0.2333 - accuracy: 0.9688\n",
      "126/126 [==============================] - 0s 241us/sample - loss: 0.2216 - accuracy: 0.9603\n",
      "128/128 [==============================] - 0s 248us/sample - loss: 0.2395 - accuracy: 0.9609\n",
      "127/127 [==============================] - 0s 288us/sample - loss: 0.2461 - accuracy: 0.9606\n",
      "126/126 [==============================] - 0s 286us/sample - loss: 0.2558 - accuracy: 0.9603\n",
      "125/125 [==============================] - 0s 333us/sample - loss: 0.2741 - accuracy: 0.9440\n",
      "126/126 [==============================] - 0s 253us/sample - loss: 0.2677 - accuracy: 0.9524\n",
      "124/124 [==============================] - 0s 265us/sample - loss: 0.2638 - accuracy: 0.9355\n",
      "123/123 [==============================] - 0s 266us/sample - loss: 0.2713 - accuracy: 0.9350\n",
      "121/121 [==============================] - 0s 261us/sample - loss: 0.2768 - accuracy: 0.9421\n",
      "119/119 [==============================] - 0s 299us/sample - loss: 0.2684 - accuracy: 0.9664\n",
      "121/121 [==============================] - 0s 261us/sample - loss: 0.2862 - accuracy: 0.9339\n",
      "118/118 [==============================] - 0s 254us/sample - loss: 0.2769 - accuracy: 0.9407\n",
      "117/117 [==============================] - 0s 263us/sample - loss: 0.2876 - accuracy: 0.9231\n",
      "117/117 [==============================] - 0s 248us/sample - loss: 0.2730 - accuracy: 0.9402\n",
      "114/114 [==============================] - 0s 273us/sample - loss: 0.2735 - accuracy: 0.9386\n",
      "113/113 [==============================] - 0s 264us/sample - loss: 0.2614 - accuracy: 0.9646\n",
      "113/113 [==============================] - 0s 302us/sample - loss: 0.2626 - accuracy: 0.9469\n",
      "112/112 [==============================] - 0s 286us/sample - loss: 0.2728 - accuracy: 0.9196\n",
      "112/112 [==============================] - 0s 253us/sample - loss: 0.2749 - accuracy: 0.9018\n",
      "110/110 [==============================] - 0s 242us/sample - loss: 0.2546 - accuracy: 0.9455\n",
      "110/110 [==============================] - 0s 281us/sample - loss: 0.2531 - accuracy: 0.9545\n",
      "109/109 [==============================] - 0s 283us/sample - loss: 0.2944 - accuracy: 0.9174\n",
      "110/110 [==============================] - 0s 252us/sample - loss: 0.2867 - accuracy: 0.9273\n",
      "109/109 [==============================] - 0s 251us/sample - loss: 0.3370 - accuracy: 0.9083\n",
      "107/107 [==============================] - 0s 264us/sample - loss: 0.3091 - accuracy: 0.9065\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2867 samples, validate on 679 samples\n",
      "Epoch 1/300\n",
      "2867/2867 [==============================] - 3s 878us/sample - loss: 0.6725 - accuracy: 0.5814 - val_loss: 0.6718 - val_accuracy: 0.5994\n",
      "Epoch 2/300\n",
      "2867/2867 [==============================] - 1s 214us/sample - loss: 0.6390 - accuracy: 0.6299 - val_loss: 0.6535 - val_accuracy: 0.6406\n",
      "Epoch 3/300\n",
      "2867/2867 [==============================] - 1s 214us/sample - loss: 0.6159 - accuracy: 0.6829 - val_loss: 0.6418 - val_accuracy: 0.6627\n",
      "Epoch 4/300\n",
      "2867/2867 [==============================] - 1s 219us/sample - loss: 0.6005 - accuracy: 0.7060 - val_loss: 0.6329 - val_accuracy: 0.6745\n",
      "Epoch 5/300\n",
      "2867/2867 [==============================] - 1s 221us/sample - loss: 0.5843 - accuracy: 0.7269 - val_loss: 0.6258 - val_accuracy: 0.6892\n",
      "Epoch 6/300\n",
      "2867/2867 [==============================] - 1s 209us/sample - loss: 0.5716 - accuracy: 0.7363 - val_loss: 0.6201 - val_accuracy: 0.6996\n",
      "Epoch 7/300\n",
      "2867/2867 [==============================] - 1s 178us/sample - loss: 0.5655 - accuracy: 0.7513 - val_loss: 0.6154 - val_accuracy: 0.6981\n",
      "Epoch 8/300\n",
      "2867/2867 [==============================] - 1s 193us/sample - loss: 0.5563 - accuracy: 0.7593 - val_loss: 0.6114 - val_accuracy: 0.7040\n",
      "Epoch 9/300\n",
      "2867/2867 [==============================] - 1s 216us/sample - loss: 0.5493 - accuracy: 0.7667 - val_loss: 0.6078 - val_accuracy: 0.7099\n",
      "Epoch 10/300\n",
      "2867/2867 [==============================] - 1s 220us/sample - loss: 0.5435 - accuracy: 0.7660 - val_loss: 0.6049 - val_accuracy: 0.7084\n",
      "Epoch 11/300\n",
      "2867/2867 [==============================] - 1s 215us/sample - loss: 0.5384 - accuracy: 0.7687 - val_loss: 0.6024 - val_accuracy: 0.7128\n",
      "Epoch 12/300\n",
      "2867/2867 [==============================] - 1s 190us/sample - loss: 0.5315 - accuracy: 0.7764 - val_loss: 0.6001 - val_accuracy: 0.7113\n",
      "Epoch 13/300\n",
      "2867/2867 [==============================] - 1s 211us/sample - loss: 0.5285 - accuracy: 0.7757 - val_loss: 0.5982 - val_accuracy: 0.7113\n",
      "Epoch 14/300\n",
      "2867/2867 [==============================] - 1s 193us/sample - loss: 0.5232 - accuracy: 0.7900 - val_loss: 0.5965 - val_accuracy: 0.7128\n",
      "Epoch 15/300\n",
      "2867/2867 [==============================] - 1s 177us/sample - loss: 0.5160 - accuracy: 0.7824 - val_loss: 0.5951 - val_accuracy: 0.7143\n",
      "Epoch 16/300\n",
      "2867/2867 [==============================] - 1s 207us/sample - loss: 0.5167 - accuracy: 0.7820 - val_loss: 0.5937 - val_accuracy: 0.7158\n",
      "Epoch 17/300\n",
      "2867/2867 [==============================] - 1s 209us/sample - loss: 0.5084 - accuracy: 0.7858 - val_loss: 0.5927 - val_accuracy: 0.7187\n",
      "Epoch 18/300\n",
      "2867/2867 [==============================] - 1s 201us/sample - loss: 0.5027 - accuracy: 0.7893 - val_loss: 0.5917 - val_accuracy: 0.7187\n",
      "Epoch 19/300\n",
      "2867/2867 [==============================] - 1s 205us/sample - loss: 0.5009 - accuracy: 0.7879 - val_loss: 0.5910 - val_accuracy: 0.7216\n",
      "Epoch 20/300\n",
      "2867/2867 [==============================] - 1s 207us/sample - loss: 0.4964 - accuracy: 0.7876 - val_loss: 0.5903 - val_accuracy: 0.7216\n",
      "Epoch 21/300\n",
      "2867/2867 [==============================] - 1s 214us/sample - loss: 0.4909 - accuracy: 0.7921 - val_loss: 0.5897 - val_accuracy: 0.7202\n",
      "Epoch 22/300\n",
      "2867/2867 [==============================] - 1s 212us/sample - loss: 0.4880 - accuracy: 0.7946 - val_loss: 0.5893 - val_accuracy: 0.7202\n",
      "Epoch 23/300\n",
      "2867/2867 [==============================] - 1s 184us/sample - loss: 0.4837 - accuracy: 0.7973 - val_loss: 0.5889 - val_accuracy: 0.7202\n",
      "Epoch 24/300\n",
      "2867/2867 [==============================] - 0s 172us/sample - loss: 0.4858 - accuracy: 0.7953 - val_loss: 0.5887 - val_accuracy: 0.7216\n",
      "Epoch 25/300\n",
      "2867/2867 [==============================] - 1s 177us/sample - loss: 0.4802 - accuracy: 0.7960 - val_loss: 0.5884 - val_accuracy: 0.7202\n",
      "Epoch 26/300\n",
      "2867/2867 [==============================] - 1s 198us/sample - loss: 0.4810 - accuracy: 0.7886 - val_loss: 0.5883 - val_accuracy: 0.7216\n",
      "Epoch 27/300\n",
      "2867/2867 [==============================] - 1s 196us/sample - loss: 0.4787 - accuracy: 0.7960 - val_loss: 0.5882 - val_accuracy: 0.7246\n",
      "Epoch 28/300\n",
      "2867/2867 [==============================] - 1s 201us/sample - loss: 0.4728 - accuracy: 0.8015 - val_loss: 0.5881 - val_accuracy: 0.7246\n",
      "Epoch 29/300\n",
      "2867/2867 [==============================] - 1s 208us/sample - loss: 0.4716 - accuracy: 0.7980 - val_loss: 0.5882 - val_accuracy: 0.7246\n",
      "Epoch 30/300\n",
      "2867/2867 [==============================] - 1s 199us/sample - loss: 0.4674 - accuracy: 0.7984 - val_loss: 0.5882 - val_accuracy: 0.7246\n",
      "Epoch 31/300\n",
      "2867/2867 [==============================] - 1s 234us/sample - loss: 0.4662 - accuracy: 0.8001 - val_loss: 0.5882 - val_accuracy: 0.7261\n",
      "Epoch 00031: early stopping\n",
      "103/103 [==============================] - 0s 157us/sample - loss: 0.2942 - accuracy: 0.9903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [1:27:34, 1047.67s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.52s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.31s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 849.4375 steps, validate for 203.6171875 steps\n",
      "Epoch 1/300\n",
      "850/849 [==============================] - 25s 29ms/step - loss: 0.5642 - accuracy: 0.7333 - val_loss: 0.5915 - val_accuracy: 0.7355\n",
      "Epoch 2/300\n",
      "850/849 [==============================] - 23s 28ms/step - loss: 0.5002 - accuracy: 0.7828 - val_loss: 0.6024 - val_accuracy: 0.7313\n",
      "Epoch 3/300\n",
      "850/849 [==============================] - 24s 28ms/step - loss: 0.4862 - accuracy: 0.7874 - val_loss: 0.6036 - val_accuracy: 0.7302\n",
      "Epoch 4/300\n",
      "850/849 [==============================] - 24s 28ms/step - loss: 0.4759 - accuracy: 0.7909 - val_loss: 0.6089 - val_accuracy: 0.7303\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 849.4375 steps, validate for 203.6171875 steps\n",
      "Epoch 1/300\n",
      "850/849 [==============================] - 55s 65ms/step - loss: 0.4583 - accuracy: 0.7985 - val_loss: 0.6172 - val_accuracy: 0.7158\n",
      "Epoch 2/300\n",
      "850/849 [==============================] - 54s 63ms/step - loss: 0.4313 - accuracy: 0.8110 - val_loss: 0.6202 - val_accuracy: 0.7169\n",
      "Epoch 3/300\n",
      "850/849 [==============================] - 54s 63ms/step - loss: 0.4083 - accuracy: 0.8242 - val_loss: 0.6180 - val_accuracy: 0.7253\n",
      "Epoch 4/300\n",
      "850/849 [==============================] - 54s 63ms/step - loss: 0.3869 - accuracy: 0.8364 - val_loss: 0.6271 - val_accuracy: 0.7135\n",
      "Epoch 00004: early stopping\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.3198 - accuracy: 0.8571\n",
      "103/103 [==============================] - 0s 220us/sample - loss: 0.3729 - accuracy: 0.8350\n",
      "98/98 [==============================] - 0s 240us/sample - loss: 0.3700 - accuracy: 0.8265\n",
      "97/97 [==============================] - 0s 232us/sample - loss: 0.3523 - accuracy: 0.8557\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.3733 - accuracy: 0.8854\n",
      "96/96 [==============================] - 0s 203us/sample - loss: 0.3986 - accuracy: 0.8021\n",
      "96/96 [==============================] - 0s 198us/sample - loss: 0.3940 - accuracy: 0.8542\n",
      "92/92 [==============================] - 0s 242us/sample - loss: 0.3843 - accuracy: 0.8587\n",
      "91/91 [==============================] - 0s 250us/sample - loss: 0.4369 - accuracy: 0.7912\n",
      "92/92 [==============================] - 0s 230us/sample - loss: 0.4298 - accuracy: 0.8370\n",
      "91/91 [==============================] - 0s 241us/sample - loss: 0.4195 - accuracy: 0.8132\n",
      "90/90 [==============================] - 0s 241us/sample - loss: 0.4116 - accuracy: 0.8222\n",
      "90/90 [==============================] - 0s 236us/sample - loss: 0.4495 - accuracy: 0.8111\n",
      "89/89 [==============================] - 0s 315us/sample - loss: 0.4203 - accuracy: 0.8539\n",
      "89/89 [==============================] - 0s 243us/sample - loss: 0.4127 - accuracy: 0.8202\n",
      "88/88 [==============================] - 0s 283us/sample - loss: 0.3979 - accuracy: 0.8636\n",
      "88/88 [==============================] - 0s 277us/sample - loss: 0.3773 - accuracy: 0.8636\n",
      "88/88 [==============================] - 0s 264us/sample - loss: 0.4305 - accuracy: 0.8068\n",
      "89/89 [==============================] - 0s 251us/sample - loss: 0.4073 - accuracy: 0.8427\n",
      "87/87 [==============================] - 0s 260us/sample - loss: 0.3919 - accuracy: 0.8161\n",
      "88/88 [==============================] - 0s 283us/sample - loss: 0.4078 - accuracy: 0.8750\n",
      "88/88 [==============================] - 0s 279us/sample - loss: 0.4514 - accuracy: 0.7500\n",
      "86/86 [==============================] - 0s 246us/sample - loss: 0.4502 - accuracy: 0.8140\n",
      "86/86 [==============================] - 0s 268us/sample - loss: 0.4471 - accuracy: 0.8140\n",
      "87/87 [==============================] - 0s 346us/sample - loss: 0.4022 - accuracy: 0.8276\n",
      "87/87 [==============================] - 0s 283us/sample - loss: 0.4118 - accuracy: 0.7816\n",
      "86/86 [==============================] - 0s 264us/sample - loss: 0.4592 - accuracy: 0.7674\n",
      "87/87 [==============================] - 0s 265us/sample - loss: 0.4197 - accuracy: 0.8391\n",
      "85/85 [==============================] - 0s 307us/sample - loss: 0.4486 - accuracy: 0.7765\n",
      "87/87 [==============================] - 0s 320us/sample - loss: 0.4795 - accuracy: 0.8046\n",
      "86/86 [==============================] - 0s 275us/sample - loss: 0.4339 - accuracy: 0.8372\n",
      "86/86 [==============================] - 0s 259us/sample - loss: 0.4305 - accuracy: 0.8023\n",
      "86/86 [==============================] - 0s 284us/sample - loss: 0.4496 - accuracy: 0.8140\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2882 samples, validate on 685 samples\n",
      "Epoch 1/300\n",
      "2882/2882 [==============================] - 3s 925us/sample - loss: 0.7170 - accuracy: 0.4865 - val_loss: 0.6820 - val_accuracy: 0.5679\n",
      "Epoch 2/300\n",
      "2882/2882 [==============================] - 1s 208us/sample - loss: 0.6785 - accuracy: 0.5677 - val_loss: 0.6666 - val_accuracy: 0.6015\n",
      "Epoch 3/300\n",
      "2882/2882 [==============================] - 1s 198us/sample - loss: 0.6583 - accuracy: 0.6065 - val_loss: 0.6565 - val_accuracy: 0.6350\n",
      "Epoch 4/300\n",
      "2882/2882 [==============================] - 1s 202us/sample - loss: 0.6457 - accuracy: 0.6499 - val_loss: 0.6485 - val_accuracy: 0.6555\n",
      "Epoch 5/300\n",
      "2882/2882 [==============================] - 1s 230us/sample - loss: 0.6307 - accuracy: 0.6773 - val_loss: 0.6420 - val_accuracy: 0.6730\n",
      "Epoch 6/300\n",
      "2882/2882 [==============================] - 1s 199us/sample - loss: 0.6214 - accuracy: 0.6829 - val_loss: 0.6366 - val_accuracy: 0.6803\n",
      "Epoch 7/300\n",
      "2882/2882 [==============================] - 1s 195us/sample - loss: 0.6131 - accuracy: 0.6995 - val_loss: 0.6322 - val_accuracy: 0.6832\n",
      "Epoch 8/300\n",
      "2882/2882 [==============================] - 1s 181us/sample - loss: 0.5992 - accuracy: 0.7252 - val_loss: 0.6282 - val_accuracy: 0.6920\n",
      "Epoch 9/300\n",
      "2882/2882 [==============================] - 1s 221us/sample - loss: 0.5939 - accuracy: 0.7300 - val_loss: 0.6245 - val_accuracy: 0.6993\n",
      "Epoch 10/300\n",
      "2882/2882 [==============================] - 1s 227us/sample - loss: 0.5880 - accuracy: 0.7412 - val_loss: 0.6213 - val_accuracy: 0.7051\n",
      "Epoch 11/300\n",
      "2882/2882 [==============================] - 1s 192us/sample - loss: 0.5823 - accuracy: 0.7363 - val_loss: 0.6184 - val_accuracy: 0.7095\n",
      "Epoch 12/300\n",
      "2882/2882 [==============================] - 1s 224us/sample - loss: 0.5744 - accuracy: 0.7495 - val_loss: 0.6159 - val_accuracy: 0.7080\n",
      "Epoch 13/300\n",
      "2882/2882 [==============================] - 1s 219us/sample - loss: 0.5692 - accuracy: 0.7533 - val_loss: 0.6136 - val_accuracy: 0.7095\n",
      "Epoch 14/300\n",
      "2882/2882 [==============================] - 1s 228us/sample - loss: 0.5649 - accuracy: 0.7509 - val_loss: 0.6116 - val_accuracy: 0.7109\n",
      "Epoch 15/300\n",
      "2882/2882 [==============================] - 1s 236us/sample - loss: 0.5564 - accuracy: 0.7627 - val_loss: 0.6096 - val_accuracy: 0.7080\n",
      "Epoch 16/300\n",
      "2882/2882 [==============================] - 1s 221us/sample - loss: 0.5509 - accuracy: 0.7668 - val_loss: 0.6079 - val_accuracy: 0.7066\n",
      "Epoch 17/300\n",
      "2882/2882 [==============================] - 1s 225us/sample - loss: 0.5480 - accuracy: 0.7689 - val_loss: 0.6064 - val_accuracy: 0.7095\n",
      "Epoch 18/300\n",
      "2882/2882 [==============================] - 1s 216us/sample - loss: 0.5420 - accuracy: 0.7682 - val_loss: 0.6049 - val_accuracy: 0.7124\n",
      "Epoch 19/300\n",
      "2882/2882 [==============================] - 1s 221us/sample - loss: 0.5370 - accuracy: 0.7814 - val_loss: 0.6037 - val_accuracy: 0.7153\n",
      "Epoch 20/300\n",
      "2882/2882 [==============================] - 1s 233us/sample - loss: 0.5354 - accuracy: 0.7772 - val_loss: 0.6026 - val_accuracy: 0.7153\n",
      "Epoch 21/300\n",
      "2882/2882 [==============================] - 1s 219us/sample - loss: 0.5282 - accuracy: 0.7797 - val_loss: 0.6015 - val_accuracy: 0.7139\n",
      "Epoch 22/300\n",
      "2882/2882 [==============================] - 1s 185us/sample - loss: 0.5271 - accuracy: 0.7776 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
      "Epoch 23/300\n",
      "2882/2882 [==============================] - 1s 184us/sample - loss: 0.5159 - accuracy: 0.7835 - val_loss: 0.5998 - val_accuracy: 0.7168\n",
      "Epoch 24/300\n",
      "2882/2882 [==============================] - 1s 188us/sample - loss: 0.5169 - accuracy: 0.7831 - val_loss: 0.5991 - val_accuracy: 0.7153\n",
      "Epoch 25/300\n",
      "2882/2882 [==============================] - 1s 227us/sample - loss: 0.5112 - accuracy: 0.7859 - val_loss: 0.5984 - val_accuracy: 0.7139\n",
      "Epoch 26/300\n",
      "2882/2882 [==============================] - 1s 212us/sample - loss: 0.5108 - accuracy: 0.7849 - val_loss: 0.5978 - val_accuracy: 0.7168\n",
      "Epoch 27/300\n",
      "2882/2882 [==============================] - 1s 212us/sample - loss: 0.5061 - accuracy: 0.7866 - val_loss: 0.5974 - val_accuracy: 0.7182\n",
      "Epoch 28/300\n",
      "2882/2882 [==============================] - 1s 203us/sample - loss: 0.5031 - accuracy: 0.7897 - val_loss: 0.5969 - val_accuracy: 0.7197\n",
      "Epoch 29/300\n",
      "2882/2882 [==============================] - 1s 200us/sample - loss: 0.4965 - accuracy: 0.7890 - val_loss: 0.5966 - val_accuracy: 0.7197\n",
      "Epoch 30/300\n",
      "2882/2882 [==============================] - 1s 188us/sample - loss: 0.4966 - accuracy: 0.7873 - val_loss: 0.5963 - val_accuracy: 0.7212\n",
      "Epoch 31/300\n",
      "2882/2882 [==============================] - 1s 188us/sample - loss: 0.4935 - accuracy: 0.7942 - val_loss: 0.5960 - val_accuracy: 0.7212\n",
      "Epoch 32/300\n",
      "2882/2882 [==============================] - 1s 212us/sample - loss: 0.4935 - accuracy: 0.7929 - val_loss: 0.5958 - val_accuracy: 0.7241\n",
      "Epoch 33/300\n",
      "2882/2882 [==============================] - 1s 194us/sample - loss: 0.4876 - accuracy: 0.7946 - val_loss: 0.5957 - val_accuracy: 0.7241\n",
      "Epoch 34/300\n",
      "2882/2882 [==============================] - 1s 202us/sample - loss: 0.4851 - accuracy: 0.7918 - val_loss: 0.5956 - val_accuracy: 0.7241\n",
      "Epoch 35/300\n",
      "2882/2882 [==============================] - 1s 194us/sample - loss: 0.4798 - accuracy: 0.8001 - val_loss: 0.5956 - val_accuracy: 0.7241\n",
      "Epoch 36/300\n",
      "2882/2882 [==============================] - 1s 221us/sample - loss: 0.4764 - accuracy: 0.7988 - val_loss: 0.5957 - val_accuracy: 0.7241\n",
      "Epoch 37/300\n",
      "2882/2882 [==============================] - 1s 207us/sample - loss: 0.4737 - accuracy: 0.7977 - val_loss: 0.5958 - val_accuracy: 0.7241\n",
      "Epoch 38/300\n",
      "2882/2882 [==============================] - 1s 208us/sample - loss: 0.4697 - accuracy: 0.8033 - val_loss: 0.5959 - val_accuracy: 0.7241\n",
      "Epoch 00038: early stopping\n",
      "82/82 [==============================] - 0s 167us/sample - loss: 0.3283 - accuracy: 0.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [1:44:16, 1033.97s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.43s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.19s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 839.1171875 steps, validate for 199.59375 steps\n",
      "Epoch 1/300\n",
      "840/839 [==============================] - 24s 29ms/step - loss: 0.5512 - accuracy: 0.7508 - val_loss: 0.6164 - val_accuracy: 0.7214\n",
      "Epoch 2/300\n",
      "840/839 [==============================] - 23s 27ms/step - loss: 0.5059 - accuracy: 0.7796 - val_loss: 0.6075 - val_accuracy: 0.7244\n",
      "Epoch 3/300\n",
      "840/839 [==============================] - 23s 28ms/step - loss: 0.4914 - accuracy: 0.7840 - val_loss: 0.6073 - val_accuracy: 0.7273\n",
      "Epoch 4/300\n",
      "840/839 [==============================] - 24s 28ms/step - loss: 0.4802 - accuracy: 0.7886 - val_loss: 0.6090 - val_accuracy: 0.7284\n",
      "Epoch 5/300\n",
      "840/839 [==============================] - 24s 28ms/step - loss: 0.4707 - accuracy: 0.7920 - val_loss: 0.6143 - val_accuracy: 0.7286\n",
      "Epoch 6/300\n",
      "840/839 [==============================] - 23s 28ms/step - loss: 0.4621 - accuracy: 0.7960 - val_loss: 0.6203 - val_accuracy: 0.7302\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 839.1171875 steps, validate for 199.59375 steps\n",
      "Epoch 1/300\n",
      "840/839 [==============================] - 54s 64ms/step - loss: 0.4455 - accuracy: 0.8032 - val_loss: 0.6431 - val_accuracy: 0.6805\n",
      "Epoch 2/300\n",
      "840/839 [==============================] - 53s 63ms/step - loss: 0.4199 - accuracy: 0.8163 - val_loss: 0.6394 - val_accuracy: 0.7158\n",
      "Epoch 3/300\n",
      "840/839 [==============================] - 52s 62ms/step - loss: 0.3974 - accuracy: 0.8278 - val_loss: 0.6761 - val_accuracy: 0.7218\n",
      "Epoch 4/300\n",
      "840/839 [==============================] - 53s 63ms/step - loss: 0.3771 - accuracy: 0.8406 - val_loss: 0.6634 - val_accuracy: 0.7288\n",
      "Epoch 5/300\n",
      "840/839 [==============================] - 53s 63ms/step - loss: 0.3577 - accuracy: 0.8513 - val_loss: 0.6761 - val_accuracy: 0.7232\n",
      "Epoch 00005: early stopping\n",
      "162/162 [==============================] - 0s 1ms/sample - loss: 0.2254 - accuracy: 0.9630\n",
      "160/160 [==============================] - 0s 1ms/sample - loss: 0.1948 - accuracy: 0.9750\n",
      "158/158 [==============================] - 0s 211us/sample - loss: 0.2315 - accuracy: 0.9684\n",
      "155/155 [==============================] - 0s 227us/sample - loss: 0.2317 - accuracy: 0.9806\n",
      "153/153 [==============================] - 0s 233us/sample - loss: 0.2293 - accuracy: 0.9608\n",
      "153/153 [==============================] - 0s 212us/sample - loss: 0.2169 - accuracy: 0.9477\n",
      "150/150 [==============================] - 0s 232us/sample - loss: 0.2219 - accuracy: 0.9600\n",
      "150/150 [==============================] - 0s 236us/sample - loss: 0.2172 - accuracy: 0.9733\n",
      "152/152 [==============================] - 0s 264us/sample - loss: 0.2660 - accuracy: 0.9539\n",
      "150/150 [==============================] - 0s 239us/sample - loss: 0.2497 - accuracy: 0.9533\n",
      "150/150 [==============================] - 0s 257us/sample - loss: 0.2167 - accuracy: 0.9600\n",
      "147/147 [==============================] - 0s 260us/sample - loss: 0.2451 - accuracy: 0.9524\n",
      "148/148 [==============================] - 0s 256us/sample - loss: 0.2395 - accuracy: 0.9527\n",
      "146/146 [==============================] - 0s 244us/sample - loss: 0.2292 - accuracy: 0.9452\n",
      "145/145 [==============================] - 0s 262us/sample - loss: 0.2375 - accuracy: 0.9448\n",
      "146/146 [==============================] - 0s 286us/sample - loss: 0.2515 - accuracy: 0.9521\n",
      "145/145 [==============================] - 0s 241us/sample - loss: 0.2443 - accuracy: 0.9517\n",
      "143/143 [==============================] - 0s 271us/sample - loss: 0.2612 - accuracy: 0.9441\n",
      "141/141 [==============================] - 0s 250us/sample - loss: 0.2491 - accuracy: 0.9645\n",
      "141/141 [==============================] - 0s 256us/sample - loss: 0.2403 - accuracy: 0.9433\n",
      "142/142 [==============================] - 0s 253us/sample - loss: 0.2362 - accuracy: 0.9296\n",
      "142/142 [==============================] - 0s 251us/sample - loss: 0.2471 - accuracy: 0.9296\n",
      "143/143 [==============================] - 0s 254us/sample - loss: 0.2408 - accuracy: 0.9510\n",
      "140/140 [==============================] - 0s 258us/sample - loss: 0.2423 - accuracy: 0.9500\n",
      "143/143 [==============================] - 0s 294us/sample - loss: 0.2574 - accuracy: 0.9161\n",
      "142/142 [==============================] - 0s 265us/sample - loss: 0.2592 - accuracy: 0.9366\n",
      "141/141 [==============================] - 0s 251us/sample - loss: 0.2376 - accuracy: 0.9433\n",
      "140/140 [==============================] - 0s 271us/sample - loss: 0.2486 - accuracy: 0.9143\n",
      "140/140 [==============================] - 0s 252us/sample - loss: 0.2523 - accuracy: 0.9286\n",
      "139/139 [==============================] - 0s 273us/sample - loss: 0.2744 - accuracy: 0.9137\n",
      "138/138 [==============================] - 0s 260us/sample - loss: 0.2788 - accuracy: 0.9348\n",
      "139/139 [==============================] - 0s 264us/sample - loss: 0.2559 - accuracy: 0.9209\n",
      "139/139 [==============================] - 0s 246us/sample - loss: 0.2552 - accuracy: 0.9137\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2847 samples, validate on 672 samples\n",
      "Epoch 1/300\n",
      "2847/2847 [==============================] - 2s 852us/sample - loss: 0.7544 - accuracy: 0.4292 - val_loss: 0.7036 - val_accuracy: 0.4940\n",
      "Epoch 2/300\n",
      "2847/2847 [==============================] - 1s 202us/sample - loss: 0.7070 - accuracy: 0.5300 - val_loss: 0.6793 - val_accuracy: 0.5685\n",
      "Epoch 3/300\n",
      "2847/2847 [==============================] - 1s 206us/sample - loss: 0.6737 - accuracy: 0.5957 - val_loss: 0.6628 - val_accuracy: 0.6116\n",
      "Epoch 4/300\n",
      "2847/2847 [==============================] - 1s 205us/sample - loss: 0.6545 - accuracy: 0.6294 - val_loss: 0.6498 - val_accuracy: 0.6443\n",
      "Epoch 5/300\n",
      "2847/2847 [==============================] - 1s 191us/sample - loss: 0.6341 - accuracy: 0.6765 - val_loss: 0.6399 - val_accuracy: 0.6726\n",
      "Epoch 6/300\n",
      "2847/2847 [==============================] - 1s 215us/sample - loss: 0.6209 - accuracy: 0.6990 - val_loss: 0.6314 - val_accuracy: 0.6771\n",
      "Epoch 7/300\n",
      "2847/2847 [==============================] - 1s 194us/sample - loss: 0.6051 - accuracy: 0.7271 - val_loss: 0.6244 - val_accuracy: 0.6801\n",
      "Epoch 8/300\n",
      "2847/2847 [==============================] - 1s 204us/sample - loss: 0.5961 - accuracy: 0.7292 - val_loss: 0.6182 - val_accuracy: 0.6949\n",
      "Epoch 9/300\n",
      "2847/2847 [==============================] - 1s 205us/sample - loss: 0.5845 - accuracy: 0.7471 - val_loss: 0.6127 - val_accuracy: 0.6994\n",
      "Epoch 10/300\n",
      "2847/2847 [==============================] - 1s 191us/sample - loss: 0.5728 - accuracy: 0.7647 - val_loss: 0.6081 - val_accuracy: 0.7054\n",
      "Epoch 11/300\n",
      "2847/2847 [==============================] - 0s 174us/sample - loss: 0.5610 - accuracy: 0.7654 - val_loss: 0.6041 - val_accuracy: 0.7098\n",
      "Epoch 12/300\n",
      "2847/2847 [==============================] - 1s 191us/sample - loss: 0.5544 - accuracy: 0.7773 - val_loss: 0.6006 - val_accuracy: 0.7113\n",
      "Epoch 13/300\n",
      "2847/2847 [==============================] - 1s 209us/sample - loss: 0.5470 - accuracy: 0.7777 - val_loss: 0.5974 - val_accuracy: 0.7143\n",
      "Epoch 14/300\n",
      "2847/2847 [==============================] - 1s 209us/sample - loss: 0.5409 - accuracy: 0.7766 - val_loss: 0.5948 - val_accuracy: 0.7158\n",
      "Epoch 15/300\n",
      "2847/2847 [==============================] - 1s 211us/sample - loss: 0.5364 - accuracy: 0.7815 - val_loss: 0.5925 - val_accuracy: 0.7173\n",
      "Epoch 16/300\n",
      "2847/2847 [==============================] - 1s 202us/sample - loss: 0.5266 - accuracy: 0.7826 - val_loss: 0.5906 - val_accuracy: 0.7202\n",
      "Epoch 17/300\n",
      "2847/2847 [==============================] - 1s 184us/sample - loss: 0.5216 - accuracy: 0.7875 - val_loss: 0.5889 - val_accuracy: 0.7202\n",
      "Epoch 18/300\n",
      "2847/2847 [==============================] - 1s 201us/sample - loss: 0.5165 - accuracy: 0.7924 - val_loss: 0.5875 - val_accuracy: 0.7217\n",
      "Epoch 19/300\n",
      "2847/2847 [==============================] - 1s 217us/sample - loss: 0.5127 - accuracy: 0.7889 - val_loss: 0.5864 - val_accuracy: 0.7232\n",
      "Epoch 20/300\n",
      "2847/2847 [==============================] - 1s 209us/sample - loss: 0.5073 - accuracy: 0.7924 - val_loss: 0.5854 - val_accuracy: 0.7232\n",
      "Epoch 21/300\n",
      "2847/2847 [==============================] - 1s 207us/sample - loss: 0.4982 - accuracy: 0.7945 - val_loss: 0.5846 - val_accuracy: 0.7277\n",
      "Epoch 22/300\n",
      "2847/2847 [==============================] - 1s 196us/sample - loss: 0.4951 - accuracy: 0.7970 - val_loss: 0.5841 - val_accuracy: 0.7292\n",
      "Epoch 23/300\n",
      "2847/2847 [==============================] - 1s 206us/sample - loss: 0.4928 - accuracy: 0.7984 - val_loss: 0.5837 - val_accuracy: 0.7292\n",
      "Epoch 24/300\n",
      "2847/2847 [==============================] - 1s 210us/sample - loss: 0.4865 - accuracy: 0.7952 - val_loss: 0.5834 - val_accuracy: 0.7292\n",
      "Epoch 25/300\n",
      "2847/2847 [==============================] - 1s 207us/sample - loss: 0.4835 - accuracy: 0.7994 - val_loss: 0.5832 - val_accuracy: 0.7292\n",
      "Epoch 26/300\n",
      "2847/2847 [==============================] - 1s 192us/sample - loss: 0.4846 - accuracy: 0.7973 - val_loss: 0.5832 - val_accuracy: 0.7292\n",
      "Epoch 27/300\n",
      "2847/2847 [==============================] - 1s 192us/sample - loss: 0.4783 - accuracy: 0.7998 - val_loss: 0.5832 - val_accuracy: 0.7307\n",
      "Epoch 28/300\n",
      "2847/2847 [==============================] - 1s 220us/sample - loss: 0.4721 - accuracy: 0.7994 - val_loss: 0.5834 - val_accuracy: 0.7307\n",
      "Epoch 29/300\n",
      "2847/2847 [==============================] - 1s 205us/sample - loss: 0.4722 - accuracy: 0.8012 - val_loss: 0.5836 - val_accuracy: 0.7307\n",
      "Epoch 00029: early stopping\n",
      "130/130 [==============================] - 0s 3ms/sample - loss: 0.3258 - accuracy: 0.9615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [2:02:22, 1049.71s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.35s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.14s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 843.34375 steps, validate for 208.0390625 steps\n",
      "Epoch 1/300\n",
      "844/843 [==============================] - 25s 29ms/step - loss: 0.6069 - accuracy: 0.6897 - val_loss: 0.6116 - val_accuracy: 0.7316\n",
      "Epoch 2/300\n",
      "844/843 [==============================] - 24s 28ms/step - loss: 0.5054 - accuracy: 0.7814 - val_loss: 0.6112 - val_accuracy: 0.7313\n",
      "Epoch 3/300\n",
      "844/843 [==============================] - 24s 28ms/step - loss: 0.4902 - accuracy: 0.7853 - val_loss: 0.6122 - val_accuracy: 0.7308\n",
      "Epoch 4/300\n",
      "844/843 [==============================] - 24s 28ms/step - loss: 0.4795 - accuracy: 0.7895 - val_loss: 0.6119 - val_accuracy: 0.7330\n",
      "Epoch 5/300\n",
      "844/843 [==============================] - 23s 28ms/step - loss: 0.4700 - accuracy: 0.7929 - val_loss: 0.6145 - val_accuracy: 0.7327\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 843.34375 steps, validate for 208.0390625 steps\n",
      "Epoch 1/300\n",
      "844/843 [==============================] - 55s 65ms/step - loss: 0.4537 - accuracy: 0.8015 - val_loss: 0.6160 - val_accuracy: 0.7333\n",
      "Epoch 2/300\n",
      "844/843 [==============================] - 53s 63ms/step - loss: 0.4276 - accuracy: 0.8134 - val_loss: 0.6469 - val_accuracy: 0.7233\n",
      "Epoch 3/300\n",
      "844/843 [==============================] - 53s 63ms/step - loss: 0.4061 - accuracy: 0.8247 - val_loss: 0.6367 - val_accuracy: 0.7278\n",
      "Epoch 4/300\n",
      "844/843 [==============================] - 53s 63ms/step - loss: 0.3865 - accuracy: 0.8358 - val_loss: 0.6533 - val_accuracy: 0.7015\n",
      "Epoch 00004: early stopping\n",
      "118/118 [==============================] - 0s 2ms/sample - loss: 0.2107 - accuracy: 0.9492\n",
      "116/116 [==============================] - 0s 229us/sample - loss: 0.2024 - accuracy: 0.9828\n",
      "114/114 [==============================] - 0s 233us/sample - loss: 0.2661 - accuracy: 0.9035\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.2955 - accuracy: 0.8929\n",
      "110/110 [==============================] - 0s 247us/sample - loss: 0.2493 - accuracy: 0.9455\n",
      "109/109 [==============================] - 0s 217us/sample - loss: 0.3334 - accuracy: 0.8716\n",
      "108/108 [==============================] - 0s 218us/sample - loss: 0.2781 - accuracy: 0.9444\n",
      "105/105 [==============================] - 0s 238us/sample - loss: 0.3053 - accuracy: 0.9238\n",
      "102/102 [==============================] - 0s 232us/sample - loss: 0.2946 - accuracy: 0.9020\n",
      "101/101 [==============================] - 0s 240us/sample - loss: 0.2951 - accuracy: 0.8911\n",
      "99/99 [==============================] - 0s 242us/sample - loss: 0.2622 - accuracy: 0.9394\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.2694 - accuracy: 0.9375\n",
      "94/94 [==============================] - 0s 228us/sample - loss: 0.2470 - accuracy: 0.9574\n",
      "94/94 [==============================] - 0s 232us/sample - loss: 0.2644 - accuracy: 0.9574\n",
      "93/93 [==============================] - 0s 235us/sample - loss: 0.2388 - accuracy: 0.9677\n",
      "92/92 [==============================] - 0s 241us/sample - loss: 0.2695 - accuracy: 0.9457\n",
      "93/93 [==============================] - 0s 257us/sample - loss: 0.2937 - accuracy: 0.9355\n",
      "93/93 [==============================] - 0s 257us/sample - loss: 0.2832 - accuracy: 0.9140\n",
      "92/92 [==============================] - 0s 257us/sample - loss: 0.2564 - accuracy: 0.9348\n",
      "92/92 [==============================] - 0s 276us/sample - loss: 0.2785 - accuracy: 0.9022\n",
      "91/91 [==============================] - 0s 248us/sample - loss: 0.2760 - accuracy: 0.9231\n",
      "92/92 [==============================] - 0s 284us/sample - loss: 0.2394 - accuracy: 0.9457\n",
      "91/91 [==============================] - 0s 276us/sample - loss: 0.2497 - accuracy: 0.9560\n",
      "90/90 [==============================] - 0s 269us/sample - loss: 0.2619 - accuracy: 0.9333\n",
      "89/89 [==============================] - 0s 271us/sample - loss: 0.2863 - accuracy: 0.9101\n",
      "88/88 [==============================] - 0s 280us/sample - loss: 0.2642 - accuracy: 0.9318\n",
      "89/89 [==============================] - 0s 240us/sample - loss: 0.3141 - accuracy: 0.9101\n",
      "89/89 [==============================] - 0s 247us/sample - loss: 0.2888 - accuracy: 0.9101\n",
      "89/89 [==============================] - 0s 256us/sample - loss: 0.2654 - accuracy: 0.9551\n",
      "90/90 [==============================] - 0s 281us/sample - loss: 0.2785 - accuracy: 0.9222\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.2796 - accuracy: 0.9333\n",
      "91/91 [==============================] - 0s 279us/sample - loss: 0.2829 - accuracy: 0.9451\n",
      "89/89 [==============================] - 0s 262us/sample - loss: 0.2711 - accuracy: 0.9326\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2861 samples, validate on 701 samples\n",
      "Epoch 1/300\n",
      "2861/2861 [==============================] - 3s 914us/sample - loss: 0.7090 - accuracy: 0.5488 - val_loss: 0.6743 - val_accuracy: 0.5863\n",
      "Epoch 2/300\n",
      "2861/2861 [==============================] - 1s 219us/sample - loss: 0.6739 - accuracy: 0.5806 - val_loss: 0.6581 - val_accuracy: 0.6063\n",
      "Epoch 3/300\n",
      "2861/2861 [==============================] - 1s 222us/sample - loss: 0.6456 - accuracy: 0.6264 - val_loss: 0.6470 - val_accuracy: 0.6291\n",
      "Epoch 4/300\n",
      "2861/2861 [==============================] - 1s 224us/sample - loss: 0.6310 - accuracy: 0.6319 - val_loss: 0.6385 - val_accuracy: 0.6391\n",
      "Epoch 5/300\n",
      "2861/2861 [==============================] - 1s 225us/sample - loss: 0.6189 - accuracy: 0.6533 - val_loss: 0.6318 - val_accuracy: 0.6419\n",
      "Epoch 6/300\n",
      "2861/2861 [==============================] - 1s 199us/sample - loss: 0.6072 - accuracy: 0.6746 - val_loss: 0.6261 - val_accuracy: 0.6448\n",
      "Epoch 7/300\n",
      "2861/2861 [==============================] - 1s 234us/sample - loss: 0.5960 - accuracy: 0.6907 - val_loss: 0.6211 - val_accuracy: 0.6476\n",
      "Epoch 8/300\n",
      "2861/2861 [==============================] - 1s 251us/sample - loss: 0.5890 - accuracy: 0.7015 - val_loss: 0.6170 - val_accuracy: 0.6491\n",
      "Epoch 9/300\n",
      "2861/2861 [==============================] - 1s 222us/sample - loss: 0.5816 - accuracy: 0.7043 - val_loss: 0.6134 - val_accuracy: 0.6591\n",
      "Epoch 10/300\n",
      "2861/2861 [==============================] - 1s 216us/sample - loss: 0.5707 - accuracy: 0.7151 - val_loss: 0.6101 - val_accuracy: 0.6633\n",
      "Epoch 11/300\n",
      "2861/2861 [==============================] - 1s 226us/sample - loss: 0.5653 - accuracy: 0.7312 - val_loss: 0.6074 - val_accuracy: 0.6648\n",
      "Epoch 12/300\n",
      "2861/2861 [==============================] - 1s 221us/sample - loss: 0.5585 - accuracy: 0.7253 - val_loss: 0.6049 - val_accuracy: 0.6705\n",
      "Epoch 13/300\n",
      "2861/2861 [==============================] - 1s 236us/sample - loss: 0.5510 - accuracy: 0.7365 - val_loss: 0.6027 - val_accuracy: 0.6748\n",
      "Epoch 14/300\n",
      "2861/2861 [==============================] - 1s 223us/sample - loss: 0.5508 - accuracy: 0.7431 - val_loss: 0.6008 - val_accuracy: 0.6762\n",
      "Epoch 15/300\n",
      "2861/2861 [==============================] - 1s 233us/sample - loss: 0.5449 - accuracy: 0.7445 - val_loss: 0.5991 - val_accuracy: 0.6862\n",
      "Epoch 16/300\n",
      "2861/2861 [==============================] - 1s 207us/sample - loss: 0.5321 - accuracy: 0.7578 - val_loss: 0.5976 - val_accuracy: 0.6890\n",
      "Epoch 17/300\n",
      "2861/2861 [==============================] - 1s 212us/sample - loss: 0.5274 - accuracy: 0.7606 - val_loss: 0.5962 - val_accuracy: 0.6947\n",
      "Epoch 18/300\n",
      "2861/2861 [==============================] - 1s 205us/sample - loss: 0.5251 - accuracy: 0.7620 - val_loss: 0.5950 - val_accuracy: 0.6947\n",
      "Epoch 19/300\n",
      "2861/2861 [==============================] - 1s 209us/sample - loss: 0.5233 - accuracy: 0.7662 - val_loss: 0.5939 - val_accuracy: 0.6933\n",
      "Epoch 20/300\n",
      "2861/2861 [==============================] - 1s 196us/sample - loss: 0.5202 - accuracy: 0.7697 - val_loss: 0.5930 - val_accuracy: 0.6933\n",
      "Epoch 21/300\n",
      "2861/2861 [==============================] - 1s 212us/sample - loss: 0.5123 - accuracy: 0.7676 - val_loss: 0.5921 - val_accuracy: 0.6947\n",
      "Epoch 22/300\n",
      "2861/2861 [==============================] - 1s 196us/sample - loss: 0.5091 - accuracy: 0.7756 - val_loss: 0.5913 - val_accuracy: 0.6961\n",
      "Epoch 23/300\n",
      "2861/2861 [==============================] - 1s 187us/sample - loss: 0.5077 - accuracy: 0.7780 - val_loss: 0.5908 - val_accuracy: 0.6976\n",
      "Epoch 24/300\n",
      "2861/2861 [==============================] - 1s 198us/sample - loss: 0.5030 - accuracy: 0.7801 - val_loss: 0.5902 - val_accuracy: 0.6976\n",
      "Epoch 25/300\n",
      "2861/2861 [==============================] - 1s 186us/sample - loss: 0.5014 - accuracy: 0.7812 - val_loss: 0.5896 - val_accuracy: 0.6990\n",
      "Epoch 26/300\n",
      "2861/2861 [==============================] - 1s 196us/sample - loss: 0.4989 - accuracy: 0.7850 - val_loss: 0.5893 - val_accuracy: 0.6976\n",
      "Epoch 27/300\n",
      "2861/2861 [==============================] - 1s 199us/sample - loss: 0.4966 - accuracy: 0.7829 - val_loss: 0.5888 - val_accuracy: 0.7019\n",
      "Epoch 28/300\n",
      "2861/2861 [==============================] - 1s 215us/sample - loss: 0.4973 - accuracy: 0.7826 - val_loss: 0.5887 - val_accuracy: 0.7047\n",
      "Epoch 29/300\n",
      "2861/2861 [==============================] - 1s 195us/sample - loss: 0.4893 - accuracy: 0.7906 - val_loss: 0.5884 - val_accuracy: 0.7019\n",
      "Epoch 30/300\n",
      "2861/2861 [==============================] - 1s 199us/sample - loss: 0.4842 - accuracy: 0.7955 - val_loss: 0.5882 - val_accuracy: 0.7061\n",
      "Epoch 31/300\n",
      "2861/2861 [==============================] - 1s 183us/sample - loss: 0.4822 - accuracy: 0.7910 - val_loss: 0.5880 - val_accuracy: 0.7118\n",
      "Epoch 32/300\n",
      "2861/2861 [==============================] - 1s 196us/sample - loss: 0.4777 - accuracy: 0.7997 - val_loss: 0.5879 - val_accuracy: 0.7118\n",
      "Epoch 33/300\n",
      "2861/2861 [==============================] - 1s 224us/sample - loss: 0.4788 - accuracy: 0.8001 - val_loss: 0.5879 - val_accuracy: 0.7133\n",
      "Epoch 34/300\n",
      "2861/2861 [==============================] - 1s 198us/sample - loss: 0.4770 - accuracy: 0.7990 - val_loss: 0.5879 - val_accuracy: 0.7118\n",
      "Epoch 35/300\n",
      "2861/2861 [==============================] - 1s 210us/sample - loss: 0.4735 - accuracy: 0.7980 - val_loss: 0.5879 - val_accuracy: 0.7090\n",
      "Epoch 36/300\n",
      "2861/2861 [==============================] - 1s 200us/sample - loss: 0.4714 - accuracy: 0.7987 - val_loss: 0.5879 - val_accuracy: 0.7090\n",
      "Epoch 00036: early stopping\n",
      "87/87 [==============================] - 0s 142us/sample - loss: 0.3330 - accuracy: 0.9310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [2:19:22, 1040.90s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.93s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.60s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 849.6484375 steps, validate for 199.359375 steps\n",
      "Epoch 1/300\n",
      "850/849 [==============================] - 24s 29ms/step - loss: 0.6232 - accuracy: 0.6685 - val_loss: 0.6373 - val_accuracy: 0.7183\n",
      "Epoch 2/300\n",
      "850/849 [==============================] - 24s 28ms/step - loss: 0.5074 - accuracy: 0.7819 - val_loss: 0.6373 - val_accuracy: 0.7179\n",
      "Epoch 3/300\n",
      "850/849 [==============================] - 23s 28ms/step - loss: 0.4923 - accuracy: 0.7856 - val_loss: 0.6301 - val_accuracy: 0.7192\n",
      "Epoch 4/300\n",
      "850/849 [==============================] - 23s 27ms/step - loss: 0.4813 - accuracy: 0.7886 - val_loss: 0.6278 - val_accuracy: 0.7214\n",
      "Epoch 5/300\n",
      "850/849 [==============================] - 23s 28ms/step - loss: 0.4717 - accuracy: 0.7922 - val_loss: 0.6318 - val_accuracy: 0.7242\n",
      "Epoch 6/300\n",
      "850/849 [==============================] - 24s 28ms/step - loss: 0.4630 - accuracy: 0.7965 - val_loss: 0.6311 - val_accuracy: 0.7238\n",
      "Epoch 7/300\n",
      "850/849 [==============================] - 24s 28ms/step - loss: 0.4548 - accuracy: 0.8003 - val_loss: 0.6315 - val_accuracy: 0.7253\n",
      "Epoch 00007: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 849.6484375 steps, validate for 199.359375 steps\n",
      "Epoch 1/300\n",
      "850/849 [==============================] - 55s 65ms/step - loss: 0.4400 - accuracy: 0.8076 - val_loss: 0.6623 - val_accuracy: 0.7086\n",
      "Epoch 2/300\n",
      "850/849 [==============================] - 53s 63ms/step - loss: 0.4151 - accuracy: 0.8202 - val_loss: 0.6441 - val_accuracy: 0.6993\n",
      "Epoch 3/300\n",
      "850/849 [==============================] - 54s 63ms/step - loss: 0.3933 - accuracy: 0.8324 - val_loss: 0.6291 - val_accuracy: 0.7232\n",
      "Epoch 4/300\n",
      "850/849 [==============================] - 54s 63ms/step - loss: 0.3735 - accuracy: 0.8437 - val_loss: 0.6635 - val_accuracy: 0.7180\n",
      "Epoch 5/300\n",
      "850/849 [==============================] - 54s 63ms/step - loss: 0.3547 - accuracy: 0.8536 - val_loss: 0.6649 - val_accuracy: 0.7086\n",
      "Epoch 6/300\n",
      "850/849 [==============================] - 53s 63ms/step - loss: 0.3375 - accuracy: 0.8629 - val_loss: 0.6974 - val_accuracy: 0.7172\n",
      "Epoch 00006: early stopping\n",
      "118/118 [==============================] - 0s 2ms/sample - loss: 0.1616 - accuracy: 0.9576\n",
      "113/113 [==============================] - 0s 242us/sample - loss: 0.1819 - accuracy: 0.9469\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 0.1704 - accuracy: 0.9643\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 0.2008 - accuracy: 0.9464\n",
      "111/111 [==============================] - 0s 233us/sample - loss: 0.1632 - accuracy: 0.9640\n",
      "111/111 [==============================] - 0s 254us/sample - loss: 0.1765 - accuracy: 0.9459\n",
      "108/108 [==============================] - 0s 243us/sample - loss: 0.1571 - accuracy: 0.9722\n",
      "109/109 [==============================] - 0s 245us/sample - loss: 0.1752 - accuracy: 0.9725\n",
      "106/106 [==============================] - 0s 239us/sample - loss: 0.1662 - accuracy: 0.9717\n",
      "104/104 [==============================] - 0s 316us/sample - loss: 0.1925 - accuracy: 0.9327\n",
      "104/104 [==============================] - 0s 247us/sample - loss: 0.1966 - accuracy: 0.9519\n",
      "105/105 [==============================] - 0s 259us/sample - loss: 0.1681 - accuracy: 0.9810\n",
      "104/104 [==============================] - 0s 246us/sample - loss: 0.1734 - accuracy: 0.9808\n",
      "104/104 [==============================] - 0s 257us/sample - loss: 0.1930 - accuracy: 0.9808\n",
      "103/103 [==============================] - 0s 267us/sample - loss: 0.1877 - accuracy: 0.9709\n",
      "102/102 [==============================] - 0s 253us/sample - loss: 0.1796 - accuracy: 0.9902\n",
      "101/101 [==============================] - 0s 248us/sample - loss: 0.1689 - accuracy: 0.9802\n",
      "102/102 [==============================] - 0s 264us/sample - loss: 0.1888 - accuracy: 0.9706\n",
      "105/105 [==============================] - 0s 261us/sample - loss: 0.1669 - accuracy: 0.9619\n",
      "103/103 [==============================] - 0s 264us/sample - loss: 0.1598 - accuracy: 1.0000\n",
      "104/104 [==============================] - 0s 276us/sample - loss: 0.1793 - accuracy: 0.9615\n",
      "105/105 [==============================] - 0s 255us/sample - loss: 0.1782 - accuracy: 0.9619\n",
      "103/103 [==============================] - 0s 264us/sample - loss: 0.1540 - accuracy: 0.9903\n",
      "104/104 [==============================] - 0s 244us/sample - loss: 0.1363 - accuracy: 1.0000\n",
      "105/105 [==============================] - 0s 264us/sample - loss: 0.1601 - accuracy: 1.0000\n",
      "105/105 [==============================] - 0s 263us/sample - loss: 0.1717 - accuracy: 0.9619\n",
      "105/105 [==============================] - 0s 287us/sample - loss: 0.1903 - accuracy: 0.9714\n",
      "106/106 [==============================] - 0s 263us/sample - loss: 0.1808 - accuracy: 0.9811\n",
      "104/104 [==============================] - 0s 263us/sample - loss: 0.1983 - accuracy: 0.9615\n",
      "106/106 [==============================] - 0s 253us/sample - loss: 0.1727 - accuracy: 0.9623\n",
      "107/107 [==============================] - 0s 312us/sample - loss: 0.1883 - accuracy: 0.9533\n",
      "108/108 [==============================] - 0s 268us/sample - loss: 0.1880 - accuracy: 0.9537\n",
      "106/106 [==============================] - 0s 271us/sample - loss: 0.2216 - accuracy: 0.9434\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2880 samples, validate on 671 samples\n",
      "Epoch 1/300\n",
      "2880/2880 [==============================] - 2s 799us/sample - loss: 0.7528 - accuracy: 0.4490 - val_loss: 0.6995 - val_accuracy: 0.5455\n",
      "Epoch 2/300\n",
      "2880/2880 [==============================] - 1s 190us/sample - loss: 0.6973 - accuracy: 0.5472 - val_loss: 0.6753 - val_accuracy: 0.5797\n",
      "Epoch 3/300\n",
      "2880/2880 [==============================] - 1s 184us/sample - loss: 0.6629 - accuracy: 0.6042 - val_loss: 0.6589 - val_accuracy: 0.6155\n",
      "Epoch 4/300\n",
      "2880/2880 [==============================] - 1s 184us/sample - loss: 0.6361 - accuracy: 0.6438 - val_loss: 0.6465 - val_accuracy: 0.6423\n",
      "Epoch 5/300\n",
      "2880/2880 [==============================] - 1s 182us/sample - loss: 0.6221 - accuracy: 0.6642 - val_loss: 0.6362 - val_accuracy: 0.6542\n",
      "Epoch 6/300\n",
      "2880/2880 [==============================] - 0s 171us/sample - loss: 0.6063 - accuracy: 0.6896 - val_loss: 0.6278 - val_accuracy: 0.6617\n",
      "Epoch 7/300\n",
      "2880/2880 [==============================] - 1s 178us/sample - loss: 0.5907 - accuracy: 0.7090 - val_loss: 0.6207 - val_accuracy: 0.6692\n",
      "Epoch 8/300\n",
      "2880/2880 [==============================] - 1s 187us/sample - loss: 0.5755 - accuracy: 0.7247 - val_loss: 0.6145 - val_accuracy: 0.6855\n",
      "Epoch 9/300\n",
      "2880/2880 [==============================] - 1s 174us/sample - loss: 0.5610 - accuracy: 0.7434 - val_loss: 0.6092 - val_accuracy: 0.6960\n",
      "Epoch 10/300\n",
      "2880/2880 [==============================] - 1s 176us/sample - loss: 0.5466 - accuracy: 0.7597 - val_loss: 0.6047 - val_accuracy: 0.7004\n",
      "Epoch 11/300\n",
      "2880/2880 [==============================] - 1s 199us/sample - loss: 0.5435 - accuracy: 0.7590 - val_loss: 0.6006 - val_accuracy: 0.7004\n",
      "Epoch 12/300\n",
      "2880/2880 [==============================] - 1s 201us/sample - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5971 - val_accuracy: 0.7004\n",
      "Epoch 13/300\n",
      "2880/2880 [==============================] - 1s 194us/sample - loss: 0.5249 - accuracy: 0.7712 - val_loss: 0.5940 - val_accuracy: 0.6975\n",
      "Epoch 14/300\n",
      "2880/2880 [==============================] - 1s 205us/sample - loss: 0.5129 - accuracy: 0.7750 - val_loss: 0.5913 - val_accuracy: 0.7034\n",
      "Epoch 15/300\n",
      "2880/2880 [==============================] - 1s 212us/sample - loss: 0.5039 - accuracy: 0.7837 - val_loss: 0.5891 - val_accuracy: 0.7109\n",
      "Epoch 16/300\n",
      "2880/2880 [==============================] - 1s 221us/sample - loss: 0.4958 - accuracy: 0.8000 - val_loss: 0.5871 - val_accuracy: 0.7139\n",
      "Epoch 17/300\n",
      "2880/2880 [==============================] - 1s 180us/sample - loss: 0.4898 - accuracy: 0.8017 - val_loss: 0.5854 - val_accuracy: 0.7168\n",
      "Epoch 18/300\n",
      "2880/2880 [==============================] - 1s 186us/sample - loss: 0.4838 - accuracy: 0.7990 - val_loss: 0.5841 - val_accuracy: 0.7228\n",
      "Epoch 19/300\n",
      "2880/2880 [==============================] - 1s 189us/sample - loss: 0.4763 - accuracy: 0.8021 - val_loss: 0.5830 - val_accuracy: 0.7243\n",
      "Epoch 20/300\n",
      "2880/2880 [==============================] - 0s 156us/sample - loss: 0.4695 - accuracy: 0.8097 - val_loss: 0.5820 - val_accuracy: 0.7317\n",
      "Epoch 21/300\n",
      "2880/2880 [==============================] - 0s 164us/sample - loss: 0.4661 - accuracy: 0.8101 - val_loss: 0.5814 - val_accuracy: 0.7347\n",
      "Epoch 22/300\n",
      "2880/2880 [==============================] - 1s 174us/sample - loss: 0.4609 - accuracy: 0.8174 - val_loss: 0.5809 - val_accuracy: 0.7362\n",
      "Epoch 23/300\n",
      "2880/2880 [==============================] - 0s 172us/sample - loss: 0.4522 - accuracy: 0.8170 - val_loss: 0.5806 - val_accuracy: 0.7377\n",
      "Epoch 24/300\n",
      "2880/2880 [==============================] - 1s 174us/sample - loss: 0.4508 - accuracy: 0.8139 - val_loss: 0.5805 - val_accuracy: 0.7377\n",
      "Epoch 25/300\n",
      "2880/2880 [==============================] - 1s 193us/sample - loss: 0.4401 - accuracy: 0.8243 - val_loss: 0.5806 - val_accuracy: 0.7377\n",
      "Epoch 26/300\n",
      "2880/2880 [==============================] - 1s 189us/sample - loss: 0.4373 - accuracy: 0.8212 - val_loss: 0.5809 - val_accuracy: 0.7392\n",
      "Epoch 27/300\n",
      "2880/2880 [==============================] - 1s 186us/sample - loss: 0.4343 - accuracy: 0.8274 - val_loss: 0.5812 - val_accuracy: 0.7377\n",
      "Epoch 00027: early stopping\n",
      "98/98 [==============================] - 0s 157us/sample - loss: 0.2853 - accuracy: 0.9694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [2:38:53, 1079.77s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.48s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.22s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 850.0078125 steps, validate for 208.0390625 steps\n",
      "Epoch 1/300\n",
      "851/850 [==============================] - 24s 29ms/step - loss: 0.6297 - accuracy: 0.6644 - val_loss: 0.6189 - val_accuracy: 0.7289\n",
      "Epoch 2/300\n",
      "851/850 [==============================] - 24s 28ms/step - loss: 0.5014 - accuracy: 0.7833 - val_loss: 0.6186 - val_accuracy: 0.7298\n",
      "Epoch 3/300\n",
      "851/850 [==============================] - 24s 28ms/step - loss: 0.4861 - accuracy: 0.7887 - val_loss: 0.6160 - val_accuracy: 0.7287\n",
      "Epoch 4/300\n",
      "851/850 [==============================] - 24s 28ms/step - loss: 0.4754 - accuracy: 0.7928 - val_loss: 0.6199 - val_accuracy: 0.7321\n",
      "Epoch 5/300\n",
      "851/850 [==============================] - 23s 28ms/step - loss: 0.4660 - accuracy: 0.7965 - val_loss: 0.6216 - val_accuracy: 0.7328\n",
      "Epoch 6/300\n",
      "851/850 [==============================] - 23s 28ms/step - loss: 0.4577 - accuracy: 0.8000 - val_loss: 0.6245 - val_accuracy: 0.7322\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 850.0078125 steps, validate for 208.0390625 steps\n",
      "Epoch 1/300\n",
      "851/850 [==============================] - 55s 64ms/step - loss: 0.4423 - accuracy: 0.8079 - val_loss: 0.6390 - val_accuracy: 0.6853\n",
      "Epoch 2/300\n",
      "851/850 [==============================] - 54s 63ms/step - loss: 0.4164 - accuracy: 0.8208 - val_loss: 0.6361 - val_accuracy: 0.7369\n",
      "Epoch 3/300\n",
      "851/850 [==============================] - 54s 63ms/step - loss: 0.3942 - accuracy: 0.8327 - val_loss: 0.6522 - val_accuracy: 0.7214\n",
      "Epoch 4/300\n",
      "851/850 [==============================] - 54s 63ms/step - loss: 0.3737 - accuracy: 0.8435 - val_loss: 0.6656 - val_accuracy: 0.7099\n",
      "Epoch 5/300\n",
      "851/850 [==============================] - 53s 63ms/step - loss: 0.3551 - accuracy: 0.8539 - val_loss: 0.6726 - val_accuracy: 0.7121\n",
      "Epoch 00005: early stopping\n",
      "87/87 [==============================] - 0s 2ms/sample - loss: 0.2782 - accuracy: 0.8736\n",
      "84/84 [==============================] - 0s 257us/sample - loss: 0.2856 - accuracy: 0.8929\n",
      "82/82 [==============================] - 0s 274us/sample - loss: 0.3124 - accuracy: 0.8780\n",
      "80/80 [==============================] - 0s 258us/sample - loss: 0.3527 - accuracy: 0.8625\n",
      "78/78 [==============================] - 0s 258us/sample - loss: 0.3562 - accuracy: 0.8590\n",
      "79/79 [==============================] - 0s 233us/sample - loss: 0.3342 - accuracy: 0.8734\n",
      "79/79 [==============================] - 0s 244us/sample - loss: 0.3124 - accuracy: 0.8861\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.3060 - accuracy: 0.8800\n",
      "72/72 [==============================] - 0s 270us/sample - loss: 0.3023 - accuracy: 0.9583\n",
      "72/72 [==============================] - 0s 300us/sample - loss: 0.2935 - accuracy: 0.9306\n",
      "73/73 [==============================] - 0s 276us/sample - loss: 0.3111 - accuracy: 0.8767\n",
      "74/74 [==============================] - 0s 245us/sample - loss: 0.3079 - accuracy: 0.8919\n",
      "73/73 [==============================] - 0s 257us/sample - loss: 0.3096 - accuracy: 0.8630\n",
      "70/70 [==============================] - 0s 246us/sample - loss: 0.2991 - accuracy: 0.8857\n",
      "70/70 [==============================] - 0s 319us/sample - loss: 0.2877 - accuracy: 0.9000\n",
      "71/71 [==============================] - 0s 295us/sample - loss: 0.2833 - accuracy: 0.9014\n",
      "72/72 [==============================] - 0s 278us/sample - loss: 0.2798 - accuracy: 0.8889\n",
      "73/73 [==============================] - 0s 279us/sample - loss: 0.2630 - accuracy: 0.9041\n",
      "70/70 [==============================] - 0s 296us/sample - loss: 0.2725 - accuracy: 0.9143\n",
      "70/70 [==============================] - 0s 307us/sample - loss: 0.2605 - accuracy: 0.9429\n",
      "68/68 [==============================] - 0s 366us/sample - loss: 0.2962 - accuracy: 0.8971\n",
      "66/66 [==============================] - 0s 313us/sample - loss: 0.3008 - accuracy: 0.9242\n",
      "67/67 [==============================] - 0s 312us/sample - loss: 0.2627 - accuracy: 0.9552\n",
      "66/66 [==============================] - 0s 298us/sample - loss: 0.2321 - accuracy: 0.9545\n",
      "65/65 [==============================] - 0s 329us/sample - loss: 0.2214 - accuracy: 0.9538\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.2669 - accuracy: 0.9219\n",
      "64/64 [==============================] - 0s 264us/sample - loss: 0.2877 - accuracy: 0.9062\n",
      "65/65 [==============================] - 0s 305us/sample - loss: 0.2705 - accuracy: 0.9385\n",
      "64/64 [==============================] - 0s 237us/sample - loss: 0.3387 - accuracy: 0.9062\n",
      "63/63 [==============================] - 0s 269us/sample - loss: 0.2124 - accuracy: 0.9365\n",
      "64/64 [==============================] - 0s 235us/sample - loss: 0.1984 - accuracy: 0.9531\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 0.2365 - accuracy: 0.9531\n",
      "64/64 [==============================] - 0s 257us/sample - loss: 0.2446 - accuracy: 0.9375\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2888 samples, validate on 701 samples\n",
      "Epoch 1/300\n",
      "2888/2888 [==============================] - 3s 880us/sample - loss: 0.6416 - accuracy: 0.6312 - val_loss: 0.6592 - val_accuracy: 0.6277\n",
      "Epoch 2/300\n",
      "2888/2888 [==============================] - 1s 206us/sample - loss: 0.6104 - accuracy: 0.6863 - val_loss: 0.6458 - val_accuracy: 0.6448\n",
      "Epoch 3/300\n",
      "2888/2888 [==============================] - 1s 213us/sample - loss: 0.5877 - accuracy: 0.7220 - val_loss: 0.6372 - val_accuracy: 0.6576\n",
      "Epoch 4/300\n",
      "2888/2888 [==============================] - 1s 203us/sample - loss: 0.5737 - accuracy: 0.7355 - val_loss: 0.6307 - val_accuracy: 0.6676\n",
      "Epoch 5/300\n",
      "2888/2888 [==============================] - 1s 216us/sample - loss: 0.5653 - accuracy: 0.7379 - val_loss: 0.6257 - val_accuracy: 0.6776\n",
      "Epoch 6/300\n",
      "2888/2888 [==============================] - 1s 212us/sample - loss: 0.5559 - accuracy: 0.7514 - val_loss: 0.6216 - val_accuracy: 0.6862\n",
      "Epoch 7/300\n",
      "2888/2888 [==============================] - 1s 206us/sample - loss: 0.5439 - accuracy: 0.7597 - val_loss: 0.6183 - val_accuracy: 0.6933\n",
      "Epoch 8/300\n",
      "2888/2888 [==============================] - 1s 200us/sample - loss: 0.5358 - accuracy: 0.7628 - val_loss: 0.6155 - val_accuracy: 0.6947\n",
      "Epoch 9/300\n",
      "2888/2888 [==============================] - 1s 215us/sample - loss: 0.5294 - accuracy: 0.7732 - val_loss: 0.6132 - val_accuracy: 0.7061\n",
      "Epoch 10/300\n",
      "2888/2888 [==============================] - 1s 199us/sample - loss: 0.5216 - accuracy: 0.7767 - val_loss: 0.6112 - val_accuracy: 0.7076\n",
      "Epoch 11/300\n",
      "2888/2888 [==============================] - 1s 201us/sample - loss: 0.5154 - accuracy: 0.7777 - val_loss: 0.6094 - val_accuracy: 0.7090\n",
      "Epoch 12/300\n",
      "2888/2888 [==============================] - 1s 215us/sample - loss: 0.5106 - accuracy: 0.7805 - val_loss: 0.6080 - val_accuracy: 0.7133\n",
      "Epoch 13/300\n",
      "2888/2888 [==============================] - 1s 230us/sample - loss: 0.5081 - accuracy: 0.7864 - val_loss: 0.6067 - val_accuracy: 0.7147\n",
      "Epoch 14/300\n",
      "2888/2888 [==============================] - 1s 199us/sample - loss: 0.4991 - accuracy: 0.7919 - val_loss: 0.6055 - val_accuracy: 0.7147\n",
      "Epoch 15/300\n",
      "2888/2888 [==============================] - 1s 212us/sample - loss: 0.4950 - accuracy: 0.7926 - val_loss: 0.6046 - val_accuracy: 0.7161\n",
      "Epoch 16/300\n",
      "2888/2888 [==============================] - 1s 208us/sample - loss: 0.4903 - accuracy: 0.7926 - val_loss: 0.6037 - val_accuracy: 0.7175\n",
      "Epoch 17/300\n",
      "2888/2888 [==============================] - 1s 203us/sample - loss: 0.4875 - accuracy: 0.7940 - val_loss: 0.6031 - val_accuracy: 0.7233\n",
      "Epoch 18/300\n",
      "2888/2888 [==============================] - 1s 192us/sample - loss: 0.4877 - accuracy: 0.7929 - val_loss: 0.6025 - val_accuracy: 0.7247\n",
      "Epoch 19/300\n",
      "2888/2888 [==============================] - 0s 167us/sample - loss: 0.4793 - accuracy: 0.7943 - val_loss: 0.6021 - val_accuracy: 0.7218\n",
      "Epoch 20/300\n",
      "2888/2888 [==============================] - 1s 181us/sample - loss: 0.4773 - accuracy: 0.7995 - val_loss: 0.6017 - val_accuracy: 0.7233\n",
      "Epoch 21/300\n",
      "2888/2888 [==============================] - 1s 194us/sample - loss: 0.4723 - accuracy: 0.7971 - val_loss: 0.6014 - val_accuracy: 0.7247\n",
      "Epoch 22/300\n",
      "2888/2888 [==============================] - 1s 213us/sample - loss: 0.4669 - accuracy: 0.8047 - val_loss: 0.6012 - val_accuracy: 0.7261\n",
      "Epoch 23/300\n",
      "2888/2888 [==============================] - 1s 221us/sample - loss: 0.4658 - accuracy: 0.8023 - val_loss: 0.6010 - val_accuracy: 0.7261\n",
      "Epoch 24/300\n",
      "2888/2888 [==============================] - 1s 231us/sample - loss: 0.4617 - accuracy: 0.8061 - val_loss: 0.6009 - val_accuracy: 0.7304\n",
      "Epoch 25/300\n",
      "2888/2888 [==============================] - 1s 229us/sample - loss: 0.4619 - accuracy: 0.8089 - val_loss: 0.6009 - val_accuracy: 0.7332\n",
      "Epoch 26/300\n",
      "2888/2888 [==============================] - 1s 209us/sample - loss: 0.4513 - accuracy: 0.8016 - val_loss: 0.6009 - val_accuracy: 0.7318\n",
      "Epoch 27/300\n",
      "2888/2888 [==============================] - 1s 208us/sample - loss: 0.4496 - accuracy: 0.8137 - val_loss: 0.6010 - val_accuracy: 0.7318\n",
      "Epoch 00027: early stopping\n",
      "60/60 [==============================] - 0s 169us/sample - loss: 0.3074 - accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [2:57:10, 1084.96s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.24s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.19s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 848.1953125 steps, validate for 202.5078125 steps\n",
      "Epoch 1/300\n",
      "849/848 [==============================] - 24s 29ms/step - loss: 0.5378 - accuracy: 0.7603 - val_loss: 0.6097 - val_accuracy: 0.7297\n",
      "Epoch 2/300\n",
      "849/848 [==============================] - 23s 27ms/step - loss: 0.4993 - accuracy: 0.7826 - val_loss: 0.6105 - val_accuracy: 0.7261\n",
      "Epoch 3/300\n",
      "849/848 [==============================] - 23s 28ms/step - loss: 0.4862 - accuracy: 0.7862 - val_loss: 0.6075 - val_accuracy: 0.7263\n",
      "Epoch 4/300\n",
      "849/848 [==============================] - 24s 28ms/step - loss: 0.4760 - accuracy: 0.7900 - val_loss: 0.6196 - val_accuracy: 0.7228\n",
      "Epoch 5/300\n",
      "849/848 [==============================] - 24s 28ms/step - loss: 0.4672 - accuracy: 0.7933 - val_loss: 0.6214 - val_accuracy: 0.7236\n",
      "Epoch 6/300\n",
      "849/848 [==============================] - 24s 28ms/step - loss: 0.4592 - accuracy: 0.7973 - val_loss: 0.6184 - val_accuracy: 0.7275\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 848.1953125 steps, validate for 202.5078125 steps\n",
      "Epoch 1/300\n",
      "849/848 [==============================] - 55s 64ms/step - loss: 0.4435 - accuracy: 0.8059 - val_loss: 0.6293 - val_accuracy: 0.7289\n",
      "Epoch 2/300\n",
      "849/848 [==============================] - 53s 63ms/step - loss: 0.4178 - accuracy: 0.8206 - val_loss: 0.6222 - val_accuracy: 0.7326\n",
      "Epoch 3/300\n",
      "849/848 [==============================] - 53s 63ms/step - loss: 0.3960 - accuracy: 0.8328 - val_loss: 0.6679 - val_accuracy: 0.7361\n",
      "Epoch 4/300\n",
      "849/848 [==============================] - 54s 63ms/step - loss: 0.3756 - accuracy: 0.8442 - val_loss: 0.6362 - val_accuracy: 0.7348\n",
      "Epoch 5/300\n",
      "849/848 [==============================] - 53s 63ms/step - loss: 0.3566 - accuracy: 0.8538 - val_loss: 0.6758 - val_accuracy: 0.7103\n",
      "Epoch 00005: early stopping\n",
      "127/127 [==============================] - 0s 2ms/sample - loss: 0.2919 - accuracy: 0.9370\n",
      "126/126 [==============================] - 0s 224us/sample - loss: 0.3079 - accuracy: 0.8968\n",
      "126/126 [==============================] - 0s 250us/sample - loss: 0.3046 - accuracy: 0.8889\n",
      "126/126 [==============================] - 0s 215us/sample - loss: 0.3248 - accuracy: 0.8968\n",
      "118/118 [==============================] - 0s 231us/sample - loss: 0.3036 - accuracy: 0.9068\n",
      "110/110 [==============================] - 0s 246us/sample - loss: 0.3181 - accuracy: 0.8818\n",
      "108/108 [==============================] - 0s 253us/sample - loss: 0.3106 - accuracy: 0.9259\n",
      "103/103 [==============================] - 0s 252us/sample - loss: 0.3002 - accuracy: 0.9126\n",
      "100/100 [==============================] - 0s 240us/sample - loss: 0.3161 - accuracy: 0.9000\n",
      "98/98 [==============================] - 0s 300us/sample - loss: 0.2943 - accuracy: 0.9388\n",
      "98/98 [==============================] - 0s 249us/sample - loss: 0.3069 - accuracy: 0.8878\n",
      "97/97 [==============================] - 0s 245us/sample - loss: 0.3692 - accuracy: 0.8866\n",
      "97/97 [==============================] - 0s 296us/sample - loss: 0.3203 - accuracy: 0.9278\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.2907 - accuracy: 0.8542\n",
      "97/97 [==============================] - 0s 279us/sample - loss: 0.2963 - accuracy: 0.9691\n",
      "96/96 [==============================] - 0s 252us/sample - loss: 0.3090 - accuracy: 0.9479\n",
      "94/94 [==============================] - 0s 265us/sample - loss: 0.3167 - accuracy: 0.8936\n",
      "94/94 [==============================] - 0s 261us/sample - loss: 0.2997 - accuracy: 0.9043\n",
      "92/92 [==============================] - 0s 261us/sample - loss: 0.3273 - accuracy: 0.8804\n",
      "94/94 [==============================] - 0s 250us/sample - loss: 0.3077 - accuracy: 0.8830\n",
      "92/92 [==============================] - 0s 268us/sample - loss: 0.2842 - accuracy: 0.9239\n",
      "90/90 [==============================] - 0s 264us/sample - loss: 0.2850 - accuracy: 0.9556\n",
      "92/92 [==============================] - 0s 242us/sample - loss: 0.2956 - accuracy: 0.8804\n",
      "92/92 [==============================] - 0s 257us/sample - loss: 0.2679 - accuracy: 0.9239\n",
      "94/94 [==============================] - 0s 229us/sample - loss: 0.3099 - accuracy: 0.9043\n",
      "93/93 [==============================] - 0s 246us/sample - loss: 0.3191 - accuracy: 0.9140\n",
      "94/94 [==============================] - 0s 287us/sample - loss: 0.3094 - accuracy: 0.8936\n",
      "93/93 [==============================] - 0s 259us/sample - loss: 0.2924 - accuracy: 0.9032\n",
      "91/91 [==============================] - 0s 286us/sample - loss: 0.2999 - accuracy: 0.8791\n",
      "92/92 [==============================] - 0s 266us/sample - loss: 0.3045 - accuracy: 0.9348\n",
      "90/90 [==============================] - 0s 245us/sample - loss: 0.3191 - accuracy: 0.9000\n",
      "89/89 [==============================] - 0s 284us/sample - loss: 0.2946 - accuracy: 0.9213\n",
      "89/89 [==============================] - 0s 256us/sample - loss: 0.2966 - accuracy: 0.9551\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2889 samples, validate on 685 samples\n",
      "Epoch 1/300\n",
      "2889/2889 [==============================] - 3s 920us/sample - loss: 0.7311 - accuracy: 0.5216 - val_loss: 0.6964 - val_accuracy: 0.5620\n",
      "Epoch 2/300\n",
      "2889/2889 [==============================] - 1s 199us/sample - loss: 0.6825 - accuracy: 0.5732 - val_loss: 0.6753 - val_accuracy: 0.5927\n",
      "Epoch 3/300\n",
      "2889/2889 [==============================] - 1s 221us/sample - loss: 0.6526 - accuracy: 0.6102 - val_loss: 0.6610 - val_accuracy: 0.6175\n",
      "Epoch 4/300\n",
      "2889/2889 [==============================] - 1s 216us/sample - loss: 0.6340 - accuracy: 0.6383 - val_loss: 0.6498 - val_accuracy: 0.6409\n",
      "Epoch 5/300\n",
      "2889/2889 [==============================] - 1s 226us/sample - loss: 0.6193 - accuracy: 0.6611 - val_loss: 0.6406 - val_accuracy: 0.6540\n",
      "Epoch 6/300\n",
      "2889/2889 [==============================] - 1s 208us/sample - loss: 0.6070 - accuracy: 0.6784 - val_loss: 0.6331 - val_accuracy: 0.6599\n",
      "Epoch 7/300\n",
      "2889/2889 [==============================] - 1s 224us/sample - loss: 0.5922 - accuracy: 0.7030 - val_loss: 0.6267 - val_accuracy: 0.6672\n",
      "Epoch 8/300\n",
      "2889/2889 [==============================] - 1s 234us/sample - loss: 0.5838 - accuracy: 0.6999 - val_loss: 0.6209 - val_accuracy: 0.6818\n",
      "Epoch 9/300\n",
      "2889/2889 [==============================] - 1s 220us/sample - loss: 0.5749 - accuracy: 0.7096 - val_loss: 0.6159 - val_accuracy: 0.6847\n",
      "Epoch 10/300\n",
      "2889/2889 [==============================] - 1s 215us/sample - loss: 0.5629 - accuracy: 0.7290 - val_loss: 0.6114 - val_accuracy: 0.6949\n",
      "Epoch 11/300\n",
      "2889/2889 [==============================] - 1s 243us/sample - loss: 0.5557 - accuracy: 0.7366 - val_loss: 0.6075 - val_accuracy: 0.6978\n",
      "Epoch 12/300\n",
      "2889/2889 [==============================] - 1s 249us/sample - loss: 0.5463 - accuracy: 0.7539 - val_loss: 0.6040 - val_accuracy: 0.6964\n",
      "Epoch 13/300\n",
      "2889/2889 [==============================] - 1s 233us/sample - loss: 0.5376 - accuracy: 0.7570 - val_loss: 0.6009 - val_accuracy: 0.6993\n",
      "Epoch 14/300\n",
      "2889/2889 [==============================] - 1s 271us/sample - loss: 0.5304 - accuracy: 0.7577 - val_loss: 0.5980 - val_accuracy: 0.7051\n",
      "Epoch 15/300\n",
      "2889/2889 [==============================] - 1s 235us/sample - loss: 0.5264 - accuracy: 0.7736 - val_loss: 0.5955 - val_accuracy: 0.7080\n",
      "Epoch 16/300\n",
      "2889/2889 [==============================] - 1s 233us/sample - loss: 0.5187 - accuracy: 0.7754 - val_loss: 0.5932 - val_accuracy: 0.7095\n",
      "Epoch 17/300\n",
      "2889/2889 [==============================] - 1s 205us/sample - loss: 0.5141 - accuracy: 0.7805 - val_loss: 0.5912 - val_accuracy: 0.7124\n",
      "Epoch 18/300\n",
      "2889/2889 [==============================] - 1s 205us/sample - loss: 0.5070 - accuracy: 0.7885 - val_loss: 0.5894 - val_accuracy: 0.7182\n",
      "Epoch 19/300\n",
      "2889/2889 [==============================] - 1s 193us/sample - loss: 0.5051 - accuracy: 0.7819 - val_loss: 0.5877 - val_accuracy: 0.7168\n",
      "Epoch 20/300\n",
      "2889/2889 [==============================] - 1s 202us/sample - loss: 0.4977 - accuracy: 0.7937 - val_loss: 0.5861 - val_accuracy: 0.7197\n",
      "Epoch 21/300\n",
      "2889/2889 [==============================] - 1s 191us/sample - loss: 0.4929 - accuracy: 0.7940 - val_loss: 0.5848 - val_accuracy: 0.7270\n",
      "Epoch 22/300\n",
      "2889/2889 [==============================] - 1s 180us/sample - loss: 0.4868 - accuracy: 0.7965 - val_loss: 0.5837 - val_accuracy: 0.7255\n",
      "Epoch 23/300\n",
      "2889/2889 [==============================] - 1s 212us/sample - loss: 0.4843 - accuracy: 0.8020 - val_loss: 0.5827 - val_accuracy: 0.7285\n",
      "Epoch 24/300\n",
      "2889/2889 [==============================] - 1s 221us/sample - loss: 0.4794 - accuracy: 0.8034 - val_loss: 0.5819 - val_accuracy: 0.7314\n",
      "Epoch 25/300\n",
      "2889/2889 [==============================] - 1s 182us/sample - loss: 0.4725 - accuracy: 0.8124 - val_loss: 0.5811 - val_accuracy: 0.7343\n",
      "Epoch 26/300\n",
      "2889/2889 [==============================] - 1s 204us/sample - loss: 0.4655 - accuracy: 0.8120 - val_loss: 0.5806 - val_accuracy: 0.7358\n",
      "Epoch 27/300\n",
      "2889/2889 [==============================] - 1s 200us/sample - loss: 0.4646 - accuracy: 0.8072 - val_loss: 0.5802 - val_accuracy: 0.7372\n",
      "Epoch 28/300\n",
      "2889/2889 [==============================] - 1s 223us/sample - loss: 0.4598 - accuracy: 0.8114 - val_loss: 0.5798 - val_accuracy: 0.7372\n",
      "Epoch 29/300\n",
      "2889/2889 [==============================] - 1s 214us/sample - loss: 0.4549 - accuracy: 0.8127 - val_loss: 0.5795 - val_accuracy: 0.7372\n",
      "Epoch 30/300\n",
      "2889/2889 [==============================] - 1s 203us/sample - loss: 0.4518 - accuracy: 0.8197 - val_loss: 0.5793 - val_accuracy: 0.7401\n",
      "Epoch 31/300\n",
      "2889/2889 [==============================] - 1s 196us/sample - loss: 0.4461 - accuracy: 0.8221 - val_loss: 0.5792 - val_accuracy: 0.7401\n",
      "Epoch 32/300\n",
      "2889/2889 [==============================] - 1s 198us/sample - loss: 0.4469 - accuracy: 0.8231 - val_loss: 0.5792 - val_accuracy: 0.7416\n",
      "Epoch 33/300\n",
      "2889/2889 [==============================] - 1s 224us/sample - loss: 0.4405 - accuracy: 0.8238 - val_loss: 0.5793 - val_accuracy: 0.7401\n",
      "Epoch 34/300\n",
      "2889/2889 [==============================] - 1s 215us/sample - loss: 0.4393 - accuracy: 0.8235 - val_loss: 0.5795 - val_accuracy: 0.7387\n",
      "Epoch 35/300\n",
      "2889/2889 [==============================] - 1s 231us/sample - loss: 0.4350 - accuracy: 0.8290 - val_loss: 0.5798 - val_accuracy: 0.7372\n",
      "Epoch 00035: early stopping\n",
      "75/75 [==============================] - 0s 207us/sample - loss: 0.3217 - accuracy: 0.9467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [3:15:25, 1087.99s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.94s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.45s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 839.859375 steps, validate for 202.828125 steps\n",
      "Epoch 1/300\n",
      "840/839 [==============================] - 25s 30ms/step - loss: 0.6319 - accuracy: 0.6579 - val_loss: 0.6195 - val_accuracy: 0.7228\n",
      "Epoch 2/300\n",
      "840/839 [==============================] - 23s 28ms/step - loss: 0.5070 - accuracy: 0.7812 - val_loss: 0.6276 - val_accuracy: 0.7248\n",
      "Epoch 3/300\n",
      "840/839 [==============================] - 23s 28ms/step - loss: 0.4912 - accuracy: 0.7853 - val_loss: 0.6288 - val_accuracy: 0.7266\n",
      "Epoch 4/300\n",
      "840/839 [==============================] - 24s 28ms/step - loss: 0.4801 - accuracy: 0.7894 - val_loss: 0.6344 - val_accuracy: 0.7265\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 839.859375 steps, validate for 202.828125 steps\n",
      "Epoch 1/300\n",
      "840/839 [==============================] - 55s 65ms/step - loss: 0.4616 - accuracy: 0.7971 - val_loss: 0.6333 - val_accuracy: 0.7267\n",
      "Epoch 2/300\n",
      "840/839 [==============================] - 53s 63ms/step - loss: 0.4331 - accuracy: 0.8104 - val_loss: 0.6637 - val_accuracy: 0.7247\n",
      "Epoch 3/300\n",
      "840/839 [==============================] - 53s 63ms/step - loss: 0.4086 - accuracy: 0.8240 - val_loss: 0.6450 - val_accuracy: 0.7148\n",
      "Epoch 4/300\n",
      "840/839 [==============================] - 53s 63ms/step - loss: 0.3858 - accuracy: 0.8367 - val_loss: 0.6315 - val_accuracy: 0.7335\n",
      "Epoch 5/300\n",
      "840/839 [==============================] - 53s 63ms/step - loss: 0.3651 - accuracy: 0.8481 - val_loss: 0.6499 - val_accuracy: 0.7280\n",
      "Epoch 6/300\n",
      "840/839 [==============================] - 53s 63ms/step - loss: 0.3462 - accuracy: 0.8584 - val_loss: 0.6369 - val_accuracy: 0.7222\n",
      "Epoch 7/300\n",
      "840/839 [==============================] - 53s 63ms/step - loss: 0.3283 - accuracy: 0.8685 - val_loss: 0.7134 - val_accuracy: 0.7263\n",
      "Epoch 00007: early stopping\n",
      "144/144 [==============================] - 0s 1ms/sample - loss: 0.2142 - accuracy: 0.9444\n",
      "138/138 [==============================] - 0s 285us/sample - loss: 0.1320 - accuracy: 0.9855\n",
      "138/138 [==============================] - 0s 224us/sample - loss: 0.1731 - accuracy: 0.9710\n",
      "137/137 [==============================] - 0s 234us/sample - loss: 0.1607 - accuracy: 0.9781\n",
      "137/137 [==============================] - 0s 234us/sample - loss: 0.1697 - accuracy: 0.9781\n",
      "137/137 [==============================] - 0s 250us/sample - loss: 0.1711 - accuracy: 0.9708\n",
      "136/136 [==============================] - 0s 251us/sample - loss: 0.1648 - accuracy: 0.9853\n",
      "135/135 [==============================] - 0s 245us/sample - loss: 0.1620 - accuracy: 0.9630\n",
      "133/133 [==============================] - 0s 277us/sample - loss: 0.1660 - accuracy: 0.9624\n",
      "134/134 [==============================] - 0s 262us/sample - loss: 0.1710 - accuracy: 0.9776\n",
      "134/134 [==============================] - 0s 274us/sample - loss: 0.1971 - accuracy: 0.9478\n",
      "133/133 [==============================] - 0s 278us/sample - loss: 0.1950 - accuracy: 0.9474\n",
      "133/133 [==============================] - 0s 297us/sample - loss: 0.1754 - accuracy: 0.9624\n",
      "133/133 [==============================] - 0s 237us/sample - loss: 0.1903 - accuracy: 0.9699\n",
      "129/129 [==============================] - 0s 232us/sample - loss: 0.1722 - accuracy: 0.9767\n",
      "129/129 [==============================] - 0s 292us/sample - loss: 0.2034 - accuracy: 0.9612\n",
      "132/132 [==============================] - 0s 265us/sample - loss: 0.1787 - accuracy: 0.9848\n",
      "129/129 [==============================] - 0s 252us/sample - loss: 0.2030 - accuracy: 0.9767\n",
      "131/131 [==============================] - 0s 288us/sample - loss: 0.1890 - accuracy: 0.9237\n",
      "130/130 [==============================] - 0s 242us/sample - loss: 0.1789 - accuracy: 0.9692\n",
      "129/129 [==============================] - 0s 236us/sample - loss: 0.2049 - accuracy: 0.9535\n",
      "127/127 [==============================] - 0s 222us/sample - loss: 0.2058 - accuracy: 0.9685\n",
      "124/124 [==============================] - 0s 264us/sample - loss: 0.2002 - accuracy: 0.9919\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.2162 - accuracy: 0.9453\n",
      "128/128 [==============================] - 0s 228us/sample - loss: 0.1965 - accuracy: 0.9844\n",
      "126/126 [==============================] - 0s 285us/sample - loss: 0.2479 - accuracy: 0.9286\n",
      "124/124 [==============================] - 0s 254us/sample - loss: 0.2191 - accuracy: 0.9516\n",
      "124/124 [==============================] - 0s 254us/sample - loss: 0.1903 - accuracy: 0.9435\n",
      "124/124 [==============================] - 0s 237us/sample - loss: 0.1979 - accuracy: 0.9435\n",
      "125/125 [==============================] - 0s 239us/sample - loss: 0.2131 - accuracy: 0.9280\n",
      "126/126 [==============================] - 0s 238us/sample - loss: 0.1759 - accuracy: 0.9762\n",
      "123/123 [==============================] - 0s 263us/sample - loss: 0.1941 - accuracy: 0.9593\n",
      "124/124 [==============================] - 0s 248us/sample - loss: 0.1777 - accuracy: 0.9677\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2849 samples, validate on 683 samples\n",
      "Epoch 1/300\n",
      "2849/2849 [==============================] - 3s 904us/sample - loss: 0.6743 - accuracy: 0.5876 - val_loss: 0.6764 - val_accuracy: 0.6047\n",
      "Epoch 2/300\n",
      "2849/2849 [==============================] - 1s 206us/sample - loss: 0.6302 - accuracy: 0.6574 - val_loss: 0.6590 - val_accuracy: 0.6149\n",
      "Epoch 3/300\n",
      "2849/2849 [==============================] - 1s 176us/sample - loss: 0.6091 - accuracy: 0.6845 - val_loss: 0.6479 - val_accuracy: 0.6266\n",
      "Epoch 4/300\n",
      "2849/2849 [==============================] - 1s 215us/sample - loss: 0.5890 - accuracy: 0.7164 - val_loss: 0.6398 - val_accuracy: 0.6471\n",
      "Epoch 5/300\n",
      "2849/2849 [==============================] - 1s 199us/sample - loss: 0.5739 - accuracy: 0.7339 - val_loss: 0.6332 - val_accuracy: 0.6530\n",
      "Epoch 6/300\n",
      "2849/2849 [==============================] - 1s 181us/sample - loss: 0.5619 - accuracy: 0.7434 - val_loss: 0.6280 - val_accuracy: 0.6633\n",
      "Epoch 7/300\n",
      "2849/2849 [==============================] - 1s 184us/sample - loss: 0.5502 - accuracy: 0.7547 - val_loss: 0.6237 - val_accuracy: 0.6691\n",
      "Epoch 8/300\n",
      "2849/2849 [==============================] - 1s 204us/sample - loss: 0.5411 - accuracy: 0.7694 - val_loss: 0.6201 - val_accuracy: 0.6764\n",
      "Epoch 9/300\n",
      "2849/2849 [==============================] - 1s 198us/sample - loss: 0.5346 - accuracy: 0.7722 - val_loss: 0.6170 - val_accuracy: 0.6823\n",
      "Epoch 10/300\n",
      "2849/2849 [==============================] - 1s 235us/sample - loss: 0.5256 - accuracy: 0.7771 - val_loss: 0.6145 - val_accuracy: 0.6852\n",
      "Epoch 11/300\n",
      "2849/2849 [==============================] - 1s 233us/sample - loss: 0.5151 - accuracy: 0.7834 - val_loss: 0.6122 - val_accuracy: 0.6925\n",
      "Epoch 12/300\n",
      "2849/2849 [==============================] - 1s 222us/sample - loss: 0.5098 - accuracy: 0.7880 - val_loss: 0.6102 - val_accuracy: 0.6940\n",
      "Epoch 13/300\n",
      "2849/2849 [==============================] - 1s 239us/sample - loss: 0.5047 - accuracy: 0.7905 - val_loss: 0.6084 - val_accuracy: 0.6969\n",
      "Epoch 14/300\n",
      "2849/2849 [==============================] - 1s 262us/sample - loss: 0.4966 - accuracy: 0.7905 - val_loss: 0.6070 - val_accuracy: 0.6984\n",
      "Epoch 15/300\n",
      "2849/2849 [==============================] - 1s 222us/sample - loss: 0.4908 - accuracy: 0.7954 - val_loss: 0.6057 - val_accuracy: 0.7013\n",
      "Epoch 16/300\n",
      "2849/2849 [==============================] - 1s 212us/sample - loss: 0.4870 - accuracy: 0.8003 - val_loss: 0.6047 - val_accuracy: 0.7013\n",
      "Epoch 17/300\n",
      "2849/2849 [==============================] - 1s 218us/sample - loss: 0.4803 - accuracy: 0.7996 - val_loss: 0.6038 - val_accuracy: 0.7028\n",
      "Epoch 18/300\n",
      "2849/2849 [==============================] - 1s 240us/sample - loss: 0.4785 - accuracy: 0.7975 - val_loss: 0.6031 - val_accuracy: 0.7028\n",
      "Epoch 19/300\n",
      "2849/2849 [==============================] - 1s 232us/sample - loss: 0.4744 - accuracy: 0.7999 - val_loss: 0.6024 - val_accuracy: 0.7042\n",
      "Epoch 20/300\n",
      "2849/2849 [==============================] - 1s 224us/sample - loss: 0.4657 - accuracy: 0.8052 - val_loss: 0.6018 - val_accuracy: 0.7057\n",
      "Epoch 21/300\n",
      "2849/2849 [==============================] - 1s 244us/sample - loss: 0.4646 - accuracy: 0.8031 - val_loss: 0.6014 - val_accuracy: 0.7042\n",
      "Epoch 22/300\n",
      "2849/2849 [==============================] - 1s 260us/sample - loss: 0.4618 - accuracy: 0.8066 - val_loss: 0.6011 - val_accuracy: 0.7057\n",
      "Epoch 23/300\n",
      "2849/2849 [==============================] - 1s 236us/sample - loss: 0.4591 - accuracy: 0.8038 - val_loss: 0.6008 - val_accuracy: 0.7057\n",
      "Epoch 24/300\n",
      "2849/2849 [==============================] - 1s 218us/sample - loss: 0.4570 - accuracy: 0.8066 - val_loss: 0.6005 - val_accuracy: 0.7101\n",
      "Epoch 25/300\n",
      "2849/2849 [==============================] - 1s 225us/sample - loss: 0.4511 - accuracy: 0.8087 - val_loss: 0.6003 - val_accuracy: 0.7101\n",
      "Epoch 26/300\n",
      "2849/2849 [==============================] - 1s 217us/sample - loss: 0.4500 - accuracy: 0.8038 - val_loss: 0.6002 - val_accuracy: 0.7101\n",
      "Epoch 27/300\n",
      "2849/2849 [==============================] - 1s 226us/sample - loss: 0.4457 - accuracy: 0.8115 - val_loss: 0.6000 - val_accuracy: 0.7101\n",
      "Epoch 28/300\n",
      "2849/2849 [==============================] - 1s 225us/sample - loss: 0.4442 - accuracy: 0.8080 - val_loss: 0.6000 - val_accuracy: 0.7116\n",
      "Epoch 29/300\n",
      "2849/2849 [==============================] - 1s 209us/sample - loss: 0.4370 - accuracy: 0.8094 - val_loss: 0.6000 - val_accuracy: 0.7116\n",
      "Epoch 30/300\n",
      "2849/2849 [==============================] - 1s 190us/sample - loss: 0.4339 - accuracy: 0.8129 - val_loss: 0.6000 - val_accuracy: 0.7116\n",
      "Epoch 31/300\n",
      "2849/2849 [==============================] - 1s 184us/sample - loss: 0.4327 - accuracy: 0.8126 - val_loss: 0.6000 - val_accuracy: 0.7116\n",
      "Epoch 32/300\n",
      "2849/2849 [==============================] - 1s 206us/sample - loss: 0.4311 - accuracy: 0.8157 - val_loss: 0.6001 - val_accuracy: 0.7130\n",
      "Epoch 33/300\n",
      "2849/2849 [==============================] - 1s 217us/sample - loss: 0.4272 - accuracy: 0.8136 - val_loss: 0.6002 - val_accuracy: 0.7130\n",
      "Epoch 34/300\n",
      "2849/2849 [==============================] - 1s 206us/sample - loss: 0.4226 - accuracy: 0.8147 - val_loss: 0.6003 - val_accuracy: 0.7116\n",
      "Epoch 00034: early stopping\n",
      "117/117 [==============================] - 0s 121us/sample - loss: 0.2497 - accuracy: 0.9829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [3:34:39, 1107.72s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.68s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.33s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 841.5078125 steps, validate for 202.921875 steps\n",
      "Epoch 1/300\n",
      "842/841 [==============================] - 24s 29ms/step - loss: 0.5434 - accuracy: 0.7563 - val_loss: 0.5888 - val_accuracy: 0.7300\n",
      "Epoch 2/300\n",
      "842/841 [==============================] - 23s 27ms/step - loss: 0.5018 - accuracy: 0.7817 - val_loss: 0.5909 - val_accuracy: 0.7304\n",
      "Epoch 3/300\n",
      "842/841 [==============================] - 23s 27ms/step - loss: 0.4881 - accuracy: 0.7850 - val_loss: 0.5980 - val_accuracy: 0.7274\n",
      "Epoch 4/300\n",
      "842/841 [==============================] - 23s 28ms/step - loss: 0.4778 - accuracy: 0.7887 - val_loss: 0.6081 - val_accuracy: 0.7243\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 841.5078125 steps, validate for 202.921875 steps\n",
      "Epoch 1/300\n",
      "842/841 [==============================] - 54s 65ms/step - loss: 0.4597 - accuracy: 0.7962 - val_loss: 0.6083 - val_accuracy: 0.7221\n",
      "Epoch 2/300\n",
      "842/841 [==============================] - 53s 63ms/step - loss: 0.4328 - accuracy: 0.8104 - val_loss: 0.6242 - val_accuracy: 0.7121\n",
      "Epoch 3/300\n",
      "842/841 [==============================] - 53s 63ms/step - loss: 0.4104 - accuracy: 0.8228 - val_loss: 0.6171 - val_accuracy: 0.7198\n",
      "Epoch 4/300\n",
      "842/841 [==============================] - 53s 63ms/step - loss: 0.3895 - accuracy: 0.8341 - val_loss: 0.6972 - val_accuracy: 0.7251\n",
      "Epoch 00004: early stopping\n",
      "134/134 [==============================] - 0s 2ms/sample - loss: 0.1623 - accuracy: 0.9925\n",
      "134/134 [==============================] - 0s 230us/sample - loss: 0.1638 - accuracy: 0.9925\n",
      "131/131 [==============================] - 0s 254us/sample - loss: 0.1755 - accuracy: 1.0000\n",
      "129/129 [==============================] - 0s 252us/sample - loss: 0.1675 - accuracy: 1.0000\n",
      "129/129 [==============================] - 0s 338us/sample - loss: 0.1548 - accuracy: 1.0000\n",
      "129/129 [==============================] - 0s 265us/sample - loss: 0.1464 - accuracy: 1.0000\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.1542 - accuracy: 1.0000\n",
      "126/126 [==============================] - 0s 220us/sample - loss: 0.1613 - accuracy: 1.0000\n",
      "125/125 [==============================] - 0s 237us/sample - loss: 0.1566 - accuracy: 1.0000\n",
      "126/126 [==============================] - 0s 268us/sample - loss: 0.1467 - accuracy: 1.0000\n",
      "126/126 [==============================] - 0s 242us/sample - loss: 0.1624 - accuracy: 0.9921\n",
      "126/126 [==============================] - 0s 231us/sample - loss: 0.1506 - accuracy: 1.0000\n",
      "125/125 [==============================] - 0s 236us/sample - loss: 0.1613 - accuracy: 1.0000\n",
      "126/126 [==============================] - 0s 280us/sample - loss: 0.1713 - accuracy: 1.0000\n",
      "123/123 [==============================] - 0s 263us/sample - loss: 0.1574 - accuracy: 0.9919\n",
      "121/121 [==============================] - 0s 274us/sample - loss: 0.1643 - accuracy: 0.9917\n",
      "122/122 [==============================] - 0s 253us/sample - loss: 0.1804 - accuracy: 0.9836\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.1709 - accuracy: 0.9667\n",
      "121/121 [==============================] - 0s 259us/sample - loss: 0.1629 - accuracy: 0.9917\n",
      "121/121 [==============================] - 0s 254us/sample - loss: 0.1711 - accuracy: 0.9835\n",
      "123/123 [==============================] - 0s 232us/sample - loss: 0.1589 - accuracy: 0.9919\n",
      "123/123 [==============================] - 0s 254us/sample - loss: 0.1768 - accuracy: 0.9837\n",
      "123/123 [==============================] - 0s 231us/sample - loss: 0.1684 - accuracy: 0.9837\n",
      "122/122 [==============================] - 0s 245us/sample - loss: 0.1690 - accuracy: 0.9754\n",
      "122/122 [==============================] - 0s 254us/sample - loss: 0.1847 - accuracy: 0.9672\n",
      "121/121 [==============================] - 0s 277us/sample - loss: 0.2092 - accuracy: 0.9587\n",
      "119/119 [==============================] - 0s 242us/sample - loss: 0.2047 - accuracy: 0.9580\n",
      "119/119 [==============================] - 0s 246us/sample - loss: 0.2003 - accuracy: 0.9664\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.1854 - accuracy: 0.9833\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 0.1872 - accuracy: 0.9917\n",
      "119/119 [==============================] - 0s 254us/sample - loss: 0.1698 - accuracy: 0.9832\n",
      "118/118 [==============================] - 0s 242us/sample - loss: 0.1839 - accuracy: 0.9831\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.1815 - accuracy: 0.9583\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2854 samples, validate on 685 samples\n",
      "Epoch 1/300\n",
      "2854/2854 [==============================] - 2s 812us/sample - loss: 0.7102 - accuracy: 0.5158 - val_loss: 0.6896 - val_accuracy: 0.5299\n",
      "Epoch 2/300\n",
      "2854/2854 [==============================] - 1s 218us/sample - loss: 0.6580 - accuracy: 0.6142 - val_loss: 0.6664 - val_accuracy: 0.5912\n",
      "Epoch 3/300\n",
      "2854/2854 [==============================] - 1s 205us/sample - loss: 0.6311 - accuracy: 0.6549 - val_loss: 0.6512 - val_accuracy: 0.6248\n",
      "Epoch 4/300\n",
      "2854/2854 [==============================] - 1s 183us/sample - loss: 0.6109 - accuracy: 0.6857 - val_loss: 0.6403 - val_accuracy: 0.6599\n",
      "Epoch 5/300\n",
      "2854/2854 [==============================] - 1s 198us/sample - loss: 0.5936 - accuracy: 0.7095 - val_loss: 0.6319 - val_accuracy: 0.6672\n",
      "Epoch 6/300\n",
      "2854/2854 [==============================] - 1s 200us/sample - loss: 0.5766 - accuracy: 0.7302 - val_loss: 0.6256 - val_accuracy: 0.6832\n",
      "Epoch 7/300\n",
      "2854/2854 [==============================] - 1s 190us/sample - loss: 0.5670 - accuracy: 0.7407 - val_loss: 0.6205 - val_accuracy: 0.6934\n",
      "Epoch 8/300\n",
      "2854/2854 [==============================] - 1s 198us/sample - loss: 0.5607 - accuracy: 0.7442 - val_loss: 0.6162 - val_accuracy: 0.7036\n",
      "Epoch 9/300\n",
      "2854/2854 [==============================] - 1s 206us/sample - loss: 0.5513 - accuracy: 0.7530 - val_loss: 0.6126 - val_accuracy: 0.7109\n",
      "Epoch 10/300\n",
      "2854/2854 [==============================] - 1s 203us/sample - loss: 0.5439 - accuracy: 0.7593 - val_loss: 0.6095 - val_accuracy: 0.7168\n",
      "Epoch 11/300\n",
      "2854/2854 [==============================] - 1s 194us/sample - loss: 0.5341 - accuracy: 0.7740 - val_loss: 0.6070 - val_accuracy: 0.7241\n",
      "Epoch 12/300\n",
      "2854/2854 [==============================] - 1s 202us/sample - loss: 0.5281 - accuracy: 0.7786 - val_loss: 0.6048 - val_accuracy: 0.7255\n",
      "Epoch 13/300\n",
      "2854/2854 [==============================] - 1s 214us/sample - loss: 0.5201 - accuracy: 0.7772 - val_loss: 0.6030 - val_accuracy: 0.7270\n",
      "Epoch 14/300\n",
      "2854/2854 [==============================] - 1s 234us/sample - loss: 0.5178 - accuracy: 0.7775 - val_loss: 0.6014 - val_accuracy: 0.7299\n",
      "Epoch 15/300\n",
      "2854/2854 [==============================] - 1s 198us/sample - loss: 0.5178 - accuracy: 0.7856 - val_loss: 0.6001 - val_accuracy: 0.7299\n",
      "Epoch 16/300\n",
      "2854/2854 [==============================] - 1s 243us/sample - loss: 0.5110 - accuracy: 0.7786 - val_loss: 0.5990 - val_accuracy: 0.7299\n",
      "Epoch 17/300\n",
      "2854/2854 [==============================] - 1s 260us/sample - loss: 0.5025 - accuracy: 0.7863 - val_loss: 0.5980 - val_accuracy: 0.7285\n",
      "Epoch 18/300\n",
      "2854/2854 [==============================] - 1s 229us/sample - loss: 0.4990 - accuracy: 0.7943 - val_loss: 0.5971 - val_accuracy: 0.7285\n",
      "Epoch 19/300\n",
      "2854/2854 [==============================] - 1s 208us/sample - loss: 0.4971 - accuracy: 0.7880 - val_loss: 0.5964 - val_accuracy: 0.7285\n",
      "Epoch 20/300\n",
      "2854/2854 [==============================] - 1s 254us/sample - loss: 0.4949 - accuracy: 0.7877 - val_loss: 0.5959 - val_accuracy: 0.7285\n",
      "Epoch 21/300\n",
      "2854/2854 [==============================] - 1s 240us/sample - loss: 0.4923 - accuracy: 0.7936 - val_loss: 0.5954 - val_accuracy: 0.7285\n",
      "Epoch 22/300\n",
      "2854/2854 [==============================] - 1s 218us/sample - loss: 0.4885 - accuracy: 0.7950 - val_loss: 0.5947 - val_accuracy: 0.7270\n",
      "Epoch 23/300\n",
      "2854/2854 [==============================] - 1s 204us/sample - loss: 0.4869 - accuracy: 0.7912 - val_loss: 0.5943 - val_accuracy: 0.7270\n",
      "Epoch 24/300\n",
      "2854/2854 [==============================] - 1s 228us/sample - loss: 0.4819 - accuracy: 0.7971 - val_loss: 0.5939 - val_accuracy: 0.7255\n",
      "Epoch 25/300\n",
      "2854/2854 [==============================] - 1s 222us/sample - loss: 0.4818 - accuracy: 0.7922 - val_loss: 0.5936 - val_accuracy: 0.7226\n",
      "Epoch 26/300\n",
      "2854/2854 [==============================] - 1s 201us/sample - loss: 0.4751 - accuracy: 0.7964 - val_loss: 0.5933 - val_accuracy: 0.7255\n",
      "Epoch 27/300\n",
      "2854/2854 [==============================] - 1s 226us/sample - loss: 0.4727 - accuracy: 0.8006 - val_loss: 0.5930 - val_accuracy: 0.7241\n",
      "Epoch 28/300\n",
      "2854/2854 [==============================] - 1s 217us/sample - loss: 0.4702 - accuracy: 0.8003 - val_loss: 0.5928 - val_accuracy: 0.7241\n",
      "Epoch 29/300\n",
      "2854/2854 [==============================] - 1s 221us/sample - loss: 0.4675 - accuracy: 0.7989 - val_loss: 0.5926 - val_accuracy: 0.7241\n",
      "Epoch 30/300\n",
      "2854/2854 [==============================] - 1s 223us/sample - loss: 0.4685 - accuracy: 0.7992 - val_loss: 0.5923 - val_accuracy: 0.7226\n",
      "Epoch 31/300\n",
      "2854/2854 [==============================] - 1s 226us/sample - loss: 0.4635 - accuracy: 0.8010 - val_loss: 0.5920 - val_accuracy: 0.7226\n",
      "Epoch 32/300\n",
      "2854/2854 [==============================] - 1s 224us/sample - loss: 0.4628 - accuracy: 0.8017 - val_loss: 0.5919 - val_accuracy: 0.7212\n",
      "Epoch 33/300\n",
      "2854/2854 [==============================] - 1s 209us/sample - loss: 0.4600 - accuracy: 0.8020 - val_loss: 0.5916 - val_accuracy: 0.7212\n",
      "Epoch 34/300\n",
      "2854/2854 [==============================] - 1s 207us/sample - loss: 0.4562 - accuracy: 0.7996 - val_loss: 0.5916 - val_accuracy: 0.7212\n",
      "Epoch 35/300\n",
      "2854/2854 [==============================] - 1s 213us/sample - loss: 0.4565 - accuracy: 0.8080 - val_loss: 0.5915 - val_accuracy: 0.7270\n",
      "Epoch 36/300\n",
      "2854/2854 [==============================] - 1s 183us/sample - loss: 0.4545 - accuracy: 0.8062 - val_loss: 0.5912 - val_accuracy: 0.7270\n",
      "Epoch 37/300\n",
      "2854/2854 [==============================] - 1s 194us/sample - loss: 0.4499 - accuracy: 0.8055 - val_loss: 0.5912 - val_accuracy: 0.7270\n",
      "Epoch 38/300\n",
      "2854/2854 [==============================] - 1s 196us/sample - loss: 0.4457 - accuracy: 0.8048 - val_loss: 0.5912 - val_accuracy: 0.7270\n",
      "Epoch 39/300\n",
      "2854/2854 [==============================] - 1s 227us/sample - loss: 0.4464 - accuracy: 0.8087 - val_loss: 0.5910 - val_accuracy: 0.7270\n",
      "Epoch 40/300\n",
      "2854/2854 [==============================] - 1s 217us/sample - loss: 0.4467 - accuracy: 0.8111 - val_loss: 0.5908 - val_accuracy: 0.7270\n",
      "Epoch 41/300\n",
      "2854/2854 [==============================] - 1s 195us/sample - loss: 0.4470 - accuracy: 0.8073 - val_loss: 0.5907 - val_accuracy: 0.7255\n",
      "Epoch 42/300\n",
      "2854/2854 [==============================] - 1s 216us/sample - loss: 0.4393 - accuracy: 0.8111 - val_loss: 0.5905 - val_accuracy: 0.7241\n",
      "Epoch 43/300\n",
      "2854/2854 [==============================] - 1s 217us/sample - loss: 0.4415 - accuracy: 0.8118 - val_loss: 0.5903 - val_accuracy: 0.7241\n",
      "Epoch 44/300\n",
      "2854/2854 [==============================] - 1s 222us/sample - loss: 0.4399 - accuracy: 0.8101 - val_loss: 0.5903 - val_accuracy: 0.7241\n",
      "Epoch 45/300\n",
      "2854/2854 [==============================] - 1s 205us/sample - loss: 0.4346 - accuracy: 0.8118 - val_loss: 0.5902 - val_accuracy: 0.7241\n",
      "Epoch 46/300\n",
      "2854/2854 [==============================] - 1s 177us/sample - loss: 0.4379 - accuracy: 0.8104 - val_loss: 0.5903 - val_accuracy: 0.7241\n",
      "Epoch 47/300\n",
      "2854/2854 [==============================] - 1s 204us/sample - loss: 0.4341 - accuracy: 0.8160 - val_loss: 0.5904 - val_accuracy: 0.7241\n",
      "Epoch 48/300\n",
      "2854/2854 [==============================] - 1s 203us/sample - loss: 0.4316 - accuracy: 0.8153 - val_loss: 0.5903 - val_accuracy: 0.7241\n",
      "Epoch 00048: early stopping\n",
      "110/110 [==============================] - 0s 148us/sample - loss: 0.2565 - accuracy: 0.9909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [3:51:23, 1076.51s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.29s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.21s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 841.234375 steps, validate for 198.6171875 steps\n",
      "Epoch 1/300\n",
      "842/841 [==============================] - 24s 29ms/step - loss: 0.5537 - accuracy: 0.7460 - val_loss: 0.6203 - val_accuracy: 0.7184\n",
      "Epoch 2/300\n",
      "842/841 [==============================] - 23s 28ms/step - loss: 0.5054 - accuracy: 0.7799 - val_loss: 0.6239 - val_accuracy: 0.7163\n",
      "Epoch 3/300\n",
      "842/841 [==============================] - 23s 28ms/step - loss: 0.4915 - accuracy: 0.7839 - val_loss: 0.6244 - val_accuracy: 0.7184\n",
      "Epoch 4/300\n",
      "842/841 [==============================] - 23s 28ms/step - loss: 0.4810 - accuracy: 0.7878 - val_loss: 0.6319 - val_accuracy: 0.7172\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 841.234375 steps, validate for 198.6171875 steps\n",
      "Epoch 1/300\n",
      "842/841 [==============================] - 54s 64ms/step - loss: 0.4629 - accuracy: 0.7956 - val_loss: 0.6730 - val_accuracy: 0.7203\n",
      "Epoch 2/300\n",
      "842/841 [==============================] - 53s 63ms/step - loss: 0.4355 - accuracy: 0.8091 - val_loss: 0.6445 - val_accuracy: 0.6990\n",
      "Epoch 3/300\n",
      "842/841 [==============================] - 53s 63ms/step - loss: 0.4118 - accuracy: 0.8229 - val_loss: 0.6599 - val_accuracy: 0.6920\n",
      "Epoch 4/300\n",
      "842/841 [==============================] - 53s 63ms/step - loss: 0.3899 - accuracy: 0.8340 - val_loss: 0.6814 - val_accuracy: 0.6836\n",
      "Epoch 5/300\n",
      "842/841 [==============================] - 53s 63ms/step - loss: 0.3694 - accuracy: 0.8460 - val_loss: 0.6804 - val_accuracy: 0.7048\n",
      "Epoch 00005: early stopping\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 0.2048 - accuracy: 0.9627\n",
      "155/155 [==============================] - 0s 228us/sample - loss: 0.1956 - accuracy: 0.9742\n",
      "153/153 [==============================] - 0s 218us/sample - loss: 0.1952 - accuracy: 0.9673\n",
      "153/153 [==============================] - 0s 210us/sample - loss: 0.2199 - accuracy: 0.9542\n",
      "151/151 [==============================] - 0s 222us/sample - loss: 0.2120 - accuracy: 0.9603\n",
      "149/149 [==============================] - 0s 227us/sample - loss: 0.1977 - accuracy: 0.9664\n",
      "149/149 [==============================] - 0s 215us/sample - loss: 0.2100 - accuracy: 0.9799\n",
      "149/149 [==============================] - 0s 228us/sample - loss: 0.2282 - accuracy: 0.9530\n",
      "149/149 [==============================] - 0s 214us/sample - loss: 0.1980 - accuracy: 0.9866\n",
      "149/149 [==============================] - 0s 269us/sample - loss: 0.2349 - accuracy: 0.9463\n",
      "149/149 [==============================] - 0s 244us/sample - loss: 0.2491 - accuracy: 0.9396\n",
      "146/146 [==============================] - 0s 223us/sample - loss: 0.2192 - accuracy: 0.9658\n",
      "146/146 [==============================] - 0s 236us/sample - loss: 0.1946 - accuracy: 0.9863\n",
      "141/141 [==============================] - 0s 243us/sample - loss: 0.2236 - accuracy: 0.9716\n",
      "142/142 [==============================] - 0s 238us/sample - loss: 0.2106 - accuracy: 0.9718\n",
      "140/140 [==============================] - 0s 259us/sample - loss: 0.2312 - accuracy: 0.9571\n",
      "139/139 [==============================] - 0s 229us/sample - loss: 0.2108 - accuracy: 0.9568\n",
      "140/140 [==============================] - 0s 251us/sample - loss: 0.2381 - accuracy: 0.9714\n",
      "135/135 [==============================] - 0s 267us/sample - loss: 0.2385 - accuracy: 0.9259\n",
      "136/136 [==============================] - 0s 276us/sample - loss: 0.2187 - accuracy: 0.9338\n",
      "137/137 [==============================] - 0s 252us/sample - loss: 0.2299 - accuracy: 0.9489\n",
      "137/137 [==============================] - 0s 243us/sample - loss: 0.2316 - accuracy: 0.9562\n",
      "135/135 [==============================] - 0s 244us/sample - loss: 0.2209 - accuracy: 0.9481\n",
      "136/136 [==============================] - 0s 261us/sample - loss: 0.2293 - accuracy: 0.9632\n",
      "136/136 [==============================] - 0s 276us/sample - loss: 0.2334 - accuracy: 0.9559\n",
      "134/134 [==============================] - 0s 274us/sample - loss: 0.2201 - accuracy: 0.9627\n",
      "134/134 [==============================] - 0s 282us/sample - loss: 0.2077 - accuracy: 0.9478\n",
      "134/134 [==============================] - 0s 312us/sample - loss: 0.2132 - accuracy: 0.9776\n",
      "136/136 [==============================] - 0s 287us/sample - loss: 0.2333 - accuracy: 0.9632\n",
      "134/134 [==============================] - 0s 248us/sample - loss: 0.2135 - accuracy: 0.9552\n",
      "133/133 [==============================] - 0s 249us/sample - loss: 0.2052 - accuracy: 0.9398\n",
      "129/129 [==============================] - 0s 251us/sample - loss: 0.2157 - accuracy: 0.9302\n",
      "130/130 [==============================] - 0s 247us/sample - loss: 0.2200 - accuracy: 0.9385\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2862 samples, validate on 667 samples\n",
      "Epoch 1/300\n",
      "2862/2862 [==============================] - 2s 802us/sample - loss: 0.6658 - accuracy: 0.5936 - val_loss: 0.6743 - val_accuracy: 0.5802\n",
      "Epoch 2/300\n",
      "2862/2862 [==============================] - 1s 218us/sample - loss: 0.6325 - accuracy: 0.6548 - val_loss: 0.6611 - val_accuracy: 0.6042\n",
      "Epoch 3/300\n",
      "2862/2862 [==============================] - 1s 224us/sample - loss: 0.6148 - accuracy: 0.6897 - val_loss: 0.6519 - val_accuracy: 0.6282\n",
      "Epoch 4/300\n",
      "2862/2862 [==============================] - 1s 195us/sample - loss: 0.6041 - accuracy: 0.7075 - val_loss: 0.6450 - val_accuracy: 0.6387\n",
      "Epoch 5/300\n",
      "2862/2862 [==============================] - 1s 207us/sample - loss: 0.5876 - accuracy: 0.7341 - val_loss: 0.6395 - val_accuracy: 0.6597\n",
      "Epoch 6/300\n",
      "2862/2862 [==============================] - 1s 221us/sample - loss: 0.5794 - accuracy: 0.7400 - val_loss: 0.6348 - val_accuracy: 0.6717\n",
      "Epoch 7/300\n",
      "2862/2862 [==============================] - 1s 253us/sample - loss: 0.5715 - accuracy: 0.7446 - val_loss: 0.6308 - val_accuracy: 0.6792\n",
      "Epoch 8/300\n",
      "2862/2862 [==============================] - 1s 241us/sample - loss: 0.5611 - accuracy: 0.7502 - val_loss: 0.6273 - val_accuracy: 0.6882\n",
      "Epoch 9/300\n",
      "2862/2862 [==============================] - 1s 233us/sample - loss: 0.5527 - accuracy: 0.7635 - val_loss: 0.6242 - val_accuracy: 0.6897\n",
      "Epoch 10/300\n",
      "2862/2862 [==============================] - 1s 203us/sample - loss: 0.5493 - accuracy: 0.7680 - val_loss: 0.6215 - val_accuracy: 0.6897\n",
      "Epoch 11/300\n",
      "2862/2862 [==============================] - 1s 205us/sample - loss: 0.5379 - accuracy: 0.7788 - val_loss: 0.6191 - val_accuracy: 0.6987\n",
      "Epoch 12/300\n",
      "2862/2862 [==============================] - 1s 237us/sample - loss: 0.5378 - accuracy: 0.7694 - val_loss: 0.6170 - val_accuracy: 0.7016\n",
      "Epoch 13/300\n",
      "2862/2862 [==============================] - 1s 226us/sample - loss: 0.5328 - accuracy: 0.7827 - val_loss: 0.6150 - val_accuracy: 0.7031\n",
      "Epoch 14/300\n",
      "2862/2862 [==============================] - 1s 249us/sample - loss: 0.5269 - accuracy: 0.7844 - val_loss: 0.6133 - val_accuracy: 0.7091\n",
      "Epoch 15/300\n",
      "2862/2862 [==============================] - 1s 214us/sample - loss: 0.5198 - accuracy: 0.7876 - val_loss: 0.6117 - val_accuracy: 0.7091\n",
      "Epoch 16/300\n",
      "2862/2862 [==============================] - 1s 196us/sample - loss: 0.5178 - accuracy: 0.7879 - val_loss: 0.6102 - val_accuracy: 0.7121\n",
      "Epoch 17/300\n",
      "2862/2862 [==============================] - 1s 229us/sample - loss: 0.5135 - accuracy: 0.7925 - val_loss: 0.6089 - val_accuracy: 0.7136\n",
      "Epoch 18/300\n",
      "2862/2862 [==============================] - 1s 208us/sample - loss: 0.5093 - accuracy: 0.7932 - val_loss: 0.6079 - val_accuracy: 0.7166\n",
      "Epoch 19/300\n",
      "2862/2862 [==============================] - 1s 196us/sample - loss: 0.5055 - accuracy: 0.7876 - val_loss: 0.6070 - val_accuracy: 0.7181\n",
      "Epoch 20/300\n",
      "2862/2862 [==============================] - 1s 218us/sample - loss: 0.5014 - accuracy: 0.7925 - val_loss: 0.6062 - val_accuracy: 0.7196\n",
      "Epoch 21/300\n",
      "2862/2862 [==============================] - 1s 216us/sample - loss: 0.4923 - accuracy: 0.7980 - val_loss: 0.6053 - val_accuracy: 0.7181\n",
      "Epoch 22/300\n",
      "2862/2862 [==============================] - 1s 218us/sample - loss: 0.4916 - accuracy: 0.7952 - val_loss: 0.6046 - val_accuracy: 0.7196\n",
      "Epoch 23/300\n",
      "2862/2862 [==============================] - 1s 237us/sample - loss: 0.4863 - accuracy: 0.7980 - val_loss: 0.6040 - val_accuracy: 0.7181\n",
      "Epoch 24/300\n",
      "2862/2862 [==============================] - 1s 212us/sample - loss: 0.4858 - accuracy: 0.8040 - val_loss: 0.6035 - val_accuracy: 0.7196\n",
      "Epoch 25/300\n",
      "2862/2862 [==============================] - 1s 214us/sample - loss: 0.4805 - accuracy: 0.8092 - val_loss: 0.6032 - val_accuracy: 0.7211\n",
      "Epoch 26/300\n",
      "2862/2862 [==============================] - 1s 230us/sample - loss: 0.4756 - accuracy: 0.8103 - val_loss: 0.6028 - val_accuracy: 0.7226\n",
      "Epoch 27/300\n",
      "2862/2862 [==============================] - 1s 206us/sample - loss: 0.4713 - accuracy: 0.8096 - val_loss: 0.6026 - val_accuracy: 0.7226\n",
      "Epoch 28/300\n",
      "2862/2862 [==============================] - 1s 194us/sample - loss: 0.4700 - accuracy: 0.8082 - val_loss: 0.6024 - val_accuracy: 0.7226\n",
      "Epoch 29/300\n",
      "2862/2862 [==============================] - 1s 181us/sample - loss: 0.4698 - accuracy: 0.8131 - val_loss: 0.6024 - val_accuracy: 0.7256\n",
      "Epoch 30/300\n",
      "2862/2862 [==============================] - 1s 195us/sample - loss: 0.4617 - accuracy: 0.8131 - val_loss: 0.6023 - val_accuracy: 0.7271\n",
      "Epoch 31/300\n",
      "2862/2862 [==============================] - 1s 192us/sample - loss: 0.4624 - accuracy: 0.8166 - val_loss: 0.6025 - val_accuracy: 0.7271\n",
      "Epoch 32/300\n",
      "2862/2862 [==============================] - 1s 185us/sample - loss: 0.4563 - accuracy: 0.8197 - val_loss: 0.6024 - val_accuracy: 0.7286\n",
      "Epoch 33/300\n",
      "2862/2862 [==============================] - 1s 193us/sample - loss: 0.4556 - accuracy: 0.8152 - val_loss: 0.6026 - val_accuracy: 0.7286\n",
      "Epoch 00033: early stopping\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.2739 - accuracy: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [4:08:48, 1067.17s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:04<00:04,  4.42s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.83s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 845.140625 steps, validate for 203.1328125 steps\n",
      "Epoch 1/300\n",
      "846/845 [==============================] - 24s 28ms/step - loss: 0.6164 - accuracy: 0.6717 - val_loss: 0.5925 - val_accuracy: 0.7319\n",
      "Epoch 2/300\n",
      "846/845 [==============================] - 23s 28ms/step - loss: 0.5046 - accuracy: 0.7823 - val_loss: 0.5922 - val_accuracy: 0.7346\n",
      "Epoch 3/300\n",
      "846/845 [==============================] - 23s 28ms/step - loss: 0.4884 - accuracy: 0.7875 - val_loss: 0.5915 - val_accuracy: 0.7370\n",
      "Epoch 4/300\n",
      "846/845 [==============================] - 23s 28ms/step - loss: 0.4770 - accuracy: 0.7916 - val_loss: 0.5917 - val_accuracy: 0.7387\n",
      "Epoch 5/300\n",
      "846/845 [==============================] - 24s 28ms/step - loss: 0.4672 - accuracy: 0.7962 - val_loss: 0.5954 - val_accuracy: 0.7391\n",
      "Epoch 6/300\n",
      "846/845 [==============================] - 23s 28ms/step - loss: 0.4583 - accuracy: 0.8002 - val_loss: 0.5947 - val_accuracy: 0.7406\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 845.140625 steps, validate for 203.1328125 steps\n",
      "Epoch 1/300\n",
      "846/845 [==============================] - 54s 64ms/step - loss: 0.4421 - accuracy: 0.8080 - val_loss: 0.5931 - val_accuracy: 0.7419\n",
      "Epoch 2/300\n",
      "846/845 [==============================] - 53s 63ms/step - loss: 0.4156 - accuracy: 0.8221 - val_loss: 0.6324 - val_accuracy: 0.7288\n",
      "Epoch 3/300\n",
      "846/845 [==============================] - 53s 63ms/step - loss: 0.3935 - accuracy: 0.8343 - val_loss: 0.6170 - val_accuracy: 0.7044\n",
      "Epoch 4/300\n",
      "846/845 [==============================] - 53s 63ms/step - loss: 0.3731 - accuracy: 0.8455 - val_loss: 0.6315 - val_accuracy: 0.7256\n",
      "Epoch 00004: early stopping\n",
      "144/144 [==============================] - 0s 1ms/sample - loss: 0.6545 - accuracy: 0.7222\n",
      "130/130 [==============================] - 0s 248us/sample - loss: 0.6592 - accuracy: 0.8000\n",
      "118/118 [==============================] - 0s 250us/sample - loss: 0.6514 - accuracy: 0.7458\n",
      "115/115 [==============================] - 0s 231us/sample - loss: 0.6532 - accuracy: 0.7652\n",
      "114/114 [==============================] - 0s 231us/sample - loss: 0.7334 - accuracy: 0.7456\n",
      "113/113 [==============================] - 0s 239us/sample - loss: 0.7795 - accuracy: 0.7168\n",
      "113/113 [==============================] - 0s 246us/sample - loss: 0.8466 - accuracy: 0.6991\n",
      "114/114 [==============================] - 0s 238us/sample - loss: 0.7685 - accuracy: 0.7105\n",
      "114/114 [==============================] - 0s 212us/sample - loss: 0.8216 - accuracy: 0.7018\n",
      "111/111 [==============================] - 0s 210us/sample - loss: 0.7458 - accuracy: 0.7117\n",
      "110/110 [==============================] - 0s 230us/sample - loss: 0.7286 - accuracy: 0.7000\n",
      "110/110 [==============================] - 0s 227us/sample - loss: 0.7355 - accuracy: 0.6909\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.8162 - accuracy: 0.6964\n",
      "112/112 [==============================] - 0s 265us/sample - loss: 0.7436 - accuracy: 0.7232\n",
      "113/113 [==============================] - 0s 264us/sample - loss: 0.9276 - accuracy: 0.6903\n",
      "114/114 [==============================] - 0s 270us/sample - loss: 1.0196 - accuracy: 0.6228\n",
      "111/111 [==============================] - 0s 232us/sample - loss: 0.8965 - accuracy: 0.6847\n",
      "107/107 [==============================] - 0s 275us/sample - loss: 1.2103 - accuracy: 0.5888\n",
      "107/107 [==============================] - 0s 236us/sample - loss: 0.8641 - accuracy: 0.7103\n",
      "106/106 [==============================] - 0s 278us/sample - loss: 1.0843 - accuracy: 0.6415\n",
      "103/103 [==============================] - 0s 244us/sample - loss: 1.0716 - accuracy: 0.6602\n",
      "104/104 [==============================] - 0s 268us/sample - loss: 1.2009 - accuracy: 0.6731\n",
      "103/103 [==============================] - 0s 237us/sample - loss: 1.1620 - accuracy: 0.6796\n",
      "104/104 [==============================] - 0s 257us/sample - loss: 1.0186 - accuracy: 0.6346\n",
      "103/103 [==============================] - 0s 267us/sample - loss: 0.9455 - accuracy: 0.6796\n",
      "102/102 [==============================] - 0s 300us/sample - loss: 1.1381 - accuracy: 0.6765\n",
      "100/100 [==============================] - 0s 278us/sample - loss: 1.1445 - accuracy: 0.6100\n",
      "101/101 [==============================] - 0s 345us/sample - loss: 0.9798 - accuracy: 0.6436\n",
      "101/101 [==============================] - 0s 280us/sample - loss: 0.9339 - accuracy: 0.6832\n",
      "99/99 [==============================] - 0s 254us/sample - loss: 0.9007 - accuracy: 0.7172\n",
      "98/98 [==============================] - 0s 289us/sample - loss: 1.0338 - accuracy: 0.7347\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.9051 - accuracy: 0.6979\n",
      "97/97 [==============================] - 0s 288us/sample - loss: 0.8018 - accuracy: 0.7320\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2867 samples, validate on 689 samples\n",
      "Epoch 1/300\n",
      "2867/2867 [==============================] - 2s 814us/sample - loss: 0.6976 - accuracy: 0.5455 - val_loss: 0.6921 - val_accuracy: 0.5617\n",
      "Epoch 2/300\n",
      "2867/2867 [==============================] - 1s 212us/sample - loss: 0.6639 - accuracy: 0.6156 - val_loss: 0.6757 - val_accuracy: 0.5776\n",
      "Epoch 3/300\n",
      "2867/2867 [==============================] - 1s 220us/sample - loss: 0.6419 - accuracy: 0.6505 - val_loss: 0.6643 - val_accuracy: 0.6052\n",
      "Epoch 4/300\n",
      "2867/2867 [==============================] - 1s 206us/sample - loss: 0.6233 - accuracy: 0.6721 - val_loss: 0.6554 - val_accuracy: 0.6241\n",
      "Epoch 5/300\n",
      "2867/2867 [==============================] - 1s 252us/sample - loss: 0.6125 - accuracy: 0.6850 - val_loss: 0.6482 - val_accuracy: 0.6328\n",
      "Epoch 6/300\n",
      "2867/2867 [==============================] - 1s 237us/sample - loss: 0.6015 - accuracy: 0.7035 - val_loss: 0.6418 - val_accuracy: 0.6430\n",
      "Epoch 7/300\n",
      "2867/2867 [==============================] - 1s 236us/sample - loss: 0.5934 - accuracy: 0.7077 - val_loss: 0.6363 - val_accuracy: 0.6502\n",
      "Epoch 8/300\n",
      "2867/2867 [==============================] - 1s 209us/sample - loss: 0.5856 - accuracy: 0.7220 - val_loss: 0.6314 - val_accuracy: 0.6531\n",
      "Epoch 9/300\n",
      "2867/2867 [==============================] - 1s 183us/sample - loss: 0.5725 - accuracy: 0.7293 - val_loss: 0.6271 - val_accuracy: 0.6604\n",
      "Epoch 10/300\n",
      "2867/2867 [==============================] - 1s 186us/sample - loss: 0.5676 - accuracy: 0.7415 - val_loss: 0.6232 - val_accuracy: 0.6691\n",
      "Epoch 11/300\n",
      "2867/2867 [==============================] - 1s 207us/sample - loss: 0.5590 - accuracy: 0.7412 - val_loss: 0.6196 - val_accuracy: 0.6778\n",
      "Epoch 12/300\n",
      "2867/2867 [==============================] - 1s 200us/sample - loss: 0.5470 - accuracy: 0.7632 - val_loss: 0.6163 - val_accuracy: 0.6851\n",
      "Epoch 13/300\n",
      "2867/2867 [==============================] - 1s 193us/sample - loss: 0.5452 - accuracy: 0.7646 - val_loss: 0.6133 - val_accuracy: 0.6880\n",
      "Epoch 14/300\n",
      "2867/2867 [==============================] - 1s 188us/sample - loss: 0.5362 - accuracy: 0.7667 - val_loss: 0.6105 - val_accuracy: 0.6909\n",
      "Epoch 15/300\n",
      "2867/2867 [==============================] - 1s 218us/sample - loss: 0.5312 - accuracy: 0.7736 - val_loss: 0.6079 - val_accuracy: 0.6909\n",
      "Epoch 16/300\n",
      "2867/2867 [==============================] - 1s 233us/sample - loss: 0.5297 - accuracy: 0.7642 - val_loss: 0.6056 - val_accuracy: 0.6938\n",
      "Epoch 17/300\n",
      "2867/2867 [==============================] - 1s 235us/sample - loss: 0.5204 - accuracy: 0.7768 - val_loss: 0.6035 - val_accuracy: 0.6952\n",
      "Epoch 18/300\n",
      "2867/2867 [==============================] - 1s 227us/sample - loss: 0.5159 - accuracy: 0.7792 - val_loss: 0.6016 - val_accuracy: 0.6938\n",
      "Epoch 19/300\n",
      "2867/2867 [==============================] - 1s 228us/sample - loss: 0.5104 - accuracy: 0.7844 - val_loss: 0.5997 - val_accuracy: 0.6952\n",
      "Epoch 20/300\n",
      "2867/2867 [==============================] - 1s 217us/sample - loss: 0.5065 - accuracy: 0.7837 - val_loss: 0.5981 - val_accuracy: 0.6967\n",
      "Epoch 21/300\n",
      "2867/2867 [==============================] - 1s 236us/sample - loss: 0.5019 - accuracy: 0.7886 - val_loss: 0.5966 - val_accuracy: 0.7010\n",
      "Epoch 22/300\n",
      "2867/2867 [==============================] - 1s 210us/sample - loss: 0.4975 - accuracy: 0.7942 - val_loss: 0.5952 - val_accuracy: 0.7010\n",
      "Epoch 23/300\n",
      "2867/2867 [==============================] - 1s 198us/sample - loss: 0.4910 - accuracy: 0.7960 - val_loss: 0.5940 - val_accuracy: 0.7010\n",
      "Epoch 24/300\n",
      "2867/2867 [==============================] - 1s 186us/sample - loss: 0.4877 - accuracy: 0.7956 - val_loss: 0.5929 - val_accuracy: 0.7025\n",
      "Epoch 25/300\n",
      "2867/2867 [==============================] - 1s 209us/sample - loss: 0.4819 - accuracy: 0.7991 - val_loss: 0.5919 - val_accuracy: 0.7068\n",
      "Epoch 26/300\n",
      "2867/2867 [==============================] - 1s 198us/sample - loss: 0.4810 - accuracy: 0.7939 - val_loss: 0.5910 - val_accuracy: 0.7126\n",
      "Epoch 27/300\n",
      "2867/2867 [==============================] - 1s 196us/sample - loss: 0.4752 - accuracy: 0.8029 - val_loss: 0.5901 - val_accuracy: 0.7141\n",
      "Epoch 28/300\n",
      "2867/2867 [==============================] - 1s 210us/sample - loss: 0.4717 - accuracy: 0.8050 - val_loss: 0.5894 - val_accuracy: 0.7141\n",
      "Epoch 29/300\n",
      "2867/2867 [==============================] - 1s 228us/sample - loss: 0.4646 - accuracy: 0.8068 - val_loss: 0.5887 - val_accuracy: 0.7155\n",
      "Epoch 30/300\n",
      "2867/2867 [==============================] - 1s 237us/sample - loss: 0.4634 - accuracy: 0.8078 - val_loss: 0.5881 - val_accuracy: 0.7141\n",
      "Epoch 31/300\n",
      "2867/2867 [==============================] - 1s 261us/sample - loss: 0.4590 - accuracy: 0.8057 - val_loss: 0.5877 - val_accuracy: 0.7141\n",
      "Epoch 32/300\n",
      "2867/2867 [==============================] - 1s 259us/sample - loss: 0.4589 - accuracy: 0.8151 - val_loss: 0.5872 - val_accuracy: 0.7155\n",
      "Epoch 33/300\n",
      "2867/2867 [==============================] - 1s 218us/sample - loss: 0.4532 - accuracy: 0.8158 - val_loss: 0.5869 - val_accuracy: 0.7155\n",
      "Epoch 34/300\n",
      "2867/2867 [==============================] - 1s 248us/sample - loss: 0.4486 - accuracy: 0.8113 - val_loss: 0.5867 - val_accuracy: 0.7170\n",
      "Epoch 35/300\n",
      "2867/2867 [==============================] - 1s 210us/sample - loss: 0.4463 - accuracy: 0.8228 - val_loss: 0.5865 - val_accuracy: 0.7199\n",
      "Epoch 36/300\n",
      "2867/2867 [==============================] - 1s 205us/sample - loss: 0.4461 - accuracy: 0.8193 - val_loss: 0.5863 - val_accuracy: 0.7199\n",
      "Epoch 37/300\n",
      "2867/2867 [==============================] - 1s 190us/sample - loss: 0.4416 - accuracy: 0.8242 - val_loss: 0.5862 - val_accuracy: 0.7199\n",
      "Epoch 38/300\n",
      "2867/2867 [==============================] - 1s 200us/sample - loss: 0.4352 - accuracy: 0.8211 - val_loss: 0.5863 - val_accuracy: 0.7199\n",
      "Epoch 39/300\n",
      "2867/2867 [==============================] - 1s 192us/sample - loss: 0.4363 - accuracy: 0.8232 - val_loss: 0.5863 - val_accuracy: 0.7184\n",
      "Epoch 40/300\n",
      "2867/2867 [==============================] - 1s 206us/sample - loss: 0.4334 - accuracy: 0.8221 - val_loss: 0.5864 - val_accuracy: 0.7199\n",
      "Epoch 00040: early stopping\n",
      "93/93 [==============================] - 0s 146us/sample - loss: 0.5643 - accuracy: 0.7419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [4:26:13, 1060.60s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.96s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.61s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 841.2890625 steps, validate for 203.25 steps\n",
      "Epoch 1/300\n",
      "842/841 [==============================] - 25s 29ms/step - loss: 0.5851 - accuracy: 0.7038 - val_loss: 0.6154 - val_accuracy: 0.7257\n",
      "Epoch 2/300\n",
      "842/841 [==============================] - 24s 28ms/step - loss: 0.5031 - accuracy: 0.7804 - val_loss: 0.6177 - val_accuracy: 0.7255\n",
      "Epoch 3/300\n",
      "842/841 [==============================] - 24s 28ms/step - loss: 0.4887 - accuracy: 0.7851 - val_loss: 0.6241 - val_accuracy: 0.7233\n",
      "Epoch 4/300\n",
      "842/841 [==============================] - 23s 27ms/step - loss: 0.4781 - accuracy: 0.7880 - val_loss: 0.6286 - val_accuracy: 0.7222\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 841.2890625 steps, validate for 203.25 steps\n",
      "Epoch 1/300\n",
      "842/841 [==============================] - 54s 64ms/step - loss: 0.4597 - accuracy: 0.7964 - val_loss: 0.6046 - val_accuracy: 0.7221\n",
      "Epoch 2/300\n",
      "842/841 [==============================] - 53s 63ms/step - loss: 0.4321 - accuracy: 0.8098 - val_loss: 0.6212 - val_accuracy: 0.7194\n",
      "Epoch 3/300\n",
      "842/841 [==============================] - 53s 63ms/step - loss: 0.4093 - accuracy: 0.8220 - val_loss: 0.6612 - val_accuracy: 0.7276\n",
      "Epoch 4/300\n",
      "842/841 [==============================] - 53s 63ms/step - loss: 0.3879 - accuracy: 0.8343 - val_loss: 0.6736 - val_accuracy: 0.7200\n",
      "Epoch 00004: early stopping\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.3170 - accuracy: 0.9110\n",
      "142/142 [==============================] - 0s 229us/sample - loss: 0.3305 - accuracy: 0.8873\n",
      "138/138 [==============================] - 0s 220us/sample - loss: 0.3465 - accuracy: 0.8841\n",
      "137/137 [==============================] - 0s 228us/sample - loss: 0.3150 - accuracy: 0.9124\n",
      "134/134 [==============================] - 0s 228us/sample - loss: 0.3185 - accuracy: 0.9030\n",
      "130/130 [==============================] - 0s 226us/sample - loss: 0.2990 - accuracy: 0.9154\n",
      "129/129 [==============================] - 0s 235us/sample - loss: 0.2785 - accuracy: 0.9070\n",
      "127/127 [==============================] - 0s 241us/sample - loss: 0.2997 - accuracy: 0.9291\n",
      "125/125 [==============================] - 0s 234us/sample - loss: 0.2912 - accuracy: 0.9280\n",
      "125/125 [==============================] - 0s 221us/sample - loss: 0.3222 - accuracy: 0.9200\n",
      "125/125 [==============================] - 0s 267us/sample - loss: 0.3015 - accuracy: 0.9280\n",
      "125/125 [==============================] - 0s 248us/sample - loss: 0.2915 - accuracy: 0.9120\n",
      "125/125 [==============================] - 0s 243us/sample - loss: 0.2910 - accuracy: 0.9200\n",
      "124/124 [==============================] - 0s 228us/sample - loss: 0.3223 - accuracy: 0.9113\n",
      "123/123 [==============================] - 0s 248us/sample - loss: 0.3342 - accuracy: 0.8699\n",
      "124/124 [==============================] - 0s 230us/sample - loss: 0.3204 - accuracy: 0.9032\n",
      "122/122 [==============================] - 0s 253us/sample - loss: 0.3206 - accuracy: 0.9180\n",
      "122/122 [==============================] - 0s 254us/sample - loss: 0.2923 - accuracy: 0.9426\n",
      "121/121 [==============================] - 0s 249us/sample - loss: 0.3142 - accuracy: 0.9339\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 0.3219 - accuracy: 0.9000\n",
      "117/117 [==============================] - 0s 271us/sample - loss: 0.3368 - accuracy: 0.9060\n",
      "115/115 [==============================] - 0s 247us/sample - loss: 0.3276 - accuracy: 0.9130\n",
      "119/119 [==============================] - 0s 265us/sample - loss: 0.3140 - accuracy: 0.9160\n",
      "119/119 [==============================] - 0s 234us/sample - loss: 0.3241 - accuracy: 0.8992\n",
      "117/117 [==============================] - 0s 230us/sample - loss: 0.3541 - accuracy: 0.8547\n",
      "116/116 [==============================] - 0s 231us/sample - loss: 0.3310 - accuracy: 0.8966\n",
      "117/117 [==============================] - 0s 257us/sample - loss: 0.3159 - accuracy: 0.8889\n",
      "117/117 [==============================] - 0s 261us/sample - loss: 0.2956 - accuracy: 0.9402\n",
      "116/116 [==============================] - 0s 277us/sample - loss: 0.2718 - accuracy: 0.9397\n",
      "115/115 [==============================] - 0s 254us/sample - loss: 0.3042 - accuracy: 0.9043\n",
      "116/116 [==============================] - 0s 273us/sample - loss: 0.3156 - accuracy: 0.8879\n",
      "116/116 [==============================] - 0s 239us/sample - loss: 0.2928 - accuracy: 0.9224\n",
      "113/113 [==============================] - 0s 310us/sample - loss: 0.2996 - accuracy: 0.9115\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2855 samples, validate on 686 samples\n",
      "Epoch 1/300\n",
      "2855/2855 [==============================] - 3s 878us/sample - loss: 0.7268 - accuracy: 0.4918 - val_loss: 0.7007 - val_accuracy: 0.5437\n",
      "Epoch 2/300\n",
      "2855/2855 [==============================] - 1s 221us/sample - loss: 0.6853 - accuracy: 0.5594 - val_loss: 0.6812 - val_accuracy: 0.5758\n",
      "Epoch 3/300\n",
      "2855/2855 [==============================] - 1s 204us/sample - loss: 0.6595 - accuracy: 0.6032 - val_loss: 0.6679 - val_accuracy: 0.5948\n",
      "Epoch 4/300\n",
      "2855/2855 [==============================] - 1s 219us/sample - loss: 0.6452 - accuracy: 0.6224 - val_loss: 0.6579 - val_accuracy: 0.6181\n",
      "Epoch 5/300\n",
      "2855/2855 [==============================] - 1s 234us/sample - loss: 0.6291 - accuracy: 0.6620 - val_loss: 0.6498 - val_accuracy: 0.6312\n",
      "Epoch 6/300\n",
      "2855/2855 [==============================] - 1s 239us/sample - loss: 0.6192 - accuracy: 0.6704 - val_loss: 0.6427 - val_accuracy: 0.6501\n",
      "Epoch 7/300\n",
      "2855/2855 [==============================] - 1s 230us/sample - loss: 0.6105 - accuracy: 0.6830 - val_loss: 0.6368 - val_accuracy: 0.6531\n",
      "Epoch 8/300\n",
      "2855/2855 [==============================] - 1s 246us/sample - loss: 0.5964 - accuracy: 0.7072 - val_loss: 0.6317 - val_accuracy: 0.6574\n",
      "Epoch 9/300\n",
      "2855/2855 [==============================] - 1s 249us/sample - loss: 0.5878 - accuracy: 0.7170 - val_loss: 0.6272 - val_accuracy: 0.6676\n",
      "Epoch 10/300\n",
      "2855/2855 [==============================] - 1s 251us/sample - loss: 0.5791 - accuracy: 0.7335 - val_loss: 0.6233 - val_accuracy: 0.6749\n",
      "Epoch 11/300\n",
      "2855/2855 [==============================] - 1s 224us/sample - loss: 0.5722 - accuracy: 0.7370 - val_loss: 0.6197 - val_accuracy: 0.6822\n",
      "Epoch 12/300\n",
      "2855/2855 [==============================] - 1s 217us/sample - loss: 0.5671 - accuracy: 0.7313 - val_loss: 0.6165 - val_accuracy: 0.6880\n",
      "Epoch 13/300\n",
      "2855/2855 [==============================] - 1s 189us/sample - loss: 0.5578 - accuracy: 0.7534 - val_loss: 0.6138 - val_accuracy: 0.6880\n",
      "Epoch 14/300\n",
      "2855/2855 [==============================] - 1s 213us/sample - loss: 0.5560 - accuracy: 0.7541 - val_loss: 0.6112 - val_accuracy: 0.6866\n",
      "Epoch 15/300\n",
      "2855/2855 [==============================] - 1s 192us/sample - loss: 0.5471 - accuracy: 0.7555 - val_loss: 0.6090 - val_accuracy: 0.6910\n",
      "Epoch 16/300\n",
      "2855/2855 [==============================] - 1s 212us/sample - loss: 0.5438 - accuracy: 0.7569 - val_loss: 0.6070 - val_accuracy: 0.6968\n",
      "Epoch 17/300\n",
      "2855/2855 [==============================] - 1s 214us/sample - loss: 0.5330 - accuracy: 0.7667 - val_loss: 0.6052 - val_accuracy: 0.6983\n",
      "Epoch 18/300\n",
      "2855/2855 [==============================] - 1s 204us/sample - loss: 0.5337 - accuracy: 0.7671 - val_loss: 0.6037 - val_accuracy: 0.6997\n",
      "Epoch 19/300\n",
      "2855/2855 [==============================] - 1s 224us/sample - loss: 0.5308 - accuracy: 0.7727 - val_loss: 0.6024 - val_accuracy: 0.7041\n",
      "Epoch 20/300\n",
      "2855/2855 [==============================] - 1s 235us/sample - loss: 0.5236 - accuracy: 0.7692 - val_loss: 0.6011 - val_accuracy: 0.7041\n",
      "Epoch 21/300\n",
      "2855/2855 [==============================] - 1s 220us/sample - loss: 0.5215 - accuracy: 0.7797 - val_loss: 0.6001 - val_accuracy: 0.7070\n",
      "Epoch 22/300\n",
      "2855/2855 [==============================] - 1s 230us/sample - loss: 0.5163 - accuracy: 0.7744 - val_loss: 0.5992 - val_accuracy: 0.7070\n",
      "Epoch 23/300\n",
      "2855/2855 [==============================] - 1s 243us/sample - loss: 0.5149 - accuracy: 0.7751 - val_loss: 0.5984 - val_accuracy: 0.7085\n",
      "Epoch 24/300\n",
      "2855/2855 [==============================] - 1s 247us/sample - loss: 0.5085 - accuracy: 0.7786 - val_loss: 0.5977 - val_accuracy: 0.7085\n",
      "Epoch 25/300\n",
      "2855/2855 [==============================] - 1s 218us/sample - loss: 0.5081 - accuracy: 0.7783 - val_loss: 0.5972 - val_accuracy: 0.7085\n",
      "Epoch 26/300\n",
      "2855/2855 [==============================] - 1s 249us/sample - loss: 0.5024 - accuracy: 0.7807 - val_loss: 0.5966 - val_accuracy: 0.7085\n",
      "Epoch 27/300\n",
      "2855/2855 [==============================] - 1s 193us/sample - loss: 0.5007 - accuracy: 0.7807 - val_loss: 0.5962 - val_accuracy: 0.7099\n",
      "Epoch 28/300\n",
      "2855/2855 [==============================] - 1s 218us/sample - loss: 0.4926 - accuracy: 0.7863 - val_loss: 0.5959 - val_accuracy: 0.7114\n",
      "Epoch 29/300\n",
      "2855/2855 [==============================] - 1s 215us/sample - loss: 0.4919 - accuracy: 0.7860 - val_loss: 0.5956 - val_accuracy: 0.7128\n",
      "Epoch 30/300\n",
      "2855/2855 [==============================] - 1s 199us/sample - loss: 0.4885 - accuracy: 0.7877 - val_loss: 0.5955 - val_accuracy: 0.7128\n",
      "Epoch 31/300\n",
      "2855/2855 [==============================] - 1s 193us/sample - loss: 0.4869 - accuracy: 0.7888 - val_loss: 0.5954 - val_accuracy: 0.7128\n",
      "Epoch 32/300\n",
      "2855/2855 [==============================] - 1s 213us/sample - loss: 0.4873 - accuracy: 0.7895 - val_loss: 0.5953 - val_accuracy: 0.7128\n",
      "Epoch 33/300\n",
      "2855/2855 [==============================] - 1s 229us/sample - loss: 0.4822 - accuracy: 0.7919 - val_loss: 0.5954 - val_accuracy: 0.7128\n",
      "Epoch 34/300\n",
      "2855/2855 [==============================] - 1s 220us/sample - loss: 0.4773 - accuracy: 0.7944 - val_loss: 0.5955 - val_accuracy: 0.7143\n",
      "Epoch 35/300\n",
      "2855/2855 [==============================] - 1s 219us/sample - loss: 0.4787 - accuracy: 0.7902 - val_loss: 0.5957 - val_accuracy: 0.7128\n",
      "Epoch 00035: early stopping\n",
      "108/108 [==============================] - 0s 156us/sample - loss: 0.3541 - accuracy: 0.9444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [4:42:39, 1038.20s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.73s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.44s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 842.3046875 steps, validate for 204.1640625 steps\n",
      "Epoch 1/300\n",
      "843/842 [==============================] - 24s 28ms/step - loss: 0.6256 - accuracy: 0.6642 - val_loss: 0.6202 - val_accuracy: 0.7269\n",
      "Epoch 2/300\n",
      "843/842 [==============================] - 23s 27ms/step - loss: 0.5022 - accuracy: 0.7826 - val_loss: 0.6312 - val_accuracy: 0.7261\n",
      "Epoch 3/300\n",
      "843/842 [==============================] - 23s 27ms/step - loss: 0.4881 - accuracy: 0.7865 - val_loss: 0.6273 - val_accuracy: 0.7284\n",
      "Epoch 4/300\n",
      "843/842 [==============================] - 23s 27ms/step - loss: 0.4779 - accuracy: 0.7897 - val_loss: 0.6262 - val_accuracy: 0.7308\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 842.3046875 steps, validate for 204.1640625 steps\n",
      "Epoch 1/300\n",
      "843/842 [==============================] - 54s 64ms/step - loss: 0.4604 - accuracy: 0.7968 - val_loss: 0.6660 - val_accuracy: 0.7271\n",
      "Epoch 2/300\n",
      "843/842 [==============================] - 53s 63ms/step - loss: 0.4345 - accuracy: 0.8099 - val_loss: 0.6214 - val_accuracy: 0.7143\n",
      "Epoch 3/300\n",
      "843/842 [==============================] - 53s 63ms/step - loss: 0.4128 - accuracy: 0.8215 - val_loss: 0.6509 - val_accuracy: 0.7257\n",
      "Epoch 4/300\n",
      "843/842 [==============================] - 53s 63ms/step - loss: 0.3926 - accuracy: 0.8327 - val_loss: 0.6744 - val_accuracy: 0.7337\n",
      "Epoch 5/300\n",
      "843/842 [==============================] - 53s 62ms/step - loss: 0.3729 - accuracy: 0.8437 - val_loss: 0.6556 - val_accuracy: 0.7088\n",
      "Epoch 00005: early stopping\n",
      "153/153 [==============================] - 0s 1ms/sample - loss: 0.2132 - accuracy: 0.9739\n",
      "147/147 [==============================] - 0s 232us/sample - loss: 0.2399 - accuracy: 0.9592\n",
      "141/141 [==============================] - 0s 236us/sample - loss: 0.2507 - accuracy: 0.9291\n",
      "136/136 [==============================] - 0s 218us/sample - loss: 0.2251 - accuracy: 0.9779\n",
      "129/129 [==============================] - 0s 249us/sample - loss: 0.2637 - accuracy: 0.9612\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.2772 - accuracy: 0.9531\n",
      "125/125 [==============================] - 0s 222us/sample - loss: 0.2912 - accuracy: 0.9360\n",
      "125/125 [==============================] - 0s 235us/sample - loss: 0.3187 - accuracy: 0.9200\n",
      "122/122 [==============================] - 0s 229us/sample - loss: 0.2713 - accuracy: 0.9508\n",
      "119/119 [==============================] - 0s 239us/sample - loss: 0.2354 - accuracy: 0.9580\n",
      "115/115 [==============================] - 0s 227us/sample - loss: 0.2589 - accuracy: 0.9652\n",
      "114/114 [==============================] - 0s 251us/sample - loss: 0.2604 - accuracy: 0.9561\n",
      "113/113 [==============================] - 0s 255us/sample - loss: 0.2450 - accuracy: 0.9381\n",
      "113/113 [==============================] - 0s 258us/sample - loss: 0.2157 - accuracy: 0.9735\n",
      "109/109 [==============================] - 0s 242us/sample - loss: 0.2349 - accuracy: 0.9725\n",
      "109/109 [==============================] - 0s 250us/sample - loss: 0.2511 - accuracy: 0.9541\n",
      "108/108 [==============================] - 0s 271us/sample - loss: 0.2875 - accuracy: 0.9537\n",
      "109/109 [==============================] - 0s 242us/sample - loss: 0.2515 - accuracy: 0.9633\n",
      "108/108 [==============================] - 0s 254us/sample - loss: 0.2883 - accuracy: 0.9259\n",
      "108/108 [==============================] - 0s 245us/sample - loss: 0.2887 - accuracy: 0.8981\n",
      "108/108 [==============================] - 0s 247us/sample - loss: 0.2882 - accuracy: 0.9444\n",
      "107/107 [==============================] - 0s 252us/sample - loss: 0.2848 - accuracy: 0.9346\n",
      "108/108 [==============================] - 0s 245us/sample - loss: 0.2649 - accuracy: 0.9537\n",
      "108/108 [==============================] - 0s 257us/sample - loss: 0.2919 - accuracy: 0.9167\n",
      "107/107 [==============================] - 0s 305us/sample - loss: 0.2263 - accuracy: 0.9626\n",
      "107/107 [==============================] - 0s 265us/sample - loss: 0.2790 - accuracy: 0.9626\n",
      "108/108 [==============================] - 0s 287us/sample - loss: 0.2928 - accuracy: 0.9352\n",
      "108/108 [==============================] - 0s 255us/sample - loss: 0.2430 - accuracy: 0.9722\n",
      "107/107 [==============================] - 0s 264us/sample - loss: 0.2754 - accuracy: 0.9533\n",
      "108/108 [==============================] - 0s 247us/sample - loss: 0.2946 - accuracy: 0.9074\n",
      "107/107 [==============================] - 0s 257us/sample - loss: 0.3002 - accuracy: 0.9159\n",
      "108/108 [==============================] - 0s 240us/sample - loss: 0.2514 - accuracy: 0.9167\n",
      "108/108 [==============================] - 0s 250us/sample - loss: 0.2704 - accuracy: 0.9259\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2860 samples, validate on 687 samples\n",
      "Epoch 1/300\n",
      "2860/2860 [==============================] - 2s 854us/sample - loss: 0.7003 - accuracy: 0.5339 - val_loss: 0.6950 - val_accuracy: 0.5328\n",
      "Epoch 2/300\n",
      "2860/2860 [==============================] - 1s 196us/sample - loss: 0.6642 - accuracy: 0.5937 - val_loss: 0.6778 - val_accuracy: 0.5706\n",
      "Epoch 3/300\n",
      "2860/2860 [==============================] - 1s 203us/sample - loss: 0.6435 - accuracy: 0.6266 - val_loss: 0.6660 - val_accuracy: 0.5924\n",
      "Epoch 4/300\n",
      "2860/2860 [==============================] - 1s 216us/sample - loss: 0.6249 - accuracy: 0.6577 - val_loss: 0.6568 - val_accuracy: 0.5997\n",
      "Epoch 5/300\n",
      "2860/2860 [==============================] - 1s 232us/sample - loss: 0.6145 - accuracy: 0.6745 - val_loss: 0.6497 - val_accuracy: 0.6143\n",
      "Epoch 6/300\n",
      "2860/2860 [==============================] - 1s 200us/sample - loss: 0.6033 - accuracy: 0.6853 - val_loss: 0.6433 - val_accuracy: 0.6274\n",
      "Epoch 7/300\n",
      "2860/2860 [==============================] - 1s 246us/sample - loss: 0.5917 - accuracy: 0.6997 - val_loss: 0.6377 - val_accuracy: 0.6332\n",
      "Epoch 8/300\n",
      "2860/2860 [==============================] - 1s 192us/sample - loss: 0.5831 - accuracy: 0.7091 - val_loss: 0.6330 - val_accuracy: 0.6332\n",
      "Epoch 9/300\n",
      "2860/2860 [==============================] - 1s 196us/sample - loss: 0.5788 - accuracy: 0.7227 - val_loss: 0.6289 - val_accuracy: 0.6376\n",
      "Epoch 10/300\n",
      "2860/2860 [==============================] - 1s 180us/sample - loss: 0.5695 - accuracy: 0.7259 - val_loss: 0.6250 - val_accuracy: 0.6536\n",
      "Epoch 11/300\n",
      "2860/2860 [==============================] - 1s 209us/sample - loss: 0.5620 - accuracy: 0.7360 - val_loss: 0.6216 - val_accuracy: 0.6536\n",
      "Epoch 12/300\n",
      "2860/2860 [==============================] - 1s 218us/sample - loss: 0.5587 - accuracy: 0.7395 - val_loss: 0.6185 - val_accuracy: 0.6594\n",
      "Epoch 13/300\n",
      "2860/2860 [==============================] - 1s 244us/sample - loss: 0.5507 - accuracy: 0.7514 - val_loss: 0.6158 - val_accuracy: 0.6608\n",
      "Epoch 14/300\n",
      "2860/2860 [==============================] - 1s 227us/sample - loss: 0.5464 - accuracy: 0.7531 - val_loss: 0.6132 - val_accuracy: 0.6594\n",
      "Epoch 15/300\n",
      "2860/2860 [==============================] - 1s 233us/sample - loss: 0.5400 - accuracy: 0.7493 - val_loss: 0.6109 - val_accuracy: 0.6652\n",
      "Epoch 16/300\n",
      "2860/2860 [==============================] - 1s 222us/sample - loss: 0.5341 - accuracy: 0.7654 - val_loss: 0.6089 - val_accuracy: 0.6667\n",
      "Epoch 17/300\n",
      "2860/2860 [==============================] - 1s 214us/sample - loss: 0.5299 - accuracy: 0.7643 - val_loss: 0.6070 - val_accuracy: 0.6710\n",
      "Epoch 18/300\n",
      "2860/2860 [==============================] - 1s 199us/sample - loss: 0.5271 - accuracy: 0.7640 - val_loss: 0.6053 - val_accuracy: 0.6710\n",
      "Epoch 19/300\n",
      "2860/2860 [==============================] - 1s 191us/sample - loss: 0.5213 - accuracy: 0.7706 - val_loss: 0.6038 - val_accuracy: 0.6725\n",
      "Epoch 20/300\n",
      "2860/2860 [==============================] - 1s 179us/sample - loss: 0.5182 - accuracy: 0.7689 - val_loss: 0.6024 - val_accuracy: 0.6754\n",
      "Epoch 21/300\n",
      "2860/2860 [==============================] - 1s 217us/sample - loss: 0.5134 - accuracy: 0.7734 - val_loss: 0.6011 - val_accuracy: 0.6739\n",
      "Epoch 22/300\n",
      "2860/2860 [==============================] - 1s 240us/sample - loss: 0.5124 - accuracy: 0.7755 - val_loss: 0.6000 - val_accuracy: 0.6754\n",
      "Epoch 23/300\n",
      "2860/2860 [==============================] - 1s 237us/sample - loss: 0.5044 - accuracy: 0.7797 - val_loss: 0.5990 - val_accuracy: 0.6769\n",
      "Epoch 24/300\n",
      "2860/2860 [==============================] - 1s 239us/sample - loss: 0.5012 - accuracy: 0.7871 - val_loss: 0.5980 - val_accuracy: 0.6769\n",
      "Epoch 25/300\n",
      "2860/2860 [==============================] - 1s 243us/sample - loss: 0.4983 - accuracy: 0.7864 - val_loss: 0.5972 - val_accuracy: 0.6754\n",
      "Epoch 26/300\n",
      "2860/2860 [==============================] - 1s 258us/sample - loss: 0.4935 - accuracy: 0.7850 - val_loss: 0.5965 - val_accuracy: 0.6725\n",
      "Epoch 27/300\n",
      "2860/2860 [==============================] - 1s 229us/sample - loss: 0.4899 - accuracy: 0.7885 - val_loss: 0.5958 - val_accuracy: 0.6812\n",
      "Epoch 28/300\n",
      "2860/2860 [==============================] - 1s 195us/sample - loss: 0.4861 - accuracy: 0.7941 - val_loss: 0.5953 - val_accuracy: 0.6812\n",
      "Epoch 29/300\n",
      "2860/2860 [==============================] - 1s 206us/sample - loss: 0.4867 - accuracy: 0.7916 - val_loss: 0.5947 - val_accuracy: 0.6841\n",
      "Epoch 30/300\n",
      "2860/2860 [==============================] - 1s 199us/sample - loss: 0.4827 - accuracy: 0.7906 - val_loss: 0.5943 - val_accuracy: 0.6885\n",
      "Epoch 31/300\n",
      "2860/2860 [==============================] - 1s 181us/sample - loss: 0.4766 - accuracy: 0.7986 - val_loss: 0.5939 - val_accuracy: 0.6914\n",
      "Epoch 32/300\n",
      "2860/2860 [==============================] - 1s 211us/sample - loss: 0.4790 - accuracy: 0.7958 - val_loss: 0.5936 - val_accuracy: 0.6914\n",
      "Epoch 33/300\n",
      "2860/2860 [==============================] - 1s 227us/sample - loss: 0.4703 - accuracy: 0.7993 - val_loss: 0.5933 - val_accuracy: 0.6929\n",
      "Epoch 34/300\n",
      "2860/2860 [==============================] - 1s 241us/sample - loss: 0.4715 - accuracy: 0.7990 - val_loss: 0.5931 - val_accuracy: 0.6943\n",
      "Epoch 35/300\n",
      "2860/2860 [==============================] - 1s 247us/sample - loss: 0.4701 - accuracy: 0.8063 - val_loss: 0.5930 - val_accuracy: 0.6958\n",
      "Epoch 36/300\n",
      "2860/2860 [==============================] - 1s 236us/sample - loss: 0.4633 - accuracy: 0.8042 - val_loss: 0.5929 - val_accuracy: 0.6958\n",
      "Epoch 37/300\n",
      "2860/2860 [==============================] - 1s 223us/sample - loss: 0.4629 - accuracy: 0.8066 - val_loss: 0.5928 - val_accuracy: 0.6972\n",
      "Epoch 38/300\n",
      "2860/2860 [==============================] - 1s 225us/sample - loss: 0.4593 - accuracy: 0.8091 - val_loss: 0.5928 - val_accuracy: 0.6987\n",
      "Epoch 39/300\n",
      "2860/2860 [==============================] - 1s 247us/sample - loss: 0.4601 - accuracy: 0.8084 - val_loss: 0.5928 - val_accuracy: 0.6987\n",
      "Epoch 40/300\n",
      "2860/2860 [==============================] - 1s 235us/sample - loss: 0.4565 - accuracy: 0.8080 - val_loss: 0.5929 - val_accuracy: 0.6972\n",
      "Epoch 41/300\n",
      "2860/2860 [==============================] - 1s 251us/sample - loss: 0.4518 - accuracy: 0.8094 - val_loss: 0.5930 - val_accuracy: 0.6987\n",
      "Epoch 00041: early stopping\n",
      "102/102 [==============================] - 0s 226us/sample - loss: 0.2604 - accuracy: 0.9706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [4:59:37, 1032.08s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.61s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.32s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 847.84375 steps, validate for 208.0390625 steps\n",
      "Epoch 1/300\n",
      "848/847 [==============================] - 25s 29ms/step - loss: 0.5411 - accuracy: 0.7600 - val_loss: 0.5849 - val_accuracy: 0.7388\n",
      "Epoch 2/300\n",
      "848/847 [==============================] - 23s 27ms/step - loss: 0.4995 - accuracy: 0.7840 - val_loss: 0.5872 - val_accuracy: 0.7368\n",
      "Epoch 3/300\n",
      "848/847 [==============================] - 23s 27ms/step - loss: 0.4860 - accuracy: 0.7879 - val_loss: 0.5963 - val_accuracy: 0.7370\n",
      "Epoch 4/300\n",
      "848/847 [==============================] - 24s 28ms/step - loss: 0.4755 - accuracy: 0.7921 - val_loss: 0.6043 - val_accuracy: 0.7343\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 847.84375 steps, validate for 208.0390625 steps\n",
      "Epoch 1/300\n",
      "848/847 [==============================] - 55s 65ms/step - loss: 0.4583 - accuracy: 0.7988 - val_loss: 0.6046 - val_accuracy: 0.7366\n",
      "Epoch 2/300\n",
      "848/847 [==============================] - 53s 63ms/step - loss: 0.4317 - accuracy: 0.8124 - val_loss: 0.6109 - val_accuracy: 0.7324\n",
      "Epoch 3/300\n",
      "848/847 [==============================] - 54s 64ms/step - loss: 0.4086 - accuracy: 0.8244 - val_loss: 0.6194 - val_accuracy: 0.7304\n",
      "Epoch 4/300\n",
      "848/847 [==============================] - 53s 63ms/step - loss: 0.3871 - accuracy: 0.8356 - val_loss: 0.6672 - val_accuracy: 0.7390\n",
      "Epoch 00004: early stopping\n",
      "93/93 [==============================] - 0s 2ms/sample - loss: 0.1733 - accuracy: 0.9785\n",
      "92/92 [==============================] - 0s 224us/sample - loss: 0.2209 - accuracy: 0.9565\n",
      "90/90 [==============================] - 0s 225us/sample - loss: 0.2025 - accuracy: 0.9667\n",
      "85/85 [==============================] - 0s 239us/sample - loss: 0.2161 - accuracy: 0.9529\n",
      "84/84 [==============================] - 0s 263us/sample - loss: 0.2405 - accuracy: 0.9286\n",
      "82/82 [==============================] - 0s 260us/sample - loss: 0.2220 - accuracy: 0.9512\n",
      "82/82 [==============================] - 0s 262us/sample - loss: 0.2302 - accuracy: 0.9756\n",
      "80/80 [==============================] - 0s 241us/sample - loss: 0.2165 - accuracy: 0.9625\n",
      "79/79 [==============================] - 0s 247us/sample - loss: 0.2415 - accuracy: 0.9747\n",
      "79/79 [==============================] - 0s 288us/sample - loss: 0.2261 - accuracy: 0.9494\n",
      "78/78 [==============================] - 0s 243us/sample - loss: 0.2446 - accuracy: 0.9487\n",
      "79/79 [==============================] - 0s 265us/sample - loss: 0.2402 - accuracy: 0.9747\n",
      "79/79 [==============================] - 0s 322us/sample - loss: 0.2334 - accuracy: 0.9367\n",
      "79/79 [==============================] - 0s 260us/sample - loss: 0.2596 - accuracy: 0.9620\n",
      "78/78 [==============================] - 0s 259us/sample - loss: 0.3031 - accuracy: 0.8846\n",
      "78/78 [==============================] - 0s 260us/sample - loss: 0.2532 - accuracy: 0.9231\n",
      "77/77 [==============================] - 0s 269us/sample - loss: 0.3210 - accuracy: 0.9091\n",
      "78/78 [==============================] - 0s 273us/sample - loss: 0.3368 - accuracy: 0.8974\n",
      "77/77 [==============================] - 0s 268us/sample - loss: 0.3239 - accuracy: 0.8831\n",
      "78/78 [==============================] - 0s 242us/sample - loss: 0.2892 - accuracy: 0.9231\n",
      "79/79 [==============================] - 0s 274us/sample - loss: 0.2844 - accuracy: 0.9114\n",
      "79/79 [==============================] - 0s 250us/sample - loss: 0.3017 - accuracy: 0.8987\n",
      "79/79 [==============================] - 0s 272us/sample - loss: 0.2854 - accuracy: 0.9114\n",
      "79/79 [==============================] - 0s 274us/sample - loss: 0.3500 - accuracy: 0.8987\n",
      "78/78 [==============================] - 0s 272us/sample - loss: 0.3728 - accuracy: 0.8846\n",
      "77/77 [==============================] - 0s 251us/sample - loss: 0.3480 - accuracy: 0.8961\n",
      "76/76 [==============================] - 0s 271us/sample - loss: 0.3059 - accuracy: 0.9079\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.3954 - accuracy: 0.8533\n",
      "76/76 [==============================] - 0s 256us/sample - loss: 0.3359 - accuracy: 0.9342\n",
      "76/76 [==============================] - 0s 271us/sample - loss: 0.3312 - accuracy: 0.9211\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 0.3747 - accuracy: 0.8800\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.3778 - accuracy: 0.8533\n",
      "74/74 [==============================] - 0s 287us/sample - loss: 0.3719 - accuracy: 0.8378\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2877 samples, validate on 701 samples\n",
      "Epoch 1/300\n",
      "2877/2877 [==============================] - 2s 825us/sample - loss: 0.7303 - accuracy: 0.4901 - val_loss: 0.6955 - val_accuracy: 0.5378\n",
      "Epoch 2/300\n",
      "2877/2877 [==============================] - 1s 203us/sample - loss: 0.6711 - accuracy: 0.5850 - val_loss: 0.6663 - val_accuracy: 0.5877\n",
      "Epoch 3/300\n",
      "2877/2877 [==============================] - 1s 198us/sample - loss: 0.6385 - accuracy: 0.6340 - val_loss: 0.6470 - val_accuracy: 0.6277\n",
      "Epoch 4/300\n",
      "2877/2877 [==============================] - 1s 182us/sample - loss: 0.6117 - accuracy: 0.6757 - val_loss: 0.6328 - val_accuracy: 0.6605\n",
      "Epoch 5/300\n",
      "2877/2877 [==============================] - 1s 202us/sample - loss: 0.5891 - accuracy: 0.7049 - val_loss: 0.6218 - val_accuracy: 0.6833\n",
      "Epoch 6/300\n",
      "2877/2877 [==============================] - 1s 194us/sample - loss: 0.5725 - accuracy: 0.7292 - val_loss: 0.6129 - val_accuracy: 0.6947\n",
      "Epoch 7/300\n",
      "2877/2877 [==============================] - 1s 202us/sample - loss: 0.5625 - accuracy: 0.7456 - val_loss: 0.6056 - val_accuracy: 0.7118\n",
      "Epoch 8/300\n",
      "2877/2877 [==============================] - 1s 223us/sample - loss: 0.5488 - accuracy: 0.7480 - val_loss: 0.5995 - val_accuracy: 0.7175\n",
      "Epoch 9/300\n",
      "2877/2877 [==============================] - 1s 208us/sample - loss: 0.5393 - accuracy: 0.7689 - val_loss: 0.5941 - val_accuracy: 0.7190\n",
      "Epoch 10/300\n",
      "2877/2877 [==============================] - 1s 192us/sample - loss: 0.5347 - accuracy: 0.7682 - val_loss: 0.5896 - val_accuracy: 0.7218\n",
      "Epoch 11/300\n",
      "2877/2877 [==============================] - 1s 227us/sample - loss: 0.5243 - accuracy: 0.7741 - val_loss: 0.5857 - val_accuracy: 0.7233\n",
      "Epoch 12/300\n",
      "2877/2877 [==============================] - 1s 219us/sample - loss: 0.5194 - accuracy: 0.7775 - val_loss: 0.5825 - val_accuracy: 0.7261\n",
      "Epoch 13/300\n",
      "2877/2877 [==============================] - 1s 224us/sample - loss: 0.5093 - accuracy: 0.7876 - val_loss: 0.5796 - val_accuracy: 0.7275\n",
      "Epoch 14/300\n",
      "2877/2877 [==============================] - 1s 223us/sample - loss: 0.5021 - accuracy: 0.7897 - val_loss: 0.5772 - val_accuracy: 0.7275\n",
      "Epoch 15/300\n",
      "2877/2877 [==============================] - 1s 222us/sample - loss: 0.4956 - accuracy: 0.7932 - val_loss: 0.5751 - val_accuracy: 0.7304\n",
      "Epoch 16/300\n",
      "2877/2877 [==============================] - 1s 210us/sample - loss: 0.4926 - accuracy: 0.7932 - val_loss: 0.5734 - val_accuracy: 0.7304\n",
      "Epoch 17/300\n",
      "2877/2877 [==============================] - 1s 229us/sample - loss: 0.4831 - accuracy: 0.7949 - val_loss: 0.5719 - val_accuracy: 0.7347\n",
      "Epoch 18/300\n",
      "2877/2877 [==============================] - 1s 225us/sample - loss: 0.4823 - accuracy: 0.7977 - val_loss: 0.5707 - val_accuracy: 0.7347\n",
      "Epoch 19/300\n",
      "2877/2877 [==============================] - 1s 200us/sample - loss: 0.4765 - accuracy: 0.7991 - val_loss: 0.5696 - val_accuracy: 0.7347\n",
      "Epoch 20/300\n",
      "2877/2877 [==============================] - 1s 215us/sample - loss: 0.4745 - accuracy: 0.7991 - val_loss: 0.5687 - val_accuracy: 0.7347\n",
      "Epoch 21/300\n",
      "2877/2877 [==============================] - 1s 208us/sample - loss: 0.4689 - accuracy: 0.7991 - val_loss: 0.5680 - val_accuracy: 0.7347\n",
      "Epoch 22/300\n",
      "2877/2877 [==============================] - 1s 188us/sample - loss: 0.4638 - accuracy: 0.8026 - val_loss: 0.5674 - val_accuracy: 0.7361\n",
      "Epoch 23/300\n",
      "2877/2877 [==============================] - 1s 216us/sample - loss: 0.4611 - accuracy: 0.7987 - val_loss: 0.5669 - val_accuracy: 0.7375\n",
      "Epoch 24/300\n",
      "2877/2877 [==============================] - 1s 238us/sample - loss: 0.4617 - accuracy: 0.7991 - val_loss: 0.5664 - val_accuracy: 0.7418\n",
      "Epoch 25/300\n",
      "2877/2877 [==============================] - 1s 235us/sample - loss: 0.4539 - accuracy: 0.8043 - val_loss: 0.5662 - val_accuracy: 0.7447\n",
      "Epoch 26/300\n",
      "2877/2877 [==============================] - 1s 213us/sample - loss: 0.4564 - accuracy: 0.8050 - val_loss: 0.5658 - val_accuracy: 0.7461\n",
      "Epoch 27/300\n",
      "2877/2877 [==============================] - 1s 216us/sample - loss: 0.4500 - accuracy: 0.8033 - val_loss: 0.5657 - val_accuracy: 0.7475\n",
      "Epoch 28/300\n",
      "2877/2877 [==============================] - 1s 192us/sample - loss: 0.4466 - accuracy: 0.8064 - val_loss: 0.5658 - val_accuracy: 0.7461\n",
      "Epoch 29/300\n",
      "2877/2877 [==============================] - 1s 213us/sample - loss: 0.4412 - accuracy: 0.8081 - val_loss: 0.5656 - val_accuracy: 0.7475\n",
      "Epoch 30/300\n",
      "2877/2877 [==============================] - 1s 228us/sample - loss: 0.4417 - accuracy: 0.8071 - val_loss: 0.5656 - val_accuracy: 0.7489\n",
      "Epoch 31/300\n",
      "2877/2877 [==============================] - 1s 235us/sample - loss: 0.4393 - accuracy: 0.8137 - val_loss: 0.5656 - val_accuracy: 0.7489\n",
      "Epoch 32/300\n",
      "2877/2877 [==============================] - 1s 209us/sample - loss: 0.4331 - accuracy: 0.8071 - val_loss: 0.5656 - val_accuracy: 0.7489\n",
      "Epoch 33/300\n",
      "2877/2877 [==============================] - 1s 219us/sample - loss: 0.4299 - accuracy: 0.8127 - val_loss: 0.5658 - val_accuracy: 0.7489\n",
      "Epoch 34/300\n",
      "2877/2877 [==============================] - 1s 195us/sample - loss: 0.4288 - accuracy: 0.8116 - val_loss: 0.5658 - val_accuracy: 0.7504\n",
      "Epoch 00034: early stopping\n",
      "71/71 [==============================] - 0s 153us/sample - loss: 0.4153 - accuracy: 0.8732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [5:15:38, 1010.72s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.48s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.31s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 854.8125 steps, validate for 204.2578125 steps\n",
      "Epoch 1/300\n",
      "855/854 [==============================] - 24s 28ms/step - loss: 0.5588 - accuracy: 0.7409 - val_loss: 0.6097 - val_accuracy: 0.7306\n",
      "Epoch 2/300\n",
      "855/854 [==============================] - 23s 27ms/step - loss: 0.5005 - accuracy: 0.7842 - val_loss: 0.6120 - val_accuracy: 0.7300\n",
      "Epoch 3/300\n",
      "855/854 [==============================] - 23s 27ms/step - loss: 0.4868 - accuracy: 0.7885 - val_loss: 0.6103 - val_accuracy: 0.7304\n",
      "Epoch 4/300\n",
      "855/854 [==============================] - 23s 27ms/step - loss: 0.4764 - accuracy: 0.7918 - val_loss: 0.6195 - val_accuracy: 0.7273\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 854.8125 steps, validate for 204.2578125 steps\n",
      "Epoch 1/300\n",
      "855/854 [==============================] - 55s 64ms/step - loss: 0.4585 - accuracy: 0.7991 - val_loss: 0.6304 - val_accuracy: 0.7234\n",
      "Epoch 2/300\n",
      "855/854 [==============================] - 53s 63ms/step - loss: 0.4303 - accuracy: 0.8129 - val_loss: 0.6328 - val_accuracy: 0.7210\n",
      "Epoch 3/300\n",
      "855/854 [==============================] - 54s 63ms/step - loss: 0.4063 - accuracy: 0.8257 - val_loss: 0.6557 - val_accuracy: 0.7235\n",
      "Epoch 4/300\n",
      "855/854 [==============================] - 54s 63ms/step - loss: 0.3839 - accuracy: 0.8380 - val_loss: 0.6437 - val_accuracy: 0.7093\n",
      "Epoch 00004: early stopping\n",
      "78/78 [==============================] - 0s 2ms/sample - loss: 0.3153 - accuracy: 0.9231\n",
      "75/75 [==============================] - 0s 258us/sample - loss: 0.3655 - accuracy: 0.8533\n",
      "73/73 [==============================] - 0s 309us/sample - loss: 0.3663 - accuracy: 0.8767\n",
      "71/71 [==============================] - 0s 281us/sample - loss: 0.4043 - accuracy: 0.8310\n",
      "71/71 [==============================] - 0s 284us/sample - loss: 0.3414 - accuracy: 0.9014\n",
      "68/68 [==============================] - 0s 269us/sample - loss: 0.3842 - accuracy: 0.8824\n",
      "69/69 [==============================] - 0s 247us/sample - loss: 0.3867 - accuracy: 0.8551\n",
      "68/68 [==============================] - 0s 273us/sample - loss: 0.3322 - accuracy: 0.9118\n",
      "66/66 [==============================] - 0s 319us/sample - loss: 0.3480 - accuracy: 0.8788\n",
      "65/65 [==============================] - 0s 297us/sample - loss: 0.2781 - accuracy: 0.9846\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.3776 - accuracy: 0.9219\n",
      "65/65 [==============================] - 0s 281us/sample - loss: 0.3750 - accuracy: 0.8923\n",
      "66/66 [==============================] - 0s 284us/sample - loss: 0.3521 - accuracy: 0.9242\n",
      "65/65 [==============================] - 0s 289us/sample - loss: 0.3579 - accuracy: 0.9231\n",
      "65/65 [==============================] - 0s 286us/sample - loss: 0.3680 - accuracy: 0.8615\n",
      "66/66 [==============================] - 0s 302us/sample - loss: 0.3923 - accuracy: 0.8636\n",
      "68/68 [==============================] - 0s 328us/sample - loss: 0.3767 - accuracy: 0.8971\n",
      "66/66 [==============================] - 0s 300us/sample - loss: 0.4616 - accuracy: 0.8182\n",
      "66/66 [==============================] - 0s 307us/sample - loss: 0.3986 - accuracy: 0.8939\n",
      "66/66 [==============================] - 0s 285us/sample - loss: 0.4326 - accuracy: 0.8333\n",
      "67/67 [==============================] - 0s 300us/sample - loss: 0.4036 - accuracy: 0.8507\n",
      "66/66 [==============================] - 0s 262us/sample - loss: 0.4074 - accuracy: 0.8030\n",
      "67/67 [==============================] - 0s 356us/sample - loss: 0.3865 - accuracy: 0.8955\n",
      "66/66 [==============================] - 0s 265us/sample - loss: 0.4350 - accuracy: 0.8333\n",
      "66/66 [==============================] - 0s 287us/sample - loss: 0.3558 - accuracy: 0.8939\n",
      "66/66 [==============================] - 0s 319us/sample - loss: 0.3987 - accuracy: 0.8182\n",
      "66/66 [==============================] - 0s 340us/sample - loss: 0.3712 - accuracy: 0.8485\n",
      "66/66 [==============================] - 0s 296us/sample - loss: 0.4182 - accuracy: 0.8485\n",
      "66/66 [==============================] - 0s 351us/sample - loss: 0.4867 - accuracy: 0.7727\n",
      "66/66 [==============================] - 0s 365us/sample - loss: 0.4383 - accuracy: 0.8333\n",
      "65/65 [==============================] - 0s 322us/sample - loss: 0.3857 - accuracy: 0.8462\n",
      "64/64 [==============================] - 0s 258us/sample - loss: 0.4208 - accuracy: 0.7812\n",
      "65/65 [==============================] - 0s 306us/sample - loss: 0.3829 - accuracy: 0.8769\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2899 samples, validate on 689 samples\n",
      "Epoch 1/300\n",
      "2899/2899 [==============================] - 2s 838us/sample - loss: 0.8181 - accuracy: 0.4201 - val_loss: 0.8054 - val_accuracy: 0.4049\n",
      "Epoch 2/300\n",
      "2899/2899 [==============================] - 1s 186us/sample - loss: 0.7539 - accuracy: 0.4671 - val_loss: 0.7733 - val_accuracy: 0.4340\n",
      "Epoch 3/300\n",
      "2899/2899 [==============================] - 1s 183us/sample - loss: 0.7204 - accuracy: 0.5212 - val_loss: 0.7514 - val_accuracy: 0.4644\n",
      "Epoch 4/300\n",
      "2899/2899 [==============================] - 1s 191us/sample - loss: 0.7022 - accuracy: 0.5478 - val_loss: 0.7345 - val_accuracy: 0.4862\n",
      "Epoch 5/300\n",
      "2899/2899 [==============================] - 1s 209us/sample - loss: 0.6758 - accuracy: 0.5771 - val_loss: 0.7210 - val_accuracy: 0.5007\n",
      "Epoch 6/300\n",
      "2899/2899 [==============================] - 1s 208us/sample - loss: 0.6620 - accuracy: 0.6078 - val_loss: 0.7098 - val_accuracy: 0.5312\n",
      "Epoch 7/300\n",
      "2899/2899 [==============================] - 1s 210us/sample - loss: 0.6467 - accuracy: 0.6244 - val_loss: 0.7003 - val_accuracy: 0.5544\n",
      "Epoch 8/300\n",
      "2899/2899 [==============================] - 1s 220us/sample - loss: 0.6301 - accuracy: 0.6488 - val_loss: 0.6920 - val_accuracy: 0.5704\n",
      "Epoch 9/300\n",
      "2899/2899 [==============================] - 1s 222us/sample - loss: 0.6219 - accuracy: 0.6578 - val_loss: 0.6847 - val_accuracy: 0.5907\n",
      "Epoch 10/300\n",
      "2899/2899 [==============================] - 1s 184us/sample - loss: 0.6097 - accuracy: 0.6764 - val_loss: 0.6782 - val_accuracy: 0.6052\n",
      "Epoch 11/300\n",
      "2899/2899 [==============================] - 1s 214us/sample - loss: 0.5968 - accuracy: 0.6958 - val_loss: 0.6725 - val_accuracy: 0.6139\n",
      "Epoch 12/300\n",
      "2899/2899 [==============================] - 1s 228us/sample - loss: 0.5910 - accuracy: 0.7078 - val_loss: 0.6673 - val_accuracy: 0.6270\n",
      "Epoch 13/300\n",
      "2899/2899 [==============================] - 1s 244us/sample - loss: 0.5835 - accuracy: 0.7047 - val_loss: 0.6627 - val_accuracy: 0.6372\n",
      "Epoch 14/300\n",
      "2899/2899 [==============================] - 1s 215us/sample - loss: 0.5773 - accuracy: 0.7223 - val_loss: 0.6586 - val_accuracy: 0.6415\n",
      "Epoch 15/300\n",
      "2899/2899 [==============================] - 1s 239us/sample - loss: 0.5710 - accuracy: 0.7289 - val_loss: 0.6547 - val_accuracy: 0.6531\n",
      "Epoch 16/300\n",
      "2899/2899 [==============================] - 1s 236us/sample - loss: 0.5610 - accuracy: 0.7465 - val_loss: 0.6513 - val_accuracy: 0.6589\n",
      "Epoch 17/300\n",
      "2899/2899 [==============================] - 1s 220us/sample - loss: 0.5524 - accuracy: 0.7461 - val_loss: 0.6482 - val_accuracy: 0.6633\n",
      "Epoch 18/300\n",
      "2899/2899 [==============================] - 1s 224us/sample - loss: 0.5502 - accuracy: 0.7492 - val_loss: 0.6453 - val_accuracy: 0.6705\n",
      "Epoch 19/300\n",
      "2899/2899 [==============================] - 1s 219us/sample - loss: 0.5453 - accuracy: 0.7554 - val_loss: 0.6428 - val_accuracy: 0.6662\n",
      "Epoch 20/300\n",
      "2899/2899 [==============================] - 1s 187us/sample - loss: 0.5385 - accuracy: 0.7634 - val_loss: 0.6404 - val_accuracy: 0.6720\n",
      "Epoch 21/300\n",
      "2899/2899 [==============================] - 1s 225us/sample - loss: 0.5328 - accuracy: 0.7623 - val_loss: 0.6383 - val_accuracy: 0.6749\n",
      "Epoch 22/300\n",
      "2899/2899 [==============================] - 1s 206us/sample - loss: 0.5285 - accuracy: 0.7672 - val_loss: 0.6364 - val_accuracy: 0.6763\n",
      "Epoch 23/300\n",
      "2899/2899 [==============================] - 1s 210us/sample - loss: 0.5205 - accuracy: 0.7737 - val_loss: 0.6345 - val_accuracy: 0.6763\n",
      "Epoch 24/300\n",
      "2899/2899 [==============================] - 1s 231us/sample - loss: 0.5218 - accuracy: 0.7765 - val_loss: 0.6330 - val_accuracy: 0.6821\n",
      "Epoch 25/300\n",
      "2899/2899 [==============================] - 1s 208us/sample - loss: 0.5177 - accuracy: 0.7772 - val_loss: 0.6316 - val_accuracy: 0.6851\n",
      "Epoch 26/300\n",
      "2899/2899 [==============================] - 1s 203us/sample - loss: 0.5124 - accuracy: 0.7810 - val_loss: 0.6302 - val_accuracy: 0.6851\n",
      "Epoch 27/300\n",
      "2899/2899 [==============================] - 1s 182us/sample - loss: 0.5065 - accuracy: 0.7885 - val_loss: 0.6290 - val_accuracy: 0.6880\n",
      "Epoch 28/300\n",
      "2899/2899 [==============================] - 1s 201us/sample - loss: 0.5066 - accuracy: 0.7882 - val_loss: 0.6279 - val_accuracy: 0.6851\n",
      "Epoch 29/300\n",
      "2899/2899 [==============================] - 1s 211us/sample - loss: 0.4998 - accuracy: 0.7896 - val_loss: 0.6269 - val_accuracy: 0.6836\n",
      "Epoch 30/300\n",
      "2899/2899 [==============================] - 1s 182us/sample - loss: 0.4992 - accuracy: 0.7865 - val_loss: 0.6258 - val_accuracy: 0.6851\n",
      "Epoch 31/300\n",
      "2899/2899 [==============================] - 1s 226us/sample - loss: 0.4950 - accuracy: 0.7934 - val_loss: 0.6251 - val_accuracy: 0.6880\n",
      "Epoch 32/300\n",
      "2899/2899 [==============================] - 1s 221us/sample - loss: 0.4926 - accuracy: 0.7906 - val_loss: 0.6243 - val_accuracy: 0.6938\n",
      "Epoch 33/300\n",
      "2899/2899 [==============================] - 1s 222us/sample - loss: 0.4843 - accuracy: 0.8003 - val_loss: 0.6236 - val_accuracy: 0.6938\n",
      "Epoch 34/300\n",
      "2899/2899 [==============================] - 1s 221us/sample - loss: 0.4829 - accuracy: 0.8013 - val_loss: 0.6229 - val_accuracy: 0.6967\n",
      "Epoch 35/300\n",
      "2899/2899 [==============================] - 1s 219us/sample - loss: 0.4792 - accuracy: 0.8051 - val_loss: 0.6224 - val_accuracy: 0.6981\n",
      "Epoch 36/300\n",
      "2899/2899 [==============================] - 1s 200us/sample - loss: 0.4785 - accuracy: 0.8027 - val_loss: 0.6219 - val_accuracy: 0.7010\n",
      "Epoch 37/300\n",
      "2899/2899 [==============================] - 1s 228us/sample - loss: 0.4749 - accuracy: 0.8006 - val_loss: 0.6215 - val_accuracy: 0.7054\n",
      "Epoch 38/300\n",
      "2899/2899 [==============================] - 1s 212us/sample - loss: 0.4692 - accuracy: 0.8072 - val_loss: 0.6211 - val_accuracy: 0.7068\n",
      "Epoch 39/300\n",
      "2899/2899 [==============================] - 1s 225us/sample - loss: 0.4714 - accuracy: 0.8082 - val_loss: 0.6207 - val_accuracy: 0.7112\n",
      "Epoch 40/300\n",
      "2899/2899 [==============================] - 1s 221us/sample - loss: 0.4644 - accuracy: 0.8117 - val_loss: 0.6204 - val_accuracy: 0.7097\n",
      "Epoch 41/300\n",
      "2899/2899 [==============================] - 1s 232us/sample - loss: 0.4649 - accuracy: 0.8096 - val_loss: 0.6201 - val_accuracy: 0.7097\n",
      "Epoch 42/300\n",
      "2899/2899 [==============================] - 1s 210us/sample - loss: 0.4607 - accuracy: 0.8127 - val_loss: 0.6199 - val_accuracy: 0.7097\n",
      "Epoch 43/300\n",
      "2899/2899 [==============================] - 1s 220us/sample - loss: 0.4566 - accuracy: 0.8137 - val_loss: 0.6198 - val_accuracy: 0.7097\n",
      "Epoch 44/300\n",
      "2899/2899 [==============================] - 1s 228us/sample - loss: 0.4565 - accuracy: 0.8172 - val_loss: 0.6195 - val_accuracy: 0.7097\n",
      "Epoch 45/300\n",
      "2899/2899 [==============================] - 1s 231us/sample - loss: 0.4552 - accuracy: 0.8165 - val_loss: 0.6195 - val_accuracy: 0.7068\n",
      "Epoch 46/300\n",
      "2899/2899 [==============================] - 1s 223us/sample - loss: 0.4530 - accuracy: 0.8148 - val_loss: 0.6194 - val_accuracy: 0.7039\n",
      "Epoch 47/300\n",
      "2899/2899 [==============================] - 1s 236us/sample - loss: 0.4503 - accuracy: 0.8210 - val_loss: 0.6192 - val_accuracy: 0.7025\n",
      "Epoch 48/300\n",
      "2899/2899 [==============================] - 1s 226us/sample - loss: 0.4470 - accuracy: 0.8203 - val_loss: 0.6193 - val_accuracy: 0.7025\n",
      "Epoch 49/300\n",
      "2899/2899 [==============================] - 1s 223us/sample - loss: 0.4426 - accuracy: 0.8203 - val_loss: 0.6193 - val_accuracy: 0.7025\n",
      "Epoch 50/300\n",
      "2899/2899 [==============================] - 1s 187us/sample - loss: 0.4423 - accuracy: 0.8220 - val_loss: 0.6192 - val_accuracy: 0.7025\n",
      "Epoch 00050: early stopping\n",
      "61/61 [==============================] - 0s 152us/sample - loss: 0.4195 - accuracy: 0.8361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [5:31:49, 998.96s/it] \n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.59s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.27s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 841.03125 steps, validate for 202.1796875 steps\n",
      "Epoch 1/300\n",
      "842/841 [==============================] - 24s 28ms/step - loss: 0.6320 - accuracy: 0.6582 - val_loss: 0.6170 - val_accuracy: 0.7211\n",
      "Epoch 2/300\n",
      "842/841 [==============================] - 23s 27ms/step - loss: 0.5014 - accuracy: 0.7829 - val_loss: 0.6257 - val_accuracy: 0.7227\n",
      "Epoch 3/300\n",
      "842/841 [==============================] - 23s 27ms/step - loss: 0.4871 - accuracy: 0.7874 - val_loss: 0.6343 - val_accuracy: 0.7219\n",
      "Epoch 4/300\n",
      "842/841 [==============================] - 23s 27ms/step - loss: 0.4768 - accuracy: 0.7911 - val_loss: 0.6239 - val_accuracy: 0.7263\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 841.03125 steps, validate for 202.1796875 steps\n",
      "Epoch 1/300\n",
      "842/841 [==============================] - 54s 64ms/step - loss: 0.4597 - accuracy: 0.7983 - val_loss: 0.6235 - val_accuracy: 0.7266\n",
      "Epoch 2/300\n",
      "842/841 [==============================] - 53s 63ms/step - loss: 0.4338 - accuracy: 0.8105 - val_loss: 0.6528 - val_accuracy: 0.7153\n",
      "Epoch 3/300\n",
      "842/841 [==============================] - 53s 63ms/step - loss: 0.4122 - accuracy: 0.8220 - val_loss: 0.6665 - val_accuracy: 0.6940\n",
      "Epoch 4/300\n",
      "842/841 [==============================] - 53s 63ms/step - loss: 0.3919 - accuracy: 0.8336 - val_loss: 0.6626 - val_accuracy: 0.7116\n",
      "Epoch 00004: early stopping\n",
      "144/144 [==============================] - 0s 1ms/sample - loss: 0.1970 - accuracy: 0.9792\n",
      "142/142 [==============================] - 0s 257us/sample - loss: 0.1940 - accuracy: 0.9789\n",
      "137/137 [==============================] - 0s 240us/sample - loss: 0.1781 - accuracy: 0.9854\n",
      "134/134 [==============================] - 0s 259us/sample - loss: 0.1940 - accuracy: 0.9776\n",
      "135/135 [==============================] - 0s 259us/sample - loss: 0.1716 - accuracy: 1.0000\n",
      "134/134 [==============================] - 0s 266us/sample - loss: 0.1920 - accuracy: 0.9851\n",
      "135/135 [==============================] - 0s 259us/sample - loss: 0.2036 - accuracy: 0.9852\n",
      "136/136 [==============================] - 0s 237us/sample - loss: 0.1888 - accuracy: 0.9926\n",
      "138/138 [==============================] - 0s 276us/sample - loss: 0.1794 - accuracy: 0.9928\n",
      "134/134 [==============================] - 0s 217us/sample - loss: 0.1930 - accuracy: 0.9925\n",
      "131/131 [==============================] - 0s 282us/sample - loss: 0.1976 - accuracy: 0.9924\n",
      "129/129 [==============================] - 0s 277us/sample - loss: 0.1926 - accuracy: 0.9922\n",
      "129/129 [==============================] - 0s 274us/sample - loss: 0.2002 - accuracy: 0.9922\n",
      "129/129 [==============================] - 0s 306us/sample - loss: 0.2111 - accuracy: 0.9767\n",
      "130/130 [==============================] - 0s 282us/sample - loss: 0.2198 - accuracy: 0.9615\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.2257 - accuracy: 0.9609\n",
      "127/127 [==============================] - 0s 265us/sample - loss: 0.2338 - accuracy: 0.9528\n",
      "127/127 [==============================] - 0s 253us/sample - loss: 0.2245 - accuracy: 0.9528\n",
      "127/127 [==============================] - 0s 228us/sample - loss: 0.2139 - accuracy: 0.9764\n",
      "126/126 [==============================] - 0s 218us/sample - loss: 0.2379 - accuracy: 0.9762\n",
      "125/125 [==============================] - 0s 228us/sample - loss: 0.2231 - accuracy: 0.9680\n",
      "125/125 [==============================] - 0s 262us/sample - loss: 0.2395 - accuracy: 0.9440\n",
      "124/124 [==============================] - 0s 234us/sample - loss: 0.2313 - accuracy: 0.9597\n",
      "123/123 [==============================] - 0s 238us/sample - loss: 0.2343 - accuracy: 0.9593\n",
      "122/122 [==============================] - 0s 243us/sample - loss: 0.1962 - accuracy: 0.9918\n",
      "122/122 [==============================] - 0s 283us/sample - loss: 0.2060 - accuracy: 0.9918\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.2033 - accuracy: 0.9917\n",
      "123/123 [==============================] - 0s 230us/sample - loss: 0.2204 - accuracy: 0.9756\n",
      "121/121 [==============================] - 0s 254us/sample - loss: 0.2285 - accuracy: 0.9339\n",
      "123/123 [==============================] - 0s 258us/sample - loss: 0.2410 - accuracy: 0.9512\n",
      "123/123 [==============================] - 0s 260us/sample - loss: 0.2531 - accuracy: 0.9268\n",
      "122/122 [==============================] - 0s 275us/sample - loss: 0.2266 - accuracy: 0.9426\n",
      "122/122 [==============================] - 0s 255us/sample - loss: 0.2198 - accuracy: 0.9672\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2858 samples, validate on 679 samples\n",
      "Epoch 1/300\n",
      "2858/2858 [==============================] - 3s 932us/sample - loss: 0.6946 - accuracy: 0.5616 - val_loss: 0.6702 - val_accuracy: 0.5700\n",
      "Epoch 2/300\n",
      "2858/2858 [==============================] - 1s 191us/sample - loss: 0.6610 - accuracy: 0.6186 - val_loss: 0.6549 - val_accuracy: 0.5950\n",
      "Epoch 3/300\n",
      "2858/2858 [==============================] - 1s 261us/sample - loss: 0.6413 - accuracy: 0.6358 - val_loss: 0.6443 - val_accuracy: 0.6141\n",
      "Epoch 4/300\n",
      "2858/2858 [==============================] - 1s 260us/sample - loss: 0.6253 - accuracy: 0.6662 - val_loss: 0.6360 - val_accuracy: 0.6274\n",
      "Epoch 5/300\n",
      "2858/2858 [==============================] - 1s 267us/sample - loss: 0.6112 - accuracy: 0.6858 - val_loss: 0.6293 - val_accuracy: 0.6480\n",
      "Epoch 6/300\n",
      "2858/2858 [==============================] - 1s 254us/sample - loss: 0.6031 - accuracy: 0.6949 - val_loss: 0.6236 - val_accuracy: 0.6539\n",
      "Epoch 7/300\n",
      "2858/2858 [==============================] - 1s 202us/sample - loss: 0.5949 - accuracy: 0.7082 - val_loss: 0.6186 - val_accuracy: 0.6598\n",
      "Epoch 8/300\n",
      "2858/2858 [==============================] - 1s 205us/sample - loss: 0.5879 - accuracy: 0.7117 - val_loss: 0.6142 - val_accuracy: 0.6657\n",
      "Epoch 9/300\n",
      "2858/2858 [==============================] - 1s 229us/sample - loss: 0.5753 - accuracy: 0.7355 - val_loss: 0.6103 - val_accuracy: 0.6701\n",
      "Epoch 10/300\n",
      "2858/2858 [==============================] - 1s 233us/sample - loss: 0.5703 - accuracy: 0.7383 - val_loss: 0.6068 - val_accuracy: 0.6804\n",
      "Epoch 11/300\n",
      "2858/2858 [==============================] - 1s 230us/sample - loss: 0.5625 - accuracy: 0.7488 - val_loss: 0.6037 - val_accuracy: 0.6981\n",
      "Epoch 12/300\n",
      "2858/2858 [==============================] - 1s 222us/sample - loss: 0.5565 - accuracy: 0.7502 - val_loss: 0.6010 - val_accuracy: 0.7054\n",
      "Epoch 13/300\n",
      "2858/2858 [==============================] - 1s 253us/sample - loss: 0.5503 - accuracy: 0.7544 - val_loss: 0.5984 - val_accuracy: 0.7128\n",
      "Epoch 14/300\n",
      "2858/2858 [==============================] - 1s 255us/sample - loss: 0.5464 - accuracy: 0.7582 - val_loss: 0.5962 - val_accuracy: 0.7143\n",
      "Epoch 15/300\n",
      "2858/2858 [==============================] - 1s 251us/sample - loss: 0.5410 - accuracy: 0.7631 - val_loss: 0.5941 - val_accuracy: 0.7128\n",
      "Epoch 16/300\n",
      "2858/2858 [==============================] - 1s 243us/sample - loss: 0.5364 - accuracy: 0.7701 - val_loss: 0.5922 - val_accuracy: 0.7113\n",
      "Epoch 17/300\n",
      "2858/2858 [==============================] - 1s 260us/sample - loss: 0.5320 - accuracy: 0.7701 - val_loss: 0.5904 - val_accuracy: 0.7143\n",
      "Epoch 18/300\n",
      "2858/2858 [==============================] - 1s 243us/sample - loss: 0.5256 - accuracy: 0.7771 - val_loss: 0.5889 - val_accuracy: 0.7128\n",
      "Epoch 19/300\n",
      "2858/2858 [==============================] - 1s 221us/sample - loss: 0.5199 - accuracy: 0.7810 - val_loss: 0.5875 - val_accuracy: 0.7128\n",
      "Epoch 20/300\n",
      "2858/2858 [==============================] - 1s 212us/sample - loss: 0.5190 - accuracy: 0.7831 - val_loss: 0.5863 - val_accuracy: 0.7143\n",
      "Epoch 21/300\n",
      "2858/2858 [==============================] - 1s 225us/sample - loss: 0.5127 - accuracy: 0.7838 - val_loss: 0.5851 - val_accuracy: 0.7202\n",
      "Epoch 22/300\n",
      "2858/2858 [==============================] - 1s 189us/sample - loss: 0.5092 - accuracy: 0.7824 - val_loss: 0.5841 - val_accuracy: 0.7202\n",
      "Epoch 23/300\n",
      "2858/2858 [==============================] - 1s 205us/sample - loss: 0.5061 - accuracy: 0.7852 - val_loss: 0.5832 - val_accuracy: 0.7158\n",
      "Epoch 24/300\n",
      "2858/2858 [==============================] - 1s 217us/sample - loss: 0.5010 - accuracy: 0.7946 - val_loss: 0.5825 - val_accuracy: 0.7172\n",
      "Epoch 25/300\n",
      "2858/2858 [==============================] - 1s 195us/sample - loss: 0.4986 - accuracy: 0.7873 - val_loss: 0.5819 - val_accuracy: 0.7202\n",
      "Epoch 26/300\n",
      "2858/2858 [==============================] - 1s 221us/sample - loss: 0.4981 - accuracy: 0.7925 - val_loss: 0.5813 - val_accuracy: 0.7202\n",
      "Epoch 27/300\n",
      "2858/2858 [==============================] - 1s 206us/sample - loss: 0.4948 - accuracy: 0.7915 - val_loss: 0.5808 - val_accuracy: 0.7202\n",
      "Epoch 28/300\n",
      "2858/2858 [==============================] - 1s 250us/sample - loss: 0.4897 - accuracy: 0.7939 - val_loss: 0.5805 - val_accuracy: 0.7231\n",
      "Epoch 29/300\n",
      "2858/2858 [==============================] - 1s 232us/sample - loss: 0.4848 - accuracy: 0.7992 - val_loss: 0.5802 - val_accuracy: 0.7216\n",
      "Epoch 30/300\n",
      "2858/2858 [==============================] - 1s 233us/sample - loss: 0.4823 - accuracy: 0.7936 - val_loss: 0.5800 - val_accuracy: 0.7202\n",
      "Epoch 31/300\n",
      "2858/2858 [==============================] - 1s 233us/sample - loss: 0.4824 - accuracy: 0.7964 - val_loss: 0.5798 - val_accuracy: 0.7202\n",
      "Epoch 32/300\n",
      "2858/2858 [==============================] - 1s 221us/sample - loss: 0.4808 - accuracy: 0.7978 - val_loss: 0.5798 - val_accuracy: 0.7187\n",
      "Epoch 33/300\n",
      "2858/2858 [==============================] - 1s 246us/sample - loss: 0.4775 - accuracy: 0.8055 - val_loss: 0.5799 - val_accuracy: 0.7187\n",
      "Epoch 34/300\n",
      "2858/2858 [==============================] - 1s 245us/sample - loss: 0.4772 - accuracy: 0.7978 - val_loss: 0.5799 - val_accuracy: 0.7187\n",
      "Epoch 00034: early stopping\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.2894 - accuracy: 0.9821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [5:47:52, 988.09s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.58s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.28s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 840.875 steps, validate for 204.125 steps\n",
      "Epoch 1/300\n",
      "841/840 [==============================] - 25s 29ms/step - loss: 0.5835 - accuracy: 0.7112 - val_loss: 0.6292 - val_accuracy: 0.7242\n",
      "Epoch 2/300\n",
      "841/840 [==============================] - 23s 28ms/step - loss: 0.5068 - accuracy: 0.7812 - val_loss: 0.6269 - val_accuracy: 0.7268\n",
      "Epoch 3/300\n",
      "841/840 [==============================] - 24s 28ms/step - loss: 0.4926 - accuracy: 0.7853 - val_loss: 0.6353 - val_accuracy: 0.7263\n",
      "Epoch 4/300\n",
      "841/840 [==============================] - 24s 28ms/step - loss: 0.4818 - accuracy: 0.7895 - val_loss: 0.6382 - val_accuracy: 0.7268\n",
      "Epoch 5/300\n",
      "841/840 [==============================] - 24s 28ms/step - loss: 0.4723 - accuracy: 0.7935 - val_loss: 0.6431 - val_accuracy: 0.7262\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 840.875 steps, validate for 204.125 steps\n",
      "Epoch 1/300\n",
      "841/840 [==============================] - 55s 65ms/step - loss: 0.4551 - accuracy: 0.8019 - val_loss: 0.6274 - val_accuracy: 0.7208\n",
      "Epoch 2/300\n",
      "841/840 [==============================] - 53s 63ms/step - loss: 0.4276 - accuracy: 0.8142 - val_loss: 0.6837 - val_accuracy: 0.6808\n",
      "Epoch 3/300\n",
      "841/840 [==============================] - 53s 64ms/step - loss: 0.4052 - accuracy: 0.8259 - val_loss: 0.6508 - val_accuracy: 0.7120\n",
      "Epoch 4/300\n",
      "841/840 [==============================] - 54s 64ms/step - loss: 0.3846 - accuracy: 0.8376 - val_loss: 0.7049 - val_accuracy: 0.7219\n",
      "Epoch 00004: early stopping\n",
      "134/134 [==============================] - 0s 1ms/sample - loss: 0.2166 - accuracy: 0.9328\n",
      "131/131 [==============================] - 0s 261us/sample - loss: 0.2233 - accuracy: 0.9542\n",
      "125/125 [==============================] - 0s 221us/sample - loss: 0.2186 - accuracy: 0.9600\n",
      "125/125 [==============================] - 0s 233us/sample - loss: 0.2251 - accuracy: 0.9360\n",
      "126/126 [==============================] - 0s 249us/sample - loss: 0.2453 - accuracy: 0.9286\n",
      "126/126 [==============================] - 0s 210us/sample - loss: 0.2322 - accuracy: 0.9603\n",
      "126/126 [==============================] - 0s 206us/sample - loss: 0.2211 - accuracy: 0.9603\n",
      "123/123 [==============================] - 0s 217us/sample - loss: 0.2140 - accuracy: 0.9593\n",
      "124/124 [==============================] - 0s 221us/sample - loss: 0.2080 - accuracy: 0.9516\n",
      "123/123 [==============================] - 0s 272us/sample - loss: 0.2077 - accuracy: 0.9675\n",
      "124/124 [==============================] - 0s 231us/sample - loss: 0.2176 - accuracy: 0.9597\n",
      "124/124 [==============================] - 0s 272us/sample - loss: 0.2232 - accuracy: 0.9597\n",
      "123/123 [==============================] - 0s 233us/sample - loss: 0.2139 - accuracy: 0.9512\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.2447 - accuracy: 0.9417\n",
      "121/121 [==============================] - 0s 277us/sample - loss: 0.2468 - accuracy: 0.9421\n",
      "121/121 [==============================] - 0s 240us/sample - loss: 0.2452 - accuracy: 0.9339\n",
      "121/121 [==============================] - 0s 259us/sample - loss: 0.2329 - accuracy: 0.9339\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.2548 - accuracy: 0.9333\n",
      "121/121 [==============================] - 0s 241us/sample - loss: 0.2345 - accuracy: 0.9421\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.2408 - accuracy: 0.9500\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.2457 - accuracy: 0.9333\n",
      "119/119 [==============================] - 0s 258us/sample - loss: 0.2340 - accuracy: 0.9748\n",
      "119/119 [==============================] - 0s 254us/sample - loss: 0.2293 - accuracy: 0.9496\n",
      "119/119 [==============================] - 0s 269us/sample - loss: 0.2275 - accuracy: 0.9496\n",
      "119/119 [==============================] - 0s 274us/sample - loss: 0.2227 - accuracy: 0.9412\n",
      "118/118 [==============================] - 0s 251us/sample - loss: 0.2284 - accuracy: 0.9492\n",
      "117/117 [==============================] - 0s 264us/sample - loss: 0.2482 - accuracy: 0.9573\n",
      "118/118 [==============================] - 0s 279us/sample - loss: 0.2444 - accuracy: 0.9407\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.2358 - accuracy: 0.9583\n",
      "118/118 [==============================] - 0s 265us/sample - loss: 0.2317 - accuracy: 0.9407\n",
      "117/117 [==============================] - 0s 263us/sample - loss: 0.2277 - accuracy: 0.9658\n",
      "118/118 [==============================] - 0s 242us/sample - loss: 0.2399 - accuracy: 0.9576\n",
      "118/118 [==============================] - 0s 282us/sample - loss: 0.2415 - accuracy: 0.9576\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2852 samples, validate on 686 samples\n",
      "Epoch 1/300\n",
      "2852/2852 [==============================] - 3s 1ms/sample - loss: 0.6888 - accuracy: 0.5547 - val_loss: 0.6940 - val_accuracy: 0.5452\n",
      "Epoch 2/300\n",
      "2852/2852 [==============================] - 1s 247us/sample - loss: 0.6566 - accuracy: 0.6066 - val_loss: 0.6798 - val_accuracy: 0.5918\n",
      "Epoch 3/300\n",
      "2852/2852 [==============================] - 1s 233us/sample - loss: 0.6355 - accuracy: 0.6378 - val_loss: 0.6700 - val_accuracy: 0.6108\n",
      "Epoch 4/300\n",
      "2852/2852 [==============================] - 1s 234us/sample - loss: 0.6203 - accuracy: 0.6704 - val_loss: 0.6622 - val_accuracy: 0.6239\n",
      "Epoch 5/300\n",
      "2852/2852 [==============================] - 1s 232us/sample - loss: 0.6088 - accuracy: 0.6921 - val_loss: 0.6557 - val_accuracy: 0.6312\n",
      "Epoch 6/300\n",
      "2852/2852 [==============================] - 1s 229us/sample - loss: 0.5991 - accuracy: 0.7002 - val_loss: 0.6502 - val_accuracy: 0.6399\n",
      "Epoch 7/300\n",
      "2852/2852 [==============================] - 1s 216us/sample - loss: 0.5906 - accuracy: 0.7107 - val_loss: 0.6455 - val_accuracy: 0.6501\n",
      "Epoch 8/300\n",
      "2852/2852 [==============================] - 1s 249us/sample - loss: 0.5819 - accuracy: 0.7293 - val_loss: 0.6413 - val_accuracy: 0.6589\n",
      "Epoch 9/300\n",
      "2852/2852 [==============================] - 1s 225us/sample - loss: 0.5753 - accuracy: 0.7374 - val_loss: 0.6375 - val_accuracy: 0.6676\n",
      "Epoch 10/300\n",
      "2852/2852 [==============================] - 1s 227us/sample - loss: 0.5684 - accuracy: 0.7461 - val_loss: 0.6340 - val_accuracy: 0.6778\n",
      "Epoch 11/300\n",
      "2852/2852 [==============================] - 1s 225us/sample - loss: 0.5585 - accuracy: 0.7475 - val_loss: 0.6310 - val_accuracy: 0.6851\n",
      "Epoch 12/300\n",
      "2852/2852 [==============================] - 1s 244us/sample - loss: 0.5574 - accuracy: 0.7472 - val_loss: 0.6283 - val_accuracy: 0.6910\n",
      "Epoch 13/300\n",
      "2852/2852 [==============================] - 1s 231us/sample - loss: 0.5457 - accuracy: 0.7647 - val_loss: 0.6257 - val_accuracy: 0.6968\n",
      "Epoch 14/300\n",
      "2852/2852 [==============================] - 1s 224us/sample - loss: 0.5408 - accuracy: 0.7721 - val_loss: 0.6234 - val_accuracy: 0.7012\n",
      "Epoch 15/300\n",
      "2852/2852 [==============================] - 1s 235us/sample - loss: 0.5387 - accuracy: 0.7637 - val_loss: 0.6212 - val_accuracy: 0.6997\n",
      "Epoch 16/300\n",
      "2852/2852 [==============================] - 1s 249us/sample - loss: 0.5346 - accuracy: 0.7735 - val_loss: 0.6192 - val_accuracy: 0.6968\n",
      "Epoch 17/300\n",
      "2852/2852 [==============================] - 1s 251us/sample - loss: 0.5282 - accuracy: 0.7784 - val_loss: 0.6174 - val_accuracy: 0.6983\n",
      "Epoch 18/300\n",
      "2852/2852 [==============================] - 1s 260us/sample - loss: 0.5236 - accuracy: 0.7763 - val_loss: 0.6157 - val_accuracy: 0.6997\n",
      "Epoch 19/300\n",
      "2852/2852 [==============================] - 1s 253us/sample - loss: 0.5220 - accuracy: 0.7766 - val_loss: 0.6142 - val_accuracy: 0.7026\n",
      "Epoch 20/300\n",
      "2852/2852 [==============================] - 1s 260us/sample - loss: 0.5173 - accuracy: 0.7854 - val_loss: 0.6127 - val_accuracy: 0.7055\n",
      "Epoch 21/300\n",
      "2852/2852 [==============================] - 1s 235us/sample - loss: 0.5135 - accuracy: 0.7872 - val_loss: 0.6114 - val_accuracy: 0.7085\n",
      "Epoch 22/300\n",
      "2852/2852 [==============================] - 1s 254us/sample - loss: 0.5115 - accuracy: 0.7872 - val_loss: 0.6103 - val_accuracy: 0.7099\n",
      "Epoch 23/300\n",
      "2852/2852 [==============================] - 1s 236us/sample - loss: 0.5056 - accuracy: 0.7886 - val_loss: 0.6092 - val_accuracy: 0.7128\n",
      "Epoch 24/300\n",
      "2852/2852 [==============================] - 1s 230us/sample - loss: 0.5008 - accuracy: 0.7973 - val_loss: 0.6083 - val_accuracy: 0.7128\n",
      "Epoch 25/300\n",
      "2852/2852 [==============================] - 1s 228us/sample - loss: 0.4959 - accuracy: 0.7910 - val_loss: 0.6073 - val_accuracy: 0.7128\n",
      "Epoch 26/300\n",
      "2852/2852 [==============================] - 1s 226us/sample - loss: 0.4967 - accuracy: 0.7966 - val_loss: 0.6066 - val_accuracy: 0.7128\n",
      "Epoch 27/300\n",
      "2852/2852 [==============================] - 1s 260us/sample - loss: 0.4932 - accuracy: 0.7917 - val_loss: 0.6059 - val_accuracy: 0.7172\n",
      "Epoch 28/300\n",
      "2852/2852 [==============================] - 1s 237us/sample - loss: 0.4882 - accuracy: 0.7984 - val_loss: 0.6052 - val_accuracy: 0.7172\n",
      "Epoch 29/300\n",
      "2852/2852 [==============================] - 1s 247us/sample - loss: 0.4874 - accuracy: 0.7959 - val_loss: 0.6046 - val_accuracy: 0.7172\n",
      "Epoch 30/300\n",
      "2852/2852 [==============================] - 1s 248us/sample - loss: 0.4836 - accuracy: 0.7980 - val_loss: 0.6040 - val_accuracy: 0.7172\n",
      "Epoch 31/300\n",
      "2852/2852 [==============================] - 1s 238us/sample - loss: 0.4796 - accuracy: 0.8015 - val_loss: 0.6036 - val_accuracy: 0.7230\n",
      "Epoch 32/300\n",
      "2852/2852 [==============================] - 1s 241us/sample - loss: 0.4787 - accuracy: 0.8033 - val_loss: 0.6032 - val_accuracy: 0.7245\n",
      "Epoch 33/300\n",
      "2852/2852 [==============================] - 1s 242us/sample - loss: 0.4772 - accuracy: 0.8015 - val_loss: 0.6029 - val_accuracy: 0.7245\n",
      "Epoch 34/300\n",
      "2852/2852 [==============================] - 1s 244us/sample - loss: 0.4747 - accuracy: 0.7987 - val_loss: 0.6025 - val_accuracy: 0.7245\n",
      "Epoch 35/300\n",
      "2852/2852 [==============================] - 1s 251us/sample - loss: 0.4741 - accuracy: 0.8061 - val_loss: 0.6023 - val_accuracy: 0.7259\n",
      "Epoch 36/300\n",
      "2852/2852 [==============================] - 1s 245us/sample - loss: 0.4699 - accuracy: 0.8047 - val_loss: 0.6021 - val_accuracy: 0.7245\n",
      "Epoch 37/300\n",
      "2852/2852 [==============================] - 1s 234us/sample - loss: 0.4628 - accuracy: 0.8110 - val_loss: 0.6020 - val_accuracy: 0.7259\n",
      "Epoch 38/300\n",
      "2852/2852 [==============================] - 1s 210us/sample - loss: 0.4657 - accuracy: 0.8114 - val_loss: 0.6018 - val_accuracy: 0.7274\n",
      "Epoch 39/300\n",
      "2852/2852 [==============================] - 1s 227us/sample - loss: 0.4650 - accuracy: 0.8082 - val_loss: 0.6017 - val_accuracy: 0.7274\n",
      "Epoch 40/300\n",
      "2852/2852 [==============================] - 1s 241us/sample - loss: 0.4601 - accuracy: 0.8086 - val_loss: 0.6016 - val_accuracy: 0.7289\n",
      "Epoch 41/300\n",
      "2852/2852 [==============================] - 1s 235us/sample - loss: 0.4600 - accuracy: 0.8135 - val_loss: 0.6017 - val_accuracy: 0.7274\n",
      "Epoch 42/300\n",
      "2852/2852 [==============================] - 1s 254us/sample - loss: 0.4593 - accuracy: 0.8075 - val_loss: 0.6016 - val_accuracy: 0.7274\n",
      "Epoch 43/300\n",
      "2852/2852 [==============================] - 1s 228us/sample - loss: 0.4534 - accuracy: 0.8135 - val_loss: 0.6017 - val_accuracy: 0.7289\n",
      "Epoch 00043: early stopping\n",
      "111/111 [==============================] - 0s 133us/sample - loss: 0.3210 - accuracy: 0.9550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [6:04:43, 994.89s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.60s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.29s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 845.328125 steps, validate for 200.71875 steps\n",
      "Epoch 1/300\n",
      "846/845 [==============================] - 24s 29ms/step - loss: 0.5637 - accuracy: 0.7317 - val_loss: 0.6092 - val_accuracy: 0.7210\n",
      "Epoch 2/300\n",
      "846/845 [==============================] - 23s 27ms/step - loss: 0.5001 - accuracy: 0.7828 - val_loss: 0.6227 - val_accuracy: 0.7208\n",
      "Epoch 3/300\n",
      "846/845 [==============================] - 23s 27ms/step - loss: 0.4859 - accuracy: 0.7871 - val_loss: 0.6311 - val_accuracy: 0.7208\n",
      "Epoch 4/300\n",
      "846/845 [==============================] - 23s 28ms/step - loss: 0.4753 - accuracy: 0.7905 - val_loss: 0.6406 - val_accuracy: 0.7220\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 845.328125 steps, validate for 200.71875 steps\n",
      "Epoch 1/300\n",
      "846/845 [==============================] - 55s 65ms/step - loss: 0.4578 - accuracy: 0.7980 - val_loss: 0.6235 - val_accuracy: 0.7171\n",
      "Epoch 2/300\n",
      "846/845 [==============================] - 53s 63ms/step - loss: 0.4303 - accuracy: 0.8115 - val_loss: 0.6305 - val_accuracy: 0.7119\n",
      "Epoch 3/300\n",
      "846/845 [==============================] - 53s 63ms/step - loss: 0.4079 - accuracy: 0.8241 - val_loss: 0.6744 - val_accuracy: 0.7185\n",
      "Epoch 4/300\n",
      "846/845 [==============================] - 53s 63ms/step - loss: 0.3871 - accuracy: 0.8350 - val_loss: 0.6394 - val_accuracy: 0.7120\n",
      "Epoch 00004: early stopping\n",
      "148/148 [==============================] - 0s 2ms/sample - loss: 0.2828 - accuracy: 0.9324\n",
      "138/138 [==============================] - 0s 298us/sample - loss: 0.3327 - accuracy: 0.8768\n",
      "134/134 [==============================] - 0s 237us/sample - loss: 0.3093 - accuracy: 0.9104\n",
      "133/133 [==============================] - 0s 317us/sample - loss: 0.3088 - accuracy: 0.9098\n",
      "133/133 [==============================] - 0s 252us/sample - loss: 0.3322 - accuracy: 0.8872\n",
      "130/130 [==============================] - 0s 246us/sample - loss: 0.3283 - accuracy: 0.8846\n",
      "126/126 [==============================] - 0s 223us/sample - loss: 0.3173 - accuracy: 0.9206\n",
      "126/126 [==============================] - 0s 233us/sample - loss: 0.3453 - accuracy: 0.8968\n",
      "124/124 [==============================] - 0s 241us/sample - loss: 0.3495 - accuracy: 0.8790\n",
      "121/121 [==============================] - 0s 225us/sample - loss: 0.2828 - accuracy: 0.9421\n",
      "118/118 [==============================] - 0s 270us/sample - loss: 0.3149 - accuracy: 0.9153\n",
      "117/117 [==============================] - 0s 245us/sample - loss: 0.3484 - accuracy: 0.8718\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.3464 - accuracy: 0.8750\n",
      "117/117 [==============================] - 0s 269us/sample - loss: 0.3475 - accuracy: 0.8718\n",
      "116/116 [==============================] - 0s 264us/sample - loss: 0.3738 - accuracy: 0.8362\n",
      "114/114 [==============================] - 0s 244us/sample - loss: 0.3937 - accuracy: 0.8947\n",
      "113/113 [==============================] - 0s 270us/sample - loss: 0.4049 - accuracy: 0.8584\n",
      "113/113 [==============================] - 0s 276us/sample - loss: 0.3584 - accuracy: 0.8673\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 0.3929 - accuracy: 0.8482\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 0.3499 - accuracy: 0.9107\n",
      "113/113 [==============================] - 0s 249us/sample - loss: 0.3301 - accuracy: 0.9292\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 0.3339 - accuracy: 0.9018\n",
      "113/113 [==============================] - 0s 270us/sample - loss: 0.3319 - accuracy: 0.8938\n",
      "111/111 [==============================] - 0s 260us/sample - loss: 0.3321 - accuracy: 0.8919\n",
      "110/110 [==============================] - 0s 270us/sample - loss: 0.3399 - accuracy: 0.8909\n",
      "110/110 [==============================] - 0s 242us/sample - loss: 0.3419 - accuracy: 0.8818\n",
      "111/111 [==============================] - 0s 244us/sample - loss: 0.3733 - accuracy: 0.8559\n",
      "109/109 [==============================] - 0s 254us/sample - loss: 0.3391 - accuracy: 0.9083\n",
      "108/108 [==============================] - 0s 256us/sample - loss: 0.3113 - accuracy: 0.9259\n",
      "106/106 [==============================] - 0s 266us/sample - loss: 0.3484 - accuracy: 0.9245\n",
      "106/106 [==============================] - 0s 254us/sample - loss: 0.3605 - accuracy: 0.8774\n",
      "106/106 [==============================] - 0s 277us/sample - loss: 0.3645 - accuracy: 0.8774\n",
      "104/104 [==============================] - 0s 252us/sample - loss: 0.3807 - accuracy: 0.8750\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2876 samples, validate on 674 samples\n",
      "Epoch 1/300\n",
      "2876/2876 [==============================] - 3s 991us/sample - loss: 0.6614 - accuracy: 0.6029 - val_loss: 0.6412 - val_accuracy: 0.6276\n",
      "Epoch 2/300\n",
      "2876/2876 [==============================] - 1s 249us/sample - loss: 0.6302 - accuracy: 0.6502 - val_loss: 0.6309 - val_accuracy: 0.6454\n",
      "Epoch 3/300\n",
      "2876/2876 [==============================] - 1s 241us/sample - loss: 0.6179 - accuracy: 0.6745 - val_loss: 0.6239 - val_accuracy: 0.6558\n",
      "Epoch 4/300\n",
      "2876/2876 [==============================] - 1s 240us/sample - loss: 0.6032 - accuracy: 0.6919 - val_loss: 0.6184 - val_accuracy: 0.6691\n",
      "Epoch 5/300\n",
      "2876/2876 [==============================] - 1s 219us/sample - loss: 0.5928 - accuracy: 0.7111 - val_loss: 0.6142 - val_accuracy: 0.6840\n",
      "Epoch 6/300\n",
      "2876/2876 [==============================] - 1s 203us/sample - loss: 0.5813 - accuracy: 0.7131 - val_loss: 0.6106 - val_accuracy: 0.6914\n",
      "Epoch 7/300\n",
      "2876/2876 [==============================] - 1s 206us/sample - loss: 0.5770 - accuracy: 0.7375 - val_loss: 0.6076 - val_accuracy: 0.6929\n",
      "Epoch 8/300\n",
      "2876/2876 [==============================] - 1s 241us/sample - loss: 0.5727 - accuracy: 0.7403 - val_loss: 0.6050 - val_accuracy: 0.7003\n",
      "Epoch 9/300\n",
      "2876/2876 [==============================] - 1s 230us/sample - loss: 0.5647 - accuracy: 0.7434 - val_loss: 0.6027 - val_accuracy: 0.7047\n",
      "Epoch 10/300\n",
      "2876/2876 [==============================] - 1s 251us/sample - loss: 0.5570 - accuracy: 0.7503 - val_loss: 0.6006 - val_accuracy: 0.7047\n",
      "Epoch 11/300\n",
      "2876/2876 [==============================] - 1s 243us/sample - loss: 0.5508 - accuracy: 0.7625 - val_loss: 0.5988 - val_accuracy: 0.7077\n",
      "Epoch 12/300\n",
      "2876/2876 [==============================] - 1s 244us/sample - loss: 0.5454 - accuracy: 0.7653 - val_loss: 0.5973 - val_accuracy: 0.7077\n",
      "Epoch 13/300\n",
      "2876/2876 [==============================] - 1s 252us/sample - loss: 0.5424 - accuracy: 0.7674 - val_loss: 0.5959 - val_accuracy: 0.7136\n",
      "Epoch 14/300\n",
      "2876/2876 [==============================] - 1s 232us/sample - loss: 0.5385 - accuracy: 0.7684 - val_loss: 0.5947 - val_accuracy: 0.7166\n",
      "Epoch 15/300\n",
      "2876/2876 [==============================] - 1s 234us/sample - loss: 0.5328 - accuracy: 0.7709 - val_loss: 0.5936 - val_accuracy: 0.7211\n",
      "Epoch 16/300\n",
      "2876/2876 [==============================] - 1s 245us/sample - loss: 0.5302 - accuracy: 0.7698 - val_loss: 0.5926 - val_accuracy: 0.7211\n",
      "Epoch 17/300\n",
      "2876/2876 [==============================] - 1s 248us/sample - loss: 0.5249 - accuracy: 0.7740 - val_loss: 0.5918 - val_accuracy: 0.7226\n",
      "Epoch 18/300\n",
      "2876/2876 [==============================] - 1s 239us/sample - loss: 0.5231 - accuracy: 0.7809 - val_loss: 0.5911 - val_accuracy: 0.7240\n",
      "Epoch 19/300\n",
      "2876/2876 [==============================] - 1s 235us/sample - loss: 0.5158 - accuracy: 0.7869 - val_loss: 0.5905 - val_accuracy: 0.7255\n",
      "Epoch 20/300\n",
      "2876/2876 [==============================] - 1s 237us/sample - loss: 0.5140 - accuracy: 0.7876 - val_loss: 0.5900 - val_accuracy: 0.7255\n",
      "Epoch 21/300\n",
      "2876/2876 [==============================] - 1s 241us/sample - loss: 0.5115 - accuracy: 0.7896 - val_loss: 0.5895 - val_accuracy: 0.7255\n",
      "Epoch 22/300\n",
      "2876/2876 [==============================] - 1s 242us/sample - loss: 0.5075 - accuracy: 0.7862 - val_loss: 0.5892 - val_accuracy: 0.7240\n",
      "Epoch 23/300\n",
      "2876/2876 [==============================] - 1s 241us/sample - loss: 0.5051 - accuracy: 0.7962 - val_loss: 0.5889 - val_accuracy: 0.7285\n",
      "Epoch 24/300\n",
      "2876/2876 [==============================] - 1s 246us/sample - loss: 0.4995 - accuracy: 0.7935 - val_loss: 0.5887 - val_accuracy: 0.7285\n",
      "Epoch 25/300\n",
      "2876/2876 [==============================] - 1s 254us/sample - loss: 0.5023 - accuracy: 0.7896 - val_loss: 0.5886 - val_accuracy: 0.7300\n",
      "Epoch 26/300\n",
      "2876/2876 [==============================] - 1s 253us/sample - loss: 0.4938 - accuracy: 0.8001 - val_loss: 0.5885 - val_accuracy: 0.7329\n",
      "Epoch 27/300\n",
      "2876/2876 [==============================] - 1s 238us/sample - loss: 0.4919 - accuracy: 0.7938 - val_loss: 0.5884 - val_accuracy: 0.7344\n",
      "Epoch 28/300\n",
      "2876/2876 [==============================] - 1s 247us/sample - loss: 0.4916 - accuracy: 0.7938 - val_loss: 0.5885 - val_accuracy: 0.7359\n",
      "Epoch 29/300\n",
      "2876/2876 [==============================] - 1s 232us/sample - loss: 0.4902 - accuracy: 0.7969 - val_loss: 0.5885 - val_accuracy: 0.7359\n",
      "Epoch 30/300\n",
      "2876/2876 [==============================] - 1s 245us/sample - loss: 0.4861 - accuracy: 0.7980 - val_loss: 0.5887 - val_accuracy: 0.7359\n",
      "Epoch 00030: early stopping\n",
      "99/99 [==============================] - 0s 173us/sample - loss: 0.3627 - accuracy: 0.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [6:20:55, 988.12s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.76s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.42s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 841.6953125 steps, validate for 200.65625 steps\n",
      "Epoch 1/300\n",
      "842/841 [==============================] - 25s 30ms/step - loss: 0.5556 - accuracy: 0.7496 - val_loss: 0.6232 - val_accuracy: 0.7207\n",
      "Epoch 2/300\n",
      "842/841 [==============================] - 24s 28ms/step - loss: 0.5053 - accuracy: 0.7818 - val_loss: 0.6343 - val_accuracy: 0.7194\n",
      "Epoch 3/300\n",
      "842/841 [==============================] - 24s 28ms/step - loss: 0.4901 - accuracy: 0.7864 - val_loss: 0.6362 - val_accuracy: 0.7181\n",
      "Epoch 4/300\n",
      "842/841 [==============================] - 24s 28ms/step - loss: 0.4788 - accuracy: 0.7904 - val_loss: 0.6492 - val_accuracy: 0.7177\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 841.6953125 steps, validate for 200.65625 steps\n",
      "Epoch 1/300\n",
      "842/841 [==============================] - 55s 66ms/step - loss: 0.4599 - accuracy: 0.7983 - val_loss: 0.6710 - val_accuracy: 0.6870\n",
      "Epoch 2/300\n",
      "842/841 [==============================] - 54s 64ms/step - loss: 0.4315 - accuracy: 0.8117 - val_loss: 0.6706 - val_accuracy: 0.6965\n",
      "Epoch 3/300\n",
      "842/841 [==============================] - 54s 64ms/step - loss: 0.4077 - accuracy: 0.8242 - val_loss: 0.6850 - val_accuracy: 0.7129\n",
      "Epoch 4/300\n",
      "842/841 [==============================] - 54s 64ms/step - loss: 0.3853 - accuracy: 0.8360 - val_loss: 0.6625 - val_accuracy: 0.7058\n",
      "Epoch 5/300\n",
      "842/841 [==============================] - 53s 63ms/step - loss: 0.3649 - accuracy: 0.8477 - val_loss: 0.7044 - val_accuracy: 0.6808\n",
      "Epoch 6/300\n",
      "842/841 [==============================] - 54s 64ms/step - loss: 0.3455 - accuracy: 0.8580 - val_loss: 0.6817 - val_accuracy: 0.6990\n",
      "Epoch 7/300\n",
      "842/841 [==============================] - 54s 64ms/step - loss: 0.3275 - accuracy: 0.8677 - val_loss: 0.6917 - val_accuracy: 0.7033\n",
      "Epoch 00007: early stopping\n",
      "152/152 [==============================] - 0s 1ms/sample - loss: 0.1981 - accuracy: 0.9605\n",
      "145/145 [==============================] - 0s 231us/sample - loss: 0.2082 - accuracy: 0.9655\n",
      "142/142 [==============================] - 0s 259us/sample - loss: 0.2148 - accuracy: 0.9718\n",
      "138/138 [==============================] - 0s 234us/sample - loss: 0.2421 - accuracy: 0.9493\n",
      "137/137 [==============================] - 0s 244us/sample - loss: 0.2058 - accuracy: 0.9562\n",
      "137/137 [==============================] - 0s 241us/sample - loss: 0.2142 - accuracy: 0.9489\n",
      "136/136 [==============================] - 0s 255us/sample - loss: 0.2659 - accuracy: 0.9265\n",
      "135/135 [==============================] - 0s 226us/sample - loss: 0.3022 - accuracy: 0.9185\n",
      "136/136 [==============================] - 0s 235us/sample - loss: 0.2763 - accuracy: 0.9265\n",
      "134/134 [==============================] - 0s 278us/sample - loss: 0.2563 - accuracy: 0.9328\n",
      "132/132 [==============================] - 0s 248us/sample - loss: 0.3178 - accuracy: 0.9242\n",
      "132/132 [==============================] - 0s 251us/sample - loss: 0.3348 - accuracy: 0.9091\n",
      "133/133 [==============================] - 0s 301us/sample - loss: 0.3407 - accuracy: 0.8722\n",
      "132/132 [==============================] - 0s 274us/sample - loss: 0.2853 - accuracy: 0.9015\n",
      "133/133 [==============================] - 0s 303us/sample - loss: 0.2538 - accuracy: 0.9173\n",
      "130/130 [==============================] - 0s 265us/sample - loss: 0.3574 - accuracy: 0.8846\n",
      "132/132 [==============================] - 0s 277us/sample - loss: 0.2948 - accuracy: 0.9015\n",
      "131/131 [==============================] - 0s 262us/sample - loss: 0.3109 - accuracy: 0.9008\n",
      "132/132 [==============================] - 0s 275us/sample - loss: 0.3357 - accuracy: 0.8864\n",
      "131/131 [==============================] - 0s 272us/sample - loss: 0.3341 - accuracy: 0.8626\n",
      "129/129 [==============================] - 0s 291us/sample - loss: 0.3278 - accuracy: 0.8992\n",
      "129/129 [==============================] - 0s 260us/sample - loss: 0.2766 - accuracy: 0.9225\n",
      "129/129 [==============================] - 0s 294us/sample - loss: 0.3367 - accuracy: 0.8682\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.3780 - accuracy: 0.8906\n",
      "129/129 [==============================] - 0s 262us/sample - loss: 0.3756 - accuracy: 0.8837\n",
      "127/127 [==============================] - 0s 282us/sample - loss: 0.3495 - accuracy: 0.9134\n",
      "127/127 [==============================] - 0s 268us/sample - loss: 0.2844 - accuracy: 0.9370\n",
      "126/126 [==============================] - 0s 252us/sample - loss: 0.3155 - accuracy: 0.9286\n",
      "124/124 [==============================] - 0s 313us/sample - loss: 0.3295 - accuracy: 0.9274\n",
      "126/126 [==============================] - 0s 280us/sample - loss: 0.3460 - accuracy: 0.8889\n",
      "125/125 [==============================] - 0s 270us/sample - loss: 0.3498 - accuracy: 0.9040\n",
      "123/123 [==============================] - 0s 279us/sample - loss: 0.3942 - accuracy: 0.8862\n",
      "125/125 [==============================] - 0s 242us/sample - loss: 0.4008 - accuracy: 0.8720\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2856 samples, validate on 674 samples\n",
      "Epoch 1/300\n",
      "2856/2856 [==============================] - 3s 979us/sample - loss: 0.7147 - accuracy: 0.4930 - val_loss: 0.6965 - val_accuracy: 0.5000\n",
      "Epoch 2/300\n",
      "2856/2856 [==============================] - 1s 250us/sample - loss: 0.6735 - accuracy: 0.5634 - val_loss: 0.6805 - val_accuracy: 0.5401\n",
      "Epoch 3/300\n",
      "2856/2856 [==============================] - 1s 239us/sample - loss: 0.6522 - accuracy: 0.6096 - val_loss: 0.6694 - val_accuracy: 0.5742\n",
      "Epoch 4/300\n",
      "2856/2856 [==============================] - 1s 258us/sample - loss: 0.6350 - accuracy: 0.6418 - val_loss: 0.6607 - val_accuracy: 0.6068\n",
      "Epoch 5/300\n",
      "2856/2856 [==============================] - 1s 253us/sample - loss: 0.6152 - accuracy: 0.6866 - val_loss: 0.6536 - val_accuracy: 0.6261\n",
      "Epoch 6/300\n",
      "2856/2856 [==============================] - 1s 244us/sample - loss: 0.6044 - accuracy: 0.6985 - val_loss: 0.6477 - val_accuracy: 0.6424\n",
      "Epoch 7/300\n",
      "2856/2856 [==============================] - 1s 232us/sample - loss: 0.5925 - accuracy: 0.7304 - val_loss: 0.6424 - val_accuracy: 0.6573\n",
      "Epoch 8/300\n",
      "2856/2856 [==============================] - 1s 220us/sample - loss: 0.5809 - accuracy: 0.7489 - val_loss: 0.6379 - val_accuracy: 0.6647\n",
      "Epoch 9/300\n",
      "2856/2856 [==============================] - 1s 241us/sample - loss: 0.5684 - accuracy: 0.7556 - val_loss: 0.6338 - val_accuracy: 0.6736\n",
      "Epoch 10/300\n",
      "2856/2856 [==============================] - 1s 238us/sample - loss: 0.5604 - accuracy: 0.7710 - val_loss: 0.6301 - val_accuracy: 0.6825\n",
      "Epoch 11/300\n",
      "2856/2856 [==============================] - 1s 215us/sample - loss: 0.5499 - accuracy: 0.7735 - val_loss: 0.6269 - val_accuracy: 0.6855\n",
      "Epoch 12/300\n",
      "2856/2856 [==============================] - 1s 199us/sample - loss: 0.5418 - accuracy: 0.7808 - val_loss: 0.6239 - val_accuracy: 0.6869\n",
      "Epoch 13/300\n",
      "2856/2856 [==============================] - 1s 243us/sample - loss: 0.5342 - accuracy: 0.7899 - val_loss: 0.6213 - val_accuracy: 0.6914\n",
      "Epoch 14/300\n",
      "2856/2856 [==============================] - 1s 221us/sample - loss: 0.5231 - accuracy: 0.7952 - val_loss: 0.6190 - val_accuracy: 0.6958\n",
      "Epoch 15/300\n",
      "2856/2856 [==============================] - 1s 223us/sample - loss: 0.5152 - accuracy: 0.8018 - val_loss: 0.6169 - val_accuracy: 0.7018\n",
      "Epoch 16/300\n",
      "2856/2856 [==============================] - 1s 228us/sample - loss: 0.5119 - accuracy: 0.8029 - val_loss: 0.6151 - val_accuracy: 0.7033\n",
      "Epoch 17/300\n",
      "2856/2856 [==============================] - 1s 236us/sample - loss: 0.5034 - accuracy: 0.8116 - val_loss: 0.6135 - val_accuracy: 0.7047\n",
      "Epoch 18/300\n",
      "2856/2856 [==============================] - 1s 245us/sample - loss: 0.4963 - accuracy: 0.8120 - val_loss: 0.6120 - val_accuracy: 0.6988\n",
      "Epoch 19/300\n",
      "2856/2856 [==============================] - 1s 220us/sample - loss: 0.4878 - accuracy: 0.8155 - val_loss: 0.6108 - val_accuracy: 0.7033\n",
      "Epoch 20/300\n",
      "2856/2856 [==============================] - 1s 259us/sample - loss: 0.4839 - accuracy: 0.8246 - val_loss: 0.6096 - val_accuracy: 0.7033\n",
      "Epoch 21/300\n",
      "2856/2856 [==============================] - 1s 232us/sample - loss: 0.4771 - accuracy: 0.8225 - val_loss: 0.6087 - val_accuracy: 0.7062\n",
      "Epoch 22/300\n",
      "2856/2856 [==============================] - 1s 237us/sample - loss: 0.4697 - accuracy: 0.8232 - val_loss: 0.6078 - val_accuracy: 0.7047\n",
      "Epoch 23/300\n",
      "2856/2856 [==============================] - 1s 249us/sample - loss: 0.4666 - accuracy: 0.8239 - val_loss: 0.6072 - val_accuracy: 0.7062\n",
      "Epoch 24/300\n",
      "2856/2856 [==============================] - 1s 248us/sample - loss: 0.4626 - accuracy: 0.8270 - val_loss: 0.6067 - val_accuracy: 0.7062\n",
      "Epoch 25/300\n",
      "2856/2856 [==============================] - 1s 239us/sample - loss: 0.4520 - accuracy: 0.8330 - val_loss: 0.6063 - val_accuracy: 0.7077\n",
      "Epoch 26/300\n",
      "2856/2856 [==============================] - 1s 250us/sample - loss: 0.4462 - accuracy: 0.8340 - val_loss: 0.6062 - val_accuracy: 0.7077\n",
      "Epoch 27/300\n",
      "2856/2856 [==============================] - 1s 236us/sample - loss: 0.4401 - accuracy: 0.8382 - val_loss: 0.6061 - val_accuracy: 0.7077\n",
      "Epoch 28/300\n",
      "2856/2856 [==============================] - 1s 243us/sample - loss: 0.4374 - accuracy: 0.8361 - val_loss: 0.6062 - val_accuracy: 0.7077\n",
      "Epoch 29/300\n",
      "2856/2856 [==============================] - 1s 247us/sample - loss: 0.4337 - accuracy: 0.8400 - val_loss: 0.6063 - val_accuracy: 0.7062\n",
      "Epoch 30/300\n",
      "2856/2856 [==============================] - 1s 244us/sample - loss: 0.4289 - accuracy: 0.8403 - val_loss: 0.6066 - val_accuracy: 0.7092\n",
      "Epoch 00030: early stopping\n",
      "119/119 [==============================] - 0s 114us/sample - loss: 0.3785 - accuracy: 0.9076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [6:39:55, 1033.61s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.46s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.22s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 841.65625 steps, validate for 199.3515625 steps\n",
      "Epoch 1/300\n",
      "842/841 [==============================] - 24s 28ms/step - loss: 0.5647 - accuracy: 0.7370 - val_loss: 0.6217 - val_accuracy: 0.7217\n",
      "Epoch 2/300\n",
      "842/841 [==============================] - 23s 28ms/step - loss: 0.5046 - accuracy: 0.7817 - val_loss: 0.6250 - val_accuracy: 0.7209\n",
      "Epoch 3/300\n",
      "842/841 [==============================] - 24s 28ms/step - loss: 0.4906 - accuracy: 0.7852 - val_loss: 0.6229 - val_accuracy: 0.7200\n",
      "Epoch 4/300\n",
      "842/841 [==============================] - 24s 28ms/step - loss: 0.4798 - accuracy: 0.7889 - val_loss: 0.6302 - val_accuracy: 0.7203\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 841.65625 steps, validate for 199.3515625 steps\n",
      "Epoch 1/300\n",
      "842/841 [==============================] - 55s 65ms/step - loss: 0.4615 - accuracy: 0.7962 - val_loss: 0.6441 - val_accuracy: 0.7171\n",
      "Epoch 2/300\n",
      "842/841 [==============================] - 53s 63ms/step - loss: 0.4342 - accuracy: 0.8103 - val_loss: 0.6525 - val_accuracy: 0.6996\n",
      "Epoch 3/300\n",
      "842/841 [==============================] - 53s 62ms/step - loss: 0.4114 - accuracy: 0.8224 - val_loss: 0.6446 - val_accuracy: 0.6955\n",
      "Epoch 4/300\n",
      "842/841 [==============================] - 53s 62ms/step - loss: 0.3889 - accuracy: 0.8349 - val_loss: 0.6712 - val_accuracy: 0.7245\n",
      "Epoch 00004: early stopping\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 0.2159 - accuracy: 0.9441\n",
      "154/154 [==============================] - 0s 275us/sample - loss: 0.2076 - accuracy: 0.9610\n",
      "151/151 [==============================] - 0s 229us/sample - loss: 0.2020 - accuracy: 0.9669\n",
      "146/146 [==============================] - 0s 223us/sample - loss: 0.2121 - accuracy: 0.9726\n",
      "147/147 [==============================] - 0s 246us/sample - loss: 0.1926 - accuracy: 0.9660\n",
      "145/145 [==============================] - 0s 237us/sample - loss: 0.1974 - accuracy: 0.9655\n",
      "145/145 [==============================] - 0s 221us/sample - loss: 0.1783 - accuracy: 0.9655\n",
      "144/144 [==============================] - 0s 225us/sample - loss: 0.1861 - accuracy: 0.9583\n",
      "145/145 [==============================] - 0s 246us/sample - loss: 0.1865 - accuracy: 0.9793\n",
      "143/143 [==============================] - 0s 241us/sample - loss: 0.1746 - accuracy: 0.9790\n",
      "142/142 [==============================] - 0s 253us/sample - loss: 0.1978 - accuracy: 0.9789\n",
      "140/140 [==============================] - 0s 239us/sample - loss: 0.1801 - accuracy: 0.9786\n",
      "138/138 [==============================] - 0s 247us/sample - loss: 0.1915 - accuracy: 0.9710\n",
      "138/138 [==============================] - 0s 231us/sample - loss: 0.1812 - accuracy: 0.9855\n",
      "137/137 [==============================] - 0s 290us/sample - loss: 0.1874 - accuracy: 0.9635\n",
      "136/136 [==============================] - 0s 251us/sample - loss: 0.1908 - accuracy: 0.9779\n",
      "138/138 [==============================] - 0s 250us/sample - loss: 0.1951 - accuracy: 0.9638\n",
      "138/138 [==============================] - 0s 263us/sample - loss: 0.1957 - accuracy: 0.9638\n",
      "137/137 [==============================] - 0s 250us/sample - loss: 0.1843 - accuracy: 0.9781\n",
      "136/136 [==============================] - 0s 233us/sample - loss: 0.1679 - accuracy: 0.9779\n",
      "136/136 [==============================] - 0s 252us/sample - loss: 0.1956 - accuracy: 0.9559\n",
      "136/136 [==============================] - 0s 250us/sample - loss: 0.1877 - accuracy: 0.9779\n",
      "136/136 [==============================] - 0s 245us/sample - loss: 0.1723 - accuracy: 0.9853\n",
      "135/135 [==============================] - 0s 305us/sample - loss: 0.1819 - accuracy: 0.9852\n",
      "135/135 [==============================] - 0s 274us/sample - loss: 0.1844 - accuracy: 0.9852\n",
      "134/134 [==============================] - 0s 272us/sample - loss: 0.2058 - accuracy: 0.9627\n",
      "133/133 [==============================] - 0s 262us/sample - loss: 0.2173 - accuracy: 0.9774\n",
      "125/125 [==============================] - 0s 254us/sample - loss: 0.2397 - accuracy: 0.9600\n",
      "124/124 [==============================] - 0s 228us/sample - loss: 0.2091 - accuracy: 0.9677\n",
      "122/122 [==============================] - 0s 251us/sample - loss: 0.2006 - accuracy: 0.9836\n",
      "119/119 [==============================] - 0s 231us/sample - loss: 0.2026 - accuracy: 0.9664\n",
      "117/117 [==============================] - 0s 233us/sample - loss: 0.2097 - accuracy: 0.9658\n",
      "116/116 [==============================] - 0s 263us/sample - loss: 0.1980 - accuracy: 0.9828\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2860 samples, validate on 681 samples\n",
      "Epoch 1/300\n",
      "2860/2860 [==============================] - 2s 812us/sample - loss: 0.8052 - accuracy: 0.3675 - val_loss: 0.7533 - val_accuracy: 0.4053\n",
      "Epoch 2/300\n",
      "2860/2860 [==============================] - 1s 224us/sample - loss: 0.7425 - accuracy: 0.4409 - val_loss: 0.7243 - val_accuracy: 0.4537\n",
      "Epoch 3/300\n",
      "2860/2860 [==============================] - 1s 232us/sample - loss: 0.7116 - accuracy: 0.5031 - val_loss: 0.7047 - val_accuracy: 0.5037\n",
      "Epoch 4/300\n",
      "2860/2860 [==============================] - 1s 210us/sample - loss: 0.6836 - accuracy: 0.5626 - val_loss: 0.6901 - val_accuracy: 0.5536\n",
      "Epoch 5/300\n",
      "2860/2860 [==============================] - 1s 248us/sample - loss: 0.6636 - accuracy: 0.6140 - val_loss: 0.6783 - val_accuracy: 0.5888\n",
      "Epoch 6/300\n",
      "2860/2860 [==============================] - 1s 246us/sample - loss: 0.6445 - accuracy: 0.6388 - val_loss: 0.6683 - val_accuracy: 0.6197\n",
      "Epoch 7/300\n",
      "2860/2860 [==============================] - 1s 182us/sample - loss: 0.6339 - accuracy: 0.6710 - val_loss: 0.6597 - val_accuracy: 0.6344\n",
      "Epoch 8/300\n",
      "2860/2860 [==============================] - 1s 198us/sample - loss: 0.6160 - accuracy: 0.6920 - val_loss: 0.6525 - val_accuracy: 0.6608\n",
      "Epoch 9/300\n",
      "2860/2860 [==============================] - 1s 229us/sample - loss: 0.6068 - accuracy: 0.7080 - val_loss: 0.6462 - val_accuracy: 0.6652\n",
      "Epoch 10/300\n",
      "2860/2860 [==============================] - 1s 212us/sample - loss: 0.5921 - accuracy: 0.7297 - val_loss: 0.6405 - val_accuracy: 0.6799\n",
      "Epoch 11/300\n",
      "2860/2860 [==============================] - 1s 207us/sample - loss: 0.5820 - accuracy: 0.7367 - val_loss: 0.6355 - val_accuracy: 0.6887\n",
      "Epoch 12/300\n",
      "2860/2860 [==============================] - 1s 234us/sample - loss: 0.5803 - accuracy: 0.7409 - val_loss: 0.6311 - val_accuracy: 0.6887\n",
      "Epoch 13/300\n",
      "2860/2860 [==============================] - 1s 222us/sample - loss: 0.5679 - accuracy: 0.7615 - val_loss: 0.6271 - val_accuracy: 0.6872\n",
      "Epoch 14/300\n",
      "2860/2860 [==============================] - 1s 233us/sample - loss: 0.5597 - accuracy: 0.7605 - val_loss: 0.6234 - val_accuracy: 0.6872\n",
      "Epoch 15/300\n",
      "2860/2860 [==============================] - 1s 235us/sample - loss: 0.5552 - accuracy: 0.7692 - val_loss: 0.6203 - val_accuracy: 0.6916\n",
      "Epoch 16/300\n",
      "2860/2860 [==============================] - 1s 231us/sample - loss: 0.5437 - accuracy: 0.7738 - val_loss: 0.6173 - val_accuracy: 0.6887\n",
      "Epoch 17/300\n",
      "2860/2860 [==============================] - 1s 245us/sample - loss: 0.5421 - accuracy: 0.7689 - val_loss: 0.6148 - val_accuracy: 0.6946\n",
      "Epoch 18/300\n",
      "2860/2860 [==============================] - 1s 248us/sample - loss: 0.5311 - accuracy: 0.7829 - val_loss: 0.6124 - val_accuracy: 0.6960\n",
      "Epoch 19/300\n",
      "2860/2860 [==============================] - 1s 226us/sample - loss: 0.5282 - accuracy: 0.7801 - val_loss: 0.6103 - val_accuracy: 0.6975\n",
      "Epoch 20/300\n",
      "2860/2860 [==============================] - 1s 225us/sample - loss: 0.5229 - accuracy: 0.7867 - val_loss: 0.6083 - val_accuracy: 0.6975\n",
      "Epoch 21/300\n",
      "2860/2860 [==============================] - 1s 236us/sample - loss: 0.5135 - accuracy: 0.7944 - val_loss: 0.6067 - val_accuracy: 0.6990\n",
      "Epoch 22/300\n",
      "2860/2860 [==============================] - 1s 228us/sample - loss: 0.5132 - accuracy: 0.7909 - val_loss: 0.6051 - val_accuracy: 0.7048\n",
      "Epoch 23/300\n",
      "2860/2860 [==============================] - 1s 198us/sample - loss: 0.5054 - accuracy: 0.7948 - val_loss: 0.6038 - val_accuracy: 0.7048\n",
      "Epoch 24/300\n",
      "2860/2860 [==============================] - 1s 247us/sample - loss: 0.5027 - accuracy: 0.7962 - val_loss: 0.6026 - val_accuracy: 0.7063\n",
      "Epoch 25/300\n",
      "2860/2860 [==============================] - 1s 242us/sample - loss: 0.4988 - accuracy: 0.7955 - val_loss: 0.6015 - val_accuracy: 0.7078\n",
      "Epoch 26/300\n",
      "2860/2860 [==============================] - 1s 217us/sample - loss: 0.4940 - accuracy: 0.7983 - val_loss: 0.6005 - val_accuracy: 0.7093\n",
      "Epoch 27/300\n",
      "2860/2860 [==============================] - 1s 242us/sample - loss: 0.4916 - accuracy: 0.8017 - val_loss: 0.5997 - val_accuracy: 0.7107\n",
      "Epoch 28/300\n",
      "2860/2860 [==============================] - 1s 250us/sample - loss: 0.4839 - accuracy: 0.7986 - val_loss: 0.5990 - val_accuracy: 0.7107\n",
      "Epoch 29/300\n",
      "2860/2860 [==============================] - 1s 257us/sample - loss: 0.4824 - accuracy: 0.8077 - val_loss: 0.5983 - val_accuracy: 0.7107\n",
      "Epoch 30/300\n",
      "2860/2860 [==============================] - 1s 231us/sample - loss: 0.4795 - accuracy: 0.8049 - val_loss: 0.5977 - val_accuracy: 0.7122\n",
      "Epoch 31/300\n",
      "2860/2860 [==============================] - 1s 235us/sample - loss: 0.4762 - accuracy: 0.8049 - val_loss: 0.5972 - val_accuracy: 0.7122\n",
      "Epoch 32/300\n",
      "2860/2860 [==============================] - 1s 240us/sample - loss: 0.4728 - accuracy: 0.8024 - val_loss: 0.5968 - val_accuracy: 0.7151\n",
      "Epoch 33/300\n",
      "2860/2860 [==============================] - 1s 212us/sample - loss: 0.4756 - accuracy: 0.8073 - val_loss: 0.5964 - val_accuracy: 0.7137\n",
      "Epoch 34/300\n",
      "2860/2860 [==============================] - 1s 211us/sample - loss: 0.4676 - accuracy: 0.8122 - val_loss: 0.5961 - val_accuracy: 0.7151\n",
      "Epoch 35/300\n",
      "2860/2860 [==============================] - 1s 207us/sample - loss: 0.4660 - accuracy: 0.8021 - val_loss: 0.5958 - val_accuracy: 0.7166\n",
      "Epoch 36/300\n",
      "2860/2860 [==============================] - 1s 244us/sample - loss: 0.4623 - accuracy: 0.8108 - val_loss: 0.5955 - val_accuracy: 0.7151\n",
      "Epoch 37/300\n",
      "2860/2860 [==============================] - 1s 256us/sample - loss: 0.4628 - accuracy: 0.8112 - val_loss: 0.5954 - val_accuracy: 0.7137\n",
      "Epoch 38/300\n",
      "2860/2860 [==============================] - 1s 248us/sample - loss: 0.4535 - accuracy: 0.8161 - val_loss: 0.5953 - val_accuracy: 0.7137\n",
      "Epoch 39/300\n",
      "2860/2860 [==============================] - 1s 226us/sample - loss: 0.4549 - accuracy: 0.8140 - val_loss: 0.5952 - val_accuracy: 0.7151\n",
      "Epoch 40/300\n",
      "2860/2860 [==============================] - 1s 221us/sample - loss: 0.4524 - accuracy: 0.8136 - val_loss: 0.5952 - val_accuracy: 0.7151\n",
      "Epoch 41/300\n",
      "2860/2860 [==============================] - 1s 230us/sample - loss: 0.4482 - accuracy: 0.8140 - val_loss: 0.5953 - val_accuracy: 0.7151\n",
      "Epoch 42/300\n",
      "2860/2860 [==============================] - 1s 227us/sample - loss: 0.4474 - accuracy: 0.8168 - val_loss: 0.5954 - val_accuracy: 0.7166\n",
      "Epoch 00042: early stopping\n",
      "108/108 [==============================] - 0s 153us/sample - loss: 0.2731 - accuracy: 0.9722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [6:56:16, 1017.80s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.42s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.20s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 842.1875 steps, validate for 199.9609375 steps\n",
      "Epoch 1/300\n",
      "843/842 [==============================] - 24s 29ms/step - loss: 0.6124 - accuracy: 0.6837 - val_loss: 0.6256 - val_accuracy: 0.7189\n",
      "Epoch 2/300\n",
      "843/842 [==============================] - 23s 28ms/step - loss: 0.5053 - accuracy: 0.7807 - val_loss: 0.6246 - val_accuracy: 0.7233\n",
      "Epoch 3/300\n",
      "843/842 [==============================] - 23s 28ms/step - loss: 0.4896 - accuracy: 0.7856 - val_loss: 0.6320 - val_accuracy: 0.7240\n",
      "Epoch 4/300\n",
      "843/842 [==============================] - 23s 27ms/step - loss: 0.4786 - accuracy: 0.7892 - val_loss: 0.6313 - val_accuracy: 0.7273\n",
      "Epoch 5/300\n",
      "843/842 [==============================] - 23s 27ms/step - loss: 0.4688 - accuracy: 0.7944 - val_loss: 0.6434 - val_accuracy: 0.7220\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 842.1875 steps, validate for 199.9609375 steps\n",
      "Epoch 1/300\n",
      "843/842 [==============================] - 55s 65ms/step - loss: 0.4512 - accuracy: 0.8022 - val_loss: 0.6405 - val_accuracy: 0.7281\n",
      "Epoch 2/300\n",
      "843/842 [==============================] - 54s 64ms/step - loss: 0.4247 - accuracy: 0.8155 - val_loss: 0.6575 - val_accuracy: 0.7197\n",
      "Epoch 3/300\n",
      "843/842 [==============================] - 53s 63ms/step - loss: 0.4024 - accuracy: 0.8279 - val_loss: 0.6900 - val_accuracy: 0.7265\n",
      "Epoch 4/300\n",
      "843/842 [==============================] - 53s 63ms/step - loss: 0.3824 - accuracy: 0.8386 - val_loss: 0.6514 - val_accuracy: 0.7043\n",
      "Epoch 00004: early stopping\n",
      "148/148 [==============================] - 0s 1ms/sample - loss: 0.2856 - accuracy: 0.9459\n",
      "147/147 [==============================] - 0s 232us/sample - loss: 0.2786 - accuracy: 0.9456\n",
      "146/146 [==============================] - 0s 220us/sample - loss: 0.2973 - accuracy: 0.9315\n",
      "144/144 [==============================] - 0s 240us/sample - loss: 0.2890 - accuracy: 0.9167\n",
      "144/144 [==============================] - 0s 217us/sample - loss: 0.3323 - accuracy: 0.9028\n",
      "140/140 [==============================] - 0s 202us/sample - loss: 0.2806 - accuracy: 0.9571\n",
      "139/139 [==============================] - 0s 252us/sample - loss: 0.3347 - accuracy: 0.9065\n",
      "138/138 [==============================] - 0s 217us/sample - loss: 0.2931 - accuracy: 0.9348\n",
      "135/135 [==============================] - 0s 248us/sample - loss: 0.3117 - accuracy: 0.9111\n",
      "135/135 [==============================] - 0s 264us/sample - loss: 0.3202 - accuracy: 0.9111\n",
      "135/135 [==============================] - 0s 263us/sample - loss: 0.3297 - accuracy: 0.9037\n",
      "132/132 [==============================] - 0s 254us/sample - loss: 0.3478 - accuracy: 0.9167\n",
      "132/132 [==============================] - 0s 274us/sample - loss: 0.3743 - accuracy: 0.8409\n",
      "131/131 [==============================] - 0s 257us/sample - loss: 0.2939 - accuracy: 0.9847\n",
      "130/130 [==============================] - 0s 293us/sample - loss: 0.2667 - accuracy: 0.9692\n",
      "131/131 [==============================] - 0s 318us/sample - loss: 0.3028 - accuracy: 0.9237\n",
      "130/130 [==============================] - 0s 296us/sample - loss: 0.2891 - accuracy: 0.9538\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.3088 - accuracy: 0.9219\n",
      "130/130 [==============================] - 0s 252us/sample - loss: 0.2985 - accuracy: 0.9385\n",
      "130/130 [==============================] - 0s 233us/sample - loss: 0.3183 - accuracy: 0.9077\n",
      "131/131 [==============================] - 0s 244us/sample - loss: 0.3210 - accuracy: 0.9313\n",
      "131/131 [==============================] - 0s 255us/sample - loss: 0.3416 - accuracy: 0.8931\n",
      "131/131 [==============================] - 0s 275us/sample - loss: 0.3532 - accuracy: 0.9084\n",
      "130/130 [==============================] - 0s 271us/sample - loss: 0.3177 - accuracy: 0.9231\n",
      "129/129 [==============================] - 0s 273us/sample - loss: 0.3358 - accuracy: 0.9225\n",
      "128/128 [==============================] - 0s 227us/sample - loss: 0.3024 - accuracy: 0.9297\n",
      "129/129 [==============================] - 0s 262us/sample - loss: 0.3165 - accuracy: 0.9225\n",
      "127/127 [==============================] - 0s 215us/sample - loss: 0.2646 - accuracy: 0.9528\n",
      "128/128 [==============================] - 0s 222us/sample - loss: 0.2669 - accuracy: 0.9375\n",
      "126/126 [==============================] - 0s 290us/sample - loss: 0.2705 - accuracy: 0.9603\n",
      "124/124 [==============================] - 0s 252us/sample - loss: 0.3122 - accuracy: 0.8871\n",
      "122/122 [==============================] - 0s 274us/sample - loss: 0.3092 - accuracy: 0.9508\n",
      "122/122 [==============================] - 0s 252us/sample - loss: 0.2950 - accuracy: 0.9508\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2860 samples, validate on 673 samples\n",
      "Epoch 1/300\n",
      "2860/2860 [==============================] - 2s 850us/sample - loss: 0.7274 - accuracy: 0.4871 - val_loss: 0.6797 - val_accuracy: 0.5557\n",
      "Epoch 2/300\n",
      "2860/2860 [==============================] - 1s 223us/sample - loss: 0.6874 - accuracy: 0.5577 - val_loss: 0.6651 - val_accuracy: 0.5825\n",
      "Epoch 3/300\n",
      "2860/2860 [==============================] - 1s 201us/sample - loss: 0.6654 - accuracy: 0.6066 - val_loss: 0.6555 - val_accuracy: 0.5973\n",
      "Epoch 4/300\n",
      "2860/2860 [==============================] - 1s 179us/sample - loss: 0.6498 - accuracy: 0.6213 - val_loss: 0.6487 - val_accuracy: 0.6241\n",
      "Epoch 5/300\n",
      "2860/2860 [==============================] - 1s 179us/sample - loss: 0.6363 - accuracy: 0.6563 - val_loss: 0.6432 - val_accuracy: 0.6404\n",
      "Epoch 6/300\n",
      "2860/2860 [==============================] - 1s 215us/sample - loss: 0.6298 - accuracy: 0.6703 - val_loss: 0.6388 - val_accuracy: 0.6404\n",
      "Epoch 7/300\n",
      "2860/2860 [==============================] - 1s 187us/sample - loss: 0.6179 - accuracy: 0.6668 - val_loss: 0.6350 - val_accuracy: 0.6449\n",
      "Epoch 8/300\n",
      "2860/2860 [==============================] - 1s 200us/sample - loss: 0.6064 - accuracy: 0.6867 - val_loss: 0.6319 - val_accuracy: 0.6464\n",
      "Epoch 9/300\n",
      "2860/2860 [==============================] - 1s 206us/sample - loss: 0.6040 - accuracy: 0.6885 - val_loss: 0.6293 - val_accuracy: 0.6464\n",
      "Epoch 10/300\n",
      "2860/2860 [==============================] - 1s 213us/sample - loss: 0.5978 - accuracy: 0.6965 - val_loss: 0.6270 - val_accuracy: 0.6553\n",
      "Epoch 11/300\n",
      "2860/2860 [==============================] - 1s 244us/sample - loss: 0.5920 - accuracy: 0.7175 - val_loss: 0.6249 - val_accuracy: 0.6642\n",
      "Epoch 12/300\n",
      "2860/2860 [==============================] - 1s 252us/sample - loss: 0.5861 - accuracy: 0.7196 - val_loss: 0.6231 - val_accuracy: 0.6672\n",
      "Epoch 13/300\n",
      "2860/2860 [==============================] - 1s 252us/sample - loss: 0.5799 - accuracy: 0.7206 - val_loss: 0.6214 - val_accuracy: 0.6716\n",
      "Epoch 14/300\n",
      "2860/2860 [==============================] - 1s 252us/sample - loss: 0.5747 - accuracy: 0.7287 - val_loss: 0.6200 - val_accuracy: 0.6790\n",
      "Epoch 15/300\n",
      "2860/2860 [==============================] - 1s 231us/sample - loss: 0.5676 - accuracy: 0.7353 - val_loss: 0.6187 - val_accuracy: 0.6835\n",
      "Epoch 16/300\n",
      "2860/2860 [==============================] - 1s 260us/sample - loss: 0.5668 - accuracy: 0.7388 - val_loss: 0.6175 - val_accuracy: 0.6835\n",
      "Epoch 17/300\n",
      "2860/2860 [==============================] - 1s 212us/sample - loss: 0.5586 - accuracy: 0.7406 - val_loss: 0.6164 - val_accuracy: 0.6805\n",
      "Epoch 18/300\n",
      "2860/2860 [==============================] - 1s 227us/sample - loss: 0.5556 - accuracy: 0.7559 - val_loss: 0.6155 - val_accuracy: 0.6820\n",
      "Epoch 19/300\n",
      "2860/2860 [==============================] - 1s 213us/sample - loss: 0.5511 - accuracy: 0.7528 - val_loss: 0.6146 - val_accuracy: 0.6865\n",
      "Epoch 20/300\n",
      "2860/2860 [==============================] - 1s 200us/sample - loss: 0.5492 - accuracy: 0.7601 - val_loss: 0.6138 - val_accuracy: 0.6909\n",
      "Epoch 21/300\n",
      "2860/2860 [==============================] - 1s 190us/sample - loss: 0.5416 - accuracy: 0.7640 - val_loss: 0.6130 - val_accuracy: 0.6909\n",
      "Epoch 22/300\n",
      "2860/2860 [==============================] - 1s 211us/sample - loss: 0.5410 - accuracy: 0.7647 - val_loss: 0.6125 - val_accuracy: 0.6909\n",
      "Epoch 23/300\n",
      "2860/2860 [==============================] - 1s 200us/sample - loss: 0.5378 - accuracy: 0.7598 - val_loss: 0.6119 - val_accuracy: 0.6924\n",
      "Epoch 24/300\n",
      "2860/2860 [==============================] - 1s 225us/sample - loss: 0.5354 - accuracy: 0.7594 - val_loss: 0.6113 - val_accuracy: 0.6924\n",
      "Epoch 25/300\n",
      "2860/2860 [==============================] - 1s 208us/sample - loss: 0.5304 - accuracy: 0.7629 - val_loss: 0.6107 - val_accuracy: 0.6909\n",
      "Epoch 26/300\n",
      "2860/2860 [==============================] - 1s 257us/sample - loss: 0.5260 - accuracy: 0.7717 - val_loss: 0.6103 - val_accuracy: 0.6924\n",
      "Epoch 27/300\n",
      "2860/2860 [==============================] - 1s 252us/sample - loss: 0.5235 - accuracy: 0.7787 - val_loss: 0.6098 - val_accuracy: 0.6954\n",
      "Epoch 28/300\n",
      "2860/2860 [==============================] - 1s 240us/sample - loss: 0.5263 - accuracy: 0.7738 - val_loss: 0.6093 - val_accuracy: 0.6939\n",
      "Epoch 29/300\n",
      "2860/2860 [==============================] - 1s 238us/sample - loss: 0.5218 - accuracy: 0.7678 - val_loss: 0.6090 - val_accuracy: 0.6969\n",
      "Epoch 30/300\n",
      "2860/2860 [==============================] - 1s 214us/sample - loss: 0.5135 - accuracy: 0.7769 - val_loss: 0.6087 - val_accuracy: 0.6984\n",
      "Epoch 31/300\n",
      "2860/2860 [==============================] - 1s 235us/sample - loss: 0.5097 - accuracy: 0.7797 - val_loss: 0.6082 - val_accuracy: 0.6984\n",
      "Epoch 32/300\n",
      "2860/2860 [==============================] - 1s 247us/sample - loss: 0.5108 - accuracy: 0.7818 - val_loss: 0.6079 - val_accuracy: 0.6999\n",
      "Epoch 33/300\n",
      "2860/2860 [==============================] - 1s 247us/sample - loss: 0.5071 - accuracy: 0.7804 - val_loss: 0.6076 - val_accuracy: 0.7013\n",
      "Epoch 34/300\n",
      "2860/2860 [==============================] - 1s 215us/sample - loss: 0.5077 - accuracy: 0.7846 - val_loss: 0.6073 - val_accuracy: 0.7028\n",
      "Epoch 35/300\n",
      "2860/2860 [==============================] - 1s 241us/sample - loss: 0.4995 - accuracy: 0.7937 - val_loss: 0.6072 - val_accuracy: 0.7058\n",
      "Epoch 36/300\n",
      "2860/2860 [==============================] - 1s 215us/sample - loss: 0.4976 - accuracy: 0.7895 - val_loss: 0.6070 - val_accuracy: 0.7073\n",
      "Epoch 37/300\n",
      "2860/2860 [==============================] - 1s 226us/sample - loss: 0.4984 - accuracy: 0.7857 - val_loss: 0.6067 - val_accuracy: 0.7073\n",
      "Epoch 38/300\n",
      "2860/2860 [==============================] - 0s 174us/sample - loss: 0.4966 - accuracy: 0.7885 - val_loss: 0.6064 - val_accuracy: 0.7073\n",
      "Epoch 39/300\n",
      "2860/2860 [==============================] - 1s 202us/sample - loss: 0.4952 - accuracy: 0.7885 - val_loss: 0.6063 - val_accuracy: 0.7088\n",
      "Epoch 40/300\n",
      "2860/2860 [==============================] - 1s 226us/sample - loss: 0.4913 - accuracy: 0.7913 - val_loss: 0.6060 - val_accuracy: 0.7088\n",
      "Epoch 41/300\n",
      "2860/2860 [==============================] - 1s 196us/sample - loss: 0.4883 - accuracy: 0.7930 - val_loss: 0.6059 - val_accuracy: 0.7088\n",
      "Epoch 42/300\n",
      "2860/2860 [==============================] - 1s 214us/sample - loss: 0.4830 - accuracy: 0.7951 - val_loss: 0.6057 - val_accuracy: 0.7073\n",
      "Epoch 43/300\n",
      "2860/2860 [==============================] - 1s 232us/sample - loss: 0.4811 - accuracy: 0.7965 - val_loss: 0.6057 - val_accuracy: 0.7073\n",
      "Epoch 44/300\n",
      "2860/2860 [==============================] - 1s 196us/sample - loss: 0.4827 - accuracy: 0.7951 - val_loss: 0.6056 - val_accuracy: 0.7073\n",
      "Epoch 45/300\n",
      "2860/2860 [==============================] - 1s 231us/sample - loss: 0.4820 - accuracy: 0.7962 - val_loss: 0.6054 - val_accuracy: 0.7088\n",
      "Epoch 46/300\n",
      "2860/2860 [==============================] - 1s 255us/sample - loss: 0.4764 - accuracy: 0.8031 - val_loss: 0.6053 - val_accuracy: 0.7088\n",
      "Epoch 47/300\n",
      "2860/2860 [==============================] - 1s 261us/sample - loss: 0.4718 - accuracy: 0.8038 - val_loss: 0.6052 - val_accuracy: 0.7088\n",
      "Epoch 48/300\n",
      "2860/2860 [==============================] - 1s 233us/sample - loss: 0.4722 - accuracy: 0.8007 - val_loss: 0.6051 - val_accuracy: 0.7088\n",
      "Epoch 49/300\n",
      "2860/2860 [==============================] - 1s 247us/sample - loss: 0.4702 - accuracy: 0.7979 - val_loss: 0.6050 - val_accuracy: 0.7103\n",
      "Epoch 50/300\n",
      "2860/2860 [==============================] - 1s 256us/sample - loss: 0.4711 - accuracy: 0.8003 - val_loss: 0.6049 - val_accuracy: 0.7103\n",
      "Epoch 51/300\n",
      "2860/2860 [==============================] - 1s 244us/sample - loss: 0.4693 - accuracy: 0.8024 - val_loss: 0.6048 - val_accuracy: 0.7103\n",
      "Epoch 52/300\n",
      "2860/2860 [==============================] - 1s 235us/sample - loss: 0.4665 - accuracy: 0.8021 - val_loss: 0.6046 - val_accuracy: 0.7103\n",
      "Epoch 53/300\n",
      "2860/2860 [==============================] - 1s 240us/sample - loss: 0.4623 - accuracy: 0.8077 - val_loss: 0.6045 - val_accuracy: 0.7117\n",
      "Epoch 54/300\n",
      "2860/2860 [==============================] - 1s 227us/sample - loss: 0.4593 - accuracy: 0.8021 - val_loss: 0.6044 - val_accuracy: 0.7117\n",
      "Epoch 55/300\n",
      "2860/2860 [==============================] - 1s 262us/sample - loss: 0.4575 - accuracy: 0.8024 - val_loss: 0.6043 - val_accuracy: 0.7132\n",
      "Epoch 56/300\n",
      "2860/2860 [==============================] - 1s 253us/sample - loss: 0.4532 - accuracy: 0.8098 - val_loss: 0.6043 - val_accuracy: 0.7147\n",
      "Epoch 57/300\n",
      "2860/2860 [==============================] - 1s 223us/sample - loss: 0.4532 - accuracy: 0.8063 - val_loss: 0.6043 - val_accuracy: 0.7147\n",
      "Epoch 58/300\n",
      "2860/2860 [==============================] - 1s 190us/sample - loss: 0.4535 - accuracy: 0.8112 - val_loss: 0.6041 - val_accuracy: 0.7147\n",
      "Epoch 59/300\n",
      "2860/2860 [==============================] - 1s 205us/sample - loss: 0.4508 - accuracy: 0.8087 - val_loss: 0.6042 - val_accuracy: 0.7132\n",
      "Epoch 60/300\n",
      "2860/2860 [==============================] - 1s 225us/sample - loss: 0.4516 - accuracy: 0.8094 - val_loss: 0.6041 - val_accuracy: 0.7132\n",
      "Epoch 61/300\n",
      "2860/2860 [==============================] - 1s 220us/sample - loss: 0.4477 - accuracy: 0.8091 - val_loss: 0.6042 - val_accuracy: 0.7147\n",
      "Epoch 62/300\n",
      "2860/2860 [==============================] - 1s 227us/sample - loss: 0.4479 - accuracy: 0.8115 - val_loss: 0.6043 - val_accuracy: 0.7162\n",
      "Epoch 63/300\n",
      "2860/2860 [==============================] - 1s 196us/sample - loss: 0.4424 - accuracy: 0.8140 - val_loss: 0.6043 - val_accuracy: 0.7162\n",
      "Epoch 00063: early stopping\n",
      "116/116 [==============================] - 0s 129us/sample - loss: 0.2680 - accuracy: 0.9569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [7:13:16, 1039.87s/it]\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.39s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.31s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 836.34375 steps, validate for 194.46875 steps\n",
      "Epoch 1/300\n",
      "837/836 [==============================] - 24s 29ms/step - loss: 0.5863 - accuracy: 0.7065 - val_loss: 0.5570 - val_accuracy: 0.7738\n",
      "Epoch 2/300\n",
      "837/836 [==============================] - 22s 27ms/step - loss: 0.5126 - accuracy: 0.7692 - val_loss: 0.5610 - val_accuracy: 0.7719\n",
      "Epoch 3/300\n",
      "837/836 [==============================] - 22s 27ms/step - loss: 0.4961 - accuracy: 0.7759 - val_loss: 0.5664 - val_accuracy: 0.7655\n",
      "Epoch 4/300\n",
      "837/836 [==============================] - 22s 27ms/step - loss: 0.4842 - accuracy: 0.7819 - val_loss: 0.5659 - val_accuracy: 0.7636\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 836.34375 steps, validate for 194.46875 steps\n",
      "Epoch 1/300\n",
      "837/836 [==============================] - 53s 64ms/step - loss: 0.4648 - accuracy: 0.7920 - val_loss: 0.5769 - val_accuracy: 0.7791\n",
      "Epoch 2/300\n",
      "837/836 [==============================] - 53s 63ms/step - loss: 0.4368 - accuracy: 0.8058 - val_loss: 0.5894 - val_accuracy: 0.7287\n",
      "Epoch 3/300\n",
      "837/836 [==============================] - 53s 63ms/step - loss: 0.4146 - accuracy: 0.8189 - val_loss: 0.5803 - val_accuracy: 0.7784\n",
      "Epoch 4/300\n",
      "837/836 [==============================] - 53s 63ms/step - loss: 0.3941 - accuracy: 0.8297 - val_loss: 0.6161 - val_accuracy: 0.7175\n",
      "Epoch 00004: early stopping\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.3901 - accuracy: 0.8812\n",
      "196/196 [==============================] - 0s 242us/sample - loss: 0.3697 - accuracy: 0.9082\n",
      "193/193 [==============================] - 0s 255us/sample - loss: 0.3483 - accuracy: 0.9016\n",
      "190/190 [==============================] - 0s 242us/sample - loss: 0.3944 - accuracy: 0.8579\n",
      "190/190 [==============================] - 0s 241us/sample - loss: 0.4210 - accuracy: 0.8263\n",
      "187/187 [==============================] - 0s 212us/sample - loss: 0.3685 - accuracy: 0.8877\n",
      "184/184 [==============================] - 0s 228us/sample - loss: 0.3876 - accuracy: 0.8641\n",
      "183/183 [==============================] - 0s 227us/sample - loss: 0.3524 - accuracy: 0.8689\n",
      "182/182 [==============================] - 0s 257us/sample - loss: 0.3337 - accuracy: 0.9286\n",
      "181/181 [==============================] - 0s 254us/sample - loss: 0.3386 - accuracy: 0.8840\n",
      "177/177 [==============================] - 0s 229us/sample - loss: 0.3426 - accuracy: 0.9096\n",
      "178/178 [==============================] - 0s 247us/sample - loss: 0.3713 - accuracy: 0.8876\n",
      "178/178 [==============================] - 0s 239us/sample - loss: 0.3416 - accuracy: 0.8764\n",
      "176/176 [==============================] - 0s 240us/sample - loss: 0.3397 - accuracy: 0.9034\n",
      "175/175 [==============================] - 0s 247us/sample - loss: 0.3605 - accuracy: 0.9029\n",
      "176/176 [==============================] - 0s 235us/sample - loss: 0.3519 - accuracy: 0.8977\n",
      "173/173 [==============================] - 0s 247us/sample - loss: 0.3280 - accuracy: 0.8960\n",
      "172/172 [==============================] - 0s 265us/sample - loss: 0.3704 - accuracy: 0.8605\n",
      "171/171 [==============================] - 0s 278us/sample - loss: 0.3843 - accuracy: 0.8772\n",
      "171/171 [==============================] - 0s 251us/sample - loss: 0.4010 - accuracy: 0.8304\n",
      "171/171 [==============================] - 0s 283us/sample - loss: 0.3797 - accuracy: 0.8655\n",
      "170/170 [==============================] - 0s 268us/sample - loss: 0.4106 - accuracy: 0.8294\n",
      "171/171 [==============================] - 0s 267us/sample - loss: 0.3647 - accuracy: 0.8713\n",
      "170/170 [==============================] - 0s 259us/sample - loss: 0.3408 - accuracy: 0.9059\n",
      "170/170 [==============================] - 0s 270us/sample - loss: 0.3579 - accuracy: 0.8765\n",
      "171/171 [==============================] - 0s 231us/sample - loss: 0.3678 - accuracy: 0.8596\n",
      "168/168 [==============================] - 0s 228us/sample - loss: 0.4138 - accuracy: 0.8333\n",
      "169/169 [==============================] - 0s 242us/sample - loss: 0.3637 - accuracy: 0.8817\n",
      "169/169 [==============================] - 0s 233us/sample - loss: 0.3867 - accuracy: 0.8639\n",
      "167/167 [==============================] - 0s 248us/sample - loss: 0.3783 - accuracy: 0.8743\n",
      "168/168 [==============================] - 0s 233us/sample - loss: 0.3973 - accuracy: 0.9048\n",
      "169/169 [==============================] - 0s 267us/sample - loss: 0.3951 - accuracy: 0.8521\n",
      "166/166 [==============================] - 0s 252us/sample - loss: 0.4486 - accuracy: 0.8373\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2823 samples, validate on 667 samples\n",
      "Epoch 1/300\n",
      "2823/2823 [==============================] - 2s 845us/sample - loss: 0.7327 - accuracy: 0.4786 - val_loss: 0.6658 - val_accuracy: 0.5892\n",
      "Epoch 2/300\n",
      "2823/2823 [==============================] - 1s 225us/sample - loss: 0.7010 - accuracy: 0.5423 - val_loss: 0.6478 - val_accuracy: 0.6057\n",
      "Epoch 3/300\n",
      "2823/2823 [==============================] - 1s 225us/sample - loss: 0.6859 - accuracy: 0.5586 - val_loss: 0.6351 - val_accuracy: 0.6282\n",
      "Epoch 4/300\n",
      "2823/2823 [==============================] - 1s 203us/sample - loss: 0.6682 - accuracy: 0.5940 - val_loss: 0.6251 - val_accuracy: 0.6552\n",
      "Epoch 5/300\n",
      "2823/2823 [==============================] - 1s 245us/sample - loss: 0.6615 - accuracy: 0.6135 - val_loss: 0.6170 - val_accuracy: 0.6717\n",
      "Epoch 6/300\n",
      "2823/2823 [==============================] - 1s 231us/sample - loss: 0.6483 - accuracy: 0.6295 - val_loss: 0.6100 - val_accuracy: 0.6807\n",
      "Epoch 7/300\n",
      "2823/2823 [==============================] - 1s 211us/sample - loss: 0.6378 - accuracy: 0.6472 - val_loss: 0.6037 - val_accuracy: 0.7001\n",
      "Epoch 8/300\n",
      "2823/2823 [==============================] - 1s 222us/sample - loss: 0.6312 - accuracy: 0.6652 - val_loss: 0.5982 - val_accuracy: 0.7046\n",
      "Epoch 9/300\n",
      "2823/2823 [==============================] - 1s 255us/sample - loss: 0.6246 - accuracy: 0.6713 - val_loss: 0.5931 - val_accuracy: 0.7091\n",
      "Epoch 10/300\n",
      "2823/2823 [==============================] - 1s 243us/sample - loss: 0.6154 - accuracy: 0.6869 - val_loss: 0.5884 - val_accuracy: 0.7106\n",
      "Epoch 11/300\n",
      "2823/2823 [==============================] - 1s 225us/sample - loss: 0.6100 - accuracy: 0.6908 - val_loss: 0.5842 - val_accuracy: 0.7151\n",
      "Epoch 12/300\n",
      "2823/2823 [==============================] - 1s 234us/sample - loss: 0.6049 - accuracy: 0.7000 - val_loss: 0.5804 - val_accuracy: 0.7166\n",
      "Epoch 13/300\n",
      "2823/2823 [==============================] - 1s 209us/sample - loss: 0.5978 - accuracy: 0.7063 - val_loss: 0.5769 - val_accuracy: 0.7271\n",
      "Epoch 14/300\n",
      "2823/2823 [==============================] - 1s 204us/sample - loss: 0.5948 - accuracy: 0.7127 - val_loss: 0.5736 - val_accuracy: 0.7376\n",
      "Epoch 15/300\n",
      "2823/2823 [==============================] - 1s 233us/sample - loss: 0.5900 - accuracy: 0.7180 - val_loss: 0.5706 - val_accuracy: 0.7406\n",
      "Epoch 16/300\n",
      "2823/2823 [==============================] - 1s 226us/sample - loss: 0.5831 - accuracy: 0.7173 - val_loss: 0.5677 - val_accuracy: 0.7421\n",
      "Epoch 17/300\n",
      "2823/2823 [==============================] - 1s 226us/sample - loss: 0.5797 - accuracy: 0.7279 - val_loss: 0.5649 - val_accuracy: 0.7421\n",
      "Epoch 18/300\n",
      "2823/2823 [==============================] - 1s 194us/sample - loss: 0.5766 - accuracy: 0.7269 - val_loss: 0.5625 - val_accuracy: 0.7466\n",
      "Epoch 19/300\n",
      "2823/2823 [==============================] - 1s 223us/sample - loss: 0.5728 - accuracy: 0.7315 - val_loss: 0.5601 - val_accuracy: 0.7526\n",
      "Epoch 20/300\n",
      "2823/2823 [==============================] - 1s 195us/sample - loss: 0.5692 - accuracy: 0.7375 - val_loss: 0.5580 - val_accuracy: 0.7556\n",
      "Epoch 21/300\n",
      "2823/2823 [==============================] - 1s 235us/sample - loss: 0.5639 - accuracy: 0.7372 - val_loss: 0.5559 - val_accuracy: 0.7571\n",
      "Epoch 22/300\n",
      "2823/2823 [==============================] - 1s 224us/sample - loss: 0.5600 - accuracy: 0.7386 - val_loss: 0.5540 - val_accuracy: 0.7571\n",
      "Epoch 23/300\n",
      "2823/2823 [==============================] - 1s 199us/sample - loss: 0.5545 - accuracy: 0.7517 - val_loss: 0.5521 - val_accuracy: 0.7571\n",
      "Epoch 24/300\n",
      "2823/2823 [==============================] - 1s 209us/sample - loss: 0.5531 - accuracy: 0.7450 - val_loss: 0.5504 - val_accuracy: 0.7556\n",
      "Epoch 25/300\n",
      "2823/2823 [==============================] - 1s 254us/sample - loss: 0.5497 - accuracy: 0.7453 - val_loss: 0.5489 - val_accuracy: 0.7556\n",
      "Epoch 26/300\n",
      "2823/2823 [==============================] - 1s 251us/sample - loss: 0.5421 - accuracy: 0.7559 - val_loss: 0.5475 - val_accuracy: 0.7571\n",
      "Epoch 27/300\n",
      "2823/2823 [==============================] - 1s 248us/sample - loss: 0.5391 - accuracy: 0.7577 - val_loss: 0.5462 - val_accuracy: 0.7616\n",
      "Epoch 28/300\n",
      "2823/2823 [==============================] - 1s 240us/sample - loss: 0.5390 - accuracy: 0.7612 - val_loss: 0.5450 - val_accuracy: 0.7661\n",
      "Epoch 29/300\n",
      "2823/2823 [==============================] - 1s 213us/sample - loss: 0.5319 - accuracy: 0.7584 - val_loss: 0.5439 - val_accuracy: 0.7646\n",
      "Epoch 30/300\n",
      "2823/2823 [==============================] - 1s 205us/sample - loss: 0.5301 - accuracy: 0.7612 - val_loss: 0.5428 - val_accuracy: 0.7676\n",
      "Epoch 31/300\n",
      "2823/2823 [==============================] - 1s 219us/sample - loss: 0.5291 - accuracy: 0.7552 - val_loss: 0.5420 - val_accuracy: 0.7676\n",
      "Epoch 32/300\n",
      "2823/2823 [==============================] - 1s 251us/sample - loss: 0.5233 - accuracy: 0.7648 - val_loss: 0.5410 - val_accuracy: 0.7691\n",
      "Epoch 33/300\n",
      "2823/2823 [==============================] - 1s 210us/sample - loss: 0.5244 - accuracy: 0.7605 - val_loss: 0.5402 - val_accuracy: 0.7691\n",
      "Epoch 34/300\n",
      "2823/2823 [==============================] - 1s 258us/sample - loss: 0.5191 - accuracy: 0.7644 - val_loss: 0.5394 - val_accuracy: 0.7676\n",
      "Epoch 35/300\n",
      "2823/2823 [==============================] - 1s 237us/sample - loss: 0.5146 - accuracy: 0.7701 - val_loss: 0.5389 - val_accuracy: 0.7676\n",
      "Epoch 36/300\n",
      "2823/2823 [==============================] - 1s 234us/sample - loss: 0.5142 - accuracy: 0.7669 - val_loss: 0.5382 - val_accuracy: 0.7691\n",
      "Epoch 37/300\n",
      "2823/2823 [==============================] - 1s 242us/sample - loss: 0.5134 - accuracy: 0.7680 - val_loss: 0.5377 - val_accuracy: 0.7691\n",
      "Epoch 38/300\n",
      "2823/2823 [==============================] - 1s 244us/sample - loss: 0.5082 - accuracy: 0.7705 - val_loss: 0.5372 - val_accuracy: 0.7691\n",
      "Epoch 39/300\n",
      "2823/2823 [==============================] - 1s 216us/sample - loss: 0.5024 - accuracy: 0.7761 - val_loss: 0.5368 - val_accuracy: 0.7691\n",
      "Epoch 40/300\n",
      "2823/2823 [==============================] - 1s 209us/sample - loss: 0.5024 - accuracy: 0.7740 - val_loss: 0.5364 - val_accuracy: 0.7691\n",
      "Epoch 41/300\n",
      "2823/2823 [==============================] - 1s 231us/sample - loss: 0.4998 - accuracy: 0.7765 - val_loss: 0.5360 - val_accuracy: 0.7691\n",
      "Epoch 42/300\n",
      "2823/2823 [==============================] - 1s 212us/sample - loss: 0.4969 - accuracy: 0.7761 - val_loss: 0.5358 - val_accuracy: 0.7691\n",
      "Epoch 43/300\n",
      "2823/2823 [==============================] - 1s 258us/sample - loss: 0.4920 - accuracy: 0.7793 - val_loss: 0.5356 - val_accuracy: 0.7691\n",
      "Epoch 44/300\n",
      "2823/2823 [==============================] - 1s 231us/sample - loss: 0.4894 - accuracy: 0.7811 - val_loss: 0.5354 - val_accuracy: 0.7691\n",
      "Epoch 45/300\n",
      "2823/2823 [==============================] - 1s 209us/sample - loss: 0.4914 - accuracy: 0.7783 - val_loss: 0.5353 - val_accuracy: 0.7691\n",
      "Epoch 46/300\n",
      "2823/2823 [==============================] - 1s 232us/sample - loss: 0.4863 - accuracy: 0.7811 - val_loss: 0.5352 - val_accuracy: 0.7691\n",
      "Epoch 47/300\n",
      "2823/2823 [==============================] - 1s 235us/sample - loss: 0.4802 - accuracy: 0.7857 - val_loss: 0.5352 - val_accuracy: 0.7691\n",
      "Epoch 48/300\n",
      "2823/2823 [==============================] - 1s 237us/sample - loss: 0.4823 - accuracy: 0.7853 - val_loss: 0.5353 - val_accuracy: 0.7706\n",
      "Epoch 49/300\n",
      "2823/2823 [==============================] - 1s 230us/sample - loss: 0.4815 - accuracy: 0.7814 - val_loss: 0.5354 - val_accuracy: 0.7721\n",
      "Epoch 00049: early stopping\n",
      "159/159 [==============================] - 0s 118us/sample - loss: 0.3407 - accuracy: 0.9371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [16:23, 983.02s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.61s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.33s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 842.2890625 steps, validate for 195.1953125 steps\n",
      "Epoch 1/300\n",
      "843/842 [==============================] - 24s 28ms/step - loss: 0.5502 - accuracy: 0.7529 - val_loss: 0.5527 - val_accuracy: 0.7789\n",
      "Epoch 2/300\n",
      "843/842 [==============================] - 23s 27ms/step - loss: 0.5107 - accuracy: 0.7697 - val_loss: 0.5578 - val_accuracy: 0.7717\n",
      "Epoch 3/300\n",
      "843/842 [==============================] - 23s 27ms/step - loss: 0.4949 - accuracy: 0.7762 - val_loss: 0.5566 - val_accuracy: 0.7707\n",
      "Epoch 4/300\n",
      "843/842 [==============================] - 23s 27ms/step - loss: 0.4832 - accuracy: 0.7821 - val_loss: 0.5573 - val_accuracy: 0.7710\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 842.2890625 steps, validate for 195.1953125 steps\n",
      "Epoch 1/300\n",
      "843/842 [==============================] - 54s 65ms/step - loss: 0.4653 - accuracy: 0.7900 - val_loss: 0.5763 - val_accuracy: 0.7527\n",
      "Epoch 2/300\n",
      "843/842 [==============================] - 54s 64ms/step - loss: 0.4391 - accuracy: 0.8045 - val_loss: 0.5578 - val_accuracy: 0.7743\n",
      "Epoch 3/300\n",
      "843/842 [==============================] - 53s 63ms/step - loss: 0.4172 - accuracy: 0.8172 - val_loss: 0.5767 - val_accuracy: 0.7698\n",
      "Epoch 4/300\n",
      "843/842 [==============================] - 54s 64ms/step - loss: 0.3974 - accuracy: 0.8286 - val_loss: 0.5807 - val_accuracy: 0.7436\n",
      "Epoch 5/300\n",
      "843/842 [==============================] - 53s 63ms/step - loss: 0.3785 - accuracy: 0.8399 - val_loss: 0.6126 - val_accuracy: 0.7180\n",
      "Epoch 00005: early stopping\n",
      "167/167 [==============================] - 0s 1ms/sample - loss: 0.3264 - accuracy: 0.8982\n",
      "164/164 [==============================] - 0s 249us/sample - loss: 0.3521 - accuracy: 0.8780\n",
      "162/162 [==============================] - 0s 240us/sample - loss: 0.3630 - accuracy: 0.8704\n",
      "162/162 [==============================] - 0s 314us/sample - loss: 0.3523 - accuracy: 0.8333\n",
      "162/162 [==============================] - 0s 234us/sample - loss: 0.3854 - accuracy: 0.8457\n",
      "161/161 [==============================] - 0s 244us/sample - loss: 0.3456 - accuracy: 0.8882\n",
      "162/162 [==============================] - 0s 249us/sample - loss: 0.3352 - accuracy: 0.9012\n",
      "162/162 [==============================] - 0s 270us/sample - loss: 0.3443 - accuracy: 0.8827\n",
      "157/157 [==============================] - 0s 215us/sample - loss: 0.3233 - accuracy: 0.8917\n",
      "158/158 [==============================] - 0s 260us/sample - loss: 0.3296 - accuracy: 0.8797\n",
      "157/157 [==============================] - 0s 266us/sample - loss: 0.3349 - accuracy: 0.9045\n",
      "157/157 [==============================] - 0s 214us/sample - loss: 0.3353 - accuracy: 0.9236\n",
      "157/157 [==============================] - 0s 245us/sample - loss: 0.3321 - accuracy: 0.9108\n",
      "155/155 [==============================] - 0s 250us/sample - loss: 0.3647 - accuracy: 0.8710\n",
      "152/152 [==============================] - 0s 228us/sample - loss: 0.3586 - accuracy: 0.8618\n",
      "153/153 [==============================] - 0s 288us/sample - loss: 0.3601 - accuracy: 0.8758\n",
      "150/150 [==============================] - 0s 244us/sample - loss: 0.3554 - accuracy: 0.8867\n",
      "149/149 [==============================] - 0s 266us/sample - loss: 0.3492 - accuracy: 0.8658\n",
      "147/147 [==============================] - 0s 259us/sample - loss: 0.3462 - accuracy: 0.8707\n",
      "147/147 [==============================] - 0s 249us/sample - loss: 0.3289 - accuracy: 0.9320\n",
      "146/146 [==============================] - 0s 244us/sample - loss: 0.3390 - accuracy: 0.8904\n",
      "145/145 [==============================] - 0s 227us/sample - loss: 0.3169 - accuracy: 0.8966\n",
      "145/145 [==============================] - 0s 227us/sample - loss: 0.3735 - accuracy: 0.8621\n",
      "144/144 [==============================] - 0s 266us/sample - loss: 0.3678 - accuracy: 0.8958\n",
      "141/141 [==============================] - 0s 270us/sample - loss: 0.3757 - accuracy: 0.8652\n",
      "140/140 [==============================] - 0s 247us/sample - loss: 0.3673 - accuracy: 0.8857\n",
      "140/140 [==============================] - 0s 254us/sample - loss: 0.4050 - accuracy: 0.8214\n",
      "140/140 [==============================] - 0s 249us/sample - loss: 0.3785 - accuracy: 0.8429\n",
      "140/140 [==============================] - 0s 222us/sample - loss: 0.4144 - accuracy: 0.8214\n",
      "140/140 [==============================] - 0s 254us/sample - loss: 0.3838 - accuracy: 0.8429\n",
      "141/141 [==============================] - 0s 235us/sample - loss: 0.3995 - accuracy: 0.8227\n",
      "139/139 [==============================] - 0s 227us/sample - loss: 0.3632 - accuracy: 0.8777\n",
      "138/138 [==============================] - 0s 265us/sample - loss: 0.4147 - accuracy: 0.8333\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2847 samples, validate on 668 samples\n",
      "Epoch 1/300\n",
      "2847/2847 [==============================] - 2s 835us/sample - loss: 0.7050 - accuracy: 0.5216 - val_loss: 0.6917 - val_accuracy: 0.5614\n",
      "Epoch 2/300\n",
      "2847/2847 [==============================] - 1s 186us/sample - loss: 0.6654 - accuracy: 0.5911 - val_loss: 0.6704 - val_accuracy: 0.5928\n",
      "Epoch 3/300\n",
      "2847/2847 [==============================] - 1s 183us/sample - loss: 0.6476 - accuracy: 0.6287 - val_loss: 0.6566 - val_accuracy: 0.6153\n",
      "Epoch 4/300\n",
      "2847/2847 [==============================] - 1s 209us/sample - loss: 0.6360 - accuracy: 0.6452 - val_loss: 0.6453 - val_accuracy: 0.6437\n",
      "Epoch 5/300\n",
      "2847/2847 [==============================] - 1s 224us/sample - loss: 0.6204 - accuracy: 0.6660 - val_loss: 0.6362 - val_accuracy: 0.6632\n",
      "Epoch 6/300\n",
      "2847/2847 [==============================] - 1s 218us/sample - loss: 0.6123 - accuracy: 0.6765 - val_loss: 0.6283 - val_accuracy: 0.6677\n",
      "Epoch 7/300\n",
      "2847/2847 [==============================] - 1s 233us/sample - loss: 0.6038 - accuracy: 0.6962 - val_loss: 0.6217 - val_accuracy: 0.6886\n",
      "Epoch 8/300\n",
      "2847/2847 [==============================] - 1s 183us/sample - loss: 0.5934 - accuracy: 0.7078 - val_loss: 0.6155 - val_accuracy: 0.6931\n",
      "Epoch 9/300\n",
      "2847/2847 [==============================] - 1s 236us/sample - loss: 0.5898 - accuracy: 0.7095 - val_loss: 0.6100 - val_accuracy: 0.7006\n",
      "Epoch 10/300\n",
      "2847/2847 [==============================] - 1s 225us/sample - loss: 0.5769 - accuracy: 0.7253 - val_loss: 0.6053 - val_accuracy: 0.7096\n",
      "Epoch 11/300\n",
      "2847/2847 [==============================] - 1s 241us/sample - loss: 0.5733 - accuracy: 0.7281 - val_loss: 0.6009 - val_accuracy: 0.7111\n",
      "Epoch 12/300\n",
      "2847/2847 [==============================] - 1s 220us/sample - loss: 0.5681 - accuracy: 0.7331 - val_loss: 0.5969 - val_accuracy: 0.7066\n",
      "Epoch 13/300\n",
      "2847/2847 [==============================] - 1s 229us/sample - loss: 0.5632 - accuracy: 0.7443 - val_loss: 0.5931 - val_accuracy: 0.7141\n",
      "Epoch 14/300\n",
      "2847/2847 [==============================] - 1s 199us/sample - loss: 0.5549 - accuracy: 0.7569 - val_loss: 0.5895 - val_accuracy: 0.7216\n",
      "Epoch 15/300\n",
      "2847/2847 [==============================] - 1s 245us/sample - loss: 0.5512 - accuracy: 0.7548 - val_loss: 0.5865 - val_accuracy: 0.7231\n",
      "Epoch 16/300\n",
      "2847/2847 [==============================] - 1s 254us/sample - loss: 0.5457 - accuracy: 0.7647 - val_loss: 0.5835 - val_accuracy: 0.7260\n",
      "Epoch 17/300\n",
      "2847/2847 [==============================] - 1s 203us/sample - loss: 0.5397 - accuracy: 0.7636 - val_loss: 0.5809 - val_accuracy: 0.7290\n",
      "Epoch 18/300\n",
      "2847/2847 [==============================] - 1s 224us/sample - loss: 0.5325 - accuracy: 0.7699 - val_loss: 0.5784 - val_accuracy: 0.7305\n",
      "Epoch 19/300\n",
      "2847/2847 [==============================] - 1s 223us/sample - loss: 0.5319 - accuracy: 0.7682 - val_loss: 0.5760 - val_accuracy: 0.7320\n",
      "Epoch 20/300\n",
      "2847/2847 [==============================] - 1s 224us/sample - loss: 0.5249 - accuracy: 0.7738 - val_loss: 0.5738 - val_accuracy: 0.7320\n",
      "Epoch 21/300\n",
      "2847/2847 [==============================] - 1s 211us/sample - loss: 0.5239 - accuracy: 0.7770 - val_loss: 0.5718 - val_accuracy: 0.7320\n",
      "Epoch 22/300\n",
      "2847/2847 [==============================] - 1s 202us/sample - loss: 0.5158 - accuracy: 0.7843 - val_loss: 0.5700 - val_accuracy: 0.7320\n",
      "Epoch 23/300\n",
      "2847/2847 [==============================] - 1s 210us/sample - loss: 0.5121 - accuracy: 0.7854 - val_loss: 0.5681 - val_accuracy: 0.7335\n",
      "Epoch 24/300\n",
      "2847/2847 [==============================] - 1s 231us/sample - loss: 0.5070 - accuracy: 0.7878 - val_loss: 0.5665 - val_accuracy: 0.7350\n",
      "Epoch 25/300\n",
      "2847/2847 [==============================] - 1s 198us/sample - loss: 0.5036 - accuracy: 0.7882 - val_loss: 0.5650 - val_accuracy: 0.7350\n",
      "Epoch 26/300\n",
      "2847/2847 [==============================] - 1s 221us/sample - loss: 0.5028 - accuracy: 0.7840 - val_loss: 0.5636 - val_accuracy: 0.7380\n",
      "Epoch 27/300\n",
      "2847/2847 [==============================] - 1s 216us/sample - loss: 0.5009 - accuracy: 0.7914 - val_loss: 0.5623 - val_accuracy: 0.7380\n",
      "Epoch 28/300\n",
      "2847/2847 [==============================] - 1s 232us/sample - loss: 0.4963 - accuracy: 0.7938 - val_loss: 0.5610 - val_accuracy: 0.7380\n",
      "Epoch 29/300\n",
      "2847/2847 [==============================] - 1s 219us/sample - loss: 0.4931 - accuracy: 0.7987 - val_loss: 0.5601 - val_accuracy: 0.7395\n",
      "Epoch 30/300\n",
      "2847/2847 [==============================] - 1s 224us/sample - loss: 0.4857 - accuracy: 0.8012 - val_loss: 0.5590 - val_accuracy: 0.7395\n",
      "Epoch 31/300\n",
      "2847/2847 [==============================] - 1s 249us/sample - loss: 0.4849 - accuracy: 0.8015 - val_loss: 0.5580 - val_accuracy: 0.7410\n",
      "Epoch 32/300\n",
      "2847/2847 [==============================] - 1s 236us/sample - loss: 0.4809 - accuracy: 0.8124 - val_loss: 0.5573 - val_accuracy: 0.7410\n",
      "Epoch 33/300\n",
      "2847/2847 [==============================] - 1s 217us/sample - loss: 0.4811 - accuracy: 0.8026 - val_loss: 0.5565 - val_accuracy: 0.7425\n",
      "Epoch 34/300\n",
      "2847/2847 [==============================] - 1s 244us/sample - loss: 0.4742 - accuracy: 0.8037 - val_loss: 0.5559 - val_accuracy: 0.7425\n",
      "Epoch 35/300\n",
      "2847/2847 [==============================] - 1s 223us/sample - loss: 0.4714 - accuracy: 0.8037 - val_loss: 0.5553 - val_accuracy: 0.7425\n",
      "Epoch 36/300\n",
      "2847/2847 [==============================] - 1s 209us/sample - loss: 0.4699 - accuracy: 0.8128 - val_loss: 0.5547 - val_accuracy: 0.7440\n",
      "Epoch 37/300\n",
      "2847/2847 [==============================] - 1s 257us/sample - loss: 0.4683 - accuracy: 0.8072 - val_loss: 0.5543 - val_accuracy: 0.7425\n",
      "Epoch 38/300\n",
      "2847/2847 [==============================] - 1s 242us/sample - loss: 0.4638 - accuracy: 0.8110 - val_loss: 0.5540 - val_accuracy: 0.7410\n",
      "Epoch 39/300\n",
      "2847/2847 [==============================] - 1s 220us/sample - loss: 0.4592 - accuracy: 0.8156 - val_loss: 0.5537 - val_accuracy: 0.7410\n",
      "Epoch 40/300\n",
      "2847/2847 [==============================] - 1s 230us/sample - loss: 0.4582 - accuracy: 0.8198 - val_loss: 0.5534 - val_accuracy: 0.7395\n",
      "Epoch 41/300\n",
      "2847/2847 [==============================] - 1s 229us/sample - loss: 0.4540 - accuracy: 0.8159 - val_loss: 0.5532 - val_accuracy: 0.7425\n",
      "Epoch 42/300\n",
      "2847/2847 [==============================] - 1s 226us/sample - loss: 0.4502 - accuracy: 0.8226 - val_loss: 0.5529 - val_accuracy: 0.7410\n",
      "Epoch 43/300\n",
      "2847/2847 [==============================] - 1s 216us/sample - loss: 0.4455 - accuracy: 0.8212 - val_loss: 0.5528 - val_accuracy: 0.7410\n",
      "Epoch 44/300\n",
      "2847/2847 [==============================] - 1s 234us/sample - loss: 0.4423 - accuracy: 0.8279 - val_loss: 0.5528 - val_accuracy: 0.7410\n",
      "Epoch 45/300\n",
      "2847/2847 [==============================] - 1s 204us/sample - loss: 0.4424 - accuracy: 0.8272 - val_loss: 0.5527 - val_accuracy: 0.7410\n",
      "Epoch 46/300\n",
      "2847/2847 [==============================] - 1s 218us/sample - loss: 0.4394 - accuracy: 0.8251 - val_loss: 0.5528 - val_accuracy: 0.7410\n",
      "Epoch 47/300\n",
      "2847/2847 [==============================] - 1s 211us/sample - loss: 0.4319 - accuracy: 0.8311 - val_loss: 0.5530 - val_accuracy: 0.7410\n",
      "Epoch 48/300\n",
      "2847/2847 [==============================] - 1s 201us/sample - loss: 0.4331 - accuracy: 0.8311 - val_loss: 0.5531 - val_accuracy: 0.7410\n",
      "Epoch 00048: early stopping\n",
      "134/134 [==============================] - 0s 124us/sample - loss: 0.2979 - accuracy: 0.9627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [33:41, 999.74s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.45s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.21s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 856.4765625 steps, validate for 197.3125 steps\n",
      "Epoch 1/300\n",
      "857/856 [==============================] - 24s 29ms/step - loss: 0.6743 - accuracy: 0.6254 - val_loss: 0.5484 - val_accuracy: 0.7772\n",
      "Epoch 2/300\n",
      "857/856 [==============================] - 23s 27ms/step - loss: 0.5142 - accuracy: 0.7726 - val_loss: 0.5539 - val_accuracy: 0.7747\n",
      "Epoch 3/300\n",
      "857/856 [==============================] - 23s 27ms/step - loss: 0.4964 - accuracy: 0.7794 - val_loss: 0.5590 - val_accuracy: 0.7705\n",
      "Epoch 4/300\n",
      "857/856 [==============================] - 23s 27ms/step - loss: 0.4843 - accuracy: 0.7838 - val_loss: 0.5584 - val_accuracy: 0.7721\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 856.4765625 steps, validate for 197.3125 steps\n",
      "Epoch 1/300\n",
      "857/856 [==============================] - 55s 64ms/step - loss: 0.4656 - accuracy: 0.7921 - val_loss: 0.5779 - val_accuracy: 0.7475\n",
      "Epoch 2/300\n",
      "857/856 [==============================] - 54s 63ms/step - loss: 0.4389 - accuracy: 0.8068 - val_loss: 0.5854 - val_accuracy: 0.7360\n",
      "Epoch 3/300\n",
      "857/856 [==============================] - 54s 63ms/step - loss: 0.4161 - accuracy: 0.8193 - val_loss: 0.6057 - val_accuracy: 0.7409\n",
      "Epoch 4/300\n",
      "857/856 [==============================] - 55s 64ms/step - loss: 0.3951 - accuracy: 0.8303 - val_loss: 0.5823 - val_accuracy: 0.7439\n",
      "Epoch 00004: early stopping\n",
      "106/106 [==============================] - 0s 2ms/sample - loss: 0.2405 - accuracy: 0.9717\n",
      "107/107 [==============================] - 0s 298us/sample - loss: 0.2464 - accuracy: 0.9813\n",
      "106/106 [==============================] - 0s 320us/sample - loss: 0.2637 - accuracy: 0.9340\n",
      "104/104 [==============================] - 0s 274us/sample - loss: 0.2666 - accuracy: 0.9615\n",
      "103/103 [==============================] - 0s 217us/sample - loss: 0.2773 - accuracy: 0.9806\n",
      "102/102 [==============================] - 0s 240us/sample - loss: 0.2700 - accuracy: 0.9706\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 0.2745 - accuracy: 0.9700\n",
      "99/99 [==============================] - 0s 246us/sample - loss: 0.2883 - accuracy: 0.9293\n",
      "97/97 [==============================] - 0s 274us/sample - loss: 0.2687 - accuracy: 0.9691\n",
      "98/98 [==============================] - 0s 270us/sample - loss: 0.2670 - accuracy: 0.9592\n",
      "98/98 [==============================] - 0s 274us/sample - loss: 0.2476 - accuracy: 0.9694\n",
      "92/92 [==============================] - 0s 232us/sample - loss: 0.2443 - accuracy: 0.9783\n",
      "95/95 [==============================] - 0s 252us/sample - loss: 0.2315 - accuracy: 0.9789\n",
      "94/94 [==============================] - 0s 251us/sample - loss: 0.2452 - accuracy: 0.9787\n",
      "90/90 [==============================] - 0s 317us/sample - loss: 0.2220 - accuracy: 0.9778\n",
      "91/91 [==============================] - 0s 237us/sample - loss: 0.2544 - accuracy: 0.9560\n",
      "87/87 [==============================] - 0s 260us/sample - loss: 0.2418 - accuracy: 0.9885\n",
      "87/87 [==============================] - 0s 308us/sample - loss: 0.2560 - accuracy: 0.9425\n",
      "87/87 [==============================] - 0s 258us/sample - loss: 0.2345 - accuracy: 0.9770\n",
      "77/77 [==============================] - 0s 263us/sample - loss: 0.2564 - accuracy: 0.9610\n",
      "77/77 [==============================] - 0s 269us/sample - loss: 0.2397 - accuracy: 0.9610\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.2447 - accuracy: 0.9600\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.2850 - accuracy: 0.9600\n",
      "75/75 [==============================] - 0s 267us/sample - loss: 0.2484 - accuracy: 0.9733\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.2306 - accuracy: 0.9733\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.2483 - accuracy: 0.9467\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.2473 - accuracy: 0.9733\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.2753 - accuracy: 0.9333\n",
      "74/74 [==============================] - 0s 279us/sample - loss: 0.2189 - accuracy: 0.9730\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.2624 - accuracy: 0.9600\n",
      "74/74 [==============================] - 0s 283us/sample - loss: 0.2868 - accuracy: 0.9595\n",
      "74/74 [==============================] - 0s 297us/sample - loss: 0.2916 - accuracy: 0.9324\n",
      "74/74 [==============================] - 0s 253us/sample - loss: 0.2661 - accuracy: 0.9459\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2904 samples, validate on 678 samples\n",
      "Epoch 1/300\n",
      "2904/2904 [==============================] - 2s 848us/sample - loss: 0.6558 - accuracy: 0.6126 - val_loss: 0.6543 - val_accuracy: 0.6150\n",
      "Epoch 2/300\n",
      "2904/2904 [==============================] - 1s 195us/sample - loss: 0.6341 - accuracy: 0.6577 - val_loss: 0.6392 - val_accuracy: 0.6475\n",
      "Epoch 3/300\n",
      "2904/2904 [==============================] - 1s 198us/sample - loss: 0.6183 - accuracy: 0.6808 - val_loss: 0.6281 - val_accuracy: 0.6622\n",
      "Epoch 4/300\n",
      "2904/2904 [==============================] - 1s 219us/sample - loss: 0.6092 - accuracy: 0.6921 - val_loss: 0.6191 - val_accuracy: 0.6755\n",
      "Epoch 5/300\n",
      "2904/2904 [==============================] - 1s 212us/sample - loss: 0.5993 - accuracy: 0.7145 - val_loss: 0.6116 - val_accuracy: 0.6932\n",
      "Epoch 6/300\n",
      "2904/2904 [==============================] - 1s 229us/sample - loss: 0.5886 - accuracy: 0.7311 - val_loss: 0.6050 - val_accuracy: 0.7065\n",
      "Epoch 7/300\n",
      "2904/2904 [==============================] - 1s 213us/sample - loss: 0.5830 - accuracy: 0.7324 - val_loss: 0.5988 - val_accuracy: 0.7139\n",
      "Epoch 8/300\n",
      "2904/2904 [==============================] - 1s 209us/sample - loss: 0.5749 - accuracy: 0.7390 - val_loss: 0.5935 - val_accuracy: 0.7183\n",
      "Epoch 9/300\n",
      "2904/2904 [==============================] - 1s 229us/sample - loss: 0.5700 - accuracy: 0.7500 - val_loss: 0.5885 - val_accuracy: 0.7242\n",
      "Epoch 10/300\n",
      "2904/2904 [==============================] - 1s 202us/sample - loss: 0.5657 - accuracy: 0.7441 - val_loss: 0.5838 - val_accuracy: 0.7345\n",
      "Epoch 11/300\n",
      "2904/2904 [==============================] - 1s 207us/sample - loss: 0.5556 - accuracy: 0.7565 - val_loss: 0.5794 - val_accuracy: 0.7389\n",
      "Epoch 12/300\n",
      "2904/2904 [==============================] - 1s 217us/sample - loss: 0.5506 - accuracy: 0.7641 - val_loss: 0.5755 - val_accuracy: 0.7419\n",
      "Epoch 13/300\n",
      "2904/2904 [==============================] - 1s 235us/sample - loss: 0.5448 - accuracy: 0.7672 - val_loss: 0.5719 - val_accuracy: 0.7448\n",
      "Epoch 14/300\n",
      "2904/2904 [==============================] - 1s 248us/sample - loss: 0.5426 - accuracy: 0.7648 - val_loss: 0.5684 - val_accuracy: 0.7463\n",
      "Epoch 15/300\n",
      "2904/2904 [==============================] - 1s 206us/sample - loss: 0.5372 - accuracy: 0.7758 - val_loss: 0.5653 - val_accuracy: 0.7493\n",
      "Epoch 16/300\n",
      "2904/2904 [==============================] - 1s 210us/sample - loss: 0.5329 - accuracy: 0.7676 - val_loss: 0.5623 - val_accuracy: 0.7507\n",
      "Epoch 17/300\n",
      "2904/2904 [==============================] - 1s 188us/sample - loss: 0.5300 - accuracy: 0.7744 - val_loss: 0.5595 - val_accuracy: 0.7522\n",
      "Epoch 18/300\n",
      "2904/2904 [==============================] - 1s 217us/sample - loss: 0.5251 - accuracy: 0.7724 - val_loss: 0.5569 - val_accuracy: 0.7522\n",
      "Epoch 19/300\n",
      "2904/2904 [==============================] - 1s 205us/sample - loss: 0.5217 - accuracy: 0.7775 - val_loss: 0.5544 - val_accuracy: 0.7522\n",
      "Epoch 20/300\n",
      "2904/2904 [==============================] - 1s 238us/sample - loss: 0.5161 - accuracy: 0.7851 - val_loss: 0.5522 - val_accuracy: 0.7581\n",
      "Epoch 21/300\n",
      "2904/2904 [==============================] - 1s 213us/sample - loss: 0.5150 - accuracy: 0.7786 - val_loss: 0.5501 - val_accuracy: 0.7611\n",
      "Epoch 22/300\n",
      "2904/2904 [==============================] - 1s 226us/sample - loss: 0.5110 - accuracy: 0.7844 - val_loss: 0.5482 - val_accuracy: 0.7625\n",
      "Epoch 23/300\n",
      "2904/2904 [==============================] - 1s 207us/sample - loss: 0.5086 - accuracy: 0.7803 - val_loss: 0.5463 - val_accuracy: 0.7655\n",
      "Epoch 24/300\n",
      "2904/2904 [==============================] - 1s 214us/sample - loss: 0.5024 - accuracy: 0.7889 - val_loss: 0.5446 - val_accuracy: 0.7714\n",
      "Epoch 25/300\n",
      "2904/2904 [==============================] - 1s 196us/sample - loss: 0.5017 - accuracy: 0.7882 - val_loss: 0.5431 - val_accuracy: 0.7729\n",
      "Epoch 26/300\n",
      "2904/2904 [==============================] - 1s 186us/sample - loss: 0.4966 - accuracy: 0.7930 - val_loss: 0.5417 - val_accuracy: 0.7714\n",
      "Epoch 27/300\n",
      "2904/2904 [==============================] - 1s 232us/sample - loss: 0.4952 - accuracy: 0.7868 - val_loss: 0.5403 - val_accuracy: 0.7714\n",
      "Epoch 28/300\n",
      "2904/2904 [==============================] - 1s 241us/sample - loss: 0.4923 - accuracy: 0.7903 - val_loss: 0.5392 - val_accuracy: 0.7729\n",
      "Epoch 29/300\n",
      "2904/2904 [==============================] - 1s 250us/sample - loss: 0.4892 - accuracy: 0.7851 - val_loss: 0.5381 - val_accuracy: 0.7729\n",
      "Epoch 30/300\n",
      "2904/2904 [==============================] - 1s 206us/sample - loss: 0.4849 - accuracy: 0.7961 - val_loss: 0.5371 - val_accuracy: 0.7743\n",
      "Epoch 31/300\n",
      "2904/2904 [==============================] - 1s 212us/sample - loss: 0.4830 - accuracy: 0.7930 - val_loss: 0.5362 - val_accuracy: 0.7743\n",
      "Epoch 32/300\n",
      "2904/2904 [==============================] - 1s 190us/sample - loss: 0.4818 - accuracy: 0.7927 - val_loss: 0.5354 - val_accuracy: 0.7729\n",
      "Epoch 33/300\n",
      "2904/2904 [==============================] - 1s 199us/sample - loss: 0.4757 - accuracy: 0.7989 - val_loss: 0.5348 - val_accuracy: 0.7729\n",
      "Epoch 34/300\n",
      "2904/2904 [==============================] - 1s 225us/sample - loss: 0.4783 - accuracy: 0.7961 - val_loss: 0.5342 - val_accuracy: 0.7729\n",
      "Epoch 35/300\n",
      "2904/2904 [==============================] - 1s 202us/sample - loss: 0.4729 - accuracy: 0.7958 - val_loss: 0.5337 - val_accuracy: 0.7729\n",
      "Epoch 36/300\n",
      "2904/2904 [==============================] - 1s 234us/sample - loss: 0.4714 - accuracy: 0.7951 - val_loss: 0.5332 - val_accuracy: 0.7729\n",
      "Epoch 37/300\n",
      "2904/2904 [==============================] - 1s 217us/sample - loss: 0.4685 - accuracy: 0.7982 - val_loss: 0.5329 - val_accuracy: 0.7729\n",
      "Epoch 38/300\n",
      "2904/2904 [==============================] - 1s 214us/sample - loss: 0.4651 - accuracy: 0.7989 - val_loss: 0.5326 - val_accuracy: 0.7729\n",
      "Epoch 39/300\n",
      "2904/2904 [==============================] - 1s 216us/sample - loss: 0.4636 - accuracy: 0.8051 - val_loss: 0.5324 - val_accuracy: 0.7729\n",
      "Epoch 40/300\n",
      "2904/2904 [==============================] - 1s 258us/sample - loss: 0.4616 - accuracy: 0.8030 - val_loss: 0.5322 - val_accuracy: 0.7729\n",
      "Epoch 41/300\n",
      "2904/2904 [==============================] - 1s 232us/sample - loss: 0.4571 - accuracy: 0.8037 - val_loss: 0.5321 - val_accuracy: 0.7729\n",
      "Epoch 42/300\n",
      "2904/2904 [==============================] - 1s 188us/sample - loss: 0.4560 - accuracy: 0.8051 - val_loss: 0.5321 - val_accuracy: 0.7714\n",
      "Epoch 43/300\n",
      "2904/2904 [==============================] - 1s 208us/sample - loss: 0.4559 - accuracy: 0.8075 - val_loss: 0.5321 - val_accuracy: 0.7729\n",
      "Epoch 44/300\n",
      "2904/2904 [==============================] - 1s 231us/sample - loss: 0.4534 - accuracy: 0.8065 - val_loss: 0.5321 - val_accuracy: 0.7729\n",
      "Epoch 45/300\n",
      "2904/2904 [==============================] - 1s 189us/sample - loss: 0.4487 - accuracy: 0.8065 - val_loss: 0.5322 - val_accuracy: 0.7714\n",
      "Epoch 00045: early stopping\n",
      "67/67 [==============================] - 0s 196us/sample - loss: 0.2319 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [50:09, 996.25s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.41s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.21s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 835.0390625 steps, validate for 193.9375 steps\n",
      "Epoch 1/300\n",
      "836/835 [==============================] - 24s 29ms/step - loss: 0.5740 - accuracy: 0.7172 - val_loss: 0.5478 - val_accuracy: 0.7772\n",
      "Epoch 2/300\n",
      "836/835 [==============================] - 23s 27ms/step - loss: 0.5161 - accuracy: 0.7670 - val_loss: 0.5506 - val_accuracy: 0.7732\n",
      "Epoch 3/300\n",
      "836/835 [==============================] - 22s 27ms/step - loss: 0.5011 - accuracy: 0.7729 - val_loss: 0.5526 - val_accuracy: 0.7709\n",
      "Epoch 4/300\n",
      "836/835 [==============================] - 23s 27ms/step - loss: 0.4898 - accuracy: 0.7779 - val_loss: 0.5604 - val_accuracy: 0.7672\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 835.0390625 steps, validate for 193.9375 steps\n",
      "Epoch 1/300\n",
      "836/835 [==============================] - 55s 65ms/step - loss: 0.4719 - accuracy: 0.7862 - val_loss: 0.5923 - val_accuracy: 0.7282\n",
      "Epoch 2/300\n",
      "836/835 [==============================] - 52s 63ms/step - loss: 0.4448 - accuracy: 0.8009 - val_loss: 0.5762 - val_accuracy: 0.7682\n",
      "Epoch 3/300\n",
      "836/835 [==============================] - 53s 63ms/step - loss: 0.4213 - accuracy: 0.8142 - val_loss: 0.5935 - val_accuracy: 0.7450\n",
      "Epoch 4/300\n",
      "836/835 [==============================] - 52s 63ms/step - loss: 0.4003 - accuracy: 0.8274 - val_loss: 0.5998 - val_accuracy: 0.7224\n",
      "Epoch 5/300\n",
      "836/835 [==============================] - 53s 63ms/step - loss: 0.3812 - accuracy: 0.8377 - val_loss: 0.6023 - val_accuracy: 0.7680\n",
      "Epoch 00005: early stopping\n",
      "207/207 [==============================] - 0s 1ms/sample - loss: 0.1672 - accuracy: 0.9903\n",
      "204/204 [==============================] - 0s 238us/sample - loss: 0.1790 - accuracy: 0.9853\n",
      "205/205 [==============================] - 0s 212us/sample - loss: 0.1740 - accuracy: 0.9854\n",
      "202/202 [==============================] - 0s 230us/sample - loss: 0.1907 - accuracy: 0.9752\n",
      "201/201 [==============================] - 0s 238us/sample - loss: 0.1964 - accuracy: 0.9701\n",
      "200/200 [==============================] - 0s 211us/sample - loss: 0.1800 - accuracy: 0.9800\n",
      "196/196 [==============================] - 0s 306us/sample - loss: 0.1789 - accuracy: 0.9745\n",
      "195/195 [==============================] - 0s 248us/sample - loss: 0.1540 - accuracy: 0.9949\n",
      "193/193 [==============================] - 0s 263us/sample - loss: 0.1808 - accuracy: 0.9845\n",
      "189/189 [==============================] - 0s 250us/sample - loss: 0.1751 - accuracy: 0.9788\n",
      "186/186 [==============================] - 0s 210us/sample - loss: 0.1833 - accuracy: 0.9892\n",
      "187/187 [==============================] - 0s 270us/sample - loss: 0.1840 - accuracy: 0.9893\n",
      "185/185 [==============================] - 0s 254us/sample - loss: 0.2093 - accuracy: 0.9676\n",
      "184/184 [==============================] - 0s 231us/sample - loss: 0.1985 - accuracy: 0.9674\n",
      "182/182 [==============================] - 0s 260us/sample - loss: 0.1858 - accuracy: 0.9615\n",
      "183/183 [==============================] - 0s 245us/sample - loss: 0.1929 - accuracy: 0.9727\n",
      "182/182 [==============================] - 0s 238us/sample - loss: 0.2030 - accuracy: 0.9670\n",
      "181/181 [==============================] - 0s 244us/sample - loss: 0.2064 - accuracy: 0.9669\n",
      "182/182 [==============================] - 0s 266us/sample - loss: 0.2101 - accuracy: 0.9780\n",
      "180/180 [==============================] - 0s 251us/sample - loss: 0.2193 - accuracy: 0.9667\n",
      "179/179 [==============================] - 0s 251us/sample - loss: 0.1994 - accuracy: 0.9721\n",
      "176/176 [==============================] - 0s 249us/sample - loss: 0.2258 - accuracy: 0.9659\n",
      "174/174 [==============================] - 0s 242us/sample - loss: 0.2133 - accuracy: 0.9655\n",
      "174/174 [==============================] - 0s 253us/sample - loss: 0.1881 - accuracy: 0.9713\n",
      "174/174 [==============================] - 0s 234us/sample - loss: 0.1894 - accuracy: 0.9655\n",
      "172/172 [==============================] - 0s 252us/sample - loss: 0.2066 - accuracy: 0.9419\n",
      "174/174 [==============================] - 0s 280us/sample - loss: 0.1858 - accuracy: 0.9713\n",
      "172/172 [==============================] - 0s 271us/sample - loss: 0.1809 - accuracy: 0.9826\n",
      "171/171 [==============================] - 0s 264us/sample - loss: 0.2079 - accuracy: 0.9649\n",
      "171/171 [==============================] - 0s 254us/sample - loss: 0.2079 - accuracy: 0.9591\n",
      "170/170 [==============================] - 0s 295us/sample - loss: 0.2173 - accuracy: 0.9647\n",
      "169/169 [==============================] - 0s 234us/sample - loss: 0.2362 - accuracy: 0.9349\n",
      "169/169 [==============================] - 0s 253us/sample - loss: 0.2345 - accuracy: 0.9467\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2825 samples, validate on 662 samples\n",
      "Epoch 1/300\n",
      "2825/2825 [==============================] - 2s 883us/sample - loss: 0.6578 - accuracy: 0.6191 - val_loss: 0.6319 - val_accuracy: 0.6828\n",
      "Epoch 2/300\n",
      "2825/2825 [==============================] - 1s 240us/sample - loss: 0.6192 - accuracy: 0.6981 - val_loss: 0.6140 - val_accuracy: 0.7190\n",
      "Epoch 3/300\n",
      "2825/2825 [==============================] - 1s 245us/sample - loss: 0.6013 - accuracy: 0.7186 - val_loss: 0.6016 - val_accuracy: 0.7266\n",
      "Epoch 4/300\n",
      "2825/2825 [==============================] - 1s 257us/sample - loss: 0.5865 - accuracy: 0.7416 - val_loss: 0.5923 - val_accuracy: 0.7341\n",
      "Epoch 5/300\n",
      "2825/2825 [==============================] - 1s 226us/sample - loss: 0.5781 - accuracy: 0.7416 - val_loss: 0.5845 - val_accuracy: 0.7447\n",
      "Epoch 6/300\n",
      "2825/2825 [==============================] - 1s 229us/sample - loss: 0.5642 - accuracy: 0.7575 - val_loss: 0.5781 - val_accuracy: 0.7508\n",
      "Epoch 7/300\n",
      "2825/2825 [==============================] - 1s 242us/sample - loss: 0.5532 - accuracy: 0.7621 - val_loss: 0.5727 - val_accuracy: 0.7523\n",
      "Epoch 8/300\n",
      "2825/2825 [==============================] - 1s 246us/sample - loss: 0.5467 - accuracy: 0.7706 - val_loss: 0.5679 - val_accuracy: 0.7538\n",
      "Epoch 9/300\n",
      "2825/2825 [==============================] - 1s 221us/sample - loss: 0.5381 - accuracy: 0.7724 - val_loss: 0.5638 - val_accuracy: 0.7538\n",
      "Epoch 10/300\n",
      "2825/2825 [==============================] - 1s 243us/sample - loss: 0.5321 - accuracy: 0.7763 - val_loss: 0.5602 - val_accuracy: 0.7553\n",
      "Epoch 11/300\n",
      "2825/2825 [==============================] - 1s 248us/sample - loss: 0.5269 - accuracy: 0.7812 - val_loss: 0.5569 - val_accuracy: 0.7568\n",
      "Epoch 12/300\n",
      "2825/2825 [==============================] - 1s 243us/sample - loss: 0.5232 - accuracy: 0.7798 - val_loss: 0.5540 - val_accuracy: 0.7583\n",
      "Epoch 13/300\n",
      "2825/2825 [==============================] - 1s 230us/sample - loss: 0.5167 - accuracy: 0.7816 - val_loss: 0.5515 - val_accuracy: 0.7553\n",
      "Epoch 14/300\n",
      "2825/2825 [==============================] - 1s 227us/sample - loss: 0.5118 - accuracy: 0.7869 - val_loss: 0.5490 - val_accuracy: 0.7553\n",
      "Epoch 15/300\n",
      "2825/2825 [==============================] - 1s 206us/sample - loss: 0.5088 - accuracy: 0.7802 - val_loss: 0.5469 - val_accuracy: 0.7598\n",
      "Epoch 16/300\n",
      "2825/2825 [==============================] - 1s 235us/sample - loss: 0.5039 - accuracy: 0.7936 - val_loss: 0.5450 - val_accuracy: 0.7613\n",
      "Epoch 17/300\n",
      "2825/2825 [==============================] - 1s 224us/sample - loss: 0.4972 - accuracy: 0.7869 - val_loss: 0.5434 - val_accuracy: 0.7613\n",
      "Epoch 18/300\n",
      "2825/2825 [==============================] - 1s 213us/sample - loss: 0.4939 - accuracy: 0.7950 - val_loss: 0.5420 - val_accuracy: 0.7628\n",
      "Epoch 19/300\n",
      "2825/2825 [==============================] - 1s 207us/sample - loss: 0.4896 - accuracy: 0.7929 - val_loss: 0.5407 - val_accuracy: 0.7644\n",
      "Epoch 20/300\n",
      "2825/2825 [==============================] - 1s 226us/sample - loss: 0.4862 - accuracy: 0.7936 - val_loss: 0.5396 - val_accuracy: 0.7628\n",
      "Epoch 21/300\n",
      "2825/2825 [==============================] - 1s 236us/sample - loss: 0.4847 - accuracy: 0.7915 - val_loss: 0.5385 - val_accuracy: 0.7613\n",
      "Epoch 22/300\n",
      "2825/2825 [==============================] - 1s 211us/sample - loss: 0.4779 - accuracy: 0.7986 - val_loss: 0.5376 - val_accuracy: 0.7613\n",
      "Epoch 23/300\n",
      "2825/2825 [==============================] - 1s 238us/sample - loss: 0.4743 - accuracy: 0.8021 - val_loss: 0.5370 - val_accuracy: 0.7644\n",
      "Epoch 24/300\n",
      "2825/2825 [==============================] - 1s 242us/sample - loss: 0.4723 - accuracy: 0.7993 - val_loss: 0.5364 - val_accuracy: 0.7659\n",
      "Epoch 25/300\n",
      "2825/2825 [==============================] - 1s 242us/sample - loss: 0.4706 - accuracy: 0.8014 - val_loss: 0.5358 - val_accuracy: 0.7659\n",
      "Epoch 26/300\n",
      "2825/2825 [==============================] - 1s 235us/sample - loss: 0.4678 - accuracy: 0.8032 - val_loss: 0.5354 - val_accuracy: 0.7674\n",
      "Epoch 27/300\n",
      "2825/2825 [==============================] - 1s 260us/sample - loss: 0.4649 - accuracy: 0.8011 - val_loss: 0.5351 - val_accuracy: 0.7674\n",
      "Epoch 28/300\n",
      "2825/2825 [==============================] - 1s 236us/sample - loss: 0.4585 - accuracy: 0.8096 - val_loss: 0.5348 - val_accuracy: 0.7659\n",
      "Epoch 29/300\n",
      "2825/2825 [==============================] - 1s 224us/sample - loss: 0.4586 - accuracy: 0.8078 - val_loss: 0.5347 - val_accuracy: 0.7659\n",
      "Epoch 30/300\n",
      "2825/2825 [==============================] - 1s 230us/sample - loss: 0.4539 - accuracy: 0.8088 - val_loss: 0.5346 - val_accuracy: 0.7659\n",
      "Epoch 31/300\n",
      "2825/2825 [==============================] - 1s 234us/sample - loss: 0.4485 - accuracy: 0.8103 - val_loss: 0.5346 - val_accuracy: 0.7644\n",
      "Epoch 32/300\n",
      "2825/2825 [==============================] - 1s 252us/sample - loss: 0.4508 - accuracy: 0.8135 - val_loss: 0.5347 - val_accuracy: 0.7659\n",
      "Epoch 33/300\n",
      "2825/2825 [==============================] - 1s 254us/sample - loss: 0.4480 - accuracy: 0.8096 - val_loss: 0.5348 - val_accuracy: 0.7659\n",
      "Epoch 34/300\n",
      "2825/2825 [==============================] - 1s 255us/sample - loss: 0.4463 - accuracy: 0.8127 - val_loss: 0.5350 - val_accuracy: 0.7674\n",
      "Epoch 00034: early stopping\n",
      "162/162 [==============================] - 0s 164us/sample - loss: 0.3350 - accuracy: 0.9506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [1:07:16, 1005.44s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.60s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.37s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 842.7578125 steps, validate for 202.484375 steps\n",
      "Epoch 1/300\n",
      "843/842 [==============================] - 24s 29ms/step - loss: 0.6403 - accuracy: 0.6525 - val_loss: 0.5363 - val_accuracy: 0.7857\n",
      "Epoch 2/300\n",
      "843/842 [==============================] - 23s 27ms/step - loss: 0.5140 - accuracy: 0.7696 - val_loss: 0.5417 - val_accuracy: 0.7829\n",
      "Epoch 3/300\n",
      "843/842 [==============================] - 23s 28ms/step - loss: 0.4975 - accuracy: 0.7767 - val_loss: 0.5441 - val_accuracy: 0.7795\n",
      "Epoch 4/300\n",
      "843/842 [==============================] - 24s 28ms/step - loss: 0.4860 - accuracy: 0.7814 - val_loss: 0.5463 - val_accuracy: 0.7778\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 842.7578125 steps, validate for 202.484375 steps\n",
      "Epoch 1/300\n",
      "843/842 [==============================] - 55s 65ms/step - loss: 0.4678 - accuracy: 0.7901 - val_loss: 0.5515 - val_accuracy: 0.7764\n",
      "Epoch 2/300\n",
      "843/842 [==============================] - 54s 64ms/step - loss: 0.4414 - accuracy: 0.8032 - val_loss: 0.5535 - val_accuracy: 0.7860\n",
      "Epoch 3/300\n",
      "843/842 [==============================] - 54s 64ms/step - loss: 0.4197 - accuracy: 0.8140 - val_loss: 0.5595 - val_accuracy: 0.7705\n",
      "Epoch 4/300\n",
      "843/842 [==============================] - 53s 63ms/step - loss: 0.3994 - accuracy: 0.8265 - val_loss: 0.5827 - val_accuracy: 0.7503\n",
      "Epoch 00004: early stopping\n",
      "139/139 [==============================] - 0s 2ms/sample - loss: 0.3943 - accuracy: 0.8633\n",
      "135/135 [==============================] - 0s 252us/sample - loss: 0.3296 - accuracy: 0.9185\n",
      "131/131 [==============================] - 0s 228us/sample - loss: 0.3568 - accuracy: 0.8626\n",
      "130/130 [==============================] - 0s 266us/sample - loss: 0.3247 - accuracy: 0.9308\n",
      "129/129 [==============================] - 0s 251us/sample - loss: 0.3342 - accuracy: 0.8915\n",
      "130/130 [==============================] - 0s 247us/sample - loss: 0.3053 - accuracy: 0.9385\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.3598 - accuracy: 0.8984\n",
      "128/128 [==============================] - 0s 194us/sample - loss: 0.3277 - accuracy: 0.9219\n",
      "126/126 [==============================] - 0s 258us/sample - loss: 0.3182 - accuracy: 0.9127\n",
      "128/128 [==============================] - 0s 217us/sample - loss: 0.3177 - accuracy: 0.9141\n",
      "127/127 [==============================] - 0s 208us/sample - loss: 0.2979 - accuracy: 0.9134\n",
      "126/126 [==============================] - 0s 225us/sample - loss: 0.3040 - accuracy: 0.9365\n",
      "125/125 [==============================] - 0s 257us/sample - loss: 0.2856 - accuracy: 0.9440\n",
      "126/126 [==============================] - 0s 240us/sample - loss: 0.2862 - accuracy: 0.9365\n",
      "124/124 [==============================] - 0s 229us/sample - loss: 0.2911 - accuracy: 0.9355\n",
      "123/123 [==============================] - 0s 247us/sample - loss: 0.2850 - accuracy: 0.9268\n",
      "121/121 [==============================] - 0s 248us/sample - loss: 0.2892 - accuracy: 0.9256\n",
      "119/119 [==============================] - 0s 239us/sample - loss: 0.2789 - accuracy: 0.9328\n",
      "121/121 [==============================] - 0s 237us/sample - loss: 0.2698 - accuracy: 0.9421\n",
      "118/118 [==============================] - 0s 229us/sample - loss: 0.2752 - accuracy: 0.9661\n",
      "117/117 [==============================] - 0s 237us/sample - loss: 0.2771 - accuracy: 0.9487\n",
      "117/117 [==============================] - 0s 257us/sample - loss: 0.2563 - accuracy: 0.9487\n",
      "114/114 [==============================] - 0s 292us/sample - loss: 0.2603 - accuracy: 0.9386\n",
      "113/113 [==============================] - 0s 249us/sample - loss: 0.2375 - accuracy: 0.9646\n",
      "113/113 [==============================] - 0s 275us/sample - loss: 0.2806 - accuracy: 0.9204\n",
      "112/112 [==============================] - 0s 253us/sample - loss: 0.2905 - accuracy: 0.9196\n",
      "112/112 [==============================] - 0s 261us/sample - loss: 0.2507 - accuracy: 0.9464\n",
      "110/110 [==============================] - 0s 276us/sample - loss: 0.2485 - accuracy: 0.9455\n",
      "110/110 [==============================] - 0s 290us/sample - loss: 0.2563 - accuracy: 0.9273\n",
      "109/109 [==============================] - 0s 280us/sample - loss: 0.2877 - accuracy: 0.9174\n",
      "110/110 [==============================] - 0s 283us/sample - loss: 0.2811 - accuracy: 0.9182\n",
      "109/109 [==============================] - 0s 278us/sample - loss: 0.2641 - accuracy: 0.9633\n",
      "107/107 [==============================] - 0s 274us/sample - loss: 0.2617 - accuracy: 0.9626\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2853 samples, validate on 693 samples\n",
      "Epoch 1/300\n",
      "2853/2853 [==============================] - 3s 954us/sample - loss: 0.6794 - accuracy: 0.5706 - val_loss: 0.6349 - val_accuracy: 0.6378\n",
      "Epoch 2/300\n",
      "2853/2853 [==============================] - 1s 244us/sample - loss: 0.6520 - accuracy: 0.6260 - val_loss: 0.6155 - val_accuracy: 0.6739\n",
      "Epoch 3/300\n",
      "2853/2853 [==============================] - 1s 236us/sample - loss: 0.6286 - accuracy: 0.6555 - val_loss: 0.6028 - val_accuracy: 0.7027\n",
      "Epoch 4/300\n",
      "2853/2853 [==============================] - 1s 216us/sample - loss: 0.6204 - accuracy: 0.6681 - val_loss: 0.5925 - val_accuracy: 0.7172\n",
      "Epoch 5/300\n",
      "2853/2853 [==============================] - 1s 235us/sample - loss: 0.6053 - accuracy: 0.6919 - val_loss: 0.5840 - val_accuracy: 0.7388\n",
      "Epoch 6/300\n",
      "2853/2853 [==============================] - 1s 233us/sample - loss: 0.5991 - accuracy: 0.6989 - val_loss: 0.5771 - val_accuracy: 0.7417\n",
      "Epoch 7/300\n",
      "2853/2853 [==============================] - 1s 224us/sample - loss: 0.5903 - accuracy: 0.7126 - val_loss: 0.5710 - val_accuracy: 0.7475\n",
      "Epoch 8/300\n",
      "2853/2853 [==============================] - 1s 232us/sample - loss: 0.5865 - accuracy: 0.7242 - val_loss: 0.5659 - val_accuracy: 0.7532\n",
      "Epoch 9/300\n",
      "2853/2853 [==============================] - 1s 228us/sample - loss: 0.5811 - accuracy: 0.7249 - val_loss: 0.5610 - val_accuracy: 0.7532\n",
      "Epoch 10/300\n",
      "2853/2853 [==============================] - 1s 201us/sample - loss: 0.5754 - accuracy: 0.7301 - val_loss: 0.5567 - val_accuracy: 0.7590\n",
      "Epoch 11/300\n",
      "2853/2853 [==============================] - 1s 215us/sample - loss: 0.5682 - accuracy: 0.7350 - val_loss: 0.5530 - val_accuracy: 0.7619\n",
      "Epoch 12/300\n",
      "2853/2853 [==============================] - 1s 184us/sample - loss: 0.5630 - accuracy: 0.7371 - val_loss: 0.5495 - val_accuracy: 0.7605\n",
      "Epoch 13/300\n",
      "2853/2853 [==============================] - 1s 252us/sample - loss: 0.5595 - accuracy: 0.7448 - val_loss: 0.5462 - val_accuracy: 0.7619\n",
      "Epoch 14/300\n",
      "2853/2853 [==============================] - 1s 251us/sample - loss: 0.5508 - accuracy: 0.7539 - val_loss: 0.5434 - val_accuracy: 0.7633\n",
      "Epoch 15/300\n",
      "2853/2853 [==============================] - 1s 218us/sample - loss: 0.5508 - accuracy: 0.7494 - val_loss: 0.5409 - val_accuracy: 0.7633\n",
      "Epoch 16/300\n",
      "2853/2853 [==============================] - 1s 250us/sample - loss: 0.5450 - accuracy: 0.7560 - val_loss: 0.5385 - val_accuracy: 0.7648\n",
      "Epoch 17/300\n",
      "2853/2853 [==============================] - 1s 246us/sample - loss: 0.5436 - accuracy: 0.7494 - val_loss: 0.5364 - val_accuracy: 0.7677\n",
      "Epoch 18/300\n",
      "2853/2853 [==============================] - 1s 239us/sample - loss: 0.5373 - accuracy: 0.7539 - val_loss: 0.5343 - val_accuracy: 0.7720\n",
      "Epoch 19/300\n",
      "2853/2853 [==============================] - 1s 226us/sample - loss: 0.5378 - accuracy: 0.7546 - val_loss: 0.5324 - val_accuracy: 0.7749\n",
      "Epoch 20/300\n",
      "2853/2853 [==============================] - 1s 232us/sample - loss: 0.5362 - accuracy: 0.7589 - val_loss: 0.5306 - val_accuracy: 0.7778\n",
      "Epoch 21/300\n",
      "2853/2853 [==============================] - 1s 247us/sample - loss: 0.5307 - accuracy: 0.7655 - val_loss: 0.5290 - val_accuracy: 0.7807\n",
      "Epoch 22/300\n",
      "2853/2853 [==============================] - 1s 250us/sample - loss: 0.5240 - accuracy: 0.7669 - val_loss: 0.5275 - val_accuracy: 0.7821\n",
      "Epoch 23/300\n",
      "2853/2853 [==============================] - 1s 227us/sample - loss: 0.5245 - accuracy: 0.7680 - val_loss: 0.5261 - val_accuracy: 0.7835\n",
      "Epoch 24/300\n",
      "2853/2853 [==============================] - 1s 216us/sample - loss: 0.5201 - accuracy: 0.7638 - val_loss: 0.5249 - val_accuracy: 0.7835\n",
      "Epoch 25/300\n",
      "2853/2853 [==============================] - 1s 193us/sample - loss: 0.5214 - accuracy: 0.7634 - val_loss: 0.5238 - val_accuracy: 0.7821\n",
      "Epoch 26/300\n",
      "2853/2853 [==============================] - 1s 215us/sample - loss: 0.5156 - accuracy: 0.7701 - val_loss: 0.5228 - val_accuracy: 0.7821\n",
      "Epoch 27/300\n",
      "2853/2853 [==============================] - 1s 209us/sample - loss: 0.5147 - accuracy: 0.7683 - val_loss: 0.5218 - val_accuracy: 0.7821\n",
      "Epoch 28/300\n",
      "2853/2853 [==============================] - 1s 192us/sample - loss: 0.5068 - accuracy: 0.7746 - val_loss: 0.5210 - val_accuracy: 0.7835\n",
      "Epoch 29/300\n",
      "2853/2853 [==============================] - 1s 223us/sample - loss: 0.5057 - accuracy: 0.7760 - val_loss: 0.5201 - val_accuracy: 0.7807\n",
      "Epoch 30/300\n",
      "2853/2853 [==============================] - 1s 220us/sample - loss: 0.5051 - accuracy: 0.7778 - val_loss: 0.5194 - val_accuracy: 0.7821\n",
      "Epoch 31/300\n",
      "2853/2853 [==============================] - 1s 248us/sample - loss: 0.5039 - accuracy: 0.7771 - val_loss: 0.5188 - val_accuracy: 0.7821\n",
      "Epoch 32/300\n",
      "2853/2853 [==============================] - 1s 240us/sample - loss: 0.5022 - accuracy: 0.7764 - val_loss: 0.5182 - val_accuracy: 0.7821\n",
      "Epoch 33/300\n",
      "2853/2853 [==============================] - 1s 229us/sample - loss: 0.4977 - accuracy: 0.7764 - val_loss: 0.5176 - val_accuracy: 0.7807\n",
      "Epoch 34/300\n",
      "2853/2853 [==============================] - 1s 214us/sample - loss: 0.4950 - accuracy: 0.7781 - val_loss: 0.5172 - val_accuracy: 0.7821\n",
      "Epoch 35/300\n",
      "2853/2853 [==============================] - 1s 222us/sample - loss: 0.4951 - accuracy: 0.7795 - val_loss: 0.5167 - val_accuracy: 0.7821\n",
      "Epoch 36/300\n",
      "2853/2853 [==============================] - 1s 227us/sample - loss: 0.4875 - accuracy: 0.7855 - val_loss: 0.5163 - val_accuracy: 0.7821\n",
      "Epoch 37/300\n",
      "2853/2853 [==============================] - 1s 224us/sample - loss: 0.4886 - accuracy: 0.7802 - val_loss: 0.5160 - val_accuracy: 0.7821\n",
      "Epoch 38/300\n",
      "2853/2853 [==============================] - 1s 220us/sample - loss: 0.4878 - accuracy: 0.7823 - val_loss: 0.5156 - val_accuracy: 0.7807\n",
      "Epoch 39/300\n",
      "2853/2853 [==============================] - 1s 205us/sample - loss: 0.4853 - accuracy: 0.7844 - val_loss: 0.5154 - val_accuracy: 0.7807\n",
      "Epoch 40/300\n",
      "2853/2853 [==============================] - 1s 227us/sample - loss: 0.4822 - accuracy: 0.7820 - val_loss: 0.5152 - val_accuracy: 0.7821\n",
      "Epoch 41/300\n",
      "2853/2853 [==============================] - 1s 201us/sample - loss: 0.4789 - accuracy: 0.7844 - val_loss: 0.5150 - val_accuracy: 0.7821\n",
      "Epoch 42/300\n",
      "2853/2853 [==============================] - 1s 240us/sample - loss: 0.4773 - accuracy: 0.7911 - val_loss: 0.5149 - val_accuracy: 0.7821\n",
      "Epoch 43/300\n",
      "2853/2853 [==============================] - 1s 231us/sample - loss: 0.4764 - accuracy: 0.7876 - val_loss: 0.5148 - val_accuracy: 0.7821\n",
      "Epoch 44/300\n",
      "2853/2853 [==============================] - 1s 225us/sample - loss: 0.4747 - accuracy: 0.7872 - val_loss: 0.5148 - val_accuracy: 0.7821\n",
      "Epoch 45/300\n",
      "2853/2853 [==============================] - 1s 219us/sample - loss: 0.4696 - accuracy: 0.7925 - val_loss: 0.5148 - val_accuracy: 0.7821\n",
      "Epoch 46/300\n",
      "2853/2853 [==============================] - 1s 232us/sample - loss: 0.4707 - accuracy: 0.7925 - val_loss: 0.5148 - val_accuracy: 0.7807\n",
      "Epoch 47/300\n",
      "2853/2853 [==============================] - 1s 233us/sample - loss: 0.4661 - accuracy: 0.7964 - val_loss: 0.5148 - val_accuracy: 0.7807\n",
      "Epoch 48/300\n",
      "2853/2853 [==============================] - 1s 204us/sample - loss: 0.4649 - accuracy: 0.7985 - val_loss: 0.5148 - val_accuracy: 0.7792\n",
      "Epoch 00048: early stopping\n",
      "103/103 [==============================] - 0s 198us/sample - loss: 0.2830 - accuracy: 0.9515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [1:23:32, 996.49s/it] \n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:04<00:04,  4.19s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.67s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 855.84375 steps, validate for 197.2109375 steps\n",
      "Epoch 1/300\n",
      "856/855 [==============================] - 25s 29ms/step - loss: 0.5650 - accuracy: 0.7316 - val_loss: 0.5451 - val_accuracy: 0.7792\n",
      "Epoch 2/300\n",
      "856/855 [==============================] - 23s 27ms/step - loss: 0.5079 - accuracy: 0.7732 - val_loss: 0.5498 - val_accuracy: 0.7765\n",
      "Epoch 3/300\n",
      "856/855 [==============================] - 23s 27ms/step - loss: 0.4929 - accuracy: 0.7795 - val_loss: 0.5543 - val_accuracy: 0.7743\n",
      "Epoch 4/300\n",
      "856/855 [==============================] - 24s 28ms/step - loss: 0.4817 - accuracy: 0.7843 - val_loss: 0.5591 - val_accuracy: 0.7702\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 855.84375 steps, validate for 197.2109375 steps\n",
      "Epoch 1/300\n",
      "856/855 [==============================] - 55s 65ms/step - loss: 0.4638 - accuracy: 0.7931 - val_loss: 0.5670 - val_accuracy: 0.7753\n",
      "Epoch 2/300\n",
      "856/855 [==============================] - 54s 63ms/step - loss: 0.4376 - accuracy: 0.8056 - val_loss: 0.5717 - val_accuracy: 0.7780\n",
      "Epoch 3/300\n",
      "856/855 [==============================] - 54s 63ms/step - loss: 0.4160 - accuracy: 0.8171 - val_loss: 0.5655 - val_accuracy: 0.7675\n",
      "Epoch 4/300\n",
      "856/855 [==============================] - 54s 63ms/step - loss: 0.3956 - accuracy: 0.8291 - val_loss: 0.5560 - val_accuracy: 0.7660\n",
      "Epoch 5/300\n",
      "856/855 [==============================] - 55s 64ms/step - loss: 0.3758 - accuracy: 0.8396 - val_loss: 0.6080 - val_accuracy: 0.7164\n",
      "Epoch 6/300\n",
      "856/855 [==============================] - 55s 64ms/step - loss: 0.3576 - accuracy: 0.8503 - val_loss: 0.6063 - val_accuracy: 0.7476\n",
      "Epoch 7/300\n",
      "856/855 [==============================] - 54s 64ms/step - loss: 0.3408 - accuracy: 0.8587 - val_loss: 0.6188 - val_accuracy: 0.7130\n",
      "Epoch 00007: early stopping\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.4650 - accuracy: 0.7768\n",
      "103/103 [==============================] - 0s 259us/sample - loss: 0.5009 - accuracy: 0.7476\n",
      "98/98 [==============================] - 0s 254us/sample - loss: 0.4735 - accuracy: 0.8673\n",
      "97/97 [==============================] - 0s 257us/sample - loss: 0.4409 - accuracy: 0.8454\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.4948 - accuracy: 0.7396\n",
      "96/96 [==============================] - 0s 241us/sample - loss: 0.5348 - accuracy: 0.7604\n",
      "96/96 [==============================] - 0s 232us/sample - loss: 0.5380 - accuracy: 0.7500\n",
      "92/92 [==============================] - 0s 251us/sample - loss: 0.5181 - accuracy: 0.7609\n",
      "91/91 [==============================] - 0s 338us/sample - loss: 0.4769 - accuracy: 0.8022\n",
      "92/92 [==============================] - 0s 248us/sample - loss: 0.5480 - accuracy: 0.7717\n",
      "91/91 [==============================] - 0s 226us/sample - loss: 0.5066 - accuracy: 0.7802\n",
      "90/90 [==============================] - 0s 257us/sample - loss: 0.5846 - accuracy: 0.7222\n",
      "90/90 [==============================] - 0s 237us/sample - loss: 0.6418 - accuracy: 0.6556\n",
      "89/89 [==============================] - 0s 315us/sample - loss: 0.5243 - accuracy: 0.7191\n",
      "89/89 [==============================] - 0s 269us/sample - loss: 0.6196 - accuracy: 0.7079\n",
      "88/88 [==============================] - 0s 274us/sample - loss: 0.5259 - accuracy: 0.7614\n",
      "88/88 [==============================] - 0s 256us/sample - loss: 0.5270 - accuracy: 0.7955\n",
      "88/88 [==============================] - 0s 259us/sample - loss: 0.5679 - accuracy: 0.6932\n",
      "89/89 [==============================] - 0s 274us/sample - loss: 0.5664 - accuracy: 0.7079\n",
      "87/87 [==============================] - 0s 255us/sample - loss: 0.4545 - accuracy: 0.7931\n",
      "88/88 [==============================] - 0s 248us/sample - loss: 0.4943 - accuracy: 0.8068\n",
      "88/88 [==============================] - 0s 321us/sample - loss: 0.6116 - accuracy: 0.6705\n",
      "86/86 [==============================] - 0s 271us/sample - loss: 0.5854 - accuracy: 0.7093\n",
      "86/86 [==============================] - 0s 284us/sample - loss: 0.4816 - accuracy: 0.7326\n",
      "87/87 [==============================] - 0s 264us/sample - loss: 0.4725 - accuracy: 0.7701\n",
      "87/87 [==============================] - 0s 280us/sample - loss: 0.4829 - accuracy: 0.7356\n",
      "86/86 [==============================] - 0s 256us/sample - loss: 0.5711 - accuracy: 0.6744\n",
      "87/87 [==============================] - 0s 259us/sample - loss: 0.5356 - accuracy: 0.7471\n",
      "85/85 [==============================] - 0s 247us/sample - loss: 0.5077 - accuracy: 0.8000\n",
      "87/87 [==============================] - 0s 251us/sample - loss: 0.5073 - accuracy: 0.7816\n",
      "86/86 [==============================] - 0s 312us/sample - loss: 0.5072 - accuracy: 0.8023\n",
      "86/86 [==============================] - 0s 266us/sample - loss: 0.5169 - accuracy: 0.7558\n",
      "86/86 [==============================] - 0s 253us/sample - loss: 0.6096 - accuracy: 0.7093\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2892 samples, validate on 675 samples\n",
      "Epoch 1/300\n",
      "2892/2892 [==============================] - 2s 832us/sample - loss: 0.6876 - accuracy: 0.5671 - val_loss: 0.6623 - val_accuracy: 0.6089\n",
      "Epoch 2/300\n",
      "2892/2892 [==============================] - 1s 216us/sample - loss: 0.6650 - accuracy: 0.6100 - val_loss: 0.6469 - val_accuracy: 0.6341\n",
      "Epoch 3/300\n",
      "2892/2892 [==============================] - 1s 193us/sample - loss: 0.6526 - accuracy: 0.6259 - val_loss: 0.6355 - val_accuracy: 0.6519\n",
      "Epoch 4/300\n",
      "2892/2892 [==============================] - 1s 215us/sample - loss: 0.6363 - accuracy: 0.6549 - val_loss: 0.6265 - val_accuracy: 0.6785\n",
      "Epoch 5/300\n",
      "2892/2892 [==============================] - 1s 219us/sample - loss: 0.6234 - accuracy: 0.6736 - val_loss: 0.6191 - val_accuracy: 0.6963\n",
      "Epoch 6/300\n",
      "2892/2892 [==============================] - 1s 237us/sample - loss: 0.6173 - accuracy: 0.6798 - val_loss: 0.6124 - val_accuracy: 0.7141\n",
      "Epoch 7/300\n",
      "2892/2892 [==============================] - 1s 211us/sample - loss: 0.6081 - accuracy: 0.7012 - val_loss: 0.6066 - val_accuracy: 0.7259\n",
      "Epoch 8/300\n",
      "2892/2892 [==============================] - 1s 230us/sample - loss: 0.5983 - accuracy: 0.7127 - val_loss: 0.6011 - val_accuracy: 0.7333\n",
      "Epoch 9/300\n",
      "2892/2892 [==============================] - 1s 211us/sample - loss: 0.5932 - accuracy: 0.7192 - val_loss: 0.5960 - val_accuracy: 0.7378\n",
      "Epoch 10/300\n",
      "2892/2892 [==============================] - 1s 190us/sample - loss: 0.5860 - accuracy: 0.7258 - val_loss: 0.5914 - val_accuracy: 0.7363\n",
      "Epoch 11/300\n",
      "2892/2892 [==============================] - 1s 218us/sample - loss: 0.5793 - accuracy: 0.7355 - val_loss: 0.5870 - val_accuracy: 0.7378\n",
      "Epoch 12/300\n",
      "2892/2892 [==============================] - 1s 226us/sample - loss: 0.5790 - accuracy: 0.7417 - val_loss: 0.5830 - val_accuracy: 0.7422\n",
      "Epoch 13/300\n",
      "2892/2892 [==============================] - 1s 221us/sample - loss: 0.5692 - accuracy: 0.7469 - val_loss: 0.5793 - val_accuracy: 0.7407\n",
      "Epoch 14/300\n",
      "2892/2892 [==============================] - 1s 197us/sample - loss: 0.5640 - accuracy: 0.7535 - val_loss: 0.5756 - val_accuracy: 0.7407\n",
      "Epoch 15/300\n",
      "2892/2892 [==============================] - 1s 215us/sample - loss: 0.5574 - accuracy: 0.7673 - val_loss: 0.5723 - val_accuracy: 0.7422\n",
      "Epoch 16/300\n",
      "2892/2892 [==============================] - 1s 218us/sample - loss: 0.5574 - accuracy: 0.7497 - val_loss: 0.5690 - val_accuracy: 0.7452\n",
      "Epoch 17/300\n",
      "2892/2892 [==============================] - 1s 212us/sample - loss: 0.5458 - accuracy: 0.7680 - val_loss: 0.5659 - val_accuracy: 0.7481\n",
      "Epoch 18/300\n",
      "2892/2892 [==============================] - 1s 212us/sample - loss: 0.5434 - accuracy: 0.7683 - val_loss: 0.5630 - val_accuracy: 0.7511\n",
      "Epoch 19/300\n",
      "2892/2892 [==============================] - 1s 224us/sample - loss: 0.5387 - accuracy: 0.7746 - val_loss: 0.5602 - val_accuracy: 0.7541\n",
      "Epoch 20/300\n",
      "2892/2892 [==============================] - 1s 227us/sample - loss: 0.5338 - accuracy: 0.7746 - val_loss: 0.5575 - val_accuracy: 0.7615\n",
      "Epoch 21/300\n",
      "2892/2892 [==============================] - 1s 210us/sample - loss: 0.5295 - accuracy: 0.7822 - val_loss: 0.5549 - val_accuracy: 0.7659\n",
      "Epoch 22/300\n",
      "2892/2892 [==============================] - 1s 224us/sample - loss: 0.5214 - accuracy: 0.7901 - val_loss: 0.5525 - val_accuracy: 0.7659\n",
      "Epoch 23/300\n",
      "2892/2892 [==============================] - 1s 189us/sample - loss: 0.5185 - accuracy: 0.7867 - val_loss: 0.5501 - val_accuracy: 0.7674\n",
      "Epoch 24/300\n",
      "2892/2892 [==============================] - 1s 239us/sample - loss: 0.5146 - accuracy: 0.7939 - val_loss: 0.5478 - val_accuracy: 0.7704\n",
      "Epoch 25/300\n",
      "2892/2892 [==============================] - 1s 213us/sample - loss: 0.5062 - accuracy: 0.8019 - val_loss: 0.5458 - val_accuracy: 0.7674\n",
      "Epoch 26/300\n",
      "2892/2892 [==============================] - 1s 228us/sample - loss: 0.5096 - accuracy: 0.7835 - val_loss: 0.5439 - val_accuracy: 0.7659\n",
      "Epoch 27/300\n",
      "2892/2892 [==============================] - 1s 215us/sample - loss: 0.5048 - accuracy: 0.7943 - val_loss: 0.5420 - val_accuracy: 0.7659\n",
      "Epoch 28/300\n",
      "2892/2892 [==============================] - 1s 204us/sample - loss: 0.4970 - accuracy: 0.8019 - val_loss: 0.5402 - val_accuracy: 0.7689\n",
      "Epoch 29/300\n",
      "2892/2892 [==============================] - 1s 215us/sample - loss: 0.4949 - accuracy: 0.8029 - val_loss: 0.5385 - val_accuracy: 0.7689\n",
      "Epoch 30/300\n",
      "2892/2892 [==============================] - 1s 233us/sample - loss: 0.4912 - accuracy: 0.8074 - val_loss: 0.5368 - val_accuracy: 0.7689\n",
      "Epoch 31/300\n",
      "2892/2892 [==============================] - 1s 230us/sample - loss: 0.4836 - accuracy: 0.8029 - val_loss: 0.5352 - val_accuracy: 0.7689\n",
      "Epoch 32/300\n",
      "2892/2892 [==============================] - 1s 219us/sample - loss: 0.4798 - accuracy: 0.8053 - val_loss: 0.5338 - val_accuracy: 0.7674\n",
      "Epoch 33/300\n",
      "2892/2892 [==============================] - 1s 213us/sample - loss: 0.4798 - accuracy: 0.8060 - val_loss: 0.5325 - val_accuracy: 0.7674\n",
      "Epoch 34/300\n",
      "2892/2892 [==============================] - 1s 221us/sample - loss: 0.4755 - accuracy: 0.8029 - val_loss: 0.5312 - val_accuracy: 0.7659\n",
      "Epoch 35/300\n",
      "2892/2892 [==============================] - 1s 224us/sample - loss: 0.4686 - accuracy: 0.8126 - val_loss: 0.5300 - val_accuracy: 0.7659\n",
      "Epoch 36/300\n",
      "2892/2892 [==============================] - 1s 233us/sample - loss: 0.4661 - accuracy: 0.8119 - val_loss: 0.5289 - val_accuracy: 0.7689\n",
      "Epoch 37/300\n",
      "2892/2892 [==============================] - 1s 228us/sample - loss: 0.4616 - accuracy: 0.8102 - val_loss: 0.5278 - val_accuracy: 0.7719\n",
      "Epoch 38/300\n",
      "2892/2892 [==============================] - 1s 236us/sample - loss: 0.4616 - accuracy: 0.8150 - val_loss: 0.5269 - val_accuracy: 0.7719\n",
      "Epoch 39/300\n",
      "2892/2892 [==============================] - 1s 237us/sample - loss: 0.4562 - accuracy: 0.8122 - val_loss: 0.5260 - val_accuracy: 0.7719\n",
      "Epoch 40/300\n",
      "2892/2892 [==============================] - 1s 234us/sample - loss: 0.4553 - accuracy: 0.8188 - val_loss: 0.5254 - val_accuracy: 0.7719\n",
      "Epoch 41/300\n",
      "2892/2892 [==============================] - 1s 209us/sample - loss: 0.4466 - accuracy: 0.8178 - val_loss: 0.5247 - val_accuracy: 0.7704\n",
      "Epoch 42/300\n",
      "2892/2892 [==============================] - 1s 210us/sample - loss: 0.4443 - accuracy: 0.8219 - val_loss: 0.5241 - val_accuracy: 0.7704\n",
      "Epoch 43/300\n",
      "2892/2892 [==============================] - 1s 213us/sample - loss: 0.4393 - accuracy: 0.8292 - val_loss: 0.5237 - val_accuracy: 0.7674\n",
      "Epoch 44/300\n",
      "2892/2892 [==============================] - 1s 221us/sample - loss: 0.4343 - accuracy: 0.8275 - val_loss: 0.5232 - val_accuracy: 0.7659\n",
      "Epoch 45/300\n",
      "2892/2892 [==============================] - 1s 211us/sample - loss: 0.4288 - accuracy: 0.8292 - val_loss: 0.5228 - val_accuracy: 0.7659\n",
      "Epoch 46/300\n",
      "2892/2892 [==============================] - 1s 209us/sample - loss: 0.4273 - accuracy: 0.8330 - val_loss: 0.5225 - val_accuracy: 0.7659\n",
      "Epoch 47/300\n",
      "2892/2892 [==============================] - 1s 206us/sample - loss: 0.4234 - accuracy: 0.8340 - val_loss: 0.5223 - val_accuracy: 0.7630\n",
      "Epoch 48/300\n",
      "2892/2892 [==============================] - 1s 213us/sample - loss: 0.4209 - accuracy: 0.8344 - val_loss: 0.5223 - val_accuracy: 0.7644\n",
      "Epoch 49/300\n",
      "2892/2892 [==============================] - 1s 202us/sample - loss: 0.4153 - accuracy: 0.8309 - val_loss: 0.5223 - val_accuracy: 0.7644\n",
      "Epoch 50/300\n",
      "2892/2892 [==============================] - 1s 214us/sample - loss: 0.4096 - accuracy: 0.8378 - val_loss: 0.5223 - val_accuracy: 0.7644\n",
      "Epoch 51/300\n",
      "2892/2892 [==============================] - 1s 204us/sample - loss: 0.4072 - accuracy: 0.8399 - val_loss: 0.5224 - val_accuracy: 0.7630\n",
      "Epoch 52/300\n",
      "2892/2892 [==============================] - 1s 218us/sample - loss: 0.4041 - accuracy: 0.8364 - val_loss: 0.5226 - val_accuracy: 0.7600\n",
      "Epoch 00052: early stopping\n",
      "82/82 [==============================] - 0s 170us/sample - loss: 0.4277 - accuracy: 0.8415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [1:42:34, 1040.27s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.66s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.43s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 843.703125 steps, validate for 195.0078125 steps\n",
      "Epoch 1/300\n",
      "844/843 [==============================] - 24s 29ms/step - loss: 0.5508 - accuracy: 0.7533 - val_loss: 0.5518 - val_accuracy: 0.7775\n",
      "Epoch 2/300\n",
      "844/843 [==============================] - 23s 27ms/step - loss: 0.5130 - accuracy: 0.7701 - val_loss: 0.5571 - val_accuracy: 0.7735\n",
      "Epoch 3/300\n",
      "844/843 [==============================] - 23s 27ms/step - loss: 0.4975 - accuracy: 0.7761 - val_loss: 0.5592 - val_accuracy: 0.7701\n",
      "Epoch 4/300\n",
      "844/843 [==============================] - 23s 28ms/step - loss: 0.4862 - accuracy: 0.7807 - val_loss: 0.5591 - val_accuracy: 0.7706\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 843.703125 steps, validate for 195.0078125 steps\n",
      "Epoch 1/300\n",
      "844/843 [==============================] - 55s 65ms/step - loss: 0.4666 - accuracy: 0.7909 - val_loss: 0.5725 - val_accuracy: 0.7801\n",
      "Epoch 2/300\n",
      "844/843 [==============================] - 53s 63ms/step - loss: 0.4385 - accuracy: 0.8057 - val_loss: 0.6099 - val_accuracy: 0.7095\n",
      "Epoch 3/300\n",
      "844/843 [==============================] - 53s 63ms/step - loss: 0.4154 - accuracy: 0.8187 - val_loss: 0.5990 - val_accuracy: 0.7432\n",
      "Epoch 4/300\n",
      "844/843 [==============================] - 53s 63ms/step - loss: 0.3942 - accuracy: 0.8303 - val_loss: 0.5966 - val_accuracy: 0.7379\n",
      "Epoch 00004: early stopping\n",
      "162/162 [==============================] - 0s 2ms/sample - loss: 0.2644 - accuracy: 0.9444\n",
      "160/160 [==============================] - 0s 1ms/sample - loss: 0.2342 - accuracy: 0.9500\n",
      "158/158 [==============================] - 0s 250us/sample - loss: 0.2433 - accuracy: 0.9367\n",
      "155/155 [==============================] - 0s 220us/sample - loss: 0.2451 - accuracy: 0.9419\n",
      "153/153 [==============================] - 0s 231us/sample - loss: 0.2355 - accuracy: 0.9542\n",
      "153/153 [==============================] - 0s 242us/sample - loss: 0.2365 - accuracy: 0.9542\n",
      "150/150 [==============================] - 0s 239us/sample - loss: 0.2264 - accuracy: 0.9733\n",
      "150/150 [==============================] - 0s 248us/sample - loss: 0.2433 - accuracy: 0.9533\n",
      "152/152 [==============================] - 0s 238us/sample - loss: 0.2444 - accuracy: 0.9342\n",
      "150/150 [==============================] - 0s 233us/sample - loss: 0.2410 - accuracy: 0.9467\n",
      "150/150 [==============================] - 0s 242us/sample - loss: 0.2202 - accuracy: 0.9533\n",
      "147/147 [==============================] - 0s 243us/sample - loss: 0.2069 - accuracy: 0.9728\n",
      "148/148 [==============================] - 0s 266us/sample - loss: 0.2327 - accuracy: 0.9662\n",
      "146/146 [==============================] - 0s 238us/sample - loss: 0.2434 - accuracy: 0.9384\n",
      "145/145 [==============================] - 0s 244us/sample - loss: 0.2570 - accuracy: 0.9310\n",
      "146/146 [==============================] - 0s 257us/sample - loss: 0.2296 - accuracy: 0.9658\n",
      "145/145 [==============================] - 0s 247us/sample - loss: 0.2579 - accuracy: 0.9310\n",
      "143/143 [==============================] - 0s 272us/sample - loss: 0.2529 - accuracy: 0.9301\n",
      "141/141 [==============================] - 0s 254us/sample - loss: 0.2595 - accuracy: 0.9291\n",
      "141/141 [==============================] - 0s 247us/sample - loss: 0.2391 - accuracy: 0.9362\n",
      "142/142 [==============================] - 0s 235us/sample - loss: 0.2331 - accuracy: 0.9648\n",
      "142/142 [==============================] - 0s 280us/sample - loss: 0.2414 - accuracy: 0.9366\n",
      "143/143 [==============================] - 0s 252us/sample - loss: 0.2392 - accuracy: 0.9441\n",
      "140/140 [==============================] - 0s 260us/sample - loss: 0.2461 - accuracy: 0.9286\n",
      "143/143 [==============================] - 0s 235us/sample - loss: 0.2206 - accuracy: 0.9580\n",
      "142/142 [==============================] - 0s 233us/sample - loss: 0.2368 - accuracy: 0.9648\n",
      "141/141 [==============================] - 0s 275us/sample - loss: 0.2473 - accuracy: 0.9362\n",
      "140/140 [==============================] - 0s 255us/sample - loss: 0.2363 - accuracy: 0.9500\n",
      "140/140 [==============================] - 0s 260us/sample - loss: 0.2385 - accuracy: 0.9714\n",
      "139/139 [==============================] - 0s 245us/sample - loss: 0.2503 - accuracy: 0.9281\n",
      "138/138 [==============================] - 0s 244us/sample - loss: 0.2401 - accuracy: 0.9638\n",
      "139/139 [==============================] - 0s 249us/sample - loss: 0.2273 - accuracy: 0.9640\n",
      "139/139 [==============================] - 0s 249us/sample - loss: 0.2339 - accuracy: 0.9640\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2853 samples, validate on 666 samples\n",
      "Epoch 1/300\n",
      "2853/2853 [==============================] - 3s 946us/sample - loss: 0.6976 - accuracy: 0.5303 - val_loss: 0.7073 - val_accuracy: 0.5015\n",
      "Epoch 2/300\n",
      "2853/2853 [==============================] - 1s 219us/sample - loss: 0.6669 - accuracy: 0.5892 - val_loss: 0.6843 - val_accuracy: 0.5661\n",
      "Epoch 3/300\n",
      "2853/2853 [==============================] - 1s 221us/sample - loss: 0.6486 - accuracy: 0.6229 - val_loss: 0.6684 - val_accuracy: 0.5991\n",
      "Epoch 4/300\n",
      "2853/2853 [==============================] - 1s 230us/sample - loss: 0.6280 - accuracy: 0.6547 - val_loss: 0.6559 - val_accuracy: 0.6321\n",
      "Epoch 5/300\n",
      "2853/2853 [==============================] - 1s 203us/sample - loss: 0.6195 - accuracy: 0.6649 - val_loss: 0.6453 - val_accuracy: 0.6411\n",
      "Epoch 6/300\n",
      "2853/2853 [==============================] - 1s 215us/sample - loss: 0.6106 - accuracy: 0.6828 - val_loss: 0.6366 - val_accuracy: 0.6637\n",
      "Epoch 7/300\n",
      "2853/2853 [==============================] - 1s 221us/sample - loss: 0.6013 - accuracy: 0.7084 - val_loss: 0.6287 - val_accuracy: 0.6787\n",
      "Epoch 8/300\n",
      "2853/2853 [==============================] - 1s 236us/sample - loss: 0.5915 - accuracy: 0.7210 - val_loss: 0.6218 - val_accuracy: 0.6862\n",
      "Epoch 9/300\n",
      "2853/2853 [==============================] - 1s 235us/sample - loss: 0.5853 - accuracy: 0.7263 - val_loss: 0.6153 - val_accuracy: 0.6967\n",
      "Epoch 10/300\n",
      "2853/2853 [==============================] - 1s 234us/sample - loss: 0.5770 - accuracy: 0.7406 - val_loss: 0.6095 - val_accuracy: 0.7147\n",
      "Epoch 11/300\n",
      "2853/2853 [==============================] - 1s 217us/sample - loss: 0.5707 - accuracy: 0.7462 - val_loss: 0.6044 - val_accuracy: 0.7237\n",
      "Epoch 12/300\n",
      "2853/2853 [==============================] - 1s 242us/sample - loss: 0.5640 - accuracy: 0.7438 - val_loss: 0.5995 - val_accuracy: 0.7327\n",
      "Epoch 13/300\n",
      "2853/2853 [==============================] - 1s 202us/sample - loss: 0.5600 - accuracy: 0.7529 - val_loss: 0.5951 - val_accuracy: 0.7372\n",
      "Epoch 14/300\n",
      "2853/2853 [==============================] - 1s 214us/sample - loss: 0.5546 - accuracy: 0.7599 - val_loss: 0.5911 - val_accuracy: 0.7402\n",
      "Epoch 15/300\n",
      "2853/2853 [==============================] - 1s 206us/sample - loss: 0.5471 - accuracy: 0.7764 - val_loss: 0.5871 - val_accuracy: 0.7508\n",
      "Epoch 16/300\n",
      "2853/2853 [==============================] - 1s 219us/sample - loss: 0.5430 - accuracy: 0.7750 - val_loss: 0.5836 - val_accuracy: 0.7568\n",
      "Epoch 17/300\n",
      "2853/2853 [==============================] - 1s 215us/sample - loss: 0.5402 - accuracy: 0.7746 - val_loss: 0.5803 - val_accuracy: 0.7598\n",
      "Epoch 18/300\n",
      "2853/2853 [==============================] - 1s 220us/sample - loss: 0.5339 - accuracy: 0.7795 - val_loss: 0.5772 - val_accuracy: 0.7643\n",
      "Epoch 19/300\n",
      "2853/2853 [==============================] - 1s 227us/sample - loss: 0.5304 - accuracy: 0.7781 - val_loss: 0.5743 - val_accuracy: 0.7643\n",
      "Epoch 20/300\n",
      "2853/2853 [==============================] - 1s 210us/sample - loss: 0.5282 - accuracy: 0.7778 - val_loss: 0.5716 - val_accuracy: 0.7643\n",
      "Epoch 21/300\n",
      "2853/2853 [==============================] - 1s 215us/sample - loss: 0.5259 - accuracy: 0.7834 - val_loss: 0.5691 - val_accuracy: 0.7658\n",
      "Epoch 22/300\n",
      "2853/2853 [==============================] - 1s 229us/sample - loss: 0.5162 - accuracy: 0.7897 - val_loss: 0.5668 - val_accuracy: 0.7673\n",
      "Epoch 23/300\n",
      "2853/2853 [==============================] - 1s 208us/sample - loss: 0.5156 - accuracy: 0.7897 - val_loss: 0.5647 - val_accuracy: 0.7658\n",
      "Epoch 24/300\n",
      "2853/2853 [==============================] - 1s 230us/sample - loss: 0.5114 - accuracy: 0.7890 - val_loss: 0.5627 - val_accuracy: 0.7658\n",
      "Epoch 25/300\n",
      "2853/2853 [==============================] - 1s 229us/sample - loss: 0.5080 - accuracy: 0.7893 - val_loss: 0.5609 - val_accuracy: 0.7673\n",
      "Epoch 26/300\n",
      "2853/2853 [==============================] - 1s 244us/sample - loss: 0.5030 - accuracy: 0.7960 - val_loss: 0.5591 - val_accuracy: 0.7703\n",
      "Epoch 27/300\n",
      "2853/2853 [==============================] - 1s 215us/sample - loss: 0.5010 - accuracy: 0.7992 - val_loss: 0.5575 - val_accuracy: 0.7688\n",
      "Epoch 28/300\n",
      "2853/2853 [==============================] - 1s 229us/sample - loss: 0.4959 - accuracy: 0.7978 - val_loss: 0.5561 - val_accuracy: 0.7703\n",
      "Epoch 29/300\n",
      "2853/2853 [==============================] - 1s 222us/sample - loss: 0.4934 - accuracy: 0.7985 - val_loss: 0.5547 - val_accuracy: 0.7703\n",
      "Epoch 30/300\n",
      "2853/2853 [==============================] - 1s 241us/sample - loss: 0.4923 - accuracy: 0.8002 - val_loss: 0.5533 - val_accuracy: 0.7703\n",
      "Epoch 31/300\n",
      "2853/2853 [==============================] - 1s 232us/sample - loss: 0.4879 - accuracy: 0.8023 - val_loss: 0.5521 - val_accuracy: 0.7703\n",
      "Epoch 32/300\n",
      "2853/2853 [==============================] - 1s 244us/sample - loss: 0.4836 - accuracy: 0.7988 - val_loss: 0.5511 - val_accuracy: 0.7733\n",
      "Epoch 33/300\n",
      "2853/2853 [==============================] - 1s 235us/sample - loss: 0.4819 - accuracy: 0.8079 - val_loss: 0.5502 - val_accuracy: 0.7733\n",
      "Epoch 34/300\n",
      "2853/2853 [==============================] - 1s 222us/sample - loss: 0.4790 - accuracy: 0.8023 - val_loss: 0.5494 - val_accuracy: 0.7733\n",
      "Epoch 35/300\n",
      "2853/2853 [==============================] - 1s 213us/sample - loss: 0.4767 - accuracy: 0.8055 - val_loss: 0.5487 - val_accuracy: 0.7733\n",
      "Epoch 36/300\n",
      "2853/2853 [==============================] - 1s 230us/sample - loss: 0.4717 - accuracy: 0.8107 - val_loss: 0.5479 - val_accuracy: 0.7748\n",
      "Epoch 37/300\n",
      "2853/2853 [==============================] - 1s 230us/sample - loss: 0.4734 - accuracy: 0.8041 - val_loss: 0.5473 - val_accuracy: 0.7748\n",
      "Epoch 38/300\n",
      "2853/2853 [==============================] - 1s 212us/sample - loss: 0.4683 - accuracy: 0.8030 - val_loss: 0.5468 - val_accuracy: 0.7748\n",
      "Epoch 39/300\n",
      "2853/2853 [==============================] - 1s 207us/sample - loss: 0.4672 - accuracy: 0.8079 - val_loss: 0.5463 - val_accuracy: 0.7748\n",
      "Epoch 40/300\n",
      "2853/2853 [==============================] - 1s 179us/sample - loss: 0.4652 - accuracy: 0.8069 - val_loss: 0.5460 - val_accuracy: 0.7733\n",
      "Epoch 41/300\n",
      "2853/2853 [==============================] - 1s 249us/sample - loss: 0.4600 - accuracy: 0.8132 - val_loss: 0.5457 - val_accuracy: 0.7733\n",
      "Epoch 42/300\n",
      "2853/2853 [==============================] - 1s 248us/sample - loss: 0.4600 - accuracy: 0.8149 - val_loss: 0.5455 - val_accuracy: 0.7718\n",
      "Epoch 43/300\n",
      "2853/2853 [==============================] - 1s 242us/sample - loss: 0.4584 - accuracy: 0.8174 - val_loss: 0.5452 - val_accuracy: 0.7718\n",
      "Epoch 44/300\n",
      "2853/2853 [==============================] - 1s 219us/sample - loss: 0.4540 - accuracy: 0.8118 - val_loss: 0.5451 - val_accuracy: 0.7733\n",
      "Epoch 45/300\n",
      "2853/2853 [==============================] - 1s 212us/sample - loss: 0.4525 - accuracy: 0.8128 - val_loss: 0.5451 - val_accuracy: 0.7718\n",
      "Epoch 46/300\n",
      "2853/2853 [==============================] - 1s 206us/sample - loss: 0.4495 - accuracy: 0.8216 - val_loss: 0.5452 - val_accuracy: 0.7718\n",
      "Epoch 47/300\n",
      "2853/2853 [==============================] - 1s 207us/sample - loss: 0.4448 - accuracy: 0.8181 - val_loss: 0.5451 - val_accuracy: 0.7718\n",
      "Epoch 00047: early stopping\n",
      "130/130 [==============================] - 0s 139us/sample - loss: 0.2981 - accuracy: 0.9615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [1:58:49, 1020.60s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.82s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.56s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 854.234375 steps, validate for 197.1484375 steps\n",
      "Epoch 1/300\n",
      "855/854 [==============================] - 24s 28ms/step - loss: 0.5466 - accuracy: 0.7534 - val_loss: 0.5516 - val_accuracy: 0.7805\n",
      "Epoch 2/300\n",
      "855/854 [==============================] - 23s 27ms/step - loss: 0.5081 - accuracy: 0.7725 - val_loss: 0.5551 - val_accuracy: 0.7782\n",
      "Epoch 3/300\n",
      "855/854 [==============================] - 23s 27ms/step - loss: 0.4934 - accuracy: 0.7781 - val_loss: 0.5579 - val_accuracy: 0.7774\n",
      "Epoch 4/300\n",
      "855/854 [==============================] - 23s 27ms/step - loss: 0.4827 - accuracy: 0.7831 - val_loss: 0.5583 - val_accuracy: 0.7748\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 854.234375 steps, validate for 197.1484375 steps\n",
      "Epoch 1/300\n",
      "855/854 [==============================] - 55s 64ms/step - loss: 0.4650 - accuracy: 0.7919 - val_loss: 0.5635 - val_accuracy: 0.7719\n",
      "Epoch 2/300\n",
      "855/854 [==============================] - 53s 62ms/step - loss: 0.4385 - accuracy: 0.8051 - val_loss: 0.5931 - val_accuracy: 0.7257\n",
      "Epoch 3/300\n",
      "855/854 [==============================] - 53s 62ms/step - loss: 0.4161 - accuracy: 0.8173 - val_loss: 0.5728 - val_accuracy: 0.7708\n",
      "Epoch 4/300\n",
      "855/854 [==============================] - 54s 63ms/step - loss: 0.3960 - accuracy: 0.8287 - val_loss: 0.5842 - val_accuracy: 0.7582\n",
      "Epoch 00004: early stopping\n",
      "118/118 [==============================] - 0s 2ms/sample - loss: 0.1207 - accuracy: 1.0000\n",
      "116/116 [==============================] - 0s 245us/sample - loss: 0.1091 - accuracy: 1.0000\n",
      "114/114 [==============================] - 0s 256us/sample - loss: 0.1315 - accuracy: 0.9825\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.1384 - accuracy: 0.9911\n",
      "110/110 [==============================] - 0s 242us/sample - loss: 0.1364 - accuracy: 0.9909\n",
      "109/109 [==============================] - 0s 241us/sample - loss: 0.1434 - accuracy: 0.9908\n",
      "108/108 [==============================] - 0s 238us/sample - loss: 0.1313 - accuracy: 0.9907\n",
      "105/105 [==============================] - 0s 267us/sample - loss: 0.1542 - accuracy: 0.9810\n",
      "102/102 [==============================] - 0s 224us/sample - loss: 0.1468 - accuracy: 1.0000\n",
      "101/101 [==============================] - 0s 382us/sample - loss: 0.1627 - accuracy: 0.9802\n",
      "99/99 [==============================] - 0s 244us/sample - loss: 0.1651 - accuracy: 0.9899\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1722 - accuracy: 0.9896\n",
      "94/94 [==============================] - 0s 257us/sample - loss: 0.1828 - accuracy: 1.0000\n",
      "94/94 [==============================] - 0s 253us/sample - loss: 0.1726 - accuracy: 1.0000\n",
      "93/93 [==============================] - 0s 277us/sample - loss: 0.1694 - accuracy: 1.0000\n",
      "92/92 [==============================] - 0s 273us/sample - loss: 0.1987 - accuracy: 0.9891\n",
      "93/93 [==============================] - 0s 258us/sample - loss: 0.1979 - accuracy: 0.9785\n",
      "93/93 [==============================] - 0s 254us/sample - loss: 0.1950 - accuracy: 0.9785\n",
      "92/92 [==============================] - 0s 255us/sample - loss: 0.1933 - accuracy: 0.9891\n",
      "92/92 [==============================] - 0s 269us/sample - loss: 0.2473 - accuracy: 0.9348\n",
      "91/91 [==============================] - 0s 253us/sample - loss: 0.2091 - accuracy: 0.9780\n",
      "92/92 [==============================] - 0s 270us/sample - loss: 0.1949 - accuracy: 0.9891\n",
      "91/91 [==============================] - 0s 299us/sample - loss: 0.1954 - accuracy: 0.9670\n",
      "90/90 [==============================] - 0s 272us/sample - loss: 0.1921 - accuracy: 1.0000\n",
      "89/89 [==============================] - 0s 261us/sample - loss: 0.2123 - accuracy: 0.9888\n",
      "88/88 [==============================] - 0s 253us/sample - loss: 0.2319 - accuracy: 0.9545\n",
      "89/89 [==============================] - 0s 242us/sample - loss: 0.2088 - accuracy: 0.9888\n",
      "89/89 [==============================] - 0s 264us/sample - loss: 0.2189 - accuracy: 0.9775\n",
      "89/89 [==============================] - 0s 280us/sample - loss: 0.2036 - accuracy: 1.0000\n",
      "90/90 [==============================] - 0s 264us/sample - loss: 0.2030 - accuracy: 0.9778\n",
      "90/90 [==============================] - 0s 259us/sample - loss: 0.1853 - accuracy: 0.9778\n",
      "91/91 [==============================] - 0s 268us/sample - loss: 0.2283 - accuracy: 0.9560\n",
      "89/89 [==============================] - 0s 244us/sample - loss: 0.2327 - accuracy: 0.9551\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2886 samples, validate on 676 samples\n",
      "Epoch 1/300\n",
      "2886/2886 [==============================] - 2s 859us/sample - loss: 0.6734 - accuracy: 0.5863 - val_loss: 0.6241 - val_accuracy: 0.6657\n",
      "Epoch 2/300\n",
      "2886/2886 [==============================] - 1s 216us/sample - loss: 0.6375 - accuracy: 0.6445 - val_loss: 0.6037 - val_accuracy: 0.6997\n",
      "Epoch 3/300\n",
      "2886/2886 [==============================] - 1s 224us/sample - loss: 0.6206 - accuracy: 0.6753 - val_loss: 0.5900 - val_accuracy: 0.7175\n",
      "Epoch 4/300\n",
      "2886/2886 [==============================] - 1s 226us/sample - loss: 0.6077 - accuracy: 0.6930 - val_loss: 0.5797 - val_accuracy: 0.7411\n",
      "Epoch 5/300\n",
      "2886/2886 [==============================] - 1s 205us/sample - loss: 0.5956 - accuracy: 0.7044 - val_loss: 0.5711 - val_accuracy: 0.7544\n",
      "Epoch 6/300\n",
      "2886/2886 [==============================] - 1s 201us/sample - loss: 0.5830 - accuracy: 0.7235 - val_loss: 0.5638 - val_accuracy: 0.7589\n",
      "Epoch 7/300\n",
      "2886/2886 [==============================] - 1s 210us/sample - loss: 0.5763 - accuracy: 0.7200 - val_loss: 0.5578 - val_accuracy: 0.7633\n",
      "Epoch 8/300\n",
      "2886/2886 [==============================] - 1s 199us/sample - loss: 0.5664 - accuracy: 0.7356 - val_loss: 0.5524 - val_accuracy: 0.7692\n",
      "Epoch 9/300\n",
      "2886/2886 [==============================] - 1s 233us/sample - loss: 0.5655 - accuracy: 0.7342 - val_loss: 0.5477 - val_accuracy: 0.7692\n",
      "Epoch 10/300\n",
      "2886/2886 [==============================] - 1s 228us/sample - loss: 0.5569 - accuracy: 0.7446 - val_loss: 0.5436 - val_accuracy: 0.7737\n",
      "Epoch 11/300\n",
      "2886/2886 [==============================] - 1s 221us/sample - loss: 0.5480 - accuracy: 0.7505 - val_loss: 0.5399 - val_accuracy: 0.7751\n",
      "Epoch 12/300\n",
      "2886/2886 [==============================] - 1s 232us/sample - loss: 0.5463 - accuracy: 0.7581 - val_loss: 0.5364 - val_accuracy: 0.7811\n",
      "Epoch 13/300\n",
      "2886/2886 [==============================] - 1s 219us/sample - loss: 0.5384 - accuracy: 0.7592 - val_loss: 0.5334 - val_accuracy: 0.7840\n",
      "Epoch 14/300\n",
      "2886/2886 [==============================] - 1s 227us/sample - loss: 0.5357 - accuracy: 0.7609 - val_loss: 0.5305 - val_accuracy: 0.7870\n",
      "Epoch 15/300\n",
      "2886/2886 [==============================] - 1s 245us/sample - loss: 0.5281 - accuracy: 0.7592 - val_loss: 0.5281 - val_accuracy: 0.7899\n",
      "Epoch 16/300\n",
      "2886/2886 [==============================] - 1s 217us/sample - loss: 0.5268 - accuracy: 0.7665 - val_loss: 0.5259 - val_accuracy: 0.7914\n",
      "Epoch 17/300\n",
      "2886/2886 [==============================] - 1s 229us/sample - loss: 0.5219 - accuracy: 0.7699 - val_loss: 0.5238 - val_accuracy: 0.7914\n",
      "Epoch 18/300\n",
      "2886/2886 [==============================] - 1s 212us/sample - loss: 0.5175 - accuracy: 0.7706 - val_loss: 0.5218 - val_accuracy: 0.7929\n",
      "Epoch 19/300\n",
      "2886/2886 [==============================] - 1s 191us/sample - loss: 0.5158 - accuracy: 0.7689 - val_loss: 0.5201 - val_accuracy: 0.7929\n",
      "Epoch 20/300\n",
      "2886/2886 [==============================] - 1s 216us/sample - loss: 0.5105 - accuracy: 0.7730 - val_loss: 0.5185 - val_accuracy: 0.7929\n",
      "Epoch 21/300\n",
      "2886/2886 [==============================] - 1s 199us/sample - loss: 0.5082 - accuracy: 0.7755 - val_loss: 0.5171 - val_accuracy: 0.7929\n",
      "Epoch 22/300\n",
      "2886/2886 [==============================] - 1s 222us/sample - loss: 0.5047 - accuracy: 0.7762 - val_loss: 0.5156 - val_accuracy: 0.7929\n",
      "Epoch 23/300\n",
      "2886/2886 [==============================] - 1s 208us/sample - loss: 0.4936 - accuracy: 0.7817 - val_loss: 0.5144 - val_accuracy: 0.7944\n",
      "Epoch 24/300\n",
      "2886/2886 [==============================] - 1s 209us/sample - loss: 0.4960 - accuracy: 0.7793 - val_loss: 0.5133 - val_accuracy: 0.7944\n",
      "Epoch 25/300\n",
      "2886/2886 [==============================] - 1s 210us/sample - loss: 0.4946 - accuracy: 0.7827 - val_loss: 0.5122 - val_accuracy: 0.7944\n",
      "Epoch 26/300\n",
      "2886/2886 [==============================] - 1s 194us/sample - loss: 0.4901 - accuracy: 0.7852 - val_loss: 0.5113 - val_accuracy: 0.7944\n",
      "Epoch 27/300\n",
      "2886/2886 [==============================] - 1s 190us/sample - loss: 0.4864 - accuracy: 0.7855 - val_loss: 0.5104 - val_accuracy: 0.7929\n",
      "Epoch 28/300\n",
      "2886/2886 [==============================] - 1s 218us/sample - loss: 0.4835 - accuracy: 0.7859 - val_loss: 0.5097 - val_accuracy: 0.7929\n",
      "Epoch 29/300\n",
      "2886/2886 [==============================] - 1s 229us/sample - loss: 0.4824 - accuracy: 0.7900 - val_loss: 0.5089 - val_accuracy: 0.7914\n",
      "Epoch 30/300\n",
      "2886/2886 [==============================] - 1s 230us/sample - loss: 0.4761 - accuracy: 0.7897 - val_loss: 0.5084 - val_accuracy: 0.7914\n",
      "Epoch 31/300\n",
      "2886/2886 [==============================] - 1s 219us/sample - loss: 0.4760 - accuracy: 0.7914 - val_loss: 0.5078 - val_accuracy: 0.7929\n",
      "Epoch 32/300\n",
      "2886/2886 [==============================] - 1s 207us/sample - loss: 0.4718 - accuracy: 0.7890 - val_loss: 0.5074 - val_accuracy: 0.7944\n",
      "Epoch 33/300\n",
      "2886/2886 [==============================] - 1s 224us/sample - loss: 0.4668 - accuracy: 0.7949 - val_loss: 0.5070 - val_accuracy: 0.7944\n",
      "Epoch 34/300\n",
      "2886/2886 [==============================] - 1s 226us/sample - loss: 0.4652 - accuracy: 0.7980 - val_loss: 0.5068 - val_accuracy: 0.7944\n",
      "Epoch 35/300\n",
      "2886/2886 [==============================] - 1s 218us/sample - loss: 0.4630 - accuracy: 0.7963 - val_loss: 0.5066 - val_accuracy: 0.7959\n",
      "Epoch 36/300\n",
      "2886/2886 [==============================] - 1s 245us/sample - loss: 0.4589 - accuracy: 0.7963 - val_loss: 0.5063 - val_accuracy: 0.7973\n",
      "Epoch 37/300\n",
      "2886/2886 [==============================] - 1s 228us/sample - loss: 0.4575 - accuracy: 0.8004 - val_loss: 0.5062 - val_accuracy: 0.7973\n",
      "Epoch 38/300\n",
      "2886/2886 [==============================] - 1s 222us/sample - loss: 0.4524 - accuracy: 0.8056 - val_loss: 0.5062 - val_accuracy: 0.7973\n",
      "Epoch 39/300\n",
      "2886/2886 [==============================] - 1s 243us/sample - loss: 0.4503 - accuracy: 0.8021 - val_loss: 0.5062 - val_accuracy: 0.7959\n",
      "Epoch 40/300\n",
      "2886/2886 [==============================] - 1s 245us/sample - loss: 0.4500 - accuracy: 0.8035 - val_loss: 0.5062 - val_accuracy: 0.7959\n",
      "Epoch 41/300\n",
      "2886/2886 [==============================] - 1s 217us/sample - loss: 0.4452 - accuracy: 0.8025 - val_loss: 0.5065 - val_accuracy: 0.7959\n",
      "Epoch 42/300\n",
      "2886/2886 [==============================] - 1s 216us/sample - loss: 0.4406 - accuracy: 0.8094 - val_loss: 0.5066 - val_accuracy: 0.7959\n",
      "Epoch 00042: early stopping\n",
      "87/87 [==============================] - 0s 168us/sample - loss: 0.2741 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [2:14:42, 1000.37s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:04<00:04,  4.10s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.67s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 851.03125 steps, validate for 197.9765625 steps\n",
      "Epoch 1/300\n",
      "852/851 [==============================] - 24s 28ms/step - loss: 0.5432 - accuracy: 0.7575 - val_loss: 0.5448 - val_accuracy: 0.7839\n",
      "Epoch 2/300\n",
      "852/851 [==============================] - 23s 27ms/step - loss: 0.5096 - accuracy: 0.7728 - val_loss: 0.5451 - val_accuracy: 0.7812\n",
      "Epoch 3/300\n",
      "852/851 [==============================] - 23s 27ms/step - loss: 0.4948 - accuracy: 0.7781 - val_loss: 0.5489 - val_accuracy: 0.7755\n",
      "Epoch 4/300\n",
      "852/851 [==============================] - 23s 28ms/step - loss: 0.4835 - accuracy: 0.7834 - val_loss: 0.5520 - val_accuracy: 0.7716\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 851.03125 steps, validate for 197.9765625 steps\n",
      "Epoch 1/300\n",
      "852/851 [==============================] - 54s 64ms/step - loss: 0.4661 - accuracy: 0.7913 - val_loss: 0.5564 - val_accuracy: 0.7784\n",
      "Epoch 2/300\n",
      "852/851 [==============================] - 54s 63ms/step - loss: 0.4394 - accuracy: 0.8054 - val_loss: 0.5820 - val_accuracy: 0.7440\n",
      "Epoch 3/300\n",
      "852/851 [==============================] - 53s 63ms/step - loss: 0.4182 - accuracy: 0.8176 - val_loss: 0.5729 - val_accuracy: 0.7541\n",
      "Epoch 4/300\n",
      "852/851 [==============================] - 53s 63ms/step - loss: 0.3987 - accuracy: 0.8281 - val_loss: 0.6607 - val_accuracy: 0.6683\n",
      "Epoch 00004: early stopping\n",
      "118/118 [==============================] - 0s 2ms/sample - loss: 0.4937 - accuracy: 0.7627\n",
      "113/113 [==============================] - 0s 243us/sample - loss: 0.4881 - accuracy: 0.7876\n",
      "112/112 [==============================] - 0s 259us/sample - loss: 0.5269 - accuracy: 0.8214\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 0.5479 - accuracy: 0.6964\n",
      "111/111 [==============================] - 0s 259us/sample - loss: 0.5167 - accuracy: 0.7387\n",
      "111/111 [==============================] - 0s 263us/sample - loss: 0.5206 - accuracy: 0.7297\n",
      "108/108 [==============================] - 0s 249us/sample - loss: 0.5421 - accuracy: 0.7315\n",
      "109/109 [==============================] - 0s 265us/sample - loss: 0.5008 - accuracy: 0.7339\n",
      "106/106 [==============================] - 0s 240us/sample - loss: 0.5114 - accuracy: 0.7170\n",
      "104/104 [==============================] - 0s 261us/sample - loss: 0.4961 - accuracy: 0.7404\n",
      "104/104 [==============================] - 0s 247us/sample - loss: 0.4652 - accuracy: 0.8173\n",
      "105/105 [==============================] - 0s 276us/sample - loss: 0.5136 - accuracy: 0.7333\n",
      "104/104 [==============================] - 0s 242us/sample - loss: 0.4831 - accuracy: 0.7500\n",
      "104/104 [==============================] - 0s 256us/sample - loss: 0.4810 - accuracy: 0.7885\n",
      "103/103 [==============================] - 0s 283us/sample - loss: 0.5036 - accuracy: 0.7670\n",
      "102/102 [==============================] - 0s 295us/sample - loss: 0.4877 - accuracy: 0.7353\n",
      "101/101 [==============================] - 0s 287us/sample - loss: 0.4830 - accuracy: 0.7624\n",
      "102/102 [==============================] - 0s 278us/sample - loss: 0.5347 - accuracy: 0.7059\n",
      "105/105 [==============================] - 0s 281us/sample - loss: 0.4809 - accuracy: 0.8000\n",
      "103/103 [==============================] - 0s 283us/sample - loss: 0.4777 - accuracy: 0.7573\n",
      "104/104 [==============================] - 0s 291us/sample - loss: 0.4428 - accuracy: 0.8173\n",
      "105/105 [==============================] - 0s 273us/sample - loss: 0.5409 - accuracy: 0.7810\n",
      "103/103 [==============================] - 0s 279us/sample - loss: 0.5037 - accuracy: 0.7670\n",
      "104/104 [==============================] - 0s 265us/sample - loss: 0.4620 - accuracy: 0.7981\n",
      "105/105 [==============================] - 0s 295us/sample - loss: 0.4932 - accuracy: 0.7810\n",
      "105/105 [==============================] - 0s 243us/sample - loss: 0.4531 - accuracy: 0.7905\n",
      "105/105 [==============================] - 0s 262us/sample - loss: 0.5316 - accuracy: 0.7524\n",
      "106/106 [==============================] - 0s 271us/sample - loss: 0.4804 - accuracy: 0.7642\n",
      "104/104 [==============================] - 0s 239us/sample - loss: 0.4810 - accuracy: 0.8077\n",
      "106/106 [==============================] - 0s 239us/sample - loss: 0.4788 - accuracy: 0.7736\n",
      "107/107 [==============================] - 0s 240us/sample - loss: 0.5169 - accuracy: 0.7570\n",
      "108/108 [==============================] - 0s 259us/sample - loss: 0.4663 - accuracy: 0.7870\n",
      "106/106 [==============================] - 0s 263us/sample - loss: 0.4980 - accuracy: 0.7453\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2875 samples, validate on 676 samples\n",
      "Epoch 1/300\n",
      "2875/2875 [==============================] - 3s 907us/sample - loss: 0.7026 - accuracy: 0.5245 - val_loss: 0.6591 - val_accuracy: 0.6183\n",
      "Epoch 2/300\n",
      "2875/2875 [==============================] - 1s 238us/sample - loss: 0.6739 - accuracy: 0.5781 - val_loss: 0.6396 - val_accuracy: 0.6598\n",
      "Epoch 3/300\n",
      "2875/2875 [==============================] - 1s 228us/sample - loss: 0.6599 - accuracy: 0.6163 - val_loss: 0.6257 - val_accuracy: 0.6893\n",
      "Epoch 4/300\n",
      "2875/2875 [==============================] - 1s 249us/sample - loss: 0.6465 - accuracy: 0.6330 - val_loss: 0.6151 - val_accuracy: 0.6997\n",
      "Epoch 5/300\n",
      "2875/2875 [==============================] - 1s 244us/sample - loss: 0.6345 - accuracy: 0.6543 - val_loss: 0.6061 - val_accuracy: 0.7160\n",
      "Epoch 6/300\n",
      "2875/2875 [==============================] - 1s 208us/sample - loss: 0.6305 - accuracy: 0.6563 - val_loss: 0.5987 - val_accuracy: 0.7278\n",
      "Epoch 7/300\n",
      "2875/2875 [==============================] - 1s 179us/sample - loss: 0.6187 - accuracy: 0.6831 - val_loss: 0.5921 - val_accuracy: 0.7411\n",
      "Epoch 8/300\n",
      "2875/2875 [==============================] - 1s 226us/sample - loss: 0.6033 - accuracy: 0.7040 - val_loss: 0.5863 - val_accuracy: 0.7530\n",
      "Epoch 9/300\n",
      "2875/2875 [==============================] - 1s 221us/sample - loss: 0.6008 - accuracy: 0.7071 - val_loss: 0.5811 - val_accuracy: 0.7559\n",
      "Epoch 10/300\n",
      "2875/2875 [==============================] - 1s 211us/sample - loss: 0.5947 - accuracy: 0.7050 - val_loss: 0.5764 - val_accuracy: 0.7574\n",
      "Epoch 11/300\n",
      "2875/2875 [==============================] - 1s 216us/sample - loss: 0.5886 - accuracy: 0.7151 - val_loss: 0.5720 - val_accuracy: 0.7648\n",
      "Epoch 12/300\n",
      "2875/2875 [==============================] - 1s 205us/sample - loss: 0.5837 - accuracy: 0.7224 - val_loss: 0.5678 - val_accuracy: 0.7663\n",
      "Epoch 13/300\n",
      "2875/2875 [==============================] - 1s 217us/sample - loss: 0.5710 - accuracy: 0.7391 - val_loss: 0.5642 - val_accuracy: 0.7663\n",
      "Epoch 14/300\n",
      "2875/2875 [==============================] - 1s 208us/sample - loss: 0.5771 - accuracy: 0.7256 - val_loss: 0.5608 - val_accuracy: 0.7663\n",
      "Epoch 15/300\n",
      "2875/2875 [==============================] - 1s 219us/sample - loss: 0.5719 - accuracy: 0.7325 - val_loss: 0.5577 - val_accuracy: 0.7678\n",
      "Epoch 16/300\n",
      "2875/2875 [==============================] - 1s 211us/sample - loss: 0.5641 - accuracy: 0.7433 - val_loss: 0.5548 - val_accuracy: 0.7737\n",
      "Epoch 17/300\n",
      "2875/2875 [==============================] - 1s 208us/sample - loss: 0.5593 - accuracy: 0.7464 - val_loss: 0.5521 - val_accuracy: 0.7751\n",
      "Epoch 18/300\n",
      "2875/2875 [==============================] - 1s 213us/sample - loss: 0.5570 - accuracy: 0.7499 - val_loss: 0.5496 - val_accuracy: 0.7825\n",
      "Epoch 19/300\n",
      "2875/2875 [==============================] - 1s 198us/sample - loss: 0.5512 - accuracy: 0.7530 - val_loss: 0.5472 - val_accuracy: 0.7825\n",
      "Epoch 20/300\n",
      "2875/2875 [==============================] - 1s 232us/sample - loss: 0.5519 - accuracy: 0.7534 - val_loss: 0.5451 - val_accuracy: 0.7840\n",
      "Epoch 21/300\n",
      "2875/2875 [==============================] - 1s 232us/sample - loss: 0.5457 - accuracy: 0.7586 - val_loss: 0.5431 - val_accuracy: 0.7855\n",
      "Epoch 22/300\n",
      "2875/2875 [==============================] - 1s 186us/sample - loss: 0.5409 - accuracy: 0.7597 - val_loss: 0.5412 - val_accuracy: 0.7855\n",
      "Epoch 23/300\n",
      "2875/2875 [==============================] - 1s 235us/sample - loss: 0.5389 - accuracy: 0.7534 - val_loss: 0.5395 - val_accuracy: 0.7870\n",
      "Epoch 24/300\n",
      "2875/2875 [==============================] - 1s 219us/sample - loss: 0.5356 - accuracy: 0.7645 - val_loss: 0.5377 - val_accuracy: 0.7885\n",
      "Epoch 25/300\n",
      "2875/2875 [==============================] - 1s 220us/sample - loss: 0.5319 - accuracy: 0.7610 - val_loss: 0.5361 - val_accuracy: 0.7914\n",
      "Epoch 26/300\n",
      "2875/2875 [==============================] - 1s 225us/sample - loss: 0.5270 - accuracy: 0.7631 - val_loss: 0.5348 - val_accuracy: 0.7914\n",
      "Epoch 27/300\n",
      "2875/2875 [==============================] - 1s 240us/sample - loss: 0.5233 - accuracy: 0.7645 - val_loss: 0.5334 - val_accuracy: 0.7914\n",
      "Epoch 28/300\n",
      "2875/2875 [==============================] - 1s 229us/sample - loss: 0.5169 - accuracy: 0.7652 - val_loss: 0.5321 - val_accuracy: 0.7899\n",
      "Epoch 29/300\n",
      "2875/2875 [==============================] - 1s 222us/sample - loss: 0.5188 - accuracy: 0.7663 - val_loss: 0.5309 - val_accuracy: 0.7885\n",
      "Epoch 30/300\n",
      "2875/2875 [==============================] - 1s 222us/sample - loss: 0.5123 - accuracy: 0.7739 - val_loss: 0.5297 - val_accuracy: 0.7870\n",
      "Epoch 31/300\n",
      "2875/2875 [==============================] - 1s 217us/sample - loss: 0.5117 - accuracy: 0.7736 - val_loss: 0.5288 - val_accuracy: 0.7855\n",
      "Epoch 32/300\n",
      "2875/2875 [==============================] - 1s 230us/sample - loss: 0.5044 - accuracy: 0.7711 - val_loss: 0.5279 - val_accuracy: 0.7855\n",
      "Epoch 33/300\n",
      "2875/2875 [==============================] - 1s 248us/sample - loss: 0.5075 - accuracy: 0.7732 - val_loss: 0.5271 - val_accuracy: 0.7855\n",
      "Epoch 34/300\n",
      "2875/2875 [==============================] - 1s 236us/sample - loss: 0.5049 - accuracy: 0.7788 - val_loss: 0.5263 - val_accuracy: 0.7855\n",
      "Epoch 35/300\n",
      "2875/2875 [==============================] - 1s 235us/sample - loss: 0.5022 - accuracy: 0.7746 - val_loss: 0.5256 - val_accuracy: 0.7855\n",
      "Epoch 36/300\n",
      "2875/2875 [==============================] - 1s 242us/sample - loss: 0.4950 - accuracy: 0.7812 - val_loss: 0.5249 - val_accuracy: 0.7870\n",
      "Epoch 37/300\n",
      "2875/2875 [==============================] - 1s 203us/sample - loss: 0.4982 - accuracy: 0.7805 - val_loss: 0.5243 - val_accuracy: 0.7870\n",
      "Epoch 38/300\n",
      "2875/2875 [==============================] - 1s 209us/sample - loss: 0.4929 - accuracy: 0.7857 - val_loss: 0.5238 - val_accuracy: 0.7885\n",
      "Epoch 39/300\n",
      "2875/2875 [==============================] - 1s 222us/sample - loss: 0.4889 - accuracy: 0.7878 - val_loss: 0.5232 - val_accuracy: 0.7885\n",
      "Epoch 40/300\n",
      "2875/2875 [==============================] - 1s 236us/sample - loss: 0.4891 - accuracy: 0.7840 - val_loss: 0.5228 - val_accuracy: 0.7885\n",
      "Epoch 41/300\n",
      "2875/2875 [==============================] - 1s 243us/sample - loss: 0.4867 - accuracy: 0.7850 - val_loss: 0.5224 - val_accuracy: 0.7855\n",
      "Epoch 42/300\n",
      "2875/2875 [==============================] - 1s 220us/sample - loss: 0.4839 - accuracy: 0.7864 - val_loss: 0.5220 - val_accuracy: 0.7840\n",
      "Epoch 43/300\n",
      "2875/2875 [==============================] - 1s 241us/sample - loss: 0.4773 - accuracy: 0.7885 - val_loss: 0.5216 - val_accuracy: 0.7825\n",
      "Epoch 44/300\n",
      "2875/2875 [==============================] - 1s 220us/sample - loss: 0.4800 - accuracy: 0.7882 - val_loss: 0.5214 - val_accuracy: 0.7840\n",
      "Epoch 45/300\n",
      "2875/2875 [==============================] - 1s 204us/sample - loss: 0.4739 - accuracy: 0.7896 - val_loss: 0.5213 - val_accuracy: 0.7840\n",
      "Epoch 46/300\n",
      "2875/2875 [==============================] - 1s 217us/sample - loss: 0.4739 - accuracy: 0.7899 - val_loss: 0.5210 - val_accuracy: 0.7825\n",
      "Epoch 47/300\n",
      "2875/2875 [==============================] - 1s 217us/sample - loss: 0.4732 - accuracy: 0.7951 - val_loss: 0.5209 - val_accuracy: 0.7855\n",
      "Epoch 48/300\n",
      "2875/2875 [==============================] - 1s 237us/sample - loss: 0.4716 - accuracy: 0.7955 - val_loss: 0.5208 - val_accuracy: 0.7840\n",
      "Epoch 49/300\n",
      "2875/2875 [==============================] - 1s 214us/sample - loss: 0.4717 - accuracy: 0.7854 - val_loss: 0.5207 - val_accuracy: 0.7840\n",
      "Epoch 50/300\n",
      "2875/2875 [==============================] - 1s 213us/sample - loss: 0.4645 - accuracy: 0.7951 - val_loss: 0.5205 - val_accuracy: 0.7811\n",
      "Epoch 51/300\n",
      "2875/2875 [==============================] - 1s 223us/sample - loss: 0.4647 - accuracy: 0.7903 - val_loss: 0.5206 - val_accuracy: 0.7811\n",
      "Epoch 52/300\n",
      "2875/2875 [==============================] - 1s 233us/sample - loss: 0.4601 - accuracy: 0.7993 - val_loss: 0.5207 - val_accuracy: 0.7811\n",
      "Epoch 53/300\n",
      "2875/2875 [==============================] - 1s 228us/sample - loss: 0.4597 - accuracy: 0.7951 - val_loss: 0.5207 - val_accuracy: 0.7811\n",
      "Epoch 00053: early stopping\n",
      "98/98 [==============================] - 0s 198us/sample - loss: 0.2699 - accuracy: 0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [2:30:58, 992.91s/it] \n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.78s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.44s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 859.6328125 steps, validate for 198.4140625 steps\n",
      "Epoch 1/300\n",
      "860/859 [==============================] - 25s 29ms/step - loss: 0.5520 - accuracy: 0.7396 - val_loss: 0.5475 - val_accuracy: 0.7802\n",
      "Epoch 2/300\n",
      "860/859 [==============================] - 23s 27ms/step - loss: 0.5049 - accuracy: 0.7740 - val_loss: 0.5522 - val_accuracy: 0.7764\n",
      "Epoch 3/300\n",
      "860/859 [==============================] - 23s 27ms/step - loss: 0.4901 - accuracy: 0.7797 - val_loss: 0.5564 - val_accuracy: 0.7725\n",
      "Epoch 4/300\n",
      "860/859 [==============================] - 24s 27ms/step - loss: 0.4792 - accuracy: 0.7845 - val_loss: 0.5577 - val_accuracy: 0.7730\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 859.6328125 steps, validate for 198.4140625 steps\n",
      "Epoch 1/300\n",
      "860/859 [==============================] - 55s 64ms/step - loss: 0.4613 - accuracy: 0.7937 - val_loss: 0.6082 - val_accuracy: 0.7090\n",
      "Epoch 2/300\n",
      "860/859 [==============================] - 54s 63ms/step - loss: 0.4337 - accuracy: 0.8081 - val_loss: 0.5633 - val_accuracy: 0.7730\n",
      "Epoch 3/300\n",
      "860/859 [==============================] - 54s 62ms/step - loss: 0.4107 - accuracy: 0.8210 - val_loss: 0.5703 - val_accuracy: 0.7746\n",
      "Epoch 4/300\n",
      "860/859 [==============================] - 54s 63ms/step - loss: 0.3899 - accuracy: 0.8329 - val_loss: 0.5753 - val_accuracy: 0.7543\n",
      "Epoch 5/300\n",
      "860/859 [==============================] - 54s 62ms/step - loss: 0.3707 - accuracy: 0.8431 - val_loss: 0.5788 - val_accuracy: 0.7748\n",
      "Epoch 00005: early stopping\n",
      "87/87 [==============================] - 0s 3ms/sample - loss: 0.1812 - accuracy: 0.9655\n",
      "84/84 [==============================] - 0s 252us/sample - loss: 0.1667 - accuracy: 1.0000\n",
      "82/82 [==============================] - 0s 234us/sample - loss: 0.1934 - accuracy: 0.9634\n",
      "80/80 [==============================] - 0s 262us/sample - loss: 0.1990 - accuracy: 0.9500\n",
      "78/78 [==============================] - 0s 281us/sample - loss: 0.2240 - accuracy: 0.9615\n",
      "79/79 [==============================] - 0s 247us/sample - loss: 0.2020 - accuracy: 0.9873\n",
      "79/79 [==============================] - 0s 271us/sample - loss: 0.2160 - accuracy: 0.9620\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.2036 - accuracy: 0.9600\n",
      "72/72 [==============================] - 0s 293us/sample - loss: 0.1940 - accuracy: 1.0000\n",
      "72/72 [==============================] - 0s 374us/sample - loss: 0.1942 - accuracy: 0.9861\n",
      "73/73 [==============================] - 0s 258us/sample - loss: 0.2118 - accuracy: 0.9726\n",
      "74/74 [==============================] - 0s 279us/sample - loss: 0.1819 - accuracy: 1.0000\n",
      "73/73 [==============================] - 0s 263us/sample - loss: 0.2386 - accuracy: 0.9452\n",
      "70/70 [==============================] - 0s 255us/sample - loss: 0.2109 - accuracy: 0.9571\n",
      "70/70 [==============================] - 0s 256us/sample - loss: 0.1772 - accuracy: 0.9714\n",
      "71/71 [==============================] - 0s 248us/sample - loss: 0.2018 - accuracy: 0.9577\n",
      "72/72 [==============================] - 0s 279us/sample - loss: 0.2187 - accuracy: 0.9583\n",
      "73/73 [==============================] - 0s 268us/sample - loss: 0.1759 - accuracy: 0.9863\n",
      "70/70 [==============================] - 0s 352us/sample - loss: 0.1876 - accuracy: 0.9571\n",
      "70/70 [==============================] - 0s 296us/sample - loss: 0.1844 - accuracy: 0.9857\n",
      "68/68 [==============================] - 0s 263us/sample - loss: 0.2008 - accuracy: 0.9706\n",
      "66/66 [==============================] - 0s 295us/sample - loss: 0.1711 - accuracy: 0.9848\n",
      "67/67 [==============================] - 0s 264us/sample - loss: 0.1705 - accuracy: 0.9851\n",
      "66/66 [==============================] - 0s 289us/sample - loss: 0.1648 - accuracy: 0.9848\n",
      "65/65 [==============================] - 0s 338us/sample - loss: 0.1554 - accuracy: 0.9692\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.1850 - accuracy: 0.9688\n",
      "64/64 [==============================] - 0s 242us/sample - loss: 0.1686 - accuracy: 0.9844\n",
      "65/65 [==============================] - 0s 314us/sample - loss: 0.1804 - accuracy: 0.9846\n",
      "64/64 [==============================] - 0s 236us/sample - loss: 0.2036 - accuracy: 0.9688\n",
      "63/63 [==============================] - 0s 255us/sample - loss: 0.1853 - accuracy: 0.9841\n",
      "64/64 [==============================] - 0s 233us/sample - loss: 0.1684 - accuracy: 0.9844\n",
      "64/64 [==============================] - 0s 253us/sample - loss: 0.1578 - accuracy: 0.9844\n",
      "64/64 [==============================] - 0s 292us/sample - loss: 0.1657 - accuracy: 0.9688\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2908 samples, validate on 681 samples\n",
      "Epoch 1/300\n",
      "2908/2908 [==============================] - 2s 843us/sample - loss: 0.6619 - accuracy: 0.5942 - val_loss: 0.6504 - val_accuracy: 0.6226\n",
      "Epoch 2/300\n",
      "2908/2908 [==============================] - 1s 239us/sample - loss: 0.6291 - accuracy: 0.6534 - val_loss: 0.6298 - val_accuracy: 0.6814\n",
      "Epoch 3/300\n",
      "2908/2908 [==============================] - 1s 229us/sample - loss: 0.6058 - accuracy: 0.6854 - val_loss: 0.6152 - val_accuracy: 0.7048\n",
      "Epoch 4/300\n",
      "2908/2908 [==============================] - 1s 213us/sample - loss: 0.5927 - accuracy: 0.7115 - val_loss: 0.6039 - val_accuracy: 0.7019\n",
      "Epoch 5/300\n",
      "2908/2908 [==============================] - 1s 228us/sample - loss: 0.5806 - accuracy: 0.7170 - val_loss: 0.5945 - val_accuracy: 0.7195\n",
      "Epoch 6/300\n",
      "2908/2908 [==============================] - 1s 221us/sample - loss: 0.5685 - accuracy: 0.7338 - val_loss: 0.5865 - val_accuracy: 0.7269\n",
      "Epoch 7/300\n",
      "2908/2908 [==============================] - 1s 189us/sample - loss: 0.5629 - accuracy: 0.7500 - val_loss: 0.5795 - val_accuracy: 0.7416\n",
      "Epoch 8/300\n",
      "2908/2908 [==============================] - 1s 204us/sample - loss: 0.5515 - accuracy: 0.7541 - val_loss: 0.5732 - val_accuracy: 0.7548\n",
      "Epoch 9/300\n",
      "2908/2908 [==============================] - 1s 211us/sample - loss: 0.5413 - accuracy: 0.7613 - val_loss: 0.5678 - val_accuracy: 0.7636\n",
      "Epoch 10/300\n",
      "2908/2908 [==============================] - 1s 202us/sample - loss: 0.5387 - accuracy: 0.7651 - val_loss: 0.5628 - val_accuracy: 0.7695\n",
      "Epoch 11/300\n",
      "2908/2908 [==============================] - 1s 199us/sample - loss: 0.5237 - accuracy: 0.7754 - val_loss: 0.5583 - val_accuracy: 0.7739\n",
      "Epoch 12/300\n",
      "2908/2908 [==============================] - 1s 200us/sample - loss: 0.5223 - accuracy: 0.7751 - val_loss: 0.5541 - val_accuracy: 0.7797\n",
      "Epoch 13/300\n",
      "2908/2908 [==============================] - 1s 199us/sample - loss: 0.5138 - accuracy: 0.7779 - val_loss: 0.5503 - val_accuracy: 0.7812\n",
      "Epoch 14/300\n",
      "2908/2908 [==============================] - 1s 206us/sample - loss: 0.5083 - accuracy: 0.7851 - val_loss: 0.5469 - val_accuracy: 0.7797\n",
      "Epoch 15/300\n",
      "2908/2908 [==============================] - 1s 206us/sample - loss: 0.5003 - accuracy: 0.7895 - val_loss: 0.5437 - val_accuracy: 0.7812\n",
      "Epoch 16/300\n",
      "2908/2908 [==============================] - 1s 224us/sample - loss: 0.5008 - accuracy: 0.7854 - val_loss: 0.5409 - val_accuracy: 0.7797\n",
      "Epoch 17/300\n",
      "2908/2908 [==============================] - 1s 195us/sample - loss: 0.4942 - accuracy: 0.7909 - val_loss: 0.5383 - val_accuracy: 0.7812\n",
      "Epoch 18/300\n",
      "2908/2908 [==============================] - 1s 198us/sample - loss: 0.4864 - accuracy: 0.7920 - val_loss: 0.5357 - val_accuracy: 0.7812\n",
      "Epoch 19/300\n",
      "2908/2908 [==============================] - 1s 221us/sample - loss: 0.4839 - accuracy: 0.7999 - val_loss: 0.5335 - val_accuracy: 0.7841\n",
      "Epoch 20/300\n",
      "2908/2908 [==============================] - 1s 209us/sample - loss: 0.4757 - accuracy: 0.8030 - val_loss: 0.5314 - val_accuracy: 0.7856\n",
      "Epoch 21/300\n",
      "2908/2908 [==============================] - 1s 212us/sample - loss: 0.4706 - accuracy: 0.8036 - val_loss: 0.5295 - val_accuracy: 0.7841\n",
      "Epoch 22/300\n",
      "2908/2908 [==============================] - 1s 239us/sample - loss: 0.4677 - accuracy: 0.8036 - val_loss: 0.5277 - val_accuracy: 0.7841\n",
      "Epoch 23/300\n",
      "2908/2908 [==============================] - 1s 234us/sample - loss: 0.4648 - accuracy: 0.8078 - val_loss: 0.5262 - val_accuracy: 0.7841\n",
      "Epoch 24/300\n",
      "2908/2908 [==============================] - 1s 225us/sample - loss: 0.4629 - accuracy: 0.8064 - val_loss: 0.5248 - val_accuracy: 0.7827\n",
      "Epoch 25/300\n",
      "2908/2908 [==============================] - 1s 220us/sample - loss: 0.4535 - accuracy: 0.8126 - val_loss: 0.5235 - val_accuracy: 0.7856\n",
      "Epoch 26/300\n",
      "2908/2908 [==============================] - 1s 224us/sample - loss: 0.4522 - accuracy: 0.8074 - val_loss: 0.5224 - val_accuracy: 0.7856\n",
      "Epoch 27/300\n",
      "2908/2908 [==============================] - 1s 227us/sample - loss: 0.4483 - accuracy: 0.8119 - val_loss: 0.5213 - val_accuracy: 0.7856\n",
      "Epoch 28/300\n",
      "2908/2908 [==============================] - 1s 215us/sample - loss: 0.4459 - accuracy: 0.8150 - val_loss: 0.5205 - val_accuracy: 0.7856\n",
      "Epoch 29/300\n",
      "2908/2908 [==============================] - 1s 219us/sample - loss: 0.4414 - accuracy: 0.8164 - val_loss: 0.5196 - val_accuracy: 0.7856\n",
      "Epoch 30/300\n",
      "2908/2908 [==============================] - 1s 218us/sample - loss: 0.4383 - accuracy: 0.8143 - val_loss: 0.5190 - val_accuracy: 0.7856\n",
      "Epoch 31/300\n",
      "2908/2908 [==============================] - 1s 221us/sample - loss: 0.4353 - accuracy: 0.8150 - val_loss: 0.5183 - val_accuracy: 0.7856\n",
      "Epoch 32/300\n",
      "2908/2908 [==============================] - 1s 222us/sample - loss: 0.4305 - accuracy: 0.8205 - val_loss: 0.5179 - val_accuracy: 0.7841\n",
      "Epoch 33/300\n",
      "2908/2908 [==============================] - 1s 207us/sample - loss: 0.4290 - accuracy: 0.8208 - val_loss: 0.5175 - val_accuracy: 0.7856\n",
      "Epoch 34/300\n",
      "2908/2908 [==============================] - 1s 206us/sample - loss: 0.4246 - accuracy: 0.8212 - val_loss: 0.5172 - val_accuracy: 0.7885\n",
      "Epoch 35/300\n",
      "2908/2908 [==============================] - 1s 217us/sample - loss: 0.4201 - accuracy: 0.8239 - val_loss: 0.5170 - val_accuracy: 0.7871\n",
      "Epoch 36/300\n",
      "2908/2908 [==============================] - 1s 220us/sample - loss: 0.4204 - accuracy: 0.8253 - val_loss: 0.5168 - val_accuracy: 0.7841\n",
      "Epoch 37/300\n",
      "2908/2908 [==============================] - 1s 218us/sample - loss: 0.4150 - accuracy: 0.8205 - val_loss: 0.5167 - val_accuracy: 0.7841\n",
      "Epoch 38/300\n",
      "2908/2908 [==============================] - 1s 216us/sample - loss: 0.4108 - accuracy: 0.8274 - val_loss: 0.5167 - val_accuracy: 0.7841\n",
      "Epoch 39/300\n",
      "2908/2908 [==============================] - 1s 208us/sample - loss: 0.4085 - accuracy: 0.8260 - val_loss: 0.5167 - val_accuracy: 0.7827\n",
      "Epoch 40/300\n",
      "2908/2908 [==============================] - 1s 216us/sample - loss: 0.4060 - accuracy: 0.8294 - val_loss: 0.5168 - val_accuracy: 0.7812\n",
      "Epoch 41/300\n",
      "2908/2908 [==============================] - 1s 210us/sample - loss: 0.4037 - accuracy: 0.8343 - val_loss: 0.5171 - val_accuracy: 0.7812\n",
      "Epoch 00041: early stopping\n",
      "60/60 [==============================] - 0s 179us/sample - loss: 0.2286 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [2:47:50, 998.85s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.56s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.36s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 854.0859375 steps, validate for 196.6171875 steps\n",
      "Epoch 1/300\n",
      "855/854 [==============================] - 24s 28ms/step - loss: 0.5980 - accuracy: 0.6946 - val_loss: 0.5527 - val_accuracy: 0.7742\n",
      "Epoch 2/300\n",
      "855/854 [==============================] - 23s 27ms/step - loss: 0.5094 - accuracy: 0.7730 - val_loss: 0.5480 - val_accuracy: 0.7772\n",
      "Epoch 3/300\n",
      "855/854 [==============================] - 23s 27ms/step - loss: 0.4934 - accuracy: 0.7790 - val_loss: 0.5540 - val_accuracy: 0.7733\n",
      "Epoch 4/300\n",
      "855/854 [==============================] - 23s 27ms/step - loss: 0.4819 - accuracy: 0.7839 - val_loss: 0.5583 - val_accuracy: 0.7664\n",
      "Epoch 5/300\n",
      "855/854 [==============================] - 23s 27ms/step - loss: 0.4720 - accuracy: 0.7881 - val_loss: 0.5590 - val_accuracy: 0.7669\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 854.0859375 steps, validate for 196.6171875 steps\n",
      "Epoch 1/300\n",
      "855/854 [==============================] - 55s 64ms/step - loss: 0.4552 - accuracy: 0.7962 - val_loss: 0.5572 - val_accuracy: 0.7683\n",
      "Epoch 2/300\n",
      "855/854 [==============================] - 53s 62ms/step - loss: 0.4295 - accuracy: 0.8102 - val_loss: 0.5792 - val_accuracy: 0.7412\n",
      "Epoch 3/300\n",
      "855/854 [==============================] - 54s 63ms/step - loss: 0.4077 - accuracy: 0.8227 - val_loss: 0.5713 - val_accuracy: 0.7672\n",
      "Epoch 4/300\n",
      "855/854 [==============================] - 54s 64ms/step - loss: 0.3880 - accuracy: 0.8344 - val_loss: 0.5867 - val_accuracy: 0.7544\n",
      "Epoch 00004: early stopping\n",
      "127/127 [==============================] - 0s 2ms/sample - loss: 0.3056 - accuracy: 0.9370\n",
      "126/126 [==============================] - 0s 222us/sample - loss: 0.3345 - accuracy: 0.8968\n",
      "126/126 [==============================] - 0s 249us/sample - loss: 0.3340 - accuracy: 0.8810\n",
      "126/126 [==============================] - 0s 226us/sample - loss: 0.3594 - accuracy: 0.8492\n",
      "118/118 [==============================] - 0s 247us/sample - loss: 0.3300 - accuracy: 0.8983\n",
      "110/110 [==============================] - 0s 251us/sample - loss: 0.3316 - accuracy: 0.9000\n",
      "108/108 [==============================] - 0s 256us/sample - loss: 0.3261 - accuracy: 0.9167\n",
      "103/103 [==============================] - 0s 282us/sample - loss: 0.3095 - accuracy: 0.9029\n",
      "100/100 [==============================] - 0s 265us/sample - loss: 0.3190 - accuracy: 0.9200\n",
      "98/98 [==============================] - 0s 282us/sample - loss: 0.3191 - accuracy: 0.9286\n",
      "98/98 [==============================] - 0s 287us/sample - loss: 0.2995 - accuracy: 0.9490\n",
      "97/97 [==============================] - 0s 308us/sample - loss: 0.3135 - accuracy: 0.9072\n",
      "97/97 [==============================] - 0s 319us/sample - loss: 0.3678 - accuracy: 0.8351\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.3054 - accuracy: 0.9375\n",
      "97/97 [==============================] - 0s 282us/sample - loss: 0.3672 - accuracy: 0.8660\n",
      "96/96 [==============================] - 0s 242us/sample - loss: 0.3027 - accuracy: 0.9479\n",
      "94/94 [==============================] - 0s 254us/sample - loss: 0.3261 - accuracy: 0.9255\n",
      "94/94 [==============================] - 0s 255us/sample - loss: 0.3060 - accuracy: 0.9255\n",
      "92/92 [==============================] - 0s 246us/sample - loss: 0.3455 - accuracy: 0.8696\n",
      "94/94 [==============================] - 0s 284us/sample - loss: 0.2607 - accuracy: 0.9574\n",
      "92/92 [==============================] - 0s 240us/sample - loss: 0.2932 - accuracy: 0.9457\n",
      "90/90 [==============================] - 0s 237us/sample - loss: 0.2754 - accuracy: 0.9333\n",
      "92/92 [==============================] - 0s 242us/sample - loss: 0.3031 - accuracy: 0.9457\n",
      "92/92 [==============================] - 0s 302us/sample - loss: 0.2860 - accuracy: 0.9348\n",
      "94/94 [==============================] - 0s 237us/sample - loss: 0.2874 - accuracy: 0.9468\n",
      "93/93 [==============================] - 0s 248us/sample - loss: 0.3210 - accuracy: 0.9462\n",
      "94/94 [==============================] - 0s 250us/sample - loss: 0.3228 - accuracy: 0.9362\n",
      "93/93 [==============================] - 0s 275us/sample - loss: 0.2678 - accuracy: 0.9570\n",
      "91/91 [==============================] - 0s 240us/sample - loss: 0.2624 - accuracy: 0.9560\n",
      "92/92 [==============================] - 0s 257us/sample - loss: 0.2885 - accuracy: 0.9348\n",
      "90/90 [==============================] - 0s 269us/sample - loss: 0.2677 - accuracy: 0.9667\n",
      "89/89 [==============================] - 0s 256us/sample - loss: 0.2809 - accuracy: 0.9551\n",
      "89/89 [==============================] - 0s 270us/sample - loss: 0.2920 - accuracy: 0.9438\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2900 samples, validate on 674 samples\n",
      "Epoch 1/300\n",
      "2900/2900 [==============================] - 2s 833us/sample - loss: 0.7108 - accuracy: 0.5179 - val_loss: 0.7086 - val_accuracy: 0.5015\n",
      "Epoch 2/300\n",
      "2900/2900 [==============================] - 1s 200us/sample - loss: 0.6753 - accuracy: 0.5876 - val_loss: 0.6842 - val_accuracy: 0.5727\n",
      "Epoch 3/300\n",
      "2900/2900 [==============================] - 1s 195us/sample - loss: 0.6539 - accuracy: 0.6214 - val_loss: 0.6671 - val_accuracy: 0.6098\n",
      "Epoch 4/300\n",
      "2900/2900 [==============================] - 1s 194us/sample - loss: 0.6360 - accuracy: 0.6624 - val_loss: 0.6542 - val_accuracy: 0.6365\n",
      "Epoch 5/300\n",
      "2900/2900 [==============================] - 1s 200us/sample - loss: 0.6205 - accuracy: 0.6783 - val_loss: 0.6430 - val_accuracy: 0.6558\n",
      "Epoch 6/300\n",
      "2900/2900 [==============================] - 1s 220us/sample - loss: 0.6069 - accuracy: 0.7038 - val_loss: 0.6335 - val_accuracy: 0.6677\n",
      "Epoch 7/300\n",
      "2900/2900 [==============================] - 1s 210us/sample - loss: 0.5989 - accuracy: 0.7097 - val_loss: 0.6251 - val_accuracy: 0.6736\n",
      "Epoch 8/300\n",
      "2900/2900 [==============================] - 1s 198us/sample - loss: 0.5904 - accuracy: 0.7241 - val_loss: 0.6177 - val_accuracy: 0.6929\n",
      "Epoch 9/300\n",
      "2900/2900 [==============================] - 1s 212us/sample - loss: 0.5784 - accuracy: 0.7400 - val_loss: 0.6109 - val_accuracy: 0.7062\n",
      "Epoch 10/300\n",
      "2900/2900 [==============================] - 1s 208us/sample - loss: 0.5696 - accuracy: 0.7455 - val_loss: 0.6048 - val_accuracy: 0.7122\n",
      "Epoch 11/300\n",
      "2900/2900 [==============================] - 1s 188us/sample - loss: 0.5613 - accuracy: 0.7500 - val_loss: 0.5993 - val_accuracy: 0.7166\n",
      "Epoch 12/300\n",
      "2900/2900 [==============================] - 1s 198us/sample - loss: 0.5546 - accuracy: 0.7552 - val_loss: 0.5941 - val_accuracy: 0.7122\n",
      "Epoch 13/300\n",
      "2900/2900 [==============================] - 1s 209us/sample - loss: 0.5512 - accuracy: 0.7600 - val_loss: 0.5893 - val_accuracy: 0.7196\n",
      "Epoch 14/300\n",
      "2900/2900 [==============================] - 1s 208us/sample - loss: 0.5442 - accuracy: 0.7559 - val_loss: 0.5849 - val_accuracy: 0.7315\n",
      "Epoch 15/300\n",
      "2900/2900 [==============================] - 1s 194us/sample - loss: 0.5390 - accuracy: 0.7648 - val_loss: 0.5809 - val_accuracy: 0.7329\n",
      "Epoch 16/300\n",
      "2900/2900 [==============================] - 1s 234us/sample - loss: 0.5290 - accuracy: 0.7707 - val_loss: 0.5771 - val_accuracy: 0.7344\n",
      "Epoch 17/300\n",
      "2900/2900 [==============================] - 1s 206us/sample - loss: 0.5275 - accuracy: 0.7786 - val_loss: 0.5736 - val_accuracy: 0.7389\n",
      "Epoch 18/300\n",
      "2900/2900 [==============================] - 1s 197us/sample - loss: 0.5218 - accuracy: 0.7800 - val_loss: 0.5703 - val_accuracy: 0.7433\n",
      "Epoch 19/300\n",
      "2900/2900 [==============================] - 1s 191us/sample - loss: 0.5180 - accuracy: 0.7834 - val_loss: 0.5672 - val_accuracy: 0.7448\n",
      "Epoch 20/300\n",
      "2900/2900 [==============================] - 1s 185us/sample - loss: 0.5107 - accuracy: 0.7872 - val_loss: 0.5644 - val_accuracy: 0.7463\n",
      "Epoch 21/300\n",
      "2900/2900 [==============================] - 1s 216us/sample - loss: 0.5048 - accuracy: 0.7872 - val_loss: 0.5620 - val_accuracy: 0.7522\n",
      "Epoch 22/300\n",
      "2900/2900 [==============================] - 1s 238us/sample - loss: 0.5018 - accuracy: 0.7859 - val_loss: 0.5596 - val_accuracy: 0.7537\n",
      "Epoch 23/300\n",
      "2900/2900 [==============================] - 1s 233us/sample - loss: 0.4943 - accuracy: 0.7900 - val_loss: 0.5574 - val_accuracy: 0.7493\n",
      "Epoch 24/300\n",
      "2900/2900 [==============================] - 1s 230us/sample - loss: 0.4920 - accuracy: 0.8007 - val_loss: 0.5555 - val_accuracy: 0.7537\n",
      "Epoch 25/300\n",
      "2900/2900 [==============================] - 1s 222us/sample - loss: 0.4874 - accuracy: 0.8000 - val_loss: 0.5537 - val_accuracy: 0.7552\n",
      "Epoch 26/300\n",
      "2900/2900 [==============================] - 1s 218us/sample - loss: 0.4810 - accuracy: 0.8010 - val_loss: 0.5520 - val_accuracy: 0.7567\n",
      "Epoch 27/300\n",
      "2900/2900 [==============================] - 1s 209us/sample - loss: 0.4813 - accuracy: 0.7986 - val_loss: 0.5507 - val_accuracy: 0.7596\n",
      "Epoch 28/300\n",
      "2900/2900 [==============================] - 1s 229us/sample - loss: 0.4750 - accuracy: 0.8017 - val_loss: 0.5493 - val_accuracy: 0.7626\n",
      "Epoch 29/300\n",
      "2900/2900 [==============================] - 1s 211us/sample - loss: 0.4719 - accuracy: 0.8034 - val_loss: 0.5481 - val_accuracy: 0.7611\n",
      "Epoch 30/300\n",
      "2900/2900 [==============================] - 1s 220us/sample - loss: 0.4673 - accuracy: 0.8097 - val_loss: 0.5471 - val_accuracy: 0.7626\n",
      "Epoch 31/300\n",
      "2900/2900 [==============================] - 1s 215us/sample - loss: 0.4612 - accuracy: 0.8128 - val_loss: 0.5463 - val_accuracy: 0.7626\n",
      "Epoch 32/300\n",
      "2900/2900 [==============================] - 1s 225us/sample - loss: 0.4626 - accuracy: 0.8059 - val_loss: 0.5455 - val_accuracy: 0.7641\n",
      "Epoch 33/300\n",
      "2900/2900 [==============================] - 1s 214us/sample - loss: 0.4576 - accuracy: 0.8076 - val_loss: 0.5449 - val_accuracy: 0.7611\n",
      "Epoch 34/300\n",
      "2900/2900 [==============================] - 1s 203us/sample - loss: 0.4548 - accuracy: 0.8131 - val_loss: 0.5444 - val_accuracy: 0.7596\n",
      "Epoch 35/300\n",
      "2900/2900 [==============================] - 1s 222us/sample - loss: 0.4528 - accuracy: 0.8117 - val_loss: 0.5440 - val_accuracy: 0.7596\n",
      "Epoch 36/300\n",
      "2900/2900 [==============================] - 1s 227us/sample - loss: 0.4473 - accuracy: 0.8186 - val_loss: 0.5437 - val_accuracy: 0.7596\n",
      "Epoch 37/300\n",
      "2900/2900 [==============================] - 1s 188us/sample - loss: 0.4479 - accuracy: 0.8162 - val_loss: 0.5435 - val_accuracy: 0.7596\n",
      "Epoch 38/300\n",
      "2900/2900 [==============================] - 1s 227us/sample - loss: 0.4420 - accuracy: 0.8169 - val_loss: 0.5434 - val_accuracy: 0.7582\n",
      "Epoch 39/300\n",
      "2900/2900 [==============================] - 1s 207us/sample - loss: 0.4430 - accuracy: 0.8131 - val_loss: 0.5433 - val_accuracy: 0.7596\n",
      "Epoch 40/300\n",
      "2900/2900 [==============================] - 1s 214us/sample - loss: 0.4368 - accuracy: 0.8155 - val_loss: 0.5434 - val_accuracy: 0.7611\n",
      "Epoch 41/300\n",
      "2900/2900 [==============================] - 1s 214us/sample - loss: 0.4363 - accuracy: 0.8224 - val_loss: 0.5435 - val_accuracy: 0.7611\n",
      "Epoch 42/300\n",
      "2900/2900 [==============================] - 1s 196us/sample - loss: 0.4319 - accuracy: 0.8234 - val_loss: 0.5437 - val_accuracy: 0.7596\n",
      "Epoch 00042: early stopping\n",
      "75/75 [==============================] - 0s 157us/sample - loss: 0.2851 - accuracy: 0.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [3:04:33, 999.88s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.31s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.13s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 844.859375 steps, validate for 197.828125 steps\n",
      "Epoch 1/300\n",
      "845/844 [==============================] - 24s 29ms/step - loss: 0.5533 - accuracy: 0.7400 - val_loss: 0.5456 - val_accuracy: 0.7763\n",
      "Epoch 2/300\n",
      "845/844 [==============================] - 23s 28ms/step - loss: 0.5059 - accuracy: 0.7723 - val_loss: 0.5480 - val_accuracy: 0.7741\n",
      "Epoch 3/300\n",
      "845/844 [==============================] - 24s 28ms/step - loss: 0.4919 - accuracy: 0.7780 - val_loss: 0.5512 - val_accuracy: 0.7689\n",
      "Epoch 4/300\n",
      "845/844 [==============================] - 24s 28ms/step - loss: 0.4807 - accuracy: 0.7828 - val_loss: 0.5543 - val_accuracy: 0.7656\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 844.859375 steps, validate for 197.828125 steps\n",
      "Epoch 1/300\n",
      "845/844 [==============================] - 55s 65ms/step - loss: 0.4626 - accuracy: 0.7925 - val_loss: 0.5531 - val_accuracy: 0.7710\n",
      "Epoch 2/300\n",
      "845/844 [==============================] - 53s 63ms/step - loss: 0.4356 - accuracy: 0.8057 - val_loss: 0.5886 - val_accuracy: 0.7281\n",
      "Epoch 3/300\n",
      "845/844 [==============================] - 54s 63ms/step - loss: 0.4119 - accuracy: 0.8192 - val_loss: 0.5790 - val_accuracy: 0.7687\n",
      "Epoch 4/300\n",
      "845/844 [==============================] - 54s 63ms/step - loss: 0.3906 - accuracy: 0.8321 - val_loss: 0.5780 - val_accuracy: 0.7498\n",
      "Epoch 00004: early stopping\n",
      "144/144 [==============================] - 0s 2ms/sample - loss: 0.2326 - accuracy: 0.9444\n",
      "138/138 [==============================] - 0s 234us/sample - loss: 0.2483 - accuracy: 0.9420\n",
      "138/138 [==============================] - 0s 241us/sample - loss: 0.2901 - accuracy: 0.9420\n",
      "137/137 [==============================] - 0s 276us/sample - loss: 0.2670 - accuracy: 0.9489\n",
      "137/137 [==============================] - 0s 214us/sample - loss: 0.2934 - accuracy: 0.9197\n",
      "137/137 [==============================] - 0s 240us/sample - loss: 0.2780 - accuracy: 0.9270\n",
      "136/136 [==============================] - 0s 230us/sample - loss: 0.2798 - accuracy: 0.9485\n",
      "135/135 [==============================] - 0s 230us/sample - loss: 0.3176 - accuracy: 0.9111\n",
      "133/133 [==============================] - 0s 232us/sample - loss: 0.3273 - accuracy: 0.9173\n",
      "134/134 [==============================] - 0s 244us/sample - loss: 0.3380 - accuracy: 0.9254\n",
      "134/134 [==============================] - 0s 248us/sample - loss: 0.3423 - accuracy: 0.8881\n",
      "133/133 [==============================] - 0s 263us/sample - loss: 0.3583 - accuracy: 0.9173\n",
      "133/133 [==============================] - 0s 284us/sample - loss: 0.3244 - accuracy: 0.9248\n",
      "133/133 [==============================] - 0s 273us/sample - loss: 0.3484 - accuracy: 0.8872\n",
      "129/129 [==============================] - 0s 288us/sample - loss: 0.3496 - accuracy: 0.8992\n",
      "129/129 [==============================] - 0s 270us/sample - loss: 0.3477 - accuracy: 0.9070\n",
      "132/132 [==============================] - 0s 285us/sample - loss: 0.3219 - accuracy: 0.9242\n",
      "129/129 [==============================] - 0s 266us/sample - loss: 0.3389 - accuracy: 0.9380\n",
      "131/131 [==============================] - 0s 273us/sample - loss: 0.3098 - accuracy: 0.9389\n",
      "130/130 [==============================] - 0s 293us/sample - loss: 0.2736 - accuracy: 0.9231\n",
      "129/129 [==============================] - 0s 256us/sample - loss: 0.3045 - accuracy: 0.9612\n",
      "127/127 [==============================] - 0s 243us/sample - loss: 0.2946 - accuracy: 0.9606\n",
      "124/124 [==============================] - 0s 254us/sample - loss: 0.3300 - accuracy: 0.9355\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.3150 - accuracy: 0.9297\n",
      "128/128 [==============================] - 0s 226us/sample - loss: 0.3183 - accuracy: 0.9141\n",
      "126/126 [==============================] - 0s 272us/sample - loss: 0.3396 - accuracy: 0.9127\n",
      "124/124 [==============================] - 0s 275us/sample - loss: 0.2923 - accuracy: 0.9113\n",
      "124/124 [==============================] - 0s 243us/sample - loss: 0.3083 - accuracy: 0.9194\n",
      "124/124 [==============================] - 0s 263us/sample - loss: 0.3261 - accuracy: 0.9274\n",
      "125/125 [==============================] - 0s 249us/sample - loss: 0.3584 - accuracy: 0.8960\n",
      "126/126 [==============================] - 0s 257us/sample - loss: 0.3366 - accuracy: 0.9206\n",
      "123/123 [==============================] - 0s 260us/sample - loss: 0.3156 - accuracy: 0.9187\n",
      "124/124 [==============================] - 0s 289us/sample - loss: 0.2974 - accuracy: 0.9435\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2854 samples, validate on 678 samples\n",
      "Epoch 1/300\n",
      "2854/2854 [==============================] - 3s 889us/sample - loss: 0.6757 - accuracy: 0.5792 - val_loss: 0.6774 - val_accuracy: 0.5605\n",
      "Epoch 2/300\n",
      "2854/2854 [==============================] - 1s 243us/sample - loss: 0.6372 - accuracy: 0.6328 - val_loss: 0.6499 - val_accuracy: 0.6091\n",
      "Epoch 3/300\n",
      "2854/2854 [==============================] - 1s 229us/sample - loss: 0.6114 - accuracy: 0.6689 - val_loss: 0.6314 - val_accuracy: 0.6416\n",
      "Epoch 4/300\n",
      "2854/2854 [==============================] - 1s 240us/sample - loss: 0.5977 - accuracy: 0.6899 - val_loss: 0.6175 - val_accuracy: 0.6593\n",
      "Epoch 5/300\n",
      "2854/2854 [==============================] - 1s 266us/sample - loss: 0.5842 - accuracy: 0.7158 - val_loss: 0.6064 - val_accuracy: 0.6799\n",
      "Epoch 6/300\n",
      "2854/2854 [==============================] - 1s 236us/sample - loss: 0.5691 - accuracy: 0.7246 - val_loss: 0.5974 - val_accuracy: 0.6991\n",
      "Epoch 7/300\n",
      "2854/2854 [==============================] - 1s 236us/sample - loss: 0.5611 - accuracy: 0.7369 - val_loss: 0.5898 - val_accuracy: 0.7065\n",
      "Epoch 8/300\n",
      "2854/2854 [==============================] - 1s 251us/sample - loss: 0.5515 - accuracy: 0.7498 - val_loss: 0.5830 - val_accuracy: 0.7227\n",
      "Epoch 9/300\n",
      "2854/2854 [==============================] - 1s 240us/sample - loss: 0.5416 - accuracy: 0.7582 - val_loss: 0.5775 - val_accuracy: 0.7257\n",
      "Epoch 10/300\n",
      "2854/2854 [==============================] - 1s 244us/sample - loss: 0.5372 - accuracy: 0.7610 - val_loss: 0.5726 - val_accuracy: 0.7301\n",
      "Epoch 11/300\n",
      "2854/2854 [==============================] - 1s 234us/sample - loss: 0.5296 - accuracy: 0.7635 - val_loss: 0.5683 - val_accuracy: 0.7316\n",
      "Epoch 12/300\n",
      "2854/2854 [==============================] - 1s 205us/sample - loss: 0.5257 - accuracy: 0.7694 - val_loss: 0.5645 - val_accuracy: 0.7330\n",
      "Epoch 13/300\n",
      "2854/2854 [==============================] - 1s 212us/sample - loss: 0.5158 - accuracy: 0.7715 - val_loss: 0.5611 - val_accuracy: 0.7345\n",
      "Epoch 14/300\n",
      "2854/2854 [==============================] - 1s 194us/sample - loss: 0.5129 - accuracy: 0.7737 - val_loss: 0.5582 - val_accuracy: 0.7375\n",
      "Epoch 15/300\n",
      "2854/2854 [==============================] - 1s 233us/sample - loss: 0.5100 - accuracy: 0.7747 - val_loss: 0.5555 - val_accuracy: 0.7419\n",
      "Epoch 16/300\n",
      "2854/2854 [==============================] - 1s 222us/sample - loss: 0.5058 - accuracy: 0.7796 - val_loss: 0.5530 - val_accuracy: 0.7448\n",
      "Epoch 17/300\n",
      "2854/2854 [==============================] - 1s 241us/sample - loss: 0.4991 - accuracy: 0.7870 - val_loss: 0.5510 - val_accuracy: 0.7448\n",
      "Epoch 18/300\n",
      "2854/2854 [==============================] - 1s 231us/sample - loss: 0.4978 - accuracy: 0.7845 - val_loss: 0.5492 - val_accuracy: 0.7463\n",
      "Epoch 19/300\n",
      "2854/2854 [==============================] - 1s 205us/sample - loss: 0.4948 - accuracy: 0.7905 - val_loss: 0.5475 - val_accuracy: 0.7463\n",
      "Epoch 20/300\n",
      "2854/2854 [==============================] - 1s 251us/sample - loss: 0.4898 - accuracy: 0.7887 - val_loss: 0.5462 - val_accuracy: 0.7463\n",
      "Epoch 21/300\n",
      "2854/2854 [==============================] - 1s 218us/sample - loss: 0.4847 - accuracy: 0.7926 - val_loss: 0.5450 - val_accuracy: 0.7493\n",
      "Epoch 22/300\n",
      "2854/2854 [==============================] - 1s 231us/sample - loss: 0.4828 - accuracy: 0.7919 - val_loss: 0.5439 - val_accuracy: 0.7537\n",
      "Epoch 23/300\n",
      "2854/2854 [==============================] - 1s 255us/sample - loss: 0.4788 - accuracy: 0.7898 - val_loss: 0.5431 - val_accuracy: 0.7522\n",
      "Epoch 24/300\n",
      "2854/2854 [==============================] - 1s 261us/sample - loss: 0.4793 - accuracy: 0.7964 - val_loss: 0.5423 - val_accuracy: 0.7537\n",
      "Epoch 25/300\n",
      "2854/2854 [==============================] - 1s 231us/sample - loss: 0.4734 - accuracy: 0.7985 - val_loss: 0.5417 - val_accuracy: 0.7522\n",
      "Epoch 26/300\n",
      "2854/2854 [==============================] - 1s 246us/sample - loss: 0.4719 - accuracy: 0.8017 - val_loss: 0.5412 - val_accuracy: 0.7552\n",
      "Epoch 27/300\n",
      "2854/2854 [==============================] - 1s 236us/sample - loss: 0.4709 - accuracy: 0.7933 - val_loss: 0.5408 - val_accuracy: 0.7522\n",
      "Epoch 28/300\n",
      "2854/2854 [==============================] - 1s 229us/sample - loss: 0.4639 - accuracy: 0.8041 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
      "Epoch 29/300\n",
      "2854/2854 [==============================] - 1s 223us/sample - loss: 0.4601 - accuracy: 0.7989 - val_loss: 0.5403 - val_accuracy: 0.7566\n",
      "Epoch 30/300\n",
      "2854/2854 [==============================] - 1s 241us/sample - loss: 0.4573 - accuracy: 0.8059 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
      "Epoch 31/300\n",
      "2854/2854 [==============================] - 1s 238us/sample - loss: 0.4517 - accuracy: 0.8101 - val_loss: 0.5402 - val_accuracy: 0.7581\n",
      "Epoch 32/300\n",
      "2854/2854 [==============================] - 1s 256us/sample - loss: 0.4551 - accuracy: 0.8045 - val_loss: 0.5402 - val_accuracy: 0.7566\n",
      "Epoch 33/300\n",
      "2854/2854 [==============================] - 1s 252us/sample - loss: 0.4500 - accuracy: 0.8090 - val_loss: 0.5404 - val_accuracy: 0.7566\n",
      "Epoch 00033: early stopping\n",
      "117/117 [==============================] - 0s 194us/sample - loss: 0.3168 - accuracy: 0.9573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [3:20:45, 991.76s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.65s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.31s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 848.8984375 steps, validate for 195.53125 steps\n",
      "Epoch 1/300\n",
      "849/848 [==============================] - 25s 29ms/step - loss: 0.5844 - accuracy: 0.7054 - val_loss: 0.5623 - val_accuracy: 0.7689\n",
      "Epoch 2/300\n",
      "849/848 [==============================] - 23s 27ms/step - loss: 0.5103 - accuracy: 0.7706 - val_loss: 0.5578 - val_accuracy: 0.7725\n",
      "Epoch 3/300\n",
      "849/848 [==============================] - 23s 27ms/step - loss: 0.4965 - accuracy: 0.7760 - val_loss: 0.5607 - val_accuracy: 0.7719\n",
      "Epoch 4/300\n",
      "849/848 [==============================] - 23s 27ms/step - loss: 0.4862 - accuracy: 0.7804 - val_loss: 0.5629 - val_accuracy: 0.7692\n",
      "Epoch 5/300\n",
      "849/848 [==============================] - 23s 28ms/step - loss: 0.4775 - accuracy: 0.7845 - val_loss: 0.5649 - val_accuracy: 0.7677\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 848.8984375 steps, validate for 195.53125 steps\n",
      "Epoch 1/300\n",
      "849/848 [==============================] - 56s 66ms/step - loss: 0.4607 - accuracy: 0.7927 - val_loss: 0.5679 - val_accuracy: 0.7599\n",
      "Epoch 2/300\n",
      "849/848 [==============================] - 54s 64ms/step - loss: 0.4340 - accuracy: 0.8066 - val_loss: 0.6050 - val_accuracy: 0.7799\n",
      "Epoch 3/300\n",
      "849/848 [==============================] - 53s 63ms/step - loss: 0.4109 - accuracy: 0.8188 - val_loss: 0.5735 - val_accuracy: 0.7528\n",
      "Epoch 4/300\n",
      "849/848 [==============================] - 53s 63ms/step - loss: 0.3894 - accuracy: 0.8301 - val_loss: 0.6116 - val_accuracy: 0.7684\n",
      "Epoch 00004: early stopping\n",
      "134/134 [==============================] - 0s 2ms/sample - loss: 0.1656 - accuracy: 0.9925\n",
      "134/134 [==============================] - 0s 219us/sample - loss: 0.1811 - accuracy: 0.9851\n",
      "131/131 [==============================] - 0s 267us/sample - loss: 0.2010 - accuracy: 0.9847\n",
      "129/129 [==============================] - 0s 251us/sample - loss: 0.1815 - accuracy: 0.9922\n",
      "129/129 [==============================] - 0s 242us/sample - loss: 0.1836 - accuracy: 0.9845\n",
      "129/129 [==============================] - 0s 245us/sample - loss: 0.1839 - accuracy: 0.9767\n",
      "128/128 [==============================] - 0s 1ms/sample - loss: 0.1649 - accuracy: 0.9922\n",
      "126/126 [==============================] - 0s 237us/sample - loss: 0.1979 - accuracy: 1.0000\n",
      "125/125 [==============================] - 0s 227us/sample - loss: 0.1791 - accuracy: 0.9920\n",
      "126/126 [==============================] - 0s 214us/sample - loss: 0.1732 - accuracy: 0.9841\n",
      "126/126 [==============================] - 0s 198us/sample - loss: 0.1733 - accuracy: 0.9921\n",
      "126/126 [==============================] - 0s 244us/sample - loss: 0.1547 - accuracy: 0.9921\n",
      "125/125 [==============================] - 0s 227us/sample - loss: 0.1747 - accuracy: 0.9760\n",
      "126/126 [==============================] - 0s 224us/sample - loss: 0.1886 - accuracy: 0.9762\n",
      "123/123 [==============================] - 0s 244us/sample - loss: 0.1721 - accuracy: 0.9675\n",
      "121/121 [==============================] - 0s 238us/sample - loss: 0.1543 - accuracy: 0.9835\n",
      "122/122 [==============================] - 0s 230us/sample - loss: 0.1749 - accuracy: 0.9836\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 0.1619 - accuracy: 0.9833\n",
      "121/121 [==============================] - 0s 246us/sample - loss: 0.1819 - accuracy: 0.9835\n",
      "121/121 [==============================] - 0s 232us/sample - loss: 0.1678 - accuracy: 0.9917\n",
      "123/123 [==============================] - 0s 249us/sample - loss: 0.1722 - accuracy: 0.9756\n",
      "123/123 [==============================] - 0s 236us/sample - loss: 0.1922 - accuracy: 0.9756\n",
      "123/123 [==============================] - 0s 230us/sample - loss: 0.1718 - accuracy: 0.9837\n",
      "122/122 [==============================] - 0s 236us/sample - loss: 0.1779 - accuracy: 0.9590\n",
      "122/122 [==============================] - 0s 267us/sample - loss: 0.1745 - accuracy: 0.9590\n",
      "121/121 [==============================] - 0s 243us/sample - loss: 0.1999 - accuracy: 0.9669\n",
      "119/119 [==============================] - 0s 248us/sample - loss: 0.1650 - accuracy: 0.9748\n",
      "119/119 [==============================] - 0s 242us/sample - loss: 0.1911 - accuracy: 0.9664\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.1735 - accuracy: 0.9833\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.1958 - accuracy: 0.9667\n",
      "119/119 [==============================] - 0s 248us/sample - loss: 0.1745 - accuracy: 0.9832\n",
      "118/118 [==============================] - 0s 243us/sample - loss: 0.1644 - accuracy: 0.9831\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.1660 - accuracy: 0.9833\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2871 samples, validate on 668 samples\n",
      "Epoch 1/300\n",
      "2871/2871 [==============================] - 2s 857us/sample - loss: 0.6920 - accuracy: 0.5482 - val_loss: 0.6734 - val_accuracy: 0.5719\n",
      "Epoch 2/300\n",
      "2871/2871 [==============================] - 1s 190us/sample - loss: 0.6547 - accuracy: 0.6109 - val_loss: 0.6492 - val_accuracy: 0.6048\n",
      "Epoch 3/300\n",
      "2871/2871 [==============================] - 0s 162us/sample - loss: 0.6311 - accuracy: 0.6381 - val_loss: 0.6326 - val_accuracy: 0.6317\n",
      "Epoch 4/300\n",
      "2871/2871 [==============================] - 0s 172us/sample - loss: 0.6130 - accuracy: 0.6681 - val_loss: 0.6202 - val_accuracy: 0.6602\n",
      "Epoch 5/300\n",
      "2871/2871 [==============================] - 1s 184us/sample - loss: 0.6019 - accuracy: 0.6778 - val_loss: 0.6099 - val_accuracy: 0.6737\n",
      "Epoch 6/300\n",
      "2871/2871 [==============================] - 1s 181us/sample - loss: 0.5904 - accuracy: 0.6886 - val_loss: 0.6012 - val_accuracy: 0.6901\n",
      "Epoch 7/300\n",
      "2871/2871 [==============================] - 1s 186us/sample - loss: 0.5800 - accuracy: 0.6900 - val_loss: 0.5940 - val_accuracy: 0.7021\n",
      "Epoch 8/300\n",
      "2871/2871 [==============================] - 1s 189us/sample - loss: 0.5703 - accuracy: 0.7154 - val_loss: 0.5875 - val_accuracy: 0.7081\n",
      "Epoch 9/300\n",
      "2871/2871 [==============================] - 1s 196us/sample - loss: 0.5612 - accuracy: 0.7328 - val_loss: 0.5817 - val_accuracy: 0.7096\n",
      "Epoch 10/300\n",
      "2871/2871 [==============================] - 1s 194us/sample - loss: 0.5537 - accuracy: 0.7328 - val_loss: 0.5766 - val_accuracy: 0.7246\n",
      "Epoch 11/300\n",
      "2871/2871 [==============================] - 1s 208us/sample - loss: 0.5525 - accuracy: 0.7290 - val_loss: 0.5721 - val_accuracy: 0.7365\n",
      "Epoch 12/300\n",
      "2871/2871 [==============================] - 1s 212us/sample - loss: 0.5415 - accuracy: 0.7450 - val_loss: 0.5680 - val_accuracy: 0.7380\n",
      "Epoch 13/300\n",
      "2871/2871 [==============================] - 1s 229us/sample - loss: 0.5363 - accuracy: 0.7454 - val_loss: 0.5643 - val_accuracy: 0.7410\n",
      "Epoch 14/300\n",
      "2871/2871 [==============================] - 1s 206us/sample - loss: 0.5339 - accuracy: 0.7492 - val_loss: 0.5609 - val_accuracy: 0.7455\n",
      "Epoch 15/300\n",
      "2871/2871 [==============================] - 1s 226us/sample - loss: 0.5281 - accuracy: 0.7548 - val_loss: 0.5579 - val_accuracy: 0.7515\n",
      "Epoch 16/300\n",
      "2871/2871 [==============================] - ETA: 0s - loss: 0.5226 - accuracy: 0.76 - 1s 220us/sample - loss: 0.5226 - accuracy: 0.7607 - val_loss: 0.5552 - val_accuracy: 0.7515\n",
      "Epoch 17/300\n",
      "2871/2871 [==============================] - 1s 235us/sample - loss: 0.5202 - accuracy: 0.7638 - val_loss: 0.5527 - val_accuracy: 0.7545\n",
      "Epoch 18/300\n",
      "2871/2871 [==============================] - 1s 212us/sample - loss: 0.5139 - accuracy: 0.7729 - val_loss: 0.5505 - val_accuracy: 0.7560\n",
      "Epoch 19/300\n",
      "2871/2871 [==============================] - 1s 216us/sample - loss: 0.5136 - accuracy: 0.7677 - val_loss: 0.5484 - val_accuracy: 0.7560\n",
      "Epoch 20/300\n",
      "2871/2871 [==============================] - 1s 221us/sample - loss: 0.5108 - accuracy: 0.7705 - val_loss: 0.5465 - val_accuracy: 0.7590\n",
      "Epoch 21/300\n",
      "2871/2871 [==============================] - 1s 203us/sample - loss: 0.5028 - accuracy: 0.7687 - val_loss: 0.5448 - val_accuracy: 0.7635\n",
      "Epoch 22/300\n",
      "2871/2871 [==============================] - 1s 187us/sample - loss: 0.5024 - accuracy: 0.7722 - val_loss: 0.5433 - val_accuracy: 0.7695\n",
      "Epoch 23/300\n",
      "2871/2871 [==============================] - 1s 202us/sample - loss: 0.4987 - accuracy: 0.7739 - val_loss: 0.5420 - val_accuracy: 0.7695\n",
      "Epoch 24/300\n",
      "2871/2871 [==============================] - 1s 192us/sample - loss: 0.4966 - accuracy: 0.7781 - val_loss: 0.5407 - val_accuracy: 0.7725\n",
      "Epoch 25/300\n",
      "2871/2871 [==============================] - 1s 211us/sample - loss: 0.4929 - accuracy: 0.7771 - val_loss: 0.5396 - val_accuracy: 0.7740\n",
      "Epoch 26/300\n",
      "2871/2871 [==============================] - 1s 207us/sample - loss: 0.4933 - accuracy: 0.7792 - val_loss: 0.5386 - val_accuracy: 0.7740\n",
      "Epoch 27/300\n",
      "2871/2871 [==============================] - 1s 219us/sample - loss: 0.4888 - accuracy: 0.7778 - val_loss: 0.5377 - val_accuracy: 0.7769\n",
      "Epoch 28/300\n",
      "2871/2871 [==============================] - 1s 235us/sample - loss: 0.4826 - accuracy: 0.7823 - val_loss: 0.5368 - val_accuracy: 0.7784\n",
      "Epoch 29/300\n",
      "2871/2871 [==============================] - 1s 229us/sample - loss: 0.4830 - accuracy: 0.7820 - val_loss: 0.5362 - val_accuracy: 0.7784\n",
      "Epoch 30/300\n",
      "2871/2871 [==============================] - 1s 194us/sample - loss: 0.4772 - accuracy: 0.7879 - val_loss: 0.5354 - val_accuracy: 0.7784\n",
      "Epoch 31/300\n",
      "2871/2871 [==============================] - 1s 216us/sample - loss: 0.4793 - accuracy: 0.7910 - val_loss: 0.5349 - val_accuracy: 0.7799\n",
      "Epoch 32/300\n",
      "2871/2871 [==============================] - 1s 235us/sample - loss: 0.4756 - accuracy: 0.7900 - val_loss: 0.5344 - val_accuracy: 0.7799\n",
      "Epoch 33/300\n",
      "2871/2871 [==============================] - 1s 194us/sample - loss: 0.4695 - accuracy: 0.7893 - val_loss: 0.5340 - val_accuracy: 0.7799\n",
      "Epoch 34/300\n",
      "2871/2871 [==============================] - 1s 186us/sample - loss: 0.4681 - accuracy: 0.7938 - val_loss: 0.5336 - val_accuracy: 0.7814\n",
      "Epoch 35/300\n",
      "2871/2871 [==============================] - 1s 212us/sample - loss: 0.4696 - accuracy: 0.7889 - val_loss: 0.5332 - val_accuracy: 0.7829\n",
      "Epoch 36/300\n",
      "2871/2871 [==============================] - 1s 214us/sample - loss: 0.4676 - accuracy: 0.7896 - val_loss: 0.5330 - val_accuracy: 0.7829\n",
      "Epoch 37/300\n",
      "2871/2871 [==============================] - 1s 208us/sample - loss: 0.4629 - accuracy: 0.7896 - val_loss: 0.5328 - val_accuracy: 0.7814\n",
      "Epoch 38/300\n",
      "2871/2871 [==============================] - 1s 213us/sample - loss: 0.4644 - accuracy: 0.7861 - val_loss: 0.5326 - val_accuracy: 0.7814\n",
      "Epoch 39/300\n",
      "2871/2871 [==============================] - 1s 179us/sample - loss: 0.4620 - accuracy: 0.7959 - val_loss: 0.5325 - val_accuracy: 0.7814\n",
      "Epoch 40/300\n",
      "2871/2871 [==============================] - 1s 187us/sample - loss: 0.4552 - accuracy: 0.7962 - val_loss: 0.5324 - val_accuracy: 0.7814\n",
      "Epoch 41/300\n",
      "2871/2871 [==============================] - 1s 198us/sample - loss: 0.4530 - accuracy: 0.7990 - val_loss: 0.5324 - val_accuracy: 0.7814\n",
      "Epoch 42/300\n",
      "2871/2871 [==============================] - 1s 221us/sample - loss: 0.4549 - accuracy: 0.7945 - val_loss: 0.5325 - val_accuracy: 0.7814\n",
      "Epoch 43/300\n",
      "2871/2871 [==============================] - 1s 218us/sample - loss: 0.4532 - accuracy: 0.8025 - val_loss: 0.5325 - val_accuracy: 0.7814\n",
      "Epoch 44/300\n",
      "2871/2871 [==============================] - 1s 209us/sample - loss: 0.4481 - accuracy: 0.7980 - val_loss: 0.5326 - val_accuracy: 0.7814\n",
      "Epoch 00044: early stopping\n",
      "110/110 [==============================] - 0s 131us/sample - loss: 0.2839 - accuracy: 0.9636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [3:37:23, 993.58s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.68s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.34s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 841.1171875 steps, validate for 198.734375 steps\n",
      "Epoch 1/300\n",
      "842/841 [==============================] - 25s 30ms/step - loss: 0.5552 - accuracy: 0.7434 - val_loss: 0.5441 - val_accuracy: 0.7814\n",
      "Epoch 2/300\n",
      "842/841 [==============================] - 24s 28ms/step - loss: 0.5132 - accuracy: 0.7691 - val_loss: 0.5444 - val_accuracy: 0.7785\n",
      "Epoch 3/300\n",
      "842/841 [==============================] - 23s 28ms/step - loss: 0.4979 - accuracy: 0.7753 - val_loss: 0.5441 - val_accuracy: 0.7790\n",
      "Epoch 4/300\n",
      "842/841 [==============================] - 23s 28ms/step - loss: 0.4862 - accuracy: 0.7807 - val_loss: 0.5457 - val_accuracy: 0.7764\n",
      "Epoch 5/300\n",
      "842/841 [==============================] - 24s 28ms/step - loss: 0.4768 - accuracy: 0.7852 - val_loss: 0.5537 - val_accuracy: 0.7669\n",
      "Epoch 6/300\n",
      "842/841 [==============================] - 24s 28ms/step - loss: 0.4682 - accuracy: 0.7900 - val_loss: 0.5564 - val_accuracy: 0.7682\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 841.1171875 steps, validate for 198.734375 steps\n",
      "Epoch 1/300\n",
      "842/841 [==============================] - 55s 65ms/step - loss: 0.4537 - accuracy: 0.7977 - val_loss: 0.5969 - val_accuracy: 0.7230\n",
      "Epoch 2/300\n",
      "842/841 [==============================] - 53s 63ms/step - loss: 0.4301 - accuracy: 0.8099 - val_loss: 0.5688 - val_accuracy: 0.7541\n",
      "Epoch 3/300\n",
      "842/841 [==============================] - 53s 64ms/step - loss: 0.4101 - accuracy: 0.8204 - val_loss: 0.5797 - val_accuracy: 0.7568\n",
      "Epoch 4/300\n",
      "842/841 [==============================] - 54s 64ms/step - loss: 0.3915 - accuracy: 0.8311 - val_loss: 0.5735 - val_accuracy: 0.7521\n",
      "Epoch 5/300\n",
      "842/841 [==============================] - 54s 64ms/step - loss: 0.3735 - accuracy: 0.8407 - val_loss: 0.5954 - val_accuracy: 0.7393\n",
      "Epoch 00005: early stopping\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 0.2566 - accuracy: 0.9441\n",
      "155/155 [==============================] - 0s 227us/sample - loss: 0.3167 - accuracy: 0.9032\n",
      "153/153 [==============================] - 0s 254us/sample - loss: 0.2879 - accuracy: 0.9216\n",
      "153/153 [==============================] - 0s 248us/sample - loss: 0.3222 - accuracy: 0.8824\n",
      "151/151 [==============================] - 0s 212us/sample - loss: 0.2856 - accuracy: 0.9536\n",
      "149/149 [==============================] - 0s 240us/sample - loss: 0.2818 - accuracy: 0.9664\n",
      "149/149 [==============================] - 0s 240us/sample - loss: 0.2891 - accuracy: 0.9262\n",
      "149/149 [==============================] - 0s 231us/sample - loss: 0.2850 - accuracy: 0.9262\n",
      "149/149 [==============================] - 0s 220us/sample - loss: 0.2579 - accuracy: 0.9597\n",
      "149/149 [==============================] - 0s 267us/sample - loss: 0.3116 - accuracy: 0.9329\n",
      "149/149 [==============================] - 0s 271us/sample - loss: 0.2906 - accuracy: 0.9530\n",
      "146/146 [==============================] - 0s 245us/sample - loss: 0.3000 - accuracy: 0.9315\n",
      "146/146 [==============================] - 0s 283us/sample - loss: 0.2971 - accuracy: 0.9247\n",
      "141/141 [==============================] - 0s 264us/sample - loss: 0.3232 - accuracy: 0.9078\n",
      "142/142 [==============================] - 0s 251us/sample - loss: 0.2844 - accuracy: 0.9296\n",
      "140/140 [==============================] - 0s 247us/sample - loss: 0.2892 - accuracy: 0.9357\n",
      "139/139 [==============================] - 0s 252us/sample - loss: 0.2933 - accuracy: 0.9281\n",
      "140/140 [==============================] - 0s 276us/sample - loss: 0.2570 - accuracy: 0.9500\n",
      "135/135 [==============================] - 0s 274us/sample - loss: 0.2895 - accuracy: 0.9259\n",
      "136/136 [==============================] - 0s 260us/sample - loss: 0.2933 - accuracy: 0.9191\n",
      "137/137 [==============================] - 0s 280us/sample - loss: 0.2654 - accuracy: 0.9343\n",
      "137/137 [==============================] - 0s 256us/sample - loss: 0.2696 - accuracy: 0.9489\n",
      "135/135 [==============================] - 0s 243us/sample - loss: 0.2883 - accuracy: 0.9481\n",
      "136/136 [==============================] - 0s 278us/sample - loss: 0.2802 - accuracy: 0.9265\n",
      "136/136 [==============================] - 0s 265us/sample - loss: 0.2774 - accuracy: 0.9338\n",
      "134/134 [==============================] - 0s 275us/sample - loss: 0.2868 - accuracy: 0.9478\n",
      "134/134 [==============================] - 0s 279us/sample - loss: 0.2917 - accuracy: 0.9328\n",
      "134/134 [==============================] - 0s 288us/sample - loss: 0.3178 - accuracy: 0.9030\n",
      "136/136 [==============================] - 0s 258us/sample - loss: 0.2856 - accuracy: 0.9265\n",
      "134/134 [==============================] - 0s 237us/sample - loss: 0.2728 - accuracy: 0.9552\n",
      "133/133 [==============================] - 0s 267us/sample - loss: 0.2591 - accuracy: 0.9474\n",
      "129/129 [==============================] - 0s 272us/sample - loss: 0.2781 - accuracy: 0.9302\n",
      "130/130 [==============================] - 0s 283us/sample - loss: 0.2750 - accuracy: 0.9154\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2847 samples, validate on 682 samples\n",
      "Epoch 1/300\n",
      "2847/2847 [==============================] - 3s 1ms/sample - loss: 0.6660 - accuracy: 0.6041 - val_loss: 0.6476 - val_accuracy: 0.6408\n",
      "Epoch 2/300\n",
      "2847/2847 [==============================] - 1s 247us/sample - loss: 0.6344 - accuracy: 0.6586 - val_loss: 0.6283 - val_accuracy: 0.6774\n",
      "Epoch 3/300\n",
      "2847/2847 [==============================] - 1s 232us/sample - loss: 0.6155 - accuracy: 0.6818 - val_loss: 0.6150 - val_accuracy: 0.6921\n",
      "Epoch 4/300\n",
      "2847/2847 [==============================] - 1s 216us/sample - loss: 0.6028 - accuracy: 0.7050 - val_loss: 0.6053 - val_accuracy: 0.7155\n",
      "Epoch 5/300\n",
      "2847/2847 [==============================] - 1s 229us/sample - loss: 0.5941 - accuracy: 0.7021 - val_loss: 0.5973 - val_accuracy: 0.7273\n",
      "Epoch 6/300\n",
      "2847/2847 [==============================] - 1s 210us/sample - loss: 0.5828 - accuracy: 0.7067 - val_loss: 0.5905 - val_accuracy: 0.7287\n",
      "Epoch 7/300\n",
      "2847/2847 [==============================] - 1s 188us/sample - loss: 0.5773 - accuracy: 0.7257 - val_loss: 0.5848 - val_accuracy: 0.7361\n",
      "Epoch 8/300\n",
      "2847/2847 [==============================] - 1s 219us/sample - loss: 0.5738 - accuracy: 0.7218 - val_loss: 0.5801 - val_accuracy: 0.7390\n",
      "Epoch 9/300\n",
      "2847/2847 [==============================] - 1s 217us/sample - loss: 0.5629 - accuracy: 0.7331 - val_loss: 0.5756 - val_accuracy: 0.7449\n",
      "Epoch 10/300\n",
      "2847/2847 [==============================] - 1s 251us/sample - loss: 0.5577 - accuracy: 0.7404 - val_loss: 0.5718 - val_accuracy: 0.7478\n",
      "Epoch 11/300\n",
      "2847/2847 [==============================] - 1s 241us/sample - loss: 0.5512 - accuracy: 0.7401 - val_loss: 0.5683 - val_accuracy: 0.7507\n",
      "Epoch 12/300\n",
      "2847/2847 [==============================] - 1s 245us/sample - loss: 0.5452 - accuracy: 0.7478 - val_loss: 0.5653 - val_accuracy: 0.7537\n",
      "Epoch 13/300\n",
      "2847/2847 [==============================] - 1s 205us/sample - loss: 0.5436 - accuracy: 0.7446 - val_loss: 0.5625 - val_accuracy: 0.7537\n",
      "Epoch 14/300\n",
      "2847/2847 [==============================] - 1s 214us/sample - loss: 0.5375 - accuracy: 0.7601 - val_loss: 0.5601 - val_accuracy: 0.7551\n",
      "Epoch 15/300\n",
      "2847/2847 [==============================] - 1s 192us/sample - loss: 0.5348 - accuracy: 0.7573 - val_loss: 0.5578 - val_accuracy: 0.7551\n",
      "Epoch 16/300\n",
      "2847/2847 [==============================] - 1s 194us/sample - loss: 0.5256 - accuracy: 0.7601 - val_loss: 0.5557 - val_accuracy: 0.7566\n",
      "Epoch 17/300\n",
      "2847/2847 [==============================] - 1s 190us/sample - loss: 0.5257 - accuracy: 0.7569 - val_loss: 0.5539 - val_accuracy: 0.7537\n",
      "Epoch 18/300\n",
      "2847/2847 [==============================] - 1s 214us/sample - loss: 0.5181 - accuracy: 0.7615 - val_loss: 0.5521 - val_accuracy: 0.7566\n",
      "Epoch 19/300\n",
      "2847/2847 [==============================] - 1s 247us/sample - loss: 0.5180 - accuracy: 0.7636 - val_loss: 0.5505 - val_accuracy: 0.7566\n",
      "Epoch 20/300\n",
      "2847/2847 [==============================] - 1s 234us/sample - loss: 0.5115 - accuracy: 0.7745 - val_loss: 0.5491 - val_accuracy: 0.7566\n",
      "Epoch 21/300\n",
      "2847/2847 [==============================] - 1s 249us/sample - loss: 0.5122 - accuracy: 0.7720 - val_loss: 0.5477 - val_accuracy: 0.7581\n",
      "Epoch 22/300\n",
      "2847/2847 [==============================] - 1s 229us/sample - loss: 0.5063 - accuracy: 0.7717 - val_loss: 0.5466 - val_accuracy: 0.7581\n",
      "Epoch 23/300\n",
      "2847/2847 [==============================] - 1s 199us/sample - loss: 0.5028 - accuracy: 0.7734 - val_loss: 0.5456 - val_accuracy: 0.7581\n",
      "Epoch 24/300\n",
      "2847/2847 [==============================] - 1s 215us/sample - loss: 0.4980 - accuracy: 0.7780 - val_loss: 0.5447 - val_accuracy: 0.7581\n",
      "Epoch 25/300\n",
      "2847/2847 [==============================] - 1s 186us/sample - loss: 0.4941 - accuracy: 0.7829 - val_loss: 0.5439 - val_accuracy: 0.7581\n",
      "Epoch 26/300\n",
      "2847/2847 [==============================] - 1s 197us/sample - loss: 0.4907 - accuracy: 0.7805 - val_loss: 0.5430 - val_accuracy: 0.7581\n",
      "Epoch 27/300\n",
      "2847/2847 [==============================] - 1s 247us/sample - loss: 0.4892 - accuracy: 0.7857 - val_loss: 0.5424 - val_accuracy: 0.7566\n",
      "Epoch 28/300\n",
      "2847/2847 [==============================] - 1s 234us/sample - loss: 0.4837 - accuracy: 0.7801 - val_loss: 0.5419 - val_accuracy: 0.7625\n",
      "Epoch 29/300\n",
      "2847/2847 [==============================] - 1s 217us/sample - loss: 0.4785 - accuracy: 0.7893 - val_loss: 0.5415 - val_accuracy: 0.7610\n",
      "Epoch 30/300\n",
      "2847/2847 [==============================] - 1s 224us/sample - loss: 0.4781 - accuracy: 0.7878 - val_loss: 0.5410 - val_accuracy: 0.7625\n",
      "Epoch 31/300\n",
      "2847/2847 [==============================] - 1s 232us/sample - loss: 0.4753 - accuracy: 0.7875 - val_loss: 0.5407 - val_accuracy: 0.7625\n",
      "Epoch 32/300\n",
      "2847/2847 [==============================] - 1s 203us/sample - loss: 0.4728 - accuracy: 0.7878 - val_loss: 0.5402 - val_accuracy: 0.7639\n",
      "Epoch 33/300\n",
      "2847/2847 [==============================] - 1s 201us/sample - loss: 0.4715 - accuracy: 0.7945 - val_loss: 0.5400 - val_accuracy: 0.7639\n",
      "Epoch 34/300\n",
      "2847/2847 [==============================] - 1s 189us/sample - loss: 0.4658 - accuracy: 0.7970 - val_loss: 0.5398 - val_accuracy: 0.7639\n",
      "Epoch 35/300\n",
      "2847/2847 [==============================] - 1s 198us/sample - loss: 0.4652 - accuracy: 0.7942 - val_loss: 0.5398 - val_accuracy: 0.7639\n",
      "Epoch 36/300\n",
      "2847/2847 [==============================] - 1s 188us/sample - loss: 0.4603 - accuracy: 0.7942 - val_loss: 0.5397 - val_accuracy: 0.7639\n",
      "Epoch 37/300\n",
      "2847/2847 [==============================] - 1s 229us/sample - loss: 0.4550 - accuracy: 0.8019 - val_loss: 0.5396 - val_accuracy: 0.7639\n",
      "Epoch 38/300\n",
      "2847/2847 [==============================] - 1s 208us/sample - loss: 0.4526 - accuracy: 0.8061 - val_loss: 0.5396 - val_accuracy: 0.7654\n",
      "Epoch 39/300\n",
      "2847/2847 [==============================] - 1s 241us/sample - loss: 0.4473 - accuracy: 0.8058 - val_loss: 0.5396 - val_accuracy: 0.7669\n",
      "Epoch 40/300\n",
      "2847/2847 [==============================] - 1s 240us/sample - loss: 0.4477 - accuracy: 0.7998 - val_loss: 0.5399 - val_accuracy: 0.7669\n",
      "Epoch 41/300\n",
      "2847/2847 [==============================] - 1s 235us/sample - loss: 0.4433 - accuracy: 0.8065 - val_loss: 0.5401 - val_accuracy: 0.7669\n",
      "Epoch 42/300\n",
      "2847/2847 [==============================] - 1s 229us/sample - loss: 0.4417 - accuracy: 0.8089 - val_loss: 0.5403 - val_accuracy: 0.7669\n",
      "Epoch 00042: early stopping\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.2738 - accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [3:55:20, 1018.52s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.79s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.40s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 850.6640625 steps, validate for 197.609375 steps\n",
      "Epoch 1/300\n",
      "851/850 [==============================] - 25s 29ms/step - loss: 0.6580 - accuracy: 0.6376 - val_loss: 0.5517 - val_accuracy: 0.7806\n",
      "Epoch 2/300\n",
      "851/850 [==============================] - 23s 28ms/step - loss: 0.5099 - accuracy: 0.7756 - val_loss: 0.5516 - val_accuracy: 0.7755\n",
      "Epoch 3/300\n",
      "851/850 [==============================] - 24s 28ms/step - loss: 0.4925 - accuracy: 0.7814 - val_loss: 0.5524 - val_accuracy: 0.7744\n",
      "Epoch 4/300\n",
      "851/850 [==============================] - 24s 28ms/step - loss: 0.4801 - accuracy: 0.7859 - val_loss: 0.5566 - val_accuracy: 0.7717\n",
      "Epoch 5/300\n",
      "851/850 [==============================] - 24s 28ms/step - loss: 0.4699 - accuracy: 0.7911 - val_loss: 0.5585 - val_accuracy: 0.7688\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 850.6640625 steps, validate for 197.609375 steps\n",
      "Epoch 1/300\n",
      "851/850 [==============================] - 55s 65ms/step - loss: 0.4538 - accuracy: 0.7994 - val_loss: 0.5587 - val_accuracy: 0.7691\n",
      "Epoch 2/300\n",
      "851/850 [==============================] - 54s 64ms/step - loss: 0.4286 - accuracy: 0.8128 - val_loss: 0.5622 - val_accuracy: 0.7743\n",
      "Epoch 3/300\n",
      "851/850 [==============================] - 54s 63ms/step - loss: 0.4084 - accuracy: 0.8239 - val_loss: 0.5760 - val_accuracy: 0.7644\n",
      "Epoch 4/300\n",
      "851/850 [==============================] - 54s 63ms/step - loss: 0.3891 - accuracy: 0.8336 - val_loss: 0.6133 - val_accuracy: 0.7212\n",
      "Epoch 00004: early stopping\n",
      "144/144 [==============================] - 0s 2ms/sample - loss: 0.8039 - accuracy: 0.7153\n",
      "130/130 [==============================] - 0s 298us/sample - loss: 1.0094 - accuracy: 0.7231\n",
      "118/118 [==============================] - 0s 254us/sample - loss: 0.9352 - accuracy: 0.6780\n",
      "115/115 [==============================] - 0s 290us/sample - loss: 0.9111 - accuracy: 0.6870\n",
      "114/114 [==============================] - 0s 252us/sample - loss: 0.9948 - accuracy: 0.6930\n",
      "113/113 [==============================] - 0s 245us/sample - loss: 1.0035 - accuracy: 0.6903\n",
      "113/113 [==============================] - 0s 230us/sample - loss: 1.1003 - accuracy: 0.6283\n",
      "114/114 [==============================] - 0s 224us/sample - loss: 1.0546 - accuracy: 0.6053\n",
      "114/114 [==============================] - 0s 238us/sample - loss: 1.1369 - accuracy: 0.5965\n",
      "111/111 [==============================] - 0s 253us/sample - loss: 1.2225 - accuracy: 0.5676\n",
      "110/110 [==============================] - 0s 266us/sample - loss: 1.1415 - accuracy: 0.5636\n",
      "110/110 [==============================] - 0s 275us/sample - loss: 1.1278 - accuracy: 0.5909\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 1.2493 - accuracy: 0.6071\n",
      "112/112 [==============================] - 0s 303us/sample - loss: 1.0650 - accuracy: 0.5536\n",
      "113/113 [==============================] - 0s 301us/sample - loss: 1.1767 - accuracy: 0.5841\n",
      "114/114 [==============================] - 0s 255us/sample - loss: 1.3975 - accuracy: 0.5263\n",
      "111/111 [==============================] - 0s 252us/sample - loss: 1.2345 - accuracy: 0.5225\n",
      "107/107 [==============================] - 0s 249us/sample - loss: 1.5767 - accuracy: 0.5140\n",
      "107/107 [==============================] - 0s 309us/sample - loss: 1.2003 - accuracy: 0.5701\n",
      "106/106 [==============================] - 0s 268us/sample - loss: 1.2093 - accuracy: 0.5755\n",
      "103/103 [==============================] - 0s 275us/sample - loss: 1.5221 - accuracy: 0.5049\n",
      "104/104 [==============================] - 0s 259us/sample - loss: 1.4741 - accuracy: 0.5192\n",
      "103/103 [==============================] - 0s 266us/sample - loss: 1.4349 - accuracy: 0.5049\n",
      "104/104 [==============================] - 0s 247us/sample - loss: 1.2695 - accuracy: 0.4808\n",
      "103/103 [==============================] - 0s 279us/sample - loss: 1.2808 - accuracy: 0.5631\n",
      "102/102 [==============================] - 0s 284us/sample - loss: 1.5558 - accuracy: 0.5294\n",
      "100/100 [==============================] - 0s 278us/sample - loss: 1.2726 - accuracy: 0.5800\n",
      "101/101 [==============================] - 0s 293us/sample - loss: 1.4159 - accuracy: 0.5248\n",
      "101/101 [==============================] - 0s 312us/sample - loss: 1.1115 - accuracy: 0.5446\n",
      "99/99 [==============================] - 0s 277us/sample - loss: 1.2157 - accuracy: 0.5758\n",
      "98/98 [==============================] - 0s 334us/sample - loss: 1.2703 - accuracy: 0.6224\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 1.2080 - accuracy: 0.5417\n",
      "97/97 [==============================] - 0s 293us/sample - loss: 1.2822 - accuracy: 0.5464\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2881 samples, validate on 675 samples\n",
      "Epoch 1/300\n",
      "2881/2881 [==============================] - 3s 928us/sample - loss: 0.7246 - accuracy: 0.4655 - val_loss: 0.6823 - val_accuracy: 0.5600\n",
      "Epoch 2/300\n",
      "2881/2881 [==============================] - 1s 249us/sample - loss: 0.6921 - accuracy: 0.5429 - val_loss: 0.6628 - val_accuracy: 0.6059\n",
      "Epoch 3/300\n",
      "2881/2881 [==============================] - 1s 228us/sample - loss: 0.6769 - accuracy: 0.5807 - val_loss: 0.6501 - val_accuracy: 0.6237\n",
      "Epoch 4/300\n",
      "2881/2881 [==============================] - 1s 232us/sample - loss: 0.6626 - accuracy: 0.6151 - val_loss: 0.6397 - val_accuracy: 0.6444\n",
      "Epoch 5/300\n",
      "2881/2881 [==============================] - 1s 222us/sample - loss: 0.6495 - accuracy: 0.6380 - val_loss: 0.6313 - val_accuracy: 0.6756\n",
      "Epoch 6/300\n",
      "2881/2881 [==============================] - 1s 212us/sample - loss: 0.6431 - accuracy: 0.6536 - val_loss: 0.6238 - val_accuracy: 0.6933\n",
      "Epoch 7/300\n",
      "2881/2881 [==============================] - 1s 230us/sample - loss: 0.6326 - accuracy: 0.6696 - val_loss: 0.6167 - val_accuracy: 0.7111\n",
      "Epoch 8/300\n",
      "2881/2881 [==============================] - 1s 212us/sample - loss: 0.6210 - accuracy: 0.6883 - val_loss: 0.6103 - val_accuracy: 0.7259\n",
      "Epoch 9/300\n",
      "2881/2881 [==============================] - 1s 196us/sample - loss: 0.6157 - accuracy: 0.6949 - val_loss: 0.6045 - val_accuracy: 0.7363\n",
      "Epoch 10/300\n",
      "2881/2881 [==============================] - 1s 191us/sample - loss: 0.6082 - accuracy: 0.7067 - val_loss: 0.5991 - val_accuracy: 0.7378\n",
      "Epoch 11/300\n",
      "2881/2881 [==============================] - 1s 215us/sample - loss: 0.6021 - accuracy: 0.7164 - val_loss: 0.5940 - val_accuracy: 0.7437\n",
      "Epoch 12/300\n",
      "2881/2881 [==============================] - 1s 177us/sample - loss: 0.5964 - accuracy: 0.7147 - val_loss: 0.5893 - val_accuracy: 0.7481\n",
      "Epoch 13/300\n",
      "2881/2881 [==============================] - 1s 185us/sample - loss: 0.5903 - accuracy: 0.7282 - val_loss: 0.5850 - val_accuracy: 0.7511\n",
      "Epoch 14/300\n",
      "2881/2881 [==============================] - 1s 204us/sample - loss: 0.5847 - accuracy: 0.7313 - val_loss: 0.5808 - val_accuracy: 0.7541\n",
      "Epoch 15/300\n",
      "2881/2881 [==============================] - 1s 213us/sample - loss: 0.5808 - accuracy: 0.7383 - val_loss: 0.5770 - val_accuracy: 0.7644\n",
      "Epoch 16/300\n",
      "2881/2881 [==============================] - 1s 205us/sample - loss: 0.5733 - accuracy: 0.7393 - val_loss: 0.5736 - val_accuracy: 0.7615\n",
      "Epoch 17/300\n",
      "2881/2881 [==============================] - 1s 205us/sample - loss: 0.5702 - accuracy: 0.7473 - val_loss: 0.5702 - val_accuracy: 0.7659\n",
      "Epoch 18/300\n",
      "2881/2881 [==============================] - 1s 211us/sample - loss: 0.5661 - accuracy: 0.7438 - val_loss: 0.5671 - val_accuracy: 0.7674\n",
      "Epoch 19/300\n",
      "2881/2881 [==============================] - 1s 230us/sample - loss: 0.5598 - accuracy: 0.7549 - val_loss: 0.5641 - val_accuracy: 0.7748\n",
      "Epoch 20/300\n",
      "2881/2881 [==============================] - 1s 217us/sample - loss: 0.5524 - accuracy: 0.7539 - val_loss: 0.5616 - val_accuracy: 0.7733\n",
      "Epoch 21/300\n",
      "2881/2881 [==============================] - 1s 241us/sample - loss: 0.5538 - accuracy: 0.7511 - val_loss: 0.5588 - val_accuracy: 0.7763\n",
      "Epoch 22/300\n",
      "2881/2881 [==============================] - 1s 237us/sample - loss: 0.5494 - accuracy: 0.7622 - val_loss: 0.5563 - val_accuracy: 0.7793\n",
      "Epoch 23/300\n",
      "2881/2881 [==============================] - 1s 220us/sample - loss: 0.5442 - accuracy: 0.7647 - val_loss: 0.5539 - val_accuracy: 0.7807\n",
      "Epoch 24/300\n",
      "2881/2881 [==============================] - 1s 242us/sample - loss: 0.5413 - accuracy: 0.7667 - val_loss: 0.5517 - val_accuracy: 0.7807\n",
      "Epoch 25/300\n",
      "2881/2881 [==============================] - 1s 217us/sample - loss: 0.5386 - accuracy: 0.7664 - val_loss: 0.5496 - val_accuracy: 0.7807\n",
      "Epoch 26/300\n",
      "2881/2881 [==============================] - 1s 210us/sample - loss: 0.5339 - accuracy: 0.7643 - val_loss: 0.5476 - val_accuracy: 0.7807\n",
      "Epoch 27/300\n",
      "2881/2881 [==============================] - 1s 194us/sample - loss: 0.5309 - accuracy: 0.7661 - val_loss: 0.5456 - val_accuracy: 0.7822\n",
      "Epoch 28/300\n",
      "2881/2881 [==============================] - 1s 232us/sample - loss: 0.5290 - accuracy: 0.7713 - val_loss: 0.5439 - val_accuracy: 0.7837\n",
      "Epoch 29/300\n",
      "2881/2881 [==============================] - 1s 238us/sample - loss: 0.5250 - accuracy: 0.7678 - val_loss: 0.5422 - val_accuracy: 0.7837\n",
      "Epoch 30/300\n",
      "2881/2881 [==============================] - 1s 195us/sample - loss: 0.5217 - accuracy: 0.7647 - val_loss: 0.5406 - val_accuracy: 0.7822\n",
      "Epoch 31/300\n",
      "2881/2881 [==============================] - 1s 188us/sample - loss: 0.5213 - accuracy: 0.7629 - val_loss: 0.5391 - val_accuracy: 0.7793\n",
      "Epoch 32/300\n",
      "2881/2881 [==============================] - 1s 198us/sample - loss: 0.5143 - accuracy: 0.7726 - val_loss: 0.5377 - val_accuracy: 0.7807\n",
      "Epoch 33/300\n",
      "2881/2881 [==============================] - 1s 220us/sample - loss: 0.5119 - accuracy: 0.7768 - val_loss: 0.5365 - val_accuracy: 0.7807\n",
      "Epoch 34/300\n",
      "2881/2881 [==============================] - 1s 212us/sample - loss: 0.5118 - accuracy: 0.7806 - val_loss: 0.5354 - val_accuracy: 0.7807\n",
      "Epoch 35/300\n",
      "2881/2881 [==============================] - 1s 209us/sample - loss: 0.5070 - accuracy: 0.7765 - val_loss: 0.5345 - val_accuracy: 0.7807\n",
      "Epoch 36/300\n",
      "2881/2881 [==============================] - 1s 208us/sample - loss: 0.5074 - accuracy: 0.7747 - val_loss: 0.5335 - val_accuracy: 0.7807\n",
      "Epoch 37/300\n",
      "2881/2881 [==============================] - 1s 204us/sample - loss: 0.5041 - accuracy: 0.7813 - val_loss: 0.5326 - val_accuracy: 0.7807\n",
      "Epoch 38/300\n",
      "2881/2881 [==============================] - 1s 213us/sample - loss: 0.5006 - accuracy: 0.7803 - val_loss: 0.5319 - val_accuracy: 0.7822\n",
      "Epoch 39/300\n",
      "2881/2881 [==============================] - 1s 211us/sample - loss: 0.4963 - accuracy: 0.7834 - val_loss: 0.5310 - val_accuracy: 0.7807\n",
      "Epoch 40/300\n",
      "2881/2881 [==============================] - 1s 220us/sample - loss: 0.4934 - accuracy: 0.7817 - val_loss: 0.5304 - val_accuracy: 0.7837\n",
      "Epoch 41/300\n",
      "2881/2881 [==============================] - 1s 240us/sample - loss: 0.4939 - accuracy: 0.7844 - val_loss: 0.5297 - val_accuracy: 0.7837\n",
      "Epoch 42/300\n",
      "2881/2881 [==============================] - 1s 246us/sample - loss: 0.4927 - accuracy: 0.7827 - val_loss: 0.5291 - val_accuracy: 0.7837\n",
      "Epoch 43/300\n",
      "2881/2881 [==============================] - 1s 228us/sample - loss: 0.4883 - accuracy: 0.7886 - val_loss: 0.5285 - val_accuracy: 0.7837\n",
      "Epoch 44/300\n",
      "2881/2881 [==============================] - 1s 225us/sample - loss: 0.4898 - accuracy: 0.7838 - val_loss: 0.5281 - val_accuracy: 0.7852\n",
      "Epoch 45/300\n",
      "2881/2881 [==============================] - 1s 223us/sample - loss: 0.4819 - accuracy: 0.7883 - val_loss: 0.5276 - val_accuracy: 0.7837\n",
      "Epoch 46/300\n",
      "2881/2881 [==============================] - 1s 231us/sample - loss: 0.4832 - accuracy: 0.7897 - val_loss: 0.5272 - val_accuracy: 0.7822\n",
      "Epoch 47/300\n",
      "2881/2881 [==============================] - 1s 219us/sample - loss: 0.4812 - accuracy: 0.7876 - val_loss: 0.5268 - val_accuracy: 0.7822\n",
      "Epoch 48/300\n",
      "2881/2881 [==============================] - 1s 213us/sample - loss: 0.4763 - accuracy: 0.7963 - val_loss: 0.5265 - val_accuracy: 0.7822\n",
      "Epoch 49/300\n",
      "2881/2881 [==============================] - 1s 239us/sample - loss: 0.4765 - accuracy: 0.7897 - val_loss: 0.5263 - val_accuracy: 0.7822\n",
      "Epoch 50/300\n",
      "2881/2881 [==============================] - 1s 228us/sample - loss: 0.4739 - accuracy: 0.7879 - val_loss: 0.5261 - val_accuracy: 0.7822\n",
      "Epoch 51/300\n",
      "2881/2881 [==============================] - 1s 236us/sample - loss: 0.4704 - accuracy: 0.7928 - val_loss: 0.5259 - val_accuracy: 0.7822\n",
      "Epoch 52/300\n",
      "2881/2881 [==============================] - 1s 223us/sample - loss: 0.4686 - accuracy: 0.7980 - val_loss: 0.5257 - val_accuracy: 0.7822\n",
      "Epoch 53/300\n",
      "2881/2881 [==============================] - 1s 222us/sample - loss: 0.4672 - accuracy: 0.7931 - val_loss: 0.5256 - val_accuracy: 0.7822\n",
      "Epoch 54/300\n",
      "2881/2881 [==============================] - 1s 217us/sample - loss: 0.4675 - accuracy: 0.8011 - val_loss: 0.5255 - val_accuracy: 0.7822\n",
      "Epoch 55/300\n",
      "2881/2881 [==============================] - 1s 236us/sample - loss: 0.4660 - accuracy: 0.7956 - val_loss: 0.5253 - val_accuracy: 0.7822\n",
      "Epoch 56/300\n",
      "2881/2881 [==============================] - 1s 225us/sample - loss: 0.4621 - accuracy: 0.7987 - val_loss: 0.5253 - val_accuracy: 0.7822\n",
      "Epoch 57/300\n",
      "2881/2881 [==============================] - 1s 225us/sample - loss: 0.4612 - accuracy: 0.7983 - val_loss: 0.5253 - val_accuracy: 0.7822\n",
      "Epoch 58/300\n",
      "2881/2881 [==============================] - 1s 199us/sample - loss: 0.4546 - accuracy: 0.8018 - val_loss: 0.5253 - val_accuracy: 0.7822\n",
      "Epoch 59/300\n",
      "2881/2881 [==============================] - 1s 221us/sample - loss: 0.4563 - accuracy: 0.8022 - val_loss: 0.5253 - val_accuracy: 0.7822\n",
      "Epoch 60/300\n",
      "2881/2881 [==============================] - 1s 207us/sample - loss: 0.4534 - accuracy: 0.8004 - val_loss: 0.5254 - val_accuracy: 0.7837\n",
      "Epoch 00060: early stopping\n",
      "93/93 [==============================] - 0s 114us/sample - loss: 0.5614 - accuracy: 0.6774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [4:12:01, 1013.30s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.61s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.29s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 849.5625 steps, validate for 194.9765625 steps\n",
      "Epoch 1/300\n",
      "850/849 [==============================] - 25s 29ms/step - loss: 0.5411 - accuracy: 0.7548 - val_loss: 0.5448 - val_accuracy: 0.7774\n",
      "Epoch 2/300\n",
      "850/849 [==============================] - 23s 28ms/step - loss: 0.5068 - accuracy: 0.7709 - val_loss: 0.5481 - val_accuracy: 0.7735\n",
      "Epoch 3/300\n",
      "850/849 [==============================] - 23s 27ms/step - loss: 0.4919 - accuracy: 0.7777 - val_loss: 0.5482 - val_accuracy: 0.7712\n",
      "Epoch 4/300\n",
      "850/849 [==============================] - 24s 28ms/step - loss: 0.4805 - accuracy: 0.7834 - val_loss: 0.5493 - val_accuracy: 0.7699\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 849.5625 steps, validate for 194.9765625 steps\n",
      "Epoch 1/300\n",
      "850/849 [==============================] - 55s 65ms/step - loss: 0.4632 - accuracy: 0.7923 - val_loss: 0.5720 - val_accuracy: 0.7365\n",
      "Epoch 2/300\n",
      "850/849 [==============================] - 54s 63ms/step - loss: 0.4387 - accuracy: 0.8047 - val_loss: 0.5626 - val_accuracy: 0.7714\n",
      "Epoch 3/300\n",
      "850/849 [==============================] - 54s 64ms/step - loss: 0.4180 - accuracy: 0.8169 - val_loss: 0.5891 - val_accuracy: 0.7301\n",
      "Epoch 4/300\n",
      "850/849 [==============================] - 54s 64ms/step - loss: 0.3984 - accuracy: 0.8277 - val_loss: 0.5806 - val_accuracy: 0.7531\n",
      "Epoch 5/300\n",
      "850/849 [==============================] - 54s 63ms/step - loss: 0.3805 - accuracy: 0.8384 - val_loss: 0.5669 - val_accuracy: 0.7686\n",
      "Epoch 00005: early stopping\n",
      "146/146 [==============================] - 0s 2ms/sample - loss: 0.2918 - accuracy: 0.9247\n",
      "142/142 [==============================] - 0s 256us/sample - loss: 0.2907 - accuracy: 0.9296\n",
      "138/138 [==============================] - 0s 240us/sample - loss: 0.2974 - accuracy: 0.9493\n",
      "137/137 [==============================] - 0s 223us/sample - loss: 0.2882 - accuracy: 0.9489\n",
      "134/134 [==============================] - 0s 241us/sample - loss: 0.2984 - accuracy: 0.9328\n",
      "130/130 [==============================] - 0s 258us/sample - loss: 0.3027 - accuracy: 0.9385\n",
      "129/129 [==============================] - 0s 239us/sample - loss: 0.2952 - accuracy: 0.9225\n",
      "127/127 [==============================] - 0s 236us/sample - loss: 0.2821 - accuracy: 0.9528\n",
      "125/125 [==============================] - 0s 245us/sample - loss: 0.2617 - accuracy: 0.9840\n",
      "125/125 [==============================] - 0s 267us/sample - loss: 0.2698 - accuracy: 0.9360\n",
      "125/125 [==============================] - 0s 252us/sample - loss: 0.2717 - accuracy: 0.9520\n",
      "125/125 [==============================] - 0s 233us/sample - loss: 0.2656 - accuracy: 1.0000\n",
      "125/125 [==============================] - 0s 283us/sample - loss: 0.2594 - accuracy: 0.9840\n",
      "124/124 [==============================] - 0s 231us/sample - loss: 0.2891 - accuracy: 0.9597\n",
      "123/123 [==============================] - 0s 239us/sample - loss: 0.3135 - accuracy: 0.9350\n",
      "124/124 [==============================] - 0s 245us/sample - loss: 0.3059 - accuracy: 0.9355\n",
      "122/122 [==============================] - 0s 248us/sample - loss: 0.3071 - accuracy: 0.9426\n",
      "122/122 [==============================] - 0s 258us/sample - loss: 0.3083 - accuracy: 0.9426\n",
      "121/121 [==============================] - 0s 218us/sample - loss: 0.2993 - accuracy: 0.9256\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 0.3194 - accuracy: 0.9250\n",
      "117/117 [==============================] - 0s 298us/sample - loss: 0.3415 - accuracy: 0.9145\n",
      "115/115 [==============================] - 0s 333us/sample - loss: 0.3361 - accuracy: 0.9130\n",
      "119/119 [==============================] - 0s 268us/sample - loss: 0.3276 - accuracy: 0.9244\n",
      "119/119 [==============================] - 0s 254us/sample - loss: 0.3286 - accuracy: 0.9580\n",
      "117/117 [==============================] - 0s 277us/sample - loss: 0.3204 - accuracy: 0.9658\n",
      "116/116 [==============================] - 0s 265us/sample - loss: 0.3160 - accuracy: 0.9569\n",
      "117/117 [==============================] - 0s 298us/sample - loss: 0.3369 - accuracy: 0.9231\n",
      "117/117 [==============================] - 0s 310us/sample - loss: 0.3165 - accuracy: 0.9145\n",
      "116/116 [==============================] - 0s 305us/sample - loss: 0.3207 - accuracy: 0.9397\n",
      "115/115 [==============================] - 0s 260us/sample - loss: 0.3210 - accuracy: 0.9304\n",
      "116/116 [==============================] - 0s 267us/sample - loss: 0.3096 - accuracy: 0.9483\n",
      "116/116 [==============================] - 0s 257us/sample - loss: 0.3079 - accuracy: 0.9483\n",
      "113/113 [==============================] - 0s 305us/sample - loss: 0.2938 - accuracy: 0.9292\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2874 samples, validate on 667 samples\n",
      "Epoch 1/300\n",
      "2874/2874 [==============================] - 3s 879us/sample - loss: 0.7186 - accuracy: 0.4892 - val_loss: 0.6870 - val_accuracy: 0.5772\n",
      "Epoch 2/300\n",
      "2874/2874 [==============================] - 1s 252us/sample - loss: 0.6826 - accuracy: 0.5661 - val_loss: 0.6665 - val_accuracy: 0.6162\n",
      "Epoch 3/300\n",
      "2874/2874 [==============================] - 1s 228us/sample - loss: 0.6599 - accuracy: 0.5985 - val_loss: 0.6516 - val_accuracy: 0.6477\n",
      "Epoch 4/300\n",
      "2874/2874 [==============================] - 1s 246us/sample - loss: 0.6468 - accuracy: 0.6246 - val_loss: 0.6398 - val_accuracy: 0.6732\n",
      "Epoch 5/300\n",
      "2874/2874 [==============================] - 1s 225us/sample - loss: 0.6316 - accuracy: 0.6562 - val_loss: 0.6300 - val_accuracy: 0.6837\n",
      "Epoch 6/300\n",
      "2874/2874 [==============================] - 1s 237us/sample - loss: 0.6149 - accuracy: 0.6837 - val_loss: 0.6215 - val_accuracy: 0.7016\n",
      "Epoch 7/300\n",
      "2874/2874 [==============================] - 1s 217us/sample - loss: 0.6050 - accuracy: 0.6980 - val_loss: 0.6140 - val_accuracy: 0.7061\n",
      "Epoch 8/300\n",
      "2874/2874 [==============================] - 1s 252us/sample - loss: 0.5968 - accuracy: 0.7049 - val_loss: 0.6073 - val_accuracy: 0.7181\n",
      "Epoch 9/300\n",
      "2874/2874 [==============================] - 1s 206us/sample - loss: 0.5888 - accuracy: 0.7164 - val_loss: 0.6010 - val_accuracy: 0.7256\n",
      "Epoch 10/300\n",
      "2874/2874 [==============================] - 1s 238us/sample - loss: 0.5805 - accuracy: 0.7338 - val_loss: 0.5955 - val_accuracy: 0.7271\n",
      "Epoch 11/300\n",
      "2874/2874 [==============================] - 1s 205us/sample - loss: 0.5744 - accuracy: 0.7376 - val_loss: 0.5903 - val_accuracy: 0.7301\n",
      "Epoch 12/300\n",
      "2874/2874 [==============================] - 1s 245us/sample - loss: 0.5620 - accuracy: 0.7443 - val_loss: 0.5856 - val_accuracy: 0.7346\n",
      "Epoch 13/300\n",
      "2874/2874 [==============================] - 1s 204us/sample - loss: 0.5591 - accuracy: 0.7550 - val_loss: 0.5813 - val_accuracy: 0.7406\n",
      "Epoch 14/300\n",
      "2874/2874 [==============================] - 1s 214us/sample - loss: 0.5545 - accuracy: 0.7537 - val_loss: 0.5773 - val_accuracy: 0.7421\n",
      "Epoch 15/300\n",
      "2874/2874 [==============================] - 1s 239us/sample - loss: 0.5461 - accuracy: 0.7596 - val_loss: 0.5735 - val_accuracy: 0.7451\n",
      "Epoch 16/300\n",
      "2874/2874 [==============================] - 1s 202us/sample - loss: 0.5421 - accuracy: 0.7561 - val_loss: 0.5702 - val_accuracy: 0.7481\n",
      "Epoch 17/300\n",
      "2874/2874 [==============================] - 0s 172us/sample - loss: 0.5335 - accuracy: 0.7669 - val_loss: 0.5670 - val_accuracy: 0.7496\n",
      "Epoch 18/300\n",
      "2874/2874 [==============================] - 1s 225us/sample - loss: 0.5253 - accuracy: 0.7735 - val_loss: 0.5641 - val_accuracy: 0.7541\n",
      "Epoch 19/300\n",
      "2874/2874 [==============================] - 1s 189us/sample - loss: 0.5193 - accuracy: 0.7825 - val_loss: 0.5614 - val_accuracy: 0.7571\n",
      "Epoch 20/300\n",
      "2874/2874 [==============================] - 1s 201us/sample - loss: 0.5138 - accuracy: 0.7808 - val_loss: 0.5589 - val_accuracy: 0.7601\n",
      "Epoch 21/300\n",
      "2874/2874 [==============================] - 1s 228us/sample - loss: 0.5110 - accuracy: 0.7763 - val_loss: 0.5565 - val_accuracy: 0.7616\n",
      "Epoch 22/300\n",
      "2874/2874 [==============================] - 1s 242us/sample - loss: 0.5054 - accuracy: 0.7926 - val_loss: 0.5544 - val_accuracy: 0.7631\n",
      "Epoch 23/300\n",
      "2874/2874 [==============================] - 1s 210us/sample - loss: 0.5000 - accuracy: 0.7975 - val_loss: 0.5525 - val_accuracy: 0.7646\n",
      "Epoch 24/300\n",
      "2874/2874 [==============================] - 1s 229us/sample - loss: 0.4941 - accuracy: 0.7933 - val_loss: 0.5507 - val_accuracy: 0.7676\n",
      "Epoch 25/300\n",
      "2874/2874 [==============================] - 1s 217us/sample - loss: 0.4911 - accuracy: 0.7895 - val_loss: 0.5490 - val_accuracy: 0.7691\n",
      "Epoch 26/300\n",
      "2874/2874 [==============================] - 1s 219us/sample - loss: 0.4901 - accuracy: 0.7999 - val_loss: 0.5475 - val_accuracy: 0.7676\n",
      "Epoch 27/300\n",
      "2874/2874 [==============================] - 1s 247us/sample - loss: 0.4841 - accuracy: 0.8034 - val_loss: 0.5462 - val_accuracy: 0.7661\n",
      "Epoch 28/300\n",
      "2874/2874 [==============================] - 1s 204us/sample - loss: 0.4830 - accuracy: 0.8027 - val_loss: 0.5450 - val_accuracy: 0.7676\n",
      "Epoch 29/300\n",
      "2874/2874 [==============================] - 1s 235us/sample - loss: 0.4782 - accuracy: 0.7985 - val_loss: 0.5439 - val_accuracy: 0.7676\n",
      "Epoch 30/300\n",
      "2874/2874 [==============================] - 1s 220us/sample - loss: 0.4729 - accuracy: 0.8051 - val_loss: 0.5428 - val_accuracy: 0.7676\n",
      "Epoch 31/300\n",
      "2874/2874 [==============================] - 1s 238us/sample - loss: 0.4725 - accuracy: 0.8027 - val_loss: 0.5420 - val_accuracy: 0.7691\n",
      "Epoch 32/300\n",
      "2874/2874 [==============================] - 1s 245us/sample - loss: 0.4683 - accuracy: 0.8076 - val_loss: 0.5412 - val_accuracy: 0.7736\n",
      "Epoch 33/300\n",
      "2874/2874 [==============================] - 1s 218us/sample - loss: 0.4634 - accuracy: 0.8069 - val_loss: 0.5405 - val_accuracy: 0.7736\n",
      "Epoch 34/300\n",
      "2874/2874 [==============================] - 1s 219us/sample - loss: 0.4563 - accuracy: 0.8111 - val_loss: 0.5399 - val_accuracy: 0.7736\n",
      "Epoch 35/300\n",
      "2874/2874 [==============================] - 1s 201us/sample - loss: 0.4591 - accuracy: 0.8125 - val_loss: 0.5394 - val_accuracy: 0.7736\n",
      "Epoch 36/300\n",
      "2874/2874 [==============================] - 1s 196us/sample - loss: 0.4571 - accuracy: 0.8100 - val_loss: 0.5390 - val_accuracy: 0.7736\n",
      "Epoch 37/300\n",
      "2874/2874 [==============================] - 1s 235us/sample - loss: 0.4496 - accuracy: 0.8145 - val_loss: 0.5387 - val_accuracy: 0.7736\n",
      "Epoch 38/300\n",
      "2874/2874 [==============================] - 1s 212us/sample - loss: 0.4481 - accuracy: 0.8149 - val_loss: 0.5384 - val_accuracy: 0.7721\n",
      "Epoch 39/300\n",
      "2874/2874 [==============================] - 1s 195us/sample - loss: 0.4476 - accuracy: 0.8152 - val_loss: 0.5381 - val_accuracy: 0.7721\n",
      "Epoch 40/300\n",
      "2874/2874 [==============================] - 1s 223us/sample - loss: 0.4406 - accuracy: 0.8198 - val_loss: 0.5381 - val_accuracy: 0.7751\n",
      "Epoch 41/300\n",
      "2874/2874 [==============================] - 1s 234us/sample - loss: 0.4404 - accuracy: 0.8166 - val_loss: 0.5380 - val_accuracy: 0.7751\n",
      "Epoch 42/300\n",
      "2874/2874 [==============================] - 1s 235us/sample - loss: 0.4362 - accuracy: 0.8191 - val_loss: 0.5379 - val_accuracy: 0.7751\n",
      "Epoch 43/300\n",
      "2874/2874 [==============================] - 1s 223us/sample - loss: 0.4359 - accuracy: 0.8205 - val_loss: 0.5379 - val_accuracy: 0.7751\n",
      "Epoch 44/300\n",
      "2874/2874 [==============================] - 1s 230us/sample - loss: 0.4323 - accuracy: 0.8243 - val_loss: 0.5379 - val_accuracy: 0.7751\n",
      "Epoch 45/300\n",
      "2874/2874 [==============================] - 1s 230us/sample - loss: 0.4254 - accuracy: 0.8253 - val_loss: 0.5381 - val_accuracy: 0.7751\n",
      "Epoch 00045: early stopping\n",
      "108/108 [==============================] - 0s 167us/sample - loss: 0.3941 - accuracy: 0.9444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [4:28:56, 1013.88s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.91s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.56s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 852.28125 steps, validate for 194.1875 steps\n",
      "Epoch 1/300\n",
      "853/852 [==============================] - 25s 29ms/step - loss: 0.6455 - accuracy: 0.6549 - val_loss: 0.5603 - val_accuracy: 0.7745\n",
      "Epoch 2/300\n",
      "853/852 [==============================] - 24s 28ms/step - loss: 0.5141 - accuracy: 0.7710 - val_loss: 0.5586 - val_accuracy: 0.7766\n",
      "Epoch 3/300\n",
      "853/852 [==============================] - 24s 28ms/step - loss: 0.4986 - accuracy: 0.7768 - val_loss: 0.5608 - val_accuracy: 0.7731\n",
      "Epoch 4/300\n",
      "853/852 [==============================] - 24s 28ms/step - loss: 0.4872 - accuracy: 0.7818 - val_loss: 0.5661 - val_accuracy: 0.7691\n",
      "Epoch 5/300\n",
      "853/852 [==============================] - 24s 28ms/step - loss: 0.4775 - accuracy: 0.7864 - val_loss: 0.5656 - val_accuracy: 0.7655\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 852.28125 steps, validate for 194.1875 steps\n",
      "Epoch 1/300\n",
      "853/852 [==============================] - 56s 66ms/step - loss: 0.4611 - accuracy: 0.7950 - val_loss: 0.6002 - val_accuracy: 0.7129\n",
      "Epoch 2/300\n",
      "853/852 [==============================] - 55s 64ms/step - loss: 0.4352 - accuracy: 0.8082 - val_loss: 0.5754 - val_accuracy: 0.7596\n",
      "Epoch 3/300\n",
      "853/852 [==============================] - 54s 64ms/step - loss: 0.4128 - accuracy: 0.8198 - val_loss: 0.5874 - val_accuracy: 0.7407\n",
      "Epoch 4/300\n",
      "853/852 [==============================] - 54s 63ms/step - loss: 0.3921 - accuracy: 0.8314 - val_loss: 0.6018 - val_accuracy: 0.7411\n",
      "Epoch 5/300\n",
      "853/852 [==============================] - 54s 63ms/step - loss: 0.3726 - accuracy: 0.8428 - val_loss: 0.6308 - val_accuracy: 0.7153\n",
      "Epoch 00005: early stopping\n",
      "153/153 [==============================] - 0s 2ms/sample - loss: 0.3514 - accuracy: 0.8758\n",
      "147/147 [==============================] - 0s 274us/sample - loss: 0.3171 - accuracy: 0.9116\n",
      "141/141 [==============================] - 0s 243us/sample - loss: 0.3265 - accuracy: 0.8936\n",
      "136/136 [==============================] - 0s 257us/sample - loss: 0.2778 - accuracy: 0.9265\n",
      "129/129 [==============================] - 0s 271us/sample - loss: 0.3233 - accuracy: 0.8760\n",
      "128/128 [==============================] - 0s 1ms/sample - loss: 0.3099 - accuracy: 0.9219\n",
      "125/125 [==============================] - 0s 238us/sample - loss: 0.3157 - accuracy: 0.8720\n",
      "125/125 [==============================] - 0s 220us/sample - loss: 0.2774 - accuracy: 0.9440\n",
      "122/122 [==============================] - 0s 228us/sample - loss: 0.2817 - accuracy: 0.9262\n",
      "119/119 [==============================] - 0s 255us/sample - loss: 0.2738 - accuracy: 0.9412\n",
      "115/115 [==============================] - 0s 239us/sample - loss: 0.2486 - accuracy: 0.9391\n",
      "114/114 [==============================] - 0s 309us/sample - loss: 0.2720 - accuracy: 0.9561\n",
      "113/113 [==============================] - 0s 277us/sample - loss: 0.2385 - accuracy: 0.9558\n",
      "113/113 [==============================] - 0s 284us/sample - loss: 0.2456 - accuracy: 0.9558\n",
      "109/109 [==============================] - 0s 271us/sample - loss: 0.2836 - accuracy: 0.9266\n",
      "109/109 [==============================] - 0s 279us/sample - loss: 0.2452 - accuracy: 0.9725\n",
      "108/108 [==============================] - 0s 299us/sample - loss: 0.2712 - accuracy: 0.9537\n",
      "109/109 [==============================] - 0s 244us/sample - loss: 0.2535 - accuracy: 0.9633\n",
      "108/108 [==============================] - 0s 278us/sample - loss: 0.3040 - accuracy: 0.9259\n",
      "108/108 [==============================] - 0s 289us/sample - loss: 0.3018 - accuracy: 0.9074\n",
      "108/108 [==============================] - 0s 280us/sample - loss: 0.3149 - accuracy: 0.9074\n",
      "107/107 [==============================] - 0s 266us/sample - loss: 0.3217 - accuracy: 0.9252\n",
      "108/108 [==============================] - 0s 282us/sample - loss: 0.3261 - accuracy: 0.8889\n",
      "108/108 [==============================] - 0s 282us/sample - loss: 0.3155 - accuracy: 0.9167\n",
      "107/107 [==============================] - 0s 301us/sample - loss: 0.3101 - accuracy: 0.8879\n",
      "107/107 [==============================] - 0s 306us/sample - loss: 0.3430 - accuracy: 0.8692\n",
      "108/108 [==============================] - 0s 293us/sample - loss: 0.3452 - accuracy: 0.9167\n",
      "108/108 [==============================] - 0s 271us/sample - loss: 0.2933 - accuracy: 0.8981\n",
      "107/107 [==============================] - 0s 257us/sample - loss: 0.3064 - accuracy: 0.8972\n",
      "108/108 [==============================] - 0s 273us/sample - loss: 0.3081 - accuracy: 0.9074\n",
      "107/107 [==============================] - 0s 273us/sample - loss: 0.3207 - accuracy: 0.9159\n",
      "108/108 [==============================] - 0s 310us/sample - loss: 0.2957 - accuracy: 0.8704\n",
      "108/108 [==============================] - 0s 251us/sample - loss: 0.2973 - accuracy: 0.8889\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2884 samples, validate on 663 samples\n",
      "Epoch 1/300\n",
      "2884/2884 [==============================] - 3s 927us/sample - loss: 0.6652 - accuracy: 0.5898 - val_loss: 0.6651 - val_accuracy: 0.5807\n",
      "Epoch 2/300\n",
      "2884/2884 [==============================] - 1s 255us/sample - loss: 0.6307 - accuracy: 0.6605 - val_loss: 0.6414 - val_accuracy: 0.6305\n",
      "Epoch 3/300\n",
      "2884/2884 [==============================] - 1s 219us/sample - loss: 0.6085 - accuracy: 0.6897 - val_loss: 0.6258 - val_accuracy: 0.6637\n",
      "Epoch 4/300\n",
      "2884/2884 [==============================] - 1s 213us/sample - loss: 0.5902 - accuracy: 0.7119 - val_loss: 0.6134 - val_accuracy: 0.6938\n",
      "Epoch 5/300\n",
      "2884/2884 [==============================] - 1s 231us/sample - loss: 0.5774 - accuracy: 0.7399 - val_loss: 0.6039 - val_accuracy: 0.7089\n",
      "Epoch 6/300\n",
      "2884/2884 [==============================] - 1s 227us/sample - loss: 0.5661 - accuracy: 0.7503 - val_loss: 0.5956 - val_accuracy: 0.7285\n",
      "Epoch 7/300\n",
      "2884/2884 [==============================] - 1s 240us/sample - loss: 0.5570 - accuracy: 0.7542 - val_loss: 0.5887 - val_accuracy: 0.7345\n",
      "Epoch 8/300\n",
      "2884/2884 [==============================] - 1s 221us/sample - loss: 0.5470 - accuracy: 0.7614 - val_loss: 0.5824 - val_accuracy: 0.7421\n",
      "Epoch 9/300\n",
      "2884/2884 [==============================] - 1s 219us/sample - loss: 0.5359 - accuracy: 0.7784 - val_loss: 0.5771 - val_accuracy: 0.7511\n",
      "Epoch 10/300\n",
      "2884/2884 [==============================] - 1s 205us/sample - loss: 0.5320 - accuracy: 0.7774 - val_loss: 0.5722 - val_accuracy: 0.7541\n",
      "Epoch 11/300\n",
      "2884/2884 [==============================] - 1s 228us/sample - loss: 0.5274 - accuracy: 0.7829 - val_loss: 0.5679 - val_accuracy: 0.7617\n",
      "Epoch 12/300\n",
      "2884/2884 [==============================] - 1s 213us/sample - loss: 0.5205 - accuracy: 0.7809 - val_loss: 0.5643 - val_accuracy: 0.7647\n",
      "Epoch 13/300\n",
      "2884/2884 [==============================] - 1s 247us/sample - loss: 0.5169 - accuracy: 0.7788 - val_loss: 0.5606 - val_accuracy: 0.7617\n",
      "Epoch 14/300\n",
      "2884/2884 [==============================] - 1s 250us/sample - loss: 0.5105 - accuracy: 0.7895 - val_loss: 0.5575 - val_accuracy: 0.7632\n",
      "Epoch 15/300\n",
      "2884/2884 [==============================] - 1s 238us/sample - loss: 0.5055 - accuracy: 0.7947 - val_loss: 0.5547 - val_accuracy: 0.7677\n",
      "Epoch 16/300\n",
      "2884/2884 [==============================] - 1s 227us/sample - loss: 0.5009 - accuracy: 0.7958 - val_loss: 0.5521 - val_accuracy: 0.7677\n",
      "Epoch 17/300\n",
      "2884/2884 [==============================] - 1s 231us/sample - loss: 0.4946 - accuracy: 0.7985 - val_loss: 0.5498 - val_accuracy: 0.7707\n",
      "Epoch 18/300\n",
      "2884/2884 [==============================] - 1s 226us/sample - loss: 0.4854 - accuracy: 0.8051 - val_loss: 0.5477 - val_accuracy: 0.7722\n",
      "Epoch 19/300\n",
      "2884/2884 [==============================] - 1s 220us/sample - loss: 0.4860 - accuracy: 0.8034 - val_loss: 0.5458 - val_accuracy: 0.7722\n",
      "Epoch 20/300\n",
      "2884/2884 [==============================] - 1s 234us/sample - loss: 0.4824 - accuracy: 0.8058 - val_loss: 0.5443 - val_accuracy: 0.7753\n",
      "Epoch 21/300\n",
      "2884/2884 [==============================] - 1s 242us/sample - loss: 0.4781 - accuracy: 0.8055 - val_loss: 0.5429 - val_accuracy: 0.7783\n",
      "Epoch 22/300\n",
      "2884/2884 [==============================] - 1s 225us/sample - loss: 0.4718 - accuracy: 0.8069 - val_loss: 0.5416 - val_accuracy: 0.7798\n",
      "Epoch 23/300\n",
      "2884/2884 [==============================] - 1s 217us/sample - loss: 0.4691 - accuracy: 0.8079 - val_loss: 0.5405 - val_accuracy: 0.7783\n",
      "Epoch 24/300\n",
      "2884/2884 [==============================] - 1s 230us/sample - loss: 0.4636 - accuracy: 0.8145 - val_loss: 0.5395 - val_accuracy: 0.7798\n",
      "Epoch 25/300\n",
      "2884/2884 [==============================] - 1s 206us/sample - loss: 0.4622 - accuracy: 0.8117 - val_loss: 0.5387 - val_accuracy: 0.7798\n",
      "Epoch 26/300\n",
      "2884/2884 [==============================] - 1s 220us/sample - loss: 0.4574 - accuracy: 0.8197 - val_loss: 0.5380 - val_accuracy: 0.7798\n",
      "Epoch 27/300\n",
      "2884/2884 [==============================] - 1s 212us/sample - loss: 0.4547 - accuracy: 0.8193 - val_loss: 0.5374 - val_accuracy: 0.7798\n",
      "Epoch 28/300\n",
      "2884/2884 [==============================] - 1s 203us/sample - loss: 0.4508 - accuracy: 0.8193 - val_loss: 0.5369 - val_accuracy: 0.7813\n",
      "Epoch 29/300\n",
      "2884/2884 [==============================] - 1s 256us/sample - loss: 0.4490 - accuracy: 0.8211 - val_loss: 0.5366 - val_accuracy: 0.7813\n",
      "Epoch 30/300\n",
      "2884/2884 [==============================] - 1s 257us/sample - loss: 0.4452 - accuracy: 0.8183 - val_loss: 0.5362 - val_accuracy: 0.7813\n",
      "Epoch 31/300\n",
      "2884/2884 [==============================] - 1s 232us/sample - loss: 0.4382 - accuracy: 0.8207 - val_loss: 0.5360 - val_accuracy: 0.7798\n",
      "Epoch 32/300\n",
      "2884/2884 [==============================] - 1s 260us/sample - loss: 0.4447 - accuracy: 0.8173 - val_loss: 0.5360 - val_accuracy: 0.7798\n",
      "Epoch 33/300\n",
      "2884/2884 [==============================] - 1s 224us/sample - loss: 0.4357 - accuracy: 0.8207 - val_loss: 0.5360 - val_accuracy: 0.7783\n",
      "Epoch 34/300\n",
      "2884/2884 [==============================] - 1s 246us/sample - loss: 0.4307 - accuracy: 0.8252 - val_loss: 0.5362 - val_accuracy: 0.7783\n",
      "Epoch 35/300\n",
      "2884/2884 [==============================] - 1s 253us/sample - loss: 0.4299 - accuracy: 0.8256 - val_loss: 0.5362 - val_accuracy: 0.7783\n",
      "Epoch 00035: early stopping\n",
      "102/102 [==============================] - 0s 180us/sample - loss: 0.2657 - accuracy: 0.9706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [4:46:19, 1022.49s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.97s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.53s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 860.78125 steps, validate for 195.1015625 steps\n",
      "Epoch 1/300\n",
      "861/860 [==============================] - 25s 29ms/step - loss: 0.5570 - accuracy: 0.7413 - val_loss: 0.5536 - val_accuracy: 0.7793\n",
      "Epoch 2/300\n",
      "861/860 [==============================] - 24s 28ms/step - loss: 0.5064 - accuracy: 0.7754 - val_loss: 0.5513 - val_accuracy: 0.7799\n",
      "Epoch 3/300\n",
      "861/860 [==============================] - 24s 28ms/step - loss: 0.4916 - accuracy: 0.7816 - val_loss: 0.5519 - val_accuracy: 0.7778\n",
      "Epoch 4/300\n",
      "861/860 [==============================] - 24s 28ms/step - loss: 0.4804 - accuracy: 0.7859 - val_loss: 0.5544 - val_accuracy: 0.7757\n",
      "Epoch 5/300\n",
      "861/860 [==============================] - 24s 28ms/step - loss: 0.4708 - accuracy: 0.7905 - val_loss: 0.5601 - val_accuracy: 0.7700\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 860.78125 steps, validate for 195.1015625 steps\n",
      "Epoch 1/300\n",
      "861/860 [==============================] - 56s 65ms/step - loss: 0.4547 - accuracy: 0.7981 - val_loss: 0.5511 - val_accuracy: 0.7698\n",
      "Epoch 2/300\n",
      "861/860 [==============================] - 55s 63ms/step - loss: 0.4289 - accuracy: 0.8106 - val_loss: 0.5827 - val_accuracy: 0.7377\n",
      "Epoch 3/300\n",
      "861/860 [==============================] - 55s 64ms/step - loss: 0.4074 - accuracy: 0.8220 - val_loss: 0.5630 - val_accuracy: 0.7801\n",
      "Epoch 4/300\n",
      "861/860 [==============================] - 55s 64ms/step - loss: 0.3874 - accuracy: 0.8334 - val_loss: 0.5918 - val_accuracy: 0.7369\n",
      "Epoch 00004: early stopping\n",
      "93/93 [==============================] - 0s 3ms/sample - loss: 0.4450 - accuracy: 0.7849\n",
      "92/92 [==============================] - 0s 267us/sample - loss: 0.5052 - accuracy: 0.7391\n",
      "90/90 [==============================] - 0s 322us/sample - loss: 0.4385 - accuracy: 0.8222\n",
      "85/85 [==============================] - 0s 272us/sample - loss: 0.4965 - accuracy: 0.7882\n",
      "84/84 [==============================] - 0s 259us/sample - loss: 0.5748 - accuracy: 0.7738\n",
      "82/82 [==============================] - 0s 287us/sample - loss: 0.5373 - accuracy: 0.8049\n",
      "82/82 [==============================] - 0s 303us/sample - loss: 0.6010 - accuracy: 0.6951\n",
      "80/80 [==============================] - 0s 261us/sample - loss: 0.5267 - accuracy: 0.7750\n",
      "79/79 [==============================] - 0s 292us/sample - loss: 0.5671 - accuracy: 0.7215\n",
      "79/79 [==============================] - 0s 270us/sample - loss: 0.5072 - accuracy: 0.7595\n",
      "78/78 [==============================] - 0s 248us/sample - loss: 0.5247 - accuracy: 0.7692\n",
      "79/79 [==============================] - 0s 349us/sample - loss: 0.5532 - accuracy: 0.7342\n",
      "79/79 [==============================] - 0s 272us/sample - loss: 0.4881 - accuracy: 0.7975\n",
      "79/79 [==============================] - 0s 280us/sample - loss: 0.5424 - accuracy: 0.7342\n",
      "78/78 [==============================] - 0s 348us/sample - loss: 0.5478 - accuracy: 0.8077\n",
      "78/78 [==============================] - 0s 291us/sample - loss: 0.4787 - accuracy: 0.7949\n",
      "77/77 [==============================] - 0s 309us/sample - loss: 0.5418 - accuracy: 0.7403\n",
      "78/78 [==============================] - 0s 307us/sample - loss: 0.5694 - accuracy: 0.7308\n",
      "77/77 [==============================] - 0s 300us/sample - loss: 0.5612 - accuracy: 0.7532\n",
      "78/78 [==============================] - 0s 316us/sample - loss: 0.5490 - accuracy: 0.7692\n",
      "79/79 [==============================] - 0s 312us/sample - loss: 0.5513 - accuracy: 0.7089\n",
      "79/79 [==============================] - 0s 298us/sample - loss: 0.5829 - accuracy: 0.7342\n",
      "79/79 [==============================] - 0s 290us/sample - loss: 0.5446 - accuracy: 0.7468\n",
      "79/79 [==============================] - 0s 301us/sample - loss: 0.5319 - accuracy: 0.7595\n",
      "78/78 [==============================] - 0s 282us/sample - loss: 0.5613 - accuracy: 0.7564\n",
      "77/77 [==============================] - 0s 297us/sample - loss: 0.5739 - accuracy: 0.7143\n",
      "76/76 [==============================] - 0s 277us/sample - loss: 0.5236 - accuracy: 0.7763\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.6270 - accuracy: 0.7467\n",
      "76/76 [==============================] - 0s 267us/sample - loss: 0.6110 - accuracy: 0.7237\n",
      "76/76 [==============================] - 0s 315us/sample - loss: 0.5044 - accuracy: 0.8158\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.5112 - accuracy: 0.7600\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.6314 - accuracy: 0.6667\n",
      "74/74 [==============================] - 0s 291us/sample - loss: 0.5703 - accuracy: 0.7162\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2912 samples, validate on 666 samples\n",
      "Epoch 1/300\n",
      "2912/2912 [==============================] - 2s 847us/sample - loss: 0.7107 - accuracy: 0.5247 - val_loss: 0.6716 - val_accuracy: 0.5961\n",
      "Epoch 2/300\n",
      "2912/2912 [==============================] - 1s 231us/sample - loss: 0.6834 - accuracy: 0.5721 - val_loss: 0.6556 - val_accuracy: 0.6171\n",
      "Epoch 3/300\n",
      "2912/2912 [==============================] - 1s 206us/sample - loss: 0.6643 - accuracy: 0.6085 - val_loss: 0.6443 - val_accuracy: 0.6411\n",
      "Epoch 4/300\n",
      "2912/2912 [==============================] - 1s 183us/sample - loss: 0.6595 - accuracy: 0.6133 - val_loss: 0.6353 - val_accuracy: 0.6652\n",
      "Epoch 5/300\n",
      "2912/2912 [==============================] - 1s 218us/sample - loss: 0.6447 - accuracy: 0.6422 - val_loss: 0.6276 - val_accuracy: 0.6697\n",
      "Epoch 6/300\n",
      "2912/2912 [==============================] - 1s 216us/sample - loss: 0.6380 - accuracy: 0.6490 - val_loss: 0.6209 - val_accuracy: 0.6787\n",
      "Epoch 7/300\n",
      "2912/2912 [==============================] - 1s 216us/sample - loss: 0.6260 - accuracy: 0.6745 - val_loss: 0.6151 - val_accuracy: 0.6892\n",
      "Epoch 8/300\n",
      "2912/2912 [==============================] - 1s 204us/sample - loss: 0.6199 - accuracy: 0.6827 - val_loss: 0.6097 - val_accuracy: 0.7057\n",
      "Epoch 9/300\n",
      "2912/2912 [==============================] - 1s 239us/sample - loss: 0.6124 - accuracy: 0.6916 - val_loss: 0.6049 - val_accuracy: 0.7162\n",
      "Epoch 10/300\n",
      "2912/2912 [==============================] - 1s 217us/sample - loss: 0.6048 - accuracy: 0.6999 - val_loss: 0.6004 - val_accuracy: 0.7207\n",
      "Epoch 11/300\n",
      "2912/2912 [==============================] - 1s 196us/sample - loss: 0.5972 - accuracy: 0.7088 - val_loss: 0.5962 - val_accuracy: 0.7252\n",
      "Epoch 12/300\n",
      "2912/2912 [==============================] - 1s 208us/sample - loss: 0.5967 - accuracy: 0.7115 - val_loss: 0.5924 - val_accuracy: 0.7237\n",
      "Epoch 13/300\n",
      "2912/2912 [==============================] - 1s 205us/sample - loss: 0.5887 - accuracy: 0.7212 - val_loss: 0.5886 - val_accuracy: 0.7267\n",
      "Epoch 14/300\n",
      "2912/2912 [==============================] - 1s 205us/sample - loss: 0.5841 - accuracy: 0.7225 - val_loss: 0.5852 - val_accuracy: 0.7282\n",
      "Epoch 15/300\n",
      "2912/2912 [==============================] - 1s 217us/sample - loss: 0.5789 - accuracy: 0.7232 - val_loss: 0.5819 - val_accuracy: 0.7342\n",
      "Epoch 16/300\n",
      "2912/2912 [==============================] - 1s 203us/sample - loss: 0.5698 - accuracy: 0.7411 - val_loss: 0.5789 - val_accuracy: 0.7372\n",
      "Epoch 17/300\n",
      "2912/2912 [==============================] - 1s 178us/sample - loss: 0.5711 - accuracy: 0.7321 - val_loss: 0.5760 - val_accuracy: 0.7372\n",
      "Epoch 18/300\n",
      "2912/2912 [==============================] - 1s 196us/sample - loss: 0.5653 - accuracy: 0.7404 - val_loss: 0.5733 - val_accuracy: 0.7402\n",
      "Epoch 19/300\n",
      "2912/2912 [==============================] - 1s 184us/sample - loss: 0.5612 - accuracy: 0.7469 - val_loss: 0.5707 - val_accuracy: 0.7492\n",
      "Epoch 20/300\n",
      "2912/2912 [==============================] - 1s 192us/sample - loss: 0.5546 - accuracy: 0.7466 - val_loss: 0.5681 - val_accuracy: 0.7508\n",
      "Epoch 21/300\n",
      "2912/2912 [==============================] - 1s 206us/sample - loss: 0.5546 - accuracy: 0.7493 - val_loss: 0.5658 - val_accuracy: 0.7523\n",
      "Epoch 22/300\n",
      "2912/2912 [==============================] - 1s 198us/sample - loss: 0.5451 - accuracy: 0.7545 - val_loss: 0.5636 - val_accuracy: 0.7538\n",
      "Epoch 23/300\n",
      "2912/2912 [==============================] - 1s 230us/sample - loss: 0.5430 - accuracy: 0.7545 - val_loss: 0.5614 - val_accuracy: 0.7538\n",
      "Epoch 24/300\n",
      "2912/2912 [==============================] - 1s 232us/sample - loss: 0.5379 - accuracy: 0.7651 - val_loss: 0.5593 - val_accuracy: 0.7523\n",
      "Epoch 25/300\n",
      "2912/2912 [==============================] - 1s 238us/sample - loss: 0.5373 - accuracy: 0.7552 - val_loss: 0.5573 - val_accuracy: 0.7523\n",
      "Epoch 26/300\n",
      "2912/2912 [==============================] - 1s 199us/sample - loss: 0.5297 - accuracy: 0.7703 - val_loss: 0.5554 - val_accuracy: 0.7523\n",
      "Epoch 27/300\n",
      "2912/2912 [==============================] - 1s 221us/sample - loss: 0.5257 - accuracy: 0.7703 - val_loss: 0.5537 - val_accuracy: 0.7538\n",
      "Epoch 28/300\n",
      "2912/2912 [==============================] - 1s 215us/sample - loss: 0.5215 - accuracy: 0.7720 - val_loss: 0.5520 - val_accuracy: 0.7538\n",
      "Epoch 29/300\n",
      "2912/2912 [==============================] - 1s 212us/sample - loss: 0.5178 - accuracy: 0.7709 - val_loss: 0.5503 - val_accuracy: 0.7538\n",
      "Epoch 30/300\n",
      "2912/2912 [==============================] - 1s 190us/sample - loss: 0.5148 - accuracy: 0.7788 - val_loss: 0.5487 - val_accuracy: 0.7538\n",
      "Epoch 31/300\n",
      "2912/2912 [==============================] - 1s 232us/sample - loss: 0.5124 - accuracy: 0.7782 - val_loss: 0.5473 - val_accuracy: 0.7553\n",
      "Epoch 32/300\n",
      "2912/2912 [==============================] - 1s 220us/sample - loss: 0.5098 - accuracy: 0.7778 - val_loss: 0.5458 - val_accuracy: 0.7568\n",
      "Epoch 33/300\n",
      "2912/2912 [==============================] - 1s 212us/sample - loss: 0.5072 - accuracy: 0.7795 - val_loss: 0.5445 - val_accuracy: 0.7598\n",
      "Epoch 34/300\n",
      "2912/2912 [==============================] - 1s 187us/sample - loss: 0.5048 - accuracy: 0.7802 - val_loss: 0.5433 - val_accuracy: 0.7628\n",
      "Epoch 35/300\n",
      "2912/2912 [==============================] - 1s 180us/sample - loss: 0.4983 - accuracy: 0.7850 - val_loss: 0.5420 - val_accuracy: 0.7643\n",
      "Epoch 36/300\n",
      "2912/2912 [==============================] - 1s 222us/sample - loss: 0.4984 - accuracy: 0.7806 - val_loss: 0.5410 - val_accuracy: 0.7673\n",
      "Epoch 37/300\n",
      "2912/2912 [==============================] - 1s 211us/sample - loss: 0.4941 - accuracy: 0.7891 - val_loss: 0.5399 - val_accuracy: 0.7673\n",
      "Epoch 38/300\n",
      "2912/2912 [==============================] - 1s 212us/sample - loss: 0.4905 - accuracy: 0.7916 - val_loss: 0.5390 - val_accuracy: 0.7673\n",
      "Epoch 39/300\n",
      "2912/2912 [==============================] - 1s 223us/sample - loss: 0.4835 - accuracy: 0.7953 - val_loss: 0.5380 - val_accuracy: 0.7688\n",
      "Epoch 40/300\n",
      "2912/2912 [==============================] - 1s 221us/sample - loss: 0.4836 - accuracy: 0.7929 - val_loss: 0.5371 - val_accuracy: 0.7703\n",
      "Epoch 41/300\n",
      "2912/2912 [==============================] - 1s 210us/sample - loss: 0.4822 - accuracy: 0.7974 - val_loss: 0.5363 - val_accuracy: 0.7718\n",
      "Epoch 42/300\n",
      "2912/2912 [==============================] - 1s 227us/sample - loss: 0.4817 - accuracy: 0.7946 - val_loss: 0.5356 - val_accuracy: 0.7733\n",
      "Epoch 43/300\n",
      "2912/2912 [==============================] - 1s 210us/sample - loss: 0.4751 - accuracy: 0.7967 - val_loss: 0.5349 - val_accuracy: 0.7748\n",
      "Epoch 44/300\n",
      "2912/2912 [==============================] - 1s 221us/sample - loss: 0.4719 - accuracy: 0.7977 - val_loss: 0.5343 - val_accuracy: 0.7748\n",
      "Epoch 45/300\n",
      "2912/2912 [==============================] - 1s 175us/sample - loss: 0.4680 - accuracy: 0.8053 - val_loss: 0.5337 - val_accuracy: 0.7763\n",
      "Epoch 46/300\n",
      "2912/2912 [==============================] - 1s 186us/sample - loss: 0.4682 - accuracy: 0.8015 - val_loss: 0.5333 - val_accuracy: 0.7763\n",
      "Epoch 47/300\n",
      "2912/2912 [==============================] - 1s 205us/sample - loss: 0.4611 - accuracy: 0.8046 - val_loss: 0.5328 - val_accuracy: 0.7778\n",
      "Epoch 48/300\n",
      "2912/2912 [==============================] - 1s 182us/sample - loss: 0.4620 - accuracy: 0.8101 - val_loss: 0.5325 - val_accuracy: 0.7763\n",
      "Epoch 49/300\n",
      "2912/2912 [==============================] - 1s 192us/sample - loss: 0.4550 - accuracy: 0.8070 - val_loss: 0.5322 - val_accuracy: 0.7763\n",
      "Epoch 50/300\n",
      "2912/2912 [==============================] - 1s 209us/sample - loss: 0.4518 - accuracy: 0.8115 - val_loss: 0.5318 - val_accuracy: 0.7763\n",
      "Epoch 51/300\n",
      "2912/2912 [==============================] - 1s 174us/sample - loss: 0.4494 - accuracy: 0.8135 - val_loss: 0.5316 - val_accuracy: 0.7763\n",
      "Epoch 52/300\n",
      "2912/2912 [==============================] - 1s 174us/sample - loss: 0.4499 - accuracy: 0.8084 - val_loss: 0.5313 - val_accuracy: 0.7748\n",
      "Epoch 53/300\n",
      "2912/2912 [==============================] - 1s 197us/sample - loss: 0.4462 - accuracy: 0.8204 - val_loss: 0.5313 - val_accuracy: 0.7763\n",
      "Epoch 54/300\n",
      "2912/2912 [==============================] - 1s 188us/sample - loss: 0.4400 - accuracy: 0.8139 - val_loss: 0.5312 - val_accuracy: 0.7763\n",
      "Epoch 55/300\n",
      "2912/2912 [==============================] - 1s 211us/sample - loss: 0.4401 - accuracy: 0.8180 - val_loss: 0.5311 - val_accuracy: 0.7763\n",
      "Epoch 56/300\n",
      "2912/2912 [==============================] - 1s 227us/sample - loss: 0.4402 - accuracy: 0.8142 - val_loss: 0.5311 - val_accuracy: 0.7763\n",
      "Epoch 57/300\n",
      "2912/2912 [==============================] - 1s 196us/sample - loss: 0.4335 - accuracy: 0.8231 - val_loss: 0.5311 - val_accuracy: 0.7748\n",
      "Epoch 58/300\n",
      "2912/2912 [==============================] - 1s 216us/sample - loss: 0.4290 - accuracy: 0.8214 - val_loss: 0.5313 - val_accuracy: 0.7733\n",
      "Epoch 59/300\n",
      "2912/2912 [==============================] - 1s 221us/sample - loss: 0.4316 - accuracy: 0.8255 - val_loss: 0.5314 - val_accuracy: 0.7733\n",
      "Epoch 00059: early stopping\n",
      "71/71 [==============================] - 0s 190us/sample - loss: 0.5443 - accuracy: 0.7746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [5:03:21, 1022.25s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:04<00:04,  4.15s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.66s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 861.3671875 steps, validate for 197.703125 steps\n",
      "Epoch 1/300\n",
      "862/861 [==============================] - 25s 29ms/step - loss: 0.5475 - accuracy: 0.7570 - val_loss: 0.5506 - val_accuracy: 0.7816\n",
      "Epoch 2/300\n",
      "862/861 [==============================] - 24s 28ms/step - loss: 0.5080 - accuracy: 0.7742 - val_loss: 0.5512 - val_accuracy: 0.7770\n",
      "Epoch 3/300\n",
      "862/861 [==============================] - 24s 28ms/step - loss: 0.4932 - accuracy: 0.7795 - val_loss: 0.5547 - val_accuracy: 0.7752\n",
      "Epoch 4/300\n",
      "862/861 [==============================] - 24s 28ms/step - loss: 0.4827 - accuracy: 0.7844 - val_loss: 0.5554 - val_accuracy: 0.7752\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 861.3671875 steps, validate for 197.703125 steps\n",
      "Epoch 1/300\n",
      "862/861 [==============================] - 56s 64ms/step - loss: 0.4648 - accuracy: 0.7924 - val_loss: 0.5648 - val_accuracy: 0.7673\n",
      "Epoch 2/300\n",
      "862/861 [==============================] - 55s 64ms/step - loss: 0.4380 - accuracy: 0.8055 - val_loss: 0.5834 - val_accuracy: 0.7447\n",
      "Epoch 3/300\n",
      "862/861 [==============================] - 55s 64ms/step - loss: 0.4148 - accuracy: 0.8185 - val_loss: 0.5746 - val_accuracy: 0.7454\n",
      "Epoch 4/300\n",
      "862/861 [==============================] - 55s 64ms/step - loss: 0.3936 - accuracy: 0.8303 - val_loss: 0.6630 - val_accuracy: 0.7780\n",
      "Epoch 00004: early stopping\n",
      "78/78 [==============================] - 0s 3ms/sample - loss: 0.1115 - accuracy: 1.0000\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.1257 - accuracy: 0.9867\n",
      "73/73 [==============================] - 0s 293us/sample - loss: 0.1159 - accuracy: 1.0000\n",
      "71/71 [==============================] - 0s 338us/sample - loss: 0.1289 - accuracy: 1.0000\n",
      "71/71 [==============================] - 0s 297us/sample - loss: 0.1110 - accuracy: 0.9859\n",
      "68/68 [==============================] - 0s 320us/sample - loss: 0.1384 - accuracy: 1.0000\n",
      "69/69 [==============================] - 0s 310us/sample - loss: 0.1409 - accuracy: 0.9710\n",
      "68/68 [==============================] - 0s 309us/sample - loss: 0.1274 - accuracy: 0.9853\n",
      "66/66 [==============================] - 0s 278us/sample - loss: 0.1308 - accuracy: 1.0000\n",
      "65/65 [==============================] - 0s 291us/sample - loss: 0.1229 - accuracy: 0.9846\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.1200 - accuracy: 0.9844\n",
      "65/65 [==============================] - 0s 303us/sample - loss: 0.1219 - accuracy: 1.0000\n",
      "66/66 [==============================] - 0s 275us/sample - loss: 0.1001 - accuracy: 1.0000\n",
      "65/65 [==============================] - 0s 314us/sample - loss: 0.1034 - accuracy: 1.0000\n",
      "65/65 [==============================] - 0s 319us/sample - loss: 0.1207 - accuracy: 1.0000\n",
      "66/66 [==============================] - 0s 319us/sample - loss: 0.1165 - accuracy: 1.0000\n",
      "68/68 [==============================] - 0s 312us/sample - loss: 0.1166 - accuracy: 1.0000\n",
      "66/66 [==============================] - 0s 298us/sample - loss: 0.1371 - accuracy: 0.9848\n",
      "66/66 [==============================] - 0s 312us/sample - loss: 0.1557 - accuracy: 0.9848\n",
      "66/66 [==============================] - 0s 336us/sample - loss: 0.1383 - accuracy: 0.9848\n",
      "67/67 [==============================] - 0s 359us/sample - loss: 0.1196 - accuracy: 0.9851\n",
      "66/66 [==============================] - 0s 365us/sample - loss: 0.1329 - accuracy: 1.0000\n",
      "67/67 [==============================] - 0s 357us/sample - loss: 0.1389 - accuracy: 1.0000\n",
      "66/66 [==============================] - 0s 347us/sample - loss: 0.1611 - accuracy: 0.9848\n",
      "66/66 [==============================] - 0s 326us/sample - loss: 0.1536 - accuracy: 0.9848\n",
      "66/66 [==============================] - 0s 294us/sample - loss: 0.1408 - accuracy: 0.9848\n",
      "66/66 [==============================] - 0s 322us/sample - loss: 0.1458 - accuracy: 0.9848\n",
      "66/66 [==============================] - 0s 344us/sample - loss: 0.1427 - accuracy: 0.9848\n",
      "66/66 [==============================] - 0s 335us/sample - loss: 0.1510 - accuracy: 0.9848\n",
      "66/66 [==============================] - 0s 349us/sample - loss: 0.1431 - accuracy: 0.9697\n",
      "65/65 [==============================] - 0s 322us/sample - loss: 0.1336 - accuracy: 0.9846\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 0.1527 - accuracy: 0.9531\n",
      "65/65 [==============================] - 0s 325us/sample - loss: 0.1329 - accuracy: 0.9846\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2912 samples, validate on 676 samples\n",
      "Epoch 1/300\n",
      "2912/2912 [==============================] - 2s 789us/sample - loss: 0.7268 - accuracy: 0.5010 - val_loss: 0.6832 - val_accuracy: 0.5488\n",
      "Epoch 2/300\n",
      "2912/2912 [==============================] - 1s 228us/sample - loss: 0.6730 - accuracy: 0.5800 - val_loss: 0.6501 - val_accuracy: 0.6302\n",
      "Epoch 3/300\n",
      "2912/2912 [==============================] - 1s 191us/sample - loss: 0.6439 - accuracy: 0.6240 - val_loss: 0.6283 - val_accuracy: 0.6701\n",
      "Epoch 4/300\n",
      "2912/2912 [==============================] - 1s 203us/sample - loss: 0.6230 - accuracy: 0.6549 - val_loss: 0.6125 - val_accuracy: 0.6967\n",
      "Epoch 5/300\n",
      "2912/2912 [==============================] - 1s 216us/sample - loss: 0.6087 - accuracy: 0.6892 - val_loss: 0.6005 - val_accuracy: 0.7278\n",
      "Epoch 6/300\n",
      "2912/2912 [==============================] - 1s 206us/sample - loss: 0.5954 - accuracy: 0.7067 - val_loss: 0.5905 - val_accuracy: 0.7574\n",
      "Epoch 7/300\n",
      "2912/2912 [==============================] - 1s 175us/sample - loss: 0.5857 - accuracy: 0.7191 - val_loss: 0.5822 - val_accuracy: 0.7722\n",
      "Epoch 8/300\n",
      "2912/2912 [==============================] - 1s 196us/sample - loss: 0.5804 - accuracy: 0.7188 - val_loss: 0.5754 - val_accuracy: 0.7766\n",
      "Epoch 9/300\n",
      "2912/2912 [==============================] - 1s 227us/sample - loss: 0.5704 - accuracy: 0.7411 - val_loss: 0.5694 - val_accuracy: 0.7811\n",
      "Epoch 10/300\n",
      "2912/2912 [==============================] - 1s 188us/sample - loss: 0.5622 - accuracy: 0.7510 - val_loss: 0.5642 - val_accuracy: 0.7796\n",
      "Epoch 11/300\n",
      "2912/2912 [==============================] - 1s 202us/sample - loss: 0.5561 - accuracy: 0.7448 - val_loss: 0.5597 - val_accuracy: 0.7870\n",
      "Epoch 12/300\n",
      "2912/2912 [==============================] - 1s 216us/sample - loss: 0.5532 - accuracy: 0.7538 - val_loss: 0.5559 - val_accuracy: 0.7855\n",
      "Epoch 13/300\n",
      "2912/2912 [==============================] - 1s 177us/sample - loss: 0.5468 - accuracy: 0.7576 - val_loss: 0.5524 - val_accuracy: 0.7870\n",
      "Epoch 14/300\n",
      "2912/2912 [==============================] - 1s 220us/sample - loss: 0.5392 - accuracy: 0.7685 - val_loss: 0.5493 - val_accuracy: 0.7885\n",
      "Epoch 15/300\n",
      "2912/2912 [==============================] - 1s 231us/sample - loss: 0.5421 - accuracy: 0.7634 - val_loss: 0.5468 - val_accuracy: 0.7870\n",
      "Epoch 16/300\n",
      "2912/2912 [==============================] - 1s 219us/sample - loss: 0.5339 - accuracy: 0.7679 - val_loss: 0.5443 - val_accuracy: 0.7870\n",
      "Epoch 17/300\n",
      "2912/2912 [==============================] - 1s 207us/sample - loss: 0.5265 - accuracy: 0.7709 - val_loss: 0.5423 - val_accuracy: 0.7899\n",
      "Epoch 18/300\n",
      "2912/2912 [==============================] - 1s 221us/sample - loss: 0.5270 - accuracy: 0.7692 - val_loss: 0.5406 - val_accuracy: 0.7914\n",
      "Epoch 19/300\n",
      "2912/2912 [==============================] - 1s 194us/sample - loss: 0.5245 - accuracy: 0.7716 - val_loss: 0.5389 - val_accuracy: 0.7914\n",
      "Epoch 20/300\n",
      "2912/2912 [==============================] - 1s 219us/sample - loss: 0.5222 - accuracy: 0.7723 - val_loss: 0.5375 - val_accuracy: 0.7929\n",
      "Epoch 21/300\n",
      "2912/2912 [==============================] - 1s 211us/sample - loss: 0.5168 - accuracy: 0.7727 - val_loss: 0.5362 - val_accuracy: 0.7929\n",
      "Epoch 22/300\n",
      "2912/2912 [==============================] - 1s 203us/sample - loss: 0.5188 - accuracy: 0.7744 - val_loss: 0.5350 - val_accuracy: 0.7929\n",
      "Epoch 23/300\n",
      "2912/2912 [==============================] - 1s 228us/sample - loss: 0.5132 - accuracy: 0.7730 - val_loss: 0.5340 - val_accuracy: 0.7929\n",
      "Epoch 24/300\n",
      "2912/2912 [==============================] - 1s 204us/sample - loss: 0.5077 - accuracy: 0.7782 - val_loss: 0.5331 - val_accuracy: 0.7929\n",
      "Epoch 25/300\n",
      "2912/2912 [==============================] - 1s 200us/sample - loss: 0.5087 - accuracy: 0.7727 - val_loss: 0.5324 - val_accuracy: 0.7929\n",
      "Epoch 26/300\n",
      "2912/2912 [==============================] - 1s 206us/sample - loss: 0.5052 - accuracy: 0.7727 - val_loss: 0.5316 - val_accuracy: 0.7929\n",
      "Epoch 27/300\n",
      "2912/2912 [==============================] - 1s 205us/sample - loss: 0.5064 - accuracy: 0.7809 - val_loss: 0.5310 - val_accuracy: 0.7929\n",
      "Epoch 28/300\n",
      "2912/2912 [==============================] - 1s 200us/sample - loss: 0.5023 - accuracy: 0.7795 - val_loss: 0.5304 - val_accuracy: 0.7929\n",
      "Epoch 29/300\n",
      "2912/2912 [==============================] - 1s 194us/sample - loss: 0.4991 - accuracy: 0.7788 - val_loss: 0.5300 - val_accuracy: 0.7929\n",
      "Epoch 30/300\n",
      "2912/2912 [==============================] - 1s 187us/sample - loss: 0.4965 - accuracy: 0.7823 - val_loss: 0.5296 - val_accuracy: 0.7929\n",
      "Epoch 31/300\n",
      "2912/2912 [==============================] - 1s 188us/sample - loss: 0.4949 - accuracy: 0.7809 - val_loss: 0.5292 - val_accuracy: 0.7929\n",
      "Epoch 32/300\n",
      "2912/2912 [==============================] - 1s 207us/sample - loss: 0.4954 - accuracy: 0.7799 - val_loss: 0.5289 - val_accuracy: 0.7929\n",
      "Epoch 33/300\n",
      "2912/2912 [==============================] - 1s 217us/sample - loss: 0.4885 - accuracy: 0.7833 - val_loss: 0.5287 - val_accuracy: 0.7929\n",
      "Epoch 34/300\n",
      "2912/2912 [==============================] - 1s 212us/sample - loss: 0.4914 - accuracy: 0.7830 - val_loss: 0.5283 - val_accuracy: 0.7929\n",
      "Epoch 35/300\n",
      "2912/2912 [==============================] - 1s 210us/sample - loss: 0.4863 - accuracy: 0.7816 - val_loss: 0.5282 - val_accuracy: 0.7929\n",
      "Epoch 36/300\n",
      "2912/2912 [==============================] - 1s 214us/sample - loss: 0.4845 - accuracy: 0.7819 - val_loss: 0.5280 - val_accuracy: 0.7929\n",
      "Epoch 37/300\n",
      "2912/2912 [==============================] - 1s 207us/sample - loss: 0.4846 - accuracy: 0.7819 - val_loss: 0.5278 - val_accuracy: 0.7914\n",
      "Epoch 38/300\n",
      "2912/2912 [==============================] - 1s 202us/sample - loss: 0.4826 - accuracy: 0.7840 - val_loss: 0.5277 - val_accuracy: 0.7914\n",
      "Epoch 39/300\n",
      "2912/2912 [==============================] - 1s 202us/sample - loss: 0.4810 - accuracy: 0.7840 - val_loss: 0.5276 - val_accuracy: 0.7914\n",
      "Epoch 40/300\n",
      "2912/2912 [==============================] - 1s 212us/sample - loss: 0.4755 - accuracy: 0.7874 - val_loss: 0.5275 - val_accuracy: 0.7914\n",
      "Epoch 41/300\n",
      "2912/2912 [==============================] - 1s 214us/sample - loss: 0.4755 - accuracy: 0.7861 - val_loss: 0.5275 - val_accuracy: 0.7914\n",
      "Epoch 42/300\n",
      "2912/2912 [==============================] - 1s 225us/sample - loss: 0.4774 - accuracy: 0.7857 - val_loss: 0.5274 - val_accuracy: 0.7914\n",
      "Epoch 43/300\n",
      "2912/2912 [==============================] - 1s 223us/sample - loss: 0.4727 - accuracy: 0.7867 - val_loss: 0.5275 - val_accuracy: 0.7914\n",
      "Epoch 44/300\n",
      "2912/2912 [==============================] - 1s 205us/sample - loss: 0.4722 - accuracy: 0.7867 - val_loss: 0.5276 - val_accuracy: 0.7914\n",
      "Epoch 45/300\n",
      "2912/2912 [==============================] - 1s 199us/sample - loss: 0.4712 - accuracy: 0.7850 - val_loss: 0.5276 - val_accuracy: 0.7899\n",
      "Epoch 00045: early stopping\n",
      "61/61 [==============================] - 0s 199us/sample - loss: 0.2998 - accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [5:19:43, 1010.31s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.64s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.33s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 850.203125 steps, validate for 193.0078125 steps\n",
      "Epoch 1/300\n",
      "851/850 [==============================] - 24s 29ms/step - loss: 0.5468 - accuracy: 0.7596 - val_loss: 0.5592 - val_accuracy: 0.7738\n",
      "Epoch 2/300\n",
      "851/850 [==============================] - 23s 27ms/step - loss: 0.5105 - accuracy: 0.7727 - val_loss: 0.5610 - val_accuracy: 0.7696\n",
      "Epoch 3/300\n",
      "851/850 [==============================] - 24s 28ms/step - loss: 0.4957 - accuracy: 0.7786 - val_loss: 0.5625 - val_accuracy: 0.7683\n",
      "Epoch 4/300\n",
      "851/850 [==============================] - 24s 28ms/step - loss: 0.4848 - accuracy: 0.7826 - val_loss: 0.5654 - val_accuracy: 0.7668\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 850.203125 steps, validate for 193.0078125 steps\n",
      "Epoch 1/300\n",
      "851/850 [==============================] - 55s 65ms/step - loss: 0.4674 - accuracy: 0.7892 - val_loss: 0.5725 - val_accuracy: 0.7696\n",
      "Epoch 2/300\n",
      "851/850 [==============================] - 54s 64ms/step - loss: 0.4407 - accuracy: 0.8039 - val_loss: 0.5957 - val_accuracy: 0.7375\n",
      "Epoch 3/300\n",
      "851/850 [==============================] - 54s 64ms/step - loss: 0.4184 - accuracy: 0.8150 - val_loss: 0.5888 - val_accuracy: 0.7573\n",
      "Epoch 4/300\n",
      "851/850 [==============================] - 54s 64ms/step - loss: 0.3968 - accuracy: 0.8271 - val_loss: 0.6192 - val_accuracy: 0.7156\n",
      "Epoch 00004: early stopping\n",
      "144/144 [==============================] - 0s 2ms/sample - loss: 0.3479 - accuracy: 0.8958\n",
      "142/142 [==============================] - 0s 245us/sample - loss: 0.3223 - accuracy: 0.9366\n",
      "137/137 [==============================] - 0s 242us/sample - loss: 0.3227 - accuracy: 0.9124\n",
      "134/134 [==============================] - 0s 252us/sample - loss: 0.3220 - accuracy: 0.9030\n",
      "135/135 [==============================] - 0s 291us/sample - loss: 0.3248 - accuracy: 0.9185\n",
      "134/134 [==============================] - 0s 295us/sample - loss: 0.3308 - accuracy: 0.9179\n",
      "135/135 [==============================] - 0s 249us/sample - loss: 0.3968 - accuracy: 0.8444\n",
      "136/136 [==============================] - 0s 258us/sample - loss: 0.3231 - accuracy: 0.9338\n",
      "138/138 [==============================] - 0s 247us/sample - loss: 0.3237 - accuracy: 0.9130\n",
      "134/134 [==============================] - 0s 262us/sample - loss: 0.3405 - accuracy: 0.8955\n",
      "131/131 [==============================] - 0s 271us/sample - loss: 0.2918 - accuracy: 0.9542\n",
      "129/129 [==============================] - 0s 261us/sample - loss: 0.2956 - accuracy: 0.9380\n",
      "129/129 [==============================] - 0s 266us/sample - loss: 0.3080 - accuracy: 0.9147\n",
      "129/129 [==============================] - 0s 280us/sample - loss: 0.3080 - accuracy: 0.8682\n",
      "130/130 [==============================] - 0s 292us/sample - loss: 0.3078 - accuracy: 0.9000\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.2992 - accuracy: 0.9219\n",
      "127/127 [==============================] - 0s 311us/sample - loss: 0.3062 - accuracy: 0.8976\n",
      "127/127 [==============================] - 0s 227us/sample - loss: 0.2823 - accuracy: 0.9370\n",
      "127/127 [==============================] - 0s 265us/sample - loss: 0.2772 - accuracy: 0.9291\n",
      "126/126 [==============================] - 0s 251us/sample - loss: 0.3055 - accuracy: 0.9127\n",
      "125/125 [==============================] - 0s 261us/sample - loss: 0.3007 - accuracy: 0.8720\n",
      "125/125 [==============================] - 0s 234us/sample - loss: 0.2924 - accuracy: 0.9360\n",
      "124/124 [==============================] - 0s 243us/sample - loss: 0.2815 - accuracy: 0.9597\n",
      "123/123 [==============================] - 0s 307us/sample - loss: 0.2847 - accuracy: 0.9268\n",
      "122/122 [==============================] - 0s 247us/sample - loss: 0.2866 - accuracy: 0.9344\n",
      "122/122 [==============================] - 0s 251us/sample - loss: 0.2731 - accuracy: 0.9508\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.2968 - accuracy: 0.9417\n",
      "123/123 [==============================] - 0s 247us/sample - loss: 0.3025 - accuracy: 0.8943\n",
      "121/121 [==============================] - 0s 253us/sample - loss: 0.2753 - accuracy: 0.9504\n",
      "123/123 [==============================] - 0s 269us/sample - loss: 0.2884 - accuracy: 0.9350\n",
      "123/123 [==============================] - 0s 243us/sample - loss: 0.3029 - accuracy: 0.9268\n",
      "122/122 [==============================] - 0s 248us/sample - loss: 0.2640 - accuracy: 0.9754\n",
      "122/122 [==============================] - 0s 255us/sample - loss: 0.3083 - accuracy: 0.9180\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2877 samples, validate on 660 samples\n",
      "Epoch 1/300\n",
      "2877/2877 [==============================] - 3s 948us/sample - loss: 0.6846 - accuracy: 0.5641 - val_loss: 0.6748 - val_accuracy: 0.5727\n",
      "Epoch 2/300\n",
      "2877/2877 [==============================] - 1s 235us/sample - loss: 0.6581 - accuracy: 0.6062 - val_loss: 0.6547 - val_accuracy: 0.6212\n",
      "Epoch 3/300\n",
      "2877/2877 [==============================] - 1s 223us/sample - loss: 0.6426 - accuracy: 0.6382 - val_loss: 0.6410 - val_accuracy: 0.6697\n",
      "Epoch 4/300\n",
      "2877/2877 [==============================] - 1s 217us/sample - loss: 0.6294 - accuracy: 0.6573 - val_loss: 0.6307 - val_accuracy: 0.6742\n",
      "Epoch 5/300\n",
      "2877/2877 [==============================] - 1s 247us/sample - loss: 0.6185 - accuracy: 0.6712 - val_loss: 0.6219 - val_accuracy: 0.6833\n",
      "Epoch 6/300\n",
      "2877/2877 [==============================] - 1s 222us/sample - loss: 0.6096 - accuracy: 0.6872 - val_loss: 0.6145 - val_accuracy: 0.7015\n",
      "Epoch 7/300\n",
      "2877/2877 [==============================] - 1s 223us/sample - loss: 0.5985 - accuracy: 0.7080 - val_loss: 0.6083 - val_accuracy: 0.7106\n",
      "Epoch 8/300\n",
      "2877/2877 [==============================] - 1s 231us/sample - loss: 0.5920 - accuracy: 0.7153 - val_loss: 0.6026 - val_accuracy: 0.7106\n",
      "Epoch 9/300\n",
      "2877/2877 [==============================] - 1s 221us/sample - loss: 0.5881 - accuracy: 0.7275 - val_loss: 0.5975 - val_accuracy: 0.7152\n",
      "Epoch 10/300\n",
      "2877/2877 [==============================] - 1s 229us/sample - loss: 0.5801 - accuracy: 0.7251 - val_loss: 0.5928 - val_accuracy: 0.7182\n",
      "Epoch 11/300\n",
      "2877/2877 [==============================] - 1s 215us/sample - loss: 0.5745 - accuracy: 0.7324 - val_loss: 0.5886 - val_accuracy: 0.7333\n",
      "Epoch 12/300\n",
      "2877/2877 [==============================] - 1s 208us/sample - loss: 0.5666 - accuracy: 0.7397 - val_loss: 0.5848 - val_accuracy: 0.7424\n",
      "Epoch 13/300\n",
      "2877/2877 [==============================] - 1s 218us/sample - loss: 0.5632 - accuracy: 0.7442 - val_loss: 0.5813 - val_accuracy: 0.7455\n",
      "Epoch 14/300\n",
      "2877/2877 [==============================] - 1s 238us/sample - loss: 0.5579 - accuracy: 0.7487 - val_loss: 0.5781 - val_accuracy: 0.7530\n",
      "Epoch 15/300\n",
      "2877/2877 [==============================] - 1s 222us/sample - loss: 0.5561 - accuracy: 0.7466 - val_loss: 0.5751 - val_accuracy: 0.7561\n",
      "Epoch 16/300\n",
      "2877/2877 [==============================] - 1s 232us/sample - loss: 0.5457 - accuracy: 0.7629 - val_loss: 0.5725 - val_accuracy: 0.7591\n",
      "Epoch 17/300\n",
      "2877/2877 [==============================] - 1s 204us/sample - loss: 0.5454 - accuracy: 0.7616 - val_loss: 0.5700 - val_accuracy: 0.7591\n",
      "Epoch 18/300\n",
      "2877/2877 [==============================] - 1s 185us/sample - loss: 0.5423 - accuracy: 0.7609 - val_loss: 0.5676 - val_accuracy: 0.7591\n",
      "Epoch 19/300\n",
      "2877/2877 [==============================] - 1s 210us/sample - loss: 0.5388 - accuracy: 0.7588 - val_loss: 0.5656 - val_accuracy: 0.7606\n",
      "Epoch 20/300\n",
      "2877/2877 [==============================] - 1s 199us/sample - loss: 0.5314 - accuracy: 0.7657 - val_loss: 0.5636 - val_accuracy: 0.7621\n",
      "Epoch 21/300\n",
      "2877/2877 [==============================] - 1s 235us/sample - loss: 0.5288 - accuracy: 0.7636 - val_loss: 0.5618 - val_accuracy: 0.7652\n",
      "Epoch 22/300\n",
      "2877/2877 [==============================] - 1s 189us/sample - loss: 0.5282 - accuracy: 0.7647 - val_loss: 0.5601 - val_accuracy: 0.7667\n",
      "Epoch 23/300\n",
      "2877/2877 [==============================] - 1s 215us/sample - loss: 0.5236 - accuracy: 0.7706 - val_loss: 0.5585 - val_accuracy: 0.7697\n",
      "Epoch 24/300\n",
      "2877/2877 [==============================] - 1s 226us/sample - loss: 0.5212 - accuracy: 0.7692 - val_loss: 0.5572 - val_accuracy: 0.7697\n",
      "Epoch 25/300\n",
      "2877/2877 [==============================] - 1s 232us/sample - loss: 0.5154 - accuracy: 0.7682 - val_loss: 0.5558 - val_accuracy: 0.7697\n",
      "Epoch 26/300\n",
      "2877/2877 [==============================] - 1s 226us/sample - loss: 0.5102 - accuracy: 0.7716 - val_loss: 0.5545 - val_accuracy: 0.7727\n",
      "Epoch 27/300\n",
      "2877/2877 [==============================] - 1s 225us/sample - loss: 0.5085 - accuracy: 0.7734 - val_loss: 0.5534 - val_accuracy: 0.7727\n",
      "Epoch 28/300\n",
      "2877/2877 [==============================] - 1s 221us/sample - loss: 0.5065 - accuracy: 0.7730 - val_loss: 0.5524 - val_accuracy: 0.7712\n",
      "Epoch 29/300\n",
      "2877/2877 [==============================] - 1s 189us/sample - loss: 0.5046 - accuracy: 0.7723 - val_loss: 0.5514 - val_accuracy: 0.7727\n",
      "Epoch 30/300\n",
      "2877/2877 [==============================] - 1s 190us/sample - loss: 0.4985 - accuracy: 0.7852 - val_loss: 0.5506 - val_accuracy: 0.7727\n",
      "Epoch 31/300\n",
      "2877/2877 [==============================] - 1s 228us/sample - loss: 0.5008 - accuracy: 0.7769 - val_loss: 0.5498 - val_accuracy: 0.7727\n",
      "Epoch 32/300\n",
      "2877/2877 [==============================] - 1s 234us/sample - loss: 0.4930 - accuracy: 0.7883 - val_loss: 0.5492 - val_accuracy: 0.7742\n",
      "Epoch 33/300\n",
      "2877/2877 [==============================] - 1s 229us/sample - loss: 0.4926 - accuracy: 0.7835 - val_loss: 0.5485 - val_accuracy: 0.7742\n",
      "Epoch 34/300\n",
      "2877/2877 [==============================] - 1s 226us/sample - loss: 0.4859 - accuracy: 0.7883 - val_loss: 0.5480 - val_accuracy: 0.7758\n",
      "Epoch 35/300\n",
      "2877/2877 [==============================] - 1s 221us/sample - loss: 0.4854 - accuracy: 0.7859 - val_loss: 0.5476 - val_accuracy: 0.7742\n",
      "Epoch 36/300\n",
      "2877/2877 [==============================] - 1s 237us/sample - loss: 0.4812 - accuracy: 0.7914 - val_loss: 0.5471 - val_accuracy: 0.7727\n",
      "Epoch 37/300\n",
      "2877/2877 [==============================] - 1s 234us/sample - loss: 0.4790 - accuracy: 0.7894 - val_loss: 0.5468 - val_accuracy: 0.7712\n",
      "Epoch 38/300\n",
      "2877/2877 [==============================] - 1s 228us/sample - loss: 0.4777 - accuracy: 0.7946 - val_loss: 0.5465 - val_accuracy: 0.7712\n",
      "Epoch 39/300\n",
      "2877/2877 [==============================] - 1s 239us/sample - loss: 0.4744 - accuracy: 0.7956 - val_loss: 0.5463 - val_accuracy: 0.7712\n",
      "Epoch 40/300\n",
      "2877/2877 [==============================] - 1s 218us/sample - loss: 0.4762 - accuracy: 0.7942 - val_loss: 0.5461 - val_accuracy: 0.7727\n",
      "Epoch 41/300\n",
      "2877/2877 [==============================] - 1s 234us/sample - loss: 0.4717 - accuracy: 0.7911 - val_loss: 0.5460 - val_accuracy: 0.7727\n",
      "Epoch 42/300\n",
      "2877/2877 [==============================] - 1s 236us/sample - loss: 0.4704 - accuracy: 0.7967 - val_loss: 0.5459 - val_accuracy: 0.7727\n",
      "Epoch 43/300\n",
      "2877/2877 [==============================] - 1s 228us/sample - loss: 0.4651 - accuracy: 0.7928 - val_loss: 0.5458 - val_accuracy: 0.7727\n",
      "Epoch 44/300\n",
      "2877/2877 [==============================] - 1s 223us/sample - loss: 0.4620 - accuracy: 0.7984 - val_loss: 0.5459 - val_accuracy: 0.7742\n",
      "Epoch 45/300\n",
      "2877/2877 [==============================] - 1s 220us/sample - loss: 0.4628 - accuracy: 0.7977 - val_loss: 0.5459 - val_accuracy: 0.7727\n",
      "Epoch 46/300\n",
      "2877/2877 [==============================] - 1s 204us/sample - loss: 0.4594 - accuracy: 0.8005 - val_loss: 0.5460 - val_accuracy: 0.7727\n",
      "Epoch 00046: early stopping\n",
      "112/112 [==============================] - 0s 123us/sample - loss: 0.2844 - accuracy: 0.9821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [5:35:54, 998.62s/it] \n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.50s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.26s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 848.734375 steps, validate for 196.265625 steps\n",
      "Epoch 1/300\n",
      "849/848 [==============================] - 25s 29ms/step - loss: 0.6161 - accuracy: 0.6773 - val_loss: 0.5466 - val_accuracy: 0.7779\n",
      "Epoch 2/300\n",
      "849/848 [==============================] - 24s 28ms/step - loss: 0.5128 - accuracy: 0.7715 - val_loss: 0.5481 - val_accuracy: 0.7792\n",
      "Epoch 3/300\n",
      "849/848 [==============================] - 24s 28ms/step - loss: 0.4967 - accuracy: 0.7779 - val_loss: 0.5551 - val_accuracy: 0.7718\n",
      "Epoch 4/300\n",
      "849/848 [==============================] - 24s 29ms/step - loss: 0.4857 - accuracy: 0.7830 - val_loss: 0.5565 - val_accuracy: 0.7694\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 848.734375 steps, validate for 196.265625 steps\n",
      "Epoch 1/300\n",
      "849/848 [==============================] - 56s 65ms/step - loss: 0.4680 - accuracy: 0.7906 - val_loss: 0.6007 - val_accuracy: 0.7180\n",
      "Epoch 2/300\n",
      "849/848 [==============================] - 54s 64ms/step - loss: 0.4413 - accuracy: 0.8041 - val_loss: 0.5660 - val_accuracy: 0.7679\n",
      "Epoch 3/300\n",
      "849/848 [==============================] - 54s 64ms/step - loss: 0.4194 - accuracy: 0.8161 - val_loss: 0.5652 - val_accuracy: 0.7634\n",
      "Epoch 4/300\n",
      "849/848 [==============================] - 54s 64ms/step - loss: 0.3989 - accuracy: 0.8272 - val_loss: 0.5765 - val_accuracy: 0.7583\n",
      "Epoch 5/300\n",
      "849/848 [==============================] - 54s 64ms/step - loss: 0.3793 - accuracy: 0.8371 - val_loss: 0.5748 - val_accuracy: 0.7567\n",
      "Epoch 6/300\n",
      "849/848 [==============================] - 54s 64ms/step - loss: 0.3609 - accuracy: 0.8477 - val_loss: 0.6422 - val_accuracy: 0.7860\n",
      "Epoch 00006: early stopping\n",
      "134/134 [==============================] - 0s 2ms/sample - loss: 0.1217 - accuracy: 0.9776\n",
      "131/131 [==============================] - 0s 280us/sample - loss: 0.1389 - accuracy: 0.9771\n",
      "125/125 [==============================] - 0s 225us/sample - loss: 0.1535 - accuracy: 0.9840\n",
      "125/125 [==============================] - 0s 244us/sample - loss: 0.1676 - accuracy: 0.9760\n",
      "126/126 [==============================] - 0s 240us/sample - loss: 0.1723 - accuracy: 0.9762\n",
      "126/126 [==============================] - 0s 246us/sample - loss: 0.1692 - accuracy: 0.9524\n",
      "126/126 [==============================] - 0s 252us/sample - loss: 0.1663 - accuracy: 0.9683\n",
      "123/123 [==============================] - 0s 259us/sample - loss: 0.1344 - accuracy: 0.9919\n",
      "124/124 [==============================] - 0s 301us/sample - loss: 0.1505 - accuracy: 0.9839\n",
      "123/123 [==============================] - 0s 254us/sample - loss: 0.1334 - accuracy: 0.9837\n",
      "124/124 [==============================] - 0s 289us/sample - loss: 0.1362 - accuracy: 0.9919\n",
      "124/124 [==============================] - 0s 271us/sample - loss: 0.1274 - accuracy: 0.9919\n",
      "123/123 [==============================] - 0s 240us/sample - loss: 0.1169 - accuracy: 0.9837\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 0.1259 - accuracy: 0.9667\n",
      "121/121 [==============================] - 0s 257us/sample - loss: 0.1298 - accuracy: 0.9835\n",
      "121/121 [==============================] - 0s 249us/sample - loss: 0.1068 - accuracy: 1.0000\n",
      "121/121 [==============================] - 0s 260us/sample - loss: 0.1257 - accuracy: 0.9752\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.1147 - accuracy: 1.0000\n",
      "121/121 [==============================] - 0s 256us/sample - loss: 0.0974 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.1028 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 0.1113 - accuracy: 0.9917\n",
      "119/119 [==============================] - 0s 272us/sample - loss: 0.1119 - accuracy: 0.9916\n",
      "119/119 [==============================] - 0s 236us/sample - loss: 0.1206 - accuracy: 0.9748\n",
      "119/119 [==============================] - 0s 290us/sample - loss: 0.1067 - accuracy: 0.9916\n",
      "119/119 [==============================] - 0s 240us/sample - loss: 0.1190 - accuracy: 0.9832\n",
      "118/118 [==============================] - 0s 271us/sample - loss: 0.1064 - accuracy: 0.9915\n",
      "117/117 [==============================] - 0s 246us/sample - loss: 0.1222 - accuracy: 0.9915\n",
      "118/118 [==============================] - 0s 271us/sample - loss: 0.1069 - accuracy: 0.9831\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.1064 - accuracy: 1.0000\n",
      "118/118 [==============================] - 0s 288us/sample - loss: 0.1223 - accuracy: 0.9831\n",
      "117/117 [==============================] - 0s 268us/sample - loss: 0.1352 - accuracy: 0.9658\n",
      "118/118 [==============================] - 0s 277us/sample - loss: 0.1223 - accuracy: 0.9915\n",
      "118/118 [==============================] - 0s 231us/sample - loss: 0.1310 - accuracy: 0.9661\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2867 samples, validate on 671 samples\n",
      "Epoch 1/300\n",
      "2867/2867 [==============================] - 3s 891us/sample - loss: 0.7660 - accuracy: 0.4234 - val_loss: 0.7263 - val_accuracy: 0.4739\n",
      "Epoch 2/300\n",
      "2867/2867 [==============================] - 1s 213us/sample - loss: 0.7018 - accuracy: 0.5298 - val_loss: 0.6850 - val_accuracy: 0.5589\n",
      "Epoch 3/300\n",
      "2867/2867 [==============================] - 1s 264us/sample - loss: 0.6640 - accuracy: 0.5975 - val_loss: 0.6570 - val_accuracy: 0.6140\n",
      "Epoch 4/300\n",
      "2867/2867 [==============================] - 1s 248us/sample - loss: 0.6374 - accuracy: 0.6547 - val_loss: 0.6359 - val_accuracy: 0.6483\n",
      "Epoch 5/300\n",
      "2867/2867 [==============================] - 1s 223us/sample - loss: 0.6182 - accuracy: 0.6781 - val_loss: 0.6188 - val_accuracy: 0.6811\n",
      "Epoch 6/300\n",
      "2867/2867 [==============================] - 1s 264us/sample - loss: 0.5983 - accuracy: 0.7147 - val_loss: 0.6044 - val_accuracy: 0.7034\n",
      "Epoch 7/300\n",
      "2867/2867 [==============================] - 1s 253us/sample - loss: 0.5818 - accuracy: 0.7342 - val_loss: 0.5924 - val_accuracy: 0.7243\n",
      "Epoch 8/300\n",
      "2867/2867 [==============================] - 1s 240us/sample - loss: 0.5661 - accuracy: 0.7496 - val_loss: 0.5818 - val_accuracy: 0.7437\n",
      "Epoch 9/300\n",
      "2867/2867 [==============================] - 1s 242us/sample - loss: 0.5586 - accuracy: 0.7583 - val_loss: 0.5726 - val_accuracy: 0.7511\n",
      "Epoch 10/300\n",
      "2867/2867 [==============================] - 1s 230us/sample - loss: 0.5456 - accuracy: 0.7649 - val_loss: 0.5644 - val_accuracy: 0.7526\n",
      "Epoch 11/300\n",
      "2867/2867 [==============================] - 1s 262us/sample - loss: 0.5337 - accuracy: 0.7740 - val_loss: 0.5574 - val_accuracy: 0.7586\n",
      "Epoch 12/300\n",
      "2867/2867 [==============================] - 1s 266us/sample - loss: 0.5261 - accuracy: 0.7799 - val_loss: 0.5511 - val_accuracy: 0.7601\n",
      "Epoch 13/300\n",
      "2867/2867 [==============================] - 1s 207us/sample - loss: 0.5183 - accuracy: 0.7820 - val_loss: 0.5453 - val_accuracy: 0.7645\n",
      "Epoch 14/300\n",
      "2867/2867 [==============================] - 1s 182us/sample - loss: 0.5087 - accuracy: 0.7928 - val_loss: 0.5404 - val_accuracy: 0.7705\n",
      "Epoch 15/300\n",
      "2867/2867 [==============================] - 1s 192us/sample - loss: 0.5038 - accuracy: 0.7977 - val_loss: 0.5358 - val_accuracy: 0.7690\n",
      "Epoch 16/300\n",
      "2867/2867 [==============================] - 1s 181us/sample - loss: 0.4953 - accuracy: 0.7980 - val_loss: 0.5318 - val_accuracy: 0.7690\n",
      "Epoch 17/300\n",
      "2867/2867 [==============================] - 1s 191us/sample - loss: 0.4886 - accuracy: 0.7991 - val_loss: 0.5281 - val_accuracy: 0.7660\n",
      "Epoch 18/300\n",
      "2867/2867 [==============================] - 1s 181us/sample - loss: 0.4835 - accuracy: 0.7991 - val_loss: 0.5250 - val_accuracy: 0.7675\n",
      "Epoch 19/300\n",
      "2867/2867 [==============================] - 1s 221us/sample - loss: 0.4777 - accuracy: 0.8033 - val_loss: 0.5223 - val_accuracy: 0.7675\n",
      "Epoch 20/300\n",
      "2867/2867 [==============================] - 1s 222us/sample - loss: 0.4755 - accuracy: 0.8064 - val_loss: 0.5197 - val_accuracy: 0.7690\n",
      "Epoch 21/300\n",
      "2867/2867 [==============================] - 1s 250us/sample - loss: 0.4678 - accuracy: 0.8043 - val_loss: 0.5176 - val_accuracy: 0.7690\n",
      "Epoch 22/300\n",
      "2867/2867 [==============================] - 1s 267us/sample - loss: 0.4638 - accuracy: 0.8057 - val_loss: 0.5158 - val_accuracy: 0.7675\n",
      "Epoch 23/300\n",
      "2867/2867 [==============================] - 1s 205us/sample - loss: 0.4589 - accuracy: 0.8096 - val_loss: 0.5140 - val_accuracy: 0.7690\n",
      "Epoch 24/300\n",
      "2867/2867 [==============================] - 1s 215us/sample - loss: 0.4550 - accuracy: 0.8096 - val_loss: 0.5126 - val_accuracy: 0.7720\n",
      "Epoch 25/300\n",
      "2867/2867 [==============================] - 1s 206us/sample - loss: 0.4537 - accuracy: 0.8061 - val_loss: 0.5115 - val_accuracy: 0.7735\n",
      "Epoch 26/300\n",
      "2867/2867 [==============================] - 1s 186us/sample - loss: 0.4483 - accuracy: 0.8130 - val_loss: 0.5104 - val_accuracy: 0.7735\n",
      "Epoch 27/300\n",
      "2867/2867 [==============================] - 1s 211us/sample - loss: 0.4458 - accuracy: 0.8179 - val_loss: 0.5095 - val_accuracy: 0.7735\n",
      "Epoch 28/300\n",
      "2867/2867 [==============================] - 1s 188us/sample - loss: 0.4401 - accuracy: 0.8169 - val_loss: 0.5088 - val_accuracy: 0.7750\n",
      "Epoch 29/300\n",
      "2867/2867 [==============================] - 1s 226us/sample - loss: 0.4380 - accuracy: 0.8207 - val_loss: 0.5082 - val_accuracy: 0.7765\n",
      "Epoch 30/300\n",
      "2867/2867 [==============================] - 1s 243us/sample - loss: 0.4344 - accuracy: 0.8190 - val_loss: 0.5077 - val_accuracy: 0.7779\n",
      "Epoch 31/300\n",
      "2867/2867 [==============================] - 1s 225us/sample - loss: 0.4355 - accuracy: 0.8151 - val_loss: 0.5073 - val_accuracy: 0.7794\n",
      "Epoch 32/300\n",
      "2867/2867 [==============================] - 1s 209us/sample - loss: 0.4280 - accuracy: 0.8172 - val_loss: 0.5070 - val_accuracy: 0.7794\n",
      "Epoch 33/300\n",
      "2867/2867 [==============================] - 1s 232us/sample - loss: 0.4262 - accuracy: 0.8221 - val_loss: 0.5068 - val_accuracy: 0.7809\n",
      "Epoch 34/300\n",
      "2867/2867 [==============================] - 1s 238us/sample - loss: 0.4215 - accuracy: 0.8207 - val_loss: 0.5067 - val_accuracy: 0.7809\n",
      "Epoch 35/300\n",
      "2867/2867 [==============================] - 1s 208us/sample - loss: 0.4210 - accuracy: 0.8211 - val_loss: 0.5067 - val_accuracy: 0.7809\n",
      "Epoch 36/300\n",
      "2867/2867 [==============================] - 1s 196us/sample - loss: 0.4163 - accuracy: 0.8172 - val_loss: 0.5067 - val_accuracy: 0.7809\n",
      "Epoch 37/300\n",
      "2867/2867 [==============================] - 1s 231us/sample - loss: 0.4163 - accuracy: 0.8200 - val_loss: 0.5068 - val_accuracy: 0.7809\n",
      "Epoch 38/300\n",
      "2867/2867 [==============================] - 1s 230us/sample - loss: 0.4085 - accuracy: 0.8256 - val_loss: 0.5069 - val_accuracy: 0.7794\n",
      "Epoch 00038: early stopping\n",
      "111/111 [==============================] - 0s 145us/sample - loss: 0.2802 - accuracy: 0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [5:54:07, 1026.82s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.49s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.23s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 848.5234375 steps, validate for 197.5234375 steps\n",
      "Epoch 1/300\n",
      "849/848 [==============================] - 25s 30ms/step - loss: 0.6644 - accuracy: 0.6329 - val_loss: 0.5487 - val_accuracy: 0.7802\n",
      "Epoch 2/300\n",
      "849/848 [==============================] - 24s 28ms/step - loss: 0.5128 - accuracy: 0.7730 - val_loss: 0.5475 - val_accuracy: 0.7781\n",
      "Epoch 3/300\n",
      "849/848 [==============================] - 24s 28ms/step - loss: 0.4940 - accuracy: 0.7801 - val_loss: 0.5467 - val_accuracy: 0.7777\n",
      "Epoch 4/300\n",
      "849/848 [==============================] - 24s 28ms/step - loss: 0.4812 - accuracy: 0.7856 - val_loss: 0.5508 - val_accuracy: 0.7744\n",
      "Epoch 5/300\n",
      "849/848 [==============================] - 24s 29ms/step - loss: 0.4706 - accuracy: 0.7903 - val_loss: 0.5528 - val_accuracy: 0.7747\n",
      "Epoch 6/300\n",
      "849/848 [==============================] - 24s 28ms/step - loss: 0.4615 - accuracy: 0.7948 - val_loss: 0.5532 - val_accuracy: 0.7718\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 848.5234375 steps, validate for 197.5234375 steps\n",
      "Epoch 1/300\n",
      "849/848 [==============================] - 55s 65ms/step - loss: 0.4453 - accuracy: 0.8029 - val_loss: 0.5791 - val_accuracy: 0.7538\n",
      "Epoch 2/300\n",
      "849/848 [==============================] - 54s 64ms/step - loss: 0.4201 - accuracy: 0.8155 - val_loss: 0.5649 - val_accuracy: 0.7651\n",
      "Epoch 3/300\n",
      "849/848 [==============================] - 54s 64ms/step - loss: 0.3995 - accuracy: 0.8267 - val_loss: 0.5619 - val_accuracy: 0.7645\n",
      "Epoch 4/300\n",
      "849/848 [==============================] - 54s 64ms/step - loss: 0.3806 - accuracy: 0.8367 - val_loss: 0.6050 - val_accuracy: 0.7203\n",
      "Epoch 5/300\n",
      "849/848 [==============================] - 54s 64ms/step - loss: 0.3634 - accuracy: 0.8454 - val_loss: 0.6165 - val_accuracy: 0.7188\n",
      "Epoch 6/300\n",
      "849/848 [==============================] - 54s 64ms/step - loss: 0.3472 - accuracy: 0.8547 - val_loss: 0.5769 - val_accuracy: 0.7774\n",
      "Epoch 00006: early stopping\n",
      "148/148 [==============================] - 0s 1ms/sample - loss: 0.2288 - accuracy: 0.9257\n",
      "138/138 [==============================] - 0s 244us/sample - loss: 0.2348 - accuracy: 0.9348\n",
      "134/134 [==============================] - 0s 223us/sample - loss: 0.2390 - accuracy: 0.9552\n",
      "133/133 [==============================] - 0s 267us/sample - loss: 0.2380 - accuracy: 0.9398\n",
      "133/133 [==============================] - 0s 248us/sample - loss: 0.2211 - accuracy: 0.9398\n",
      "130/130 [==============================] - 0s 251us/sample - loss: 0.2167 - accuracy: 0.9615\n",
      "126/126 [==============================] - 0s 200us/sample - loss: 0.2149 - accuracy: 0.9444\n",
      "126/126 [==============================] - 0s 209us/sample - loss: 0.2322 - accuracy: 0.9286\n",
      "124/124 [==============================] - 0s 245us/sample - loss: 0.2012 - accuracy: 0.9274\n",
      "121/121 [==============================] - 0s 219us/sample - loss: 0.1971 - accuracy: 0.9504\n",
      "118/118 [==============================] - 0s 271us/sample - loss: 0.2225 - accuracy: 0.9407\n",
      "117/117 [==============================] - 0s 245us/sample - loss: 0.2110 - accuracy: 0.9573\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.2403 - accuracy: 0.9417\n",
      "117/117 [==============================] - 0s 269us/sample - loss: 0.2417 - accuracy: 0.9060\n",
      "116/116 [==============================] - 0s 279us/sample - loss: 0.2469 - accuracy: 0.9138\n",
      "114/114 [==============================] - 0s 259us/sample - loss: 0.2748 - accuracy: 0.9035\n",
      "113/113 [==============================] - 0s 270us/sample - loss: 0.2863 - accuracy: 0.9115\n",
      "113/113 [==============================] - 0s 314us/sample - loss: 0.2603 - accuracy: 0.9292\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 0.3222 - accuracy: 0.9375\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 0.2838 - accuracy: 0.9375\n",
      "113/113 [==============================] - 0s 259us/sample - loss: 0.2695 - accuracy: 0.9027\n",
      "112/112 [==============================] - 0s 270us/sample - loss: 0.2229 - accuracy: 0.9375\n",
      "113/113 [==============================] - 0s 257us/sample - loss: 0.2401 - accuracy: 0.9292\n",
      "111/111 [==============================] - 0s 235us/sample - loss: 0.2387 - accuracy: 0.9369\n",
      "110/110 [==============================] - 0s 250us/sample - loss: 0.2531 - accuracy: 0.9364\n",
      "110/110 [==============================] - 0s 256us/sample - loss: 0.2316 - accuracy: 0.9364\n",
      "111/111 [==============================] - 0s 233us/sample - loss: 0.2561 - accuracy: 0.9369\n",
      "109/109 [==============================] - 0s 274us/sample - loss: 0.2418 - accuracy: 0.9266\n",
      "108/108 [==============================] - 0s 300us/sample - loss: 0.2246 - accuracy: 0.9352\n",
      "106/106 [==============================] - 0s 283us/sample - loss: 0.2530 - accuracy: 0.9245\n",
      "106/106 [==============================] - 0s 297us/sample - loss: 0.2592 - accuracy: 0.9434\n",
      "106/106 [==============================] - 0s 252us/sample - loss: 0.2335 - accuracy: 0.9528\n",
      "104/104 [==============================] - 0s 248us/sample - loss: 0.2312 - accuracy: 0.9423\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2871 samples, validate on 679 samples\n",
      "Epoch 1/300\n",
      "2871/2871 [==============================] - 2s 844us/sample - loss: 0.7112 - accuracy: 0.5019 - val_loss: 0.6627 - val_accuracy: 0.6082\n",
      "Epoch 2/300\n",
      "2871/2871 [==============================] - 1s 205us/sample - loss: 0.6712 - accuracy: 0.5928 - val_loss: 0.6373 - val_accuracy: 0.6495\n",
      "Epoch 3/300\n",
      "2871/2871 [==============================] - 1s 206us/sample - loss: 0.6372 - accuracy: 0.6489 - val_loss: 0.6206 - val_accuracy: 0.6760\n",
      "Epoch 4/300\n",
      "2871/2871 [==============================] - 1s 243us/sample - loss: 0.6220 - accuracy: 0.6768 - val_loss: 0.6075 - val_accuracy: 0.7069\n",
      "Epoch 5/300\n",
      "2871/2871 [==============================] - 1s 252us/sample - loss: 0.6046 - accuracy: 0.6970 - val_loss: 0.5970 - val_accuracy: 0.7246\n",
      "Epoch 6/300\n",
      "2871/2871 [==============================] - 1s 205us/sample - loss: 0.5893 - accuracy: 0.7245 - val_loss: 0.5881 - val_accuracy: 0.7393\n",
      "Epoch 7/300\n",
      "2871/2871 [==============================] - 1s 180us/sample - loss: 0.5779 - accuracy: 0.7370 - val_loss: 0.5804 - val_accuracy: 0.7482\n",
      "Epoch 8/300\n",
      "2871/2871 [==============================] - 1s 203us/sample - loss: 0.5653 - accuracy: 0.7443 - val_loss: 0.5739 - val_accuracy: 0.7526\n",
      "Epoch 9/300\n",
      "2871/2871 [==============================] - 1s 258us/sample - loss: 0.5591 - accuracy: 0.7489 - val_loss: 0.5681 - val_accuracy: 0.7585\n",
      "Epoch 10/300\n",
      "2871/2871 [==============================] - 1s 257us/sample - loss: 0.5483 - accuracy: 0.7590 - val_loss: 0.5629 - val_accuracy: 0.7585\n",
      "Epoch 11/300\n",
      "2871/2871 [==============================] - 1s 265us/sample - loss: 0.5402 - accuracy: 0.7645 - val_loss: 0.5584 - val_accuracy: 0.7629\n",
      "Epoch 12/300\n",
      "2871/2871 [==============================] - 1s 224us/sample - loss: 0.5335 - accuracy: 0.7652 - val_loss: 0.5543 - val_accuracy: 0.7599\n",
      "Epoch 13/300\n",
      "2871/2871 [==============================] - 1s 217us/sample - loss: 0.5260 - accuracy: 0.7739 - val_loss: 0.5507 - val_accuracy: 0.7644\n",
      "Epoch 14/300\n",
      "2871/2871 [==============================] - 1s 190us/sample - loss: 0.5178 - accuracy: 0.7736 - val_loss: 0.5475 - val_accuracy: 0.7644\n",
      "Epoch 15/300\n",
      "2871/2871 [==============================] - 1s 177us/sample - loss: 0.5098 - accuracy: 0.7778 - val_loss: 0.5446 - val_accuracy: 0.7673\n",
      "Epoch 16/300\n",
      "2871/2871 [==============================] - 1s 198us/sample - loss: 0.5111 - accuracy: 0.7806 - val_loss: 0.5420 - val_accuracy: 0.7703\n",
      "Epoch 17/300\n",
      "2871/2871 [==============================] - 1s 258us/sample - loss: 0.5017 - accuracy: 0.7837 - val_loss: 0.5397 - val_accuracy: 0.7688\n",
      "Epoch 18/300\n",
      "2871/2871 [==============================] - 1s 259us/sample - loss: 0.4957 - accuracy: 0.7931 - val_loss: 0.5375 - val_accuracy: 0.7703\n",
      "Epoch 19/300\n",
      "2871/2871 [==============================] - 1s 255us/sample - loss: 0.4920 - accuracy: 0.7938 - val_loss: 0.5357 - val_accuracy: 0.7717\n",
      "Epoch 20/300\n",
      "2871/2871 [==============================] - 1s 247us/sample - loss: 0.4813 - accuracy: 0.8004 - val_loss: 0.5340 - val_accuracy: 0.7703\n",
      "Epoch 21/300\n",
      "2871/2871 [==============================] - 1s 243us/sample - loss: 0.4773 - accuracy: 0.7987 - val_loss: 0.5326 - val_accuracy: 0.7732\n",
      "Epoch 22/300\n",
      "2871/2871 [==============================] - 1s 202us/sample - loss: 0.4774 - accuracy: 0.7941 - val_loss: 0.5313 - val_accuracy: 0.7747\n",
      "Epoch 23/300\n",
      "2871/2871 [==============================] - 1s 213us/sample - loss: 0.4706 - accuracy: 0.8029 - val_loss: 0.5302 - val_accuracy: 0.7747\n",
      "Epoch 24/300\n",
      "2871/2871 [==============================] - 1s 210us/sample - loss: 0.4654 - accuracy: 0.8011 - val_loss: 0.5292 - val_accuracy: 0.7747\n",
      "Epoch 25/300\n",
      "2871/2871 [==============================] - 1s 188us/sample - loss: 0.4608 - accuracy: 0.8088 - val_loss: 0.5284 - val_accuracy: 0.7747\n",
      "Epoch 26/300\n",
      "2871/2871 [==============================] - 1s 237us/sample - loss: 0.4605 - accuracy: 0.8039 - val_loss: 0.5277 - val_accuracy: 0.7747\n",
      "Epoch 27/300\n",
      "2871/2871 [==============================] - 1s 259us/sample - loss: 0.4552 - accuracy: 0.8098 - val_loss: 0.5271 - val_accuracy: 0.7776\n",
      "Epoch 28/300\n",
      "2871/2871 [==============================] - 1s 270us/sample - loss: 0.4524 - accuracy: 0.8123 - val_loss: 0.5267 - val_accuracy: 0.7776\n",
      "Epoch 29/300\n",
      "2871/2871 [==============================] - 1s 274us/sample - loss: 0.4459 - accuracy: 0.8137 - val_loss: 0.5264 - val_accuracy: 0.7776\n",
      "Epoch 30/300\n",
      "2871/2871 [==============================] - 1s 222us/sample - loss: 0.4398 - accuracy: 0.8098 - val_loss: 0.5262 - val_accuracy: 0.7776\n",
      "Epoch 31/300\n",
      "2871/2871 [==============================] - 1s 257us/sample - loss: 0.4381 - accuracy: 0.8154 - val_loss: 0.5260 - val_accuracy: 0.7776\n",
      "Epoch 32/300\n",
      "2871/2871 [==============================] - 1s 249us/sample - loss: 0.4360 - accuracy: 0.8137 - val_loss: 0.5259 - val_accuracy: 0.7776\n",
      "Epoch 33/300\n",
      "2871/2871 [==============================] - 1s 231us/sample - loss: 0.4330 - accuracy: 0.8157 - val_loss: 0.5260 - val_accuracy: 0.7776\n",
      "Epoch 34/300\n",
      "2871/2871 [==============================] - 1s 260us/sample - loss: 0.4286 - accuracy: 0.8185 - val_loss: 0.5262 - val_accuracy: 0.7776\n",
      "Epoch 35/300\n",
      "2871/2871 [==============================] - 1s 250us/sample - loss: 0.4265 - accuracy: 0.8150 - val_loss: 0.5264 - val_accuracy: 0.7776\n",
      "Epoch 00035: early stopping\n",
      "99/99 [==============================] - 0s 150us/sample - loss: 0.3509 - accuracy: 0.9596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [6:13:12, 1062.13s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.52s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.27s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 846.0703125 steps, validate for 196.28125 steps\n",
      "Epoch 1/300\n",
      "847/846 [==============================] - 25s 29ms/step - loss: 0.5508 - accuracy: 0.7462 - val_loss: 0.5482 - val_accuracy: 0.7802\n",
      "Epoch 2/300\n",
      "847/846 [==============================] - 23s 28ms/step - loss: 0.5114 - accuracy: 0.7707 - val_loss: 0.5468 - val_accuracy: 0.7789\n",
      "Epoch 3/300\n",
      "847/846 [==============================] - 24s 28ms/step - loss: 0.4968 - accuracy: 0.7765 - val_loss: 0.5501 - val_accuracy: 0.7762\n",
      "Epoch 4/300\n",
      "847/846 [==============================] - 24s 28ms/step - loss: 0.4855 - accuracy: 0.7825 - val_loss: 0.5568 - val_accuracy: 0.7703\n",
      "Epoch 5/300\n",
      "847/846 [==============================] - 24s 28ms/step - loss: 0.4758 - accuracy: 0.7867 - val_loss: 0.5610 - val_accuracy: 0.7695\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 846.0703125 steps, validate for 196.28125 steps\n",
      "Epoch 1/300\n",
      "847/846 [==============================] - 55s 65ms/step - loss: 0.4593 - accuracy: 0.7951 - val_loss: 0.5613 - val_accuracy: 0.7824\n",
      "Epoch 2/300\n",
      "847/846 [==============================] - 54s 63ms/step - loss: 0.4336 - accuracy: 0.8080 - val_loss: 0.5762 - val_accuracy: 0.7586\n",
      "Epoch 3/300\n",
      "847/846 [==============================] - 54s 64ms/step - loss: 0.4123 - accuracy: 0.8202 - val_loss: 0.5929 - val_accuracy: 0.7759\n",
      "Epoch 4/300\n",
      "847/846 [==============================] - 54s 64ms/step - loss: 0.3925 - accuracy: 0.8310 - val_loss: 0.6133 - val_accuracy: 0.7268\n",
      "Epoch 00004: early stopping\n",
      "152/152 [==============================] - 0s 1ms/sample - loss: 0.3003 - accuracy: 0.9079\n",
      "145/145 [==============================] - 0s 227us/sample - loss: 0.2659 - accuracy: 0.9379\n",
      "142/142 [==============================] - 0s 250us/sample - loss: 0.3279 - accuracy: 0.9296\n",
      "138/138 [==============================] - 0s 305us/sample - loss: 0.3055 - accuracy: 0.9203\n",
      "137/137 [==============================] - 0s 256us/sample - loss: 0.2981 - accuracy: 0.9051\n",
      "137/137 [==============================] - 0s 267us/sample - loss: 0.2958 - accuracy: 0.9489\n",
      "136/136 [==============================] - 0s 244us/sample - loss: 0.3291 - accuracy: 0.9044\n",
      "135/135 [==============================] - 0s 239us/sample - loss: 0.3402 - accuracy: 0.8741\n",
      "136/136 [==============================] - 0s 241us/sample - loss: 0.2919 - accuracy: 0.8971\n",
      "134/134 [==============================] - 0s 279us/sample - loss: 0.2795 - accuracy: 0.9179\n",
      "132/132 [==============================] - 0s 264us/sample - loss: 0.2780 - accuracy: 0.9470\n",
      "132/132 [==============================] - 0s 288us/sample - loss: 0.3135 - accuracy: 0.9015\n",
      "133/133 [==============================] - 0s 251us/sample - loss: 0.3037 - accuracy: 0.8947\n",
      "132/132 [==============================] - 0s 277us/sample - loss: 0.3007 - accuracy: 0.9167\n",
      "133/133 [==============================] - 0s 266us/sample - loss: 0.2859 - accuracy: 0.9173\n",
      "130/130 [==============================] - 0s 273us/sample - loss: 0.3167 - accuracy: 0.8923\n",
      "132/132 [==============================] - 0s 279us/sample - loss: 0.3330 - accuracy: 0.8712\n",
      "131/131 [==============================] - 0s 287us/sample - loss: 0.3186 - accuracy: 0.8855\n",
      "132/132 [==============================] - 0s 294us/sample - loss: 0.2888 - accuracy: 0.9091\n",
      "131/131 [==============================] - 0s 307us/sample - loss: 0.2768 - accuracy: 0.9008\n",
      "129/129 [==============================] - 0s 311us/sample - loss: 0.2827 - accuracy: 0.9225\n",
      "129/129 [==============================] - 0s 278us/sample - loss: 0.3102 - accuracy: 0.8837\n",
      "129/129 [==============================] - 0s 308us/sample - loss: 0.3023 - accuracy: 0.9302\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.3022 - accuracy: 0.8984\n",
      "129/129 [==============================] - 0s 305us/sample - loss: 0.3018 - accuracy: 0.9147\n",
      "127/127 [==============================] - 0s 287us/sample - loss: 0.3184 - accuracy: 0.8976\n",
      "127/127 [==============================] - 0s 281us/sample - loss: 0.3092 - accuracy: 0.8898\n",
      "126/126 [==============================] - 0s 230us/sample - loss: 0.3485 - accuracy: 0.8889\n",
      "124/124 [==============================] - 0s 310us/sample - loss: 0.3245 - accuracy: 0.8952\n",
      "126/126 [==============================] - 0s 241us/sample - loss: 0.3213 - accuracy: 0.9127\n",
      "125/125 [==============================] - 0s 256us/sample - loss: 0.3471 - accuracy: 0.9040\n",
      "123/123 [==============================] - 0s 248us/sample - loss: 0.3536 - accuracy: 0.8780\n",
      "125/125 [==============================] - 0s 267us/sample - loss: 0.3413 - accuracy: 0.9040\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2858 samples, validate on 672 samples\n",
      "Epoch 1/300\n",
      "2858/2858 [==============================] - 2s 829us/sample - loss: 0.6791 - accuracy: 0.5857 - val_loss: 0.6487 - val_accuracy: 0.6250\n",
      "Epoch 2/300\n",
      "2858/2858 [==============================] - 1s 209us/sample - loss: 0.6500 - accuracy: 0.6274 - val_loss: 0.6302 - val_accuracy: 0.6622\n",
      "Epoch 3/300\n",
      "2858/2858 [==============================] - 1s 206us/sample - loss: 0.6295 - accuracy: 0.6620 - val_loss: 0.6172 - val_accuracy: 0.6801\n",
      "Epoch 4/300\n",
      "2858/2858 [==============================] - 1s 214us/sample - loss: 0.6172 - accuracy: 0.6872 - val_loss: 0.6069 - val_accuracy: 0.6890\n",
      "Epoch 5/300\n",
      "2858/2858 [==============================] - 1s 237us/sample - loss: 0.6097 - accuracy: 0.7057 - val_loss: 0.5988 - val_accuracy: 0.6964\n",
      "Epoch 6/300\n",
      "2858/2858 [==============================] - 1s 197us/sample - loss: 0.5974 - accuracy: 0.7141 - val_loss: 0.5916 - val_accuracy: 0.7054\n",
      "Epoch 7/300\n",
      "2858/2858 [==============================] - 1s 201us/sample - loss: 0.5912 - accuracy: 0.7267 - val_loss: 0.5855 - val_accuracy: 0.7128\n",
      "Epoch 8/300\n",
      "2858/2858 [==============================] - 1s 234us/sample - loss: 0.5834 - accuracy: 0.7383 - val_loss: 0.5800 - val_accuracy: 0.7188\n",
      "Epoch 9/300\n",
      "2858/2858 [==============================] - 1s 197us/sample - loss: 0.5766 - accuracy: 0.7418 - val_loss: 0.5752 - val_accuracy: 0.7262\n",
      "Epoch 10/300\n",
      "2858/2858 [==============================] - 1s 216us/sample - loss: 0.5648 - accuracy: 0.7516 - val_loss: 0.5707 - val_accuracy: 0.7351\n",
      "Epoch 11/300\n",
      "2858/2858 [==============================] - 1s 217us/sample - loss: 0.5609 - accuracy: 0.7614 - val_loss: 0.5667 - val_accuracy: 0.7366\n",
      "Epoch 12/300\n",
      "2858/2858 [==============================] - 1s 191us/sample - loss: 0.5604 - accuracy: 0.7481 - val_loss: 0.5631 - val_accuracy: 0.7351\n",
      "Epoch 13/300\n",
      "2858/2858 [==============================] - 1s 196us/sample - loss: 0.5560 - accuracy: 0.7568 - val_loss: 0.5596 - val_accuracy: 0.7336\n",
      "Epoch 14/300\n",
      "2858/2858 [==============================] - 1s 226us/sample - loss: 0.5481 - accuracy: 0.7631 - val_loss: 0.5567 - val_accuracy: 0.7336\n",
      "Epoch 15/300\n",
      "2858/2858 [==============================] - 1s 207us/sample - loss: 0.5446 - accuracy: 0.7582 - val_loss: 0.5538 - val_accuracy: 0.7411\n",
      "Epoch 16/300\n",
      "2858/2858 [==============================] - 1s 206us/sample - loss: 0.5388 - accuracy: 0.7652 - val_loss: 0.5513 - val_accuracy: 0.7426\n",
      "Epoch 17/300\n",
      "2858/2858 [==============================] - 1s 204us/sample - loss: 0.5352 - accuracy: 0.7652 - val_loss: 0.5490 - val_accuracy: 0.7455\n",
      "Epoch 18/300\n",
      "2858/2858 [==============================] - 1s 198us/sample - loss: 0.5318 - accuracy: 0.7750 - val_loss: 0.5469 - val_accuracy: 0.7440\n",
      "Epoch 19/300\n",
      "2858/2858 [==============================] - 1s 246us/sample - loss: 0.5283 - accuracy: 0.7764 - val_loss: 0.5447 - val_accuracy: 0.7485\n",
      "Epoch 20/300\n",
      "2858/2858 [==============================] - 1s 231us/sample - loss: 0.5233 - accuracy: 0.7726 - val_loss: 0.5428 - val_accuracy: 0.7470\n",
      "Epoch 21/300\n",
      "2858/2858 [==============================] - 1s 230us/sample - loss: 0.5220 - accuracy: 0.7785 - val_loss: 0.5411 - val_accuracy: 0.7470\n",
      "Epoch 22/300\n",
      "2858/2858 [==============================] - 1s 211us/sample - loss: 0.5172 - accuracy: 0.7736 - val_loss: 0.5396 - val_accuracy: 0.7485\n",
      "Epoch 23/300\n",
      "2858/2858 [==============================] - 1s 220us/sample - loss: 0.5124 - accuracy: 0.7806 - val_loss: 0.5381 - val_accuracy: 0.7485\n",
      "Epoch 24/300\n",
      "2858/2858 [==============================] - 1s 227us/sample - loss: 0.5134 - accuracy: 0.7771 - val_loss: 0.5367 - val_accuracy: 0.7515\n",
      "Epoch 25/300\n",
      "2858/2858 [==============================] - 1s 233us/sample - loss: 0.5055 - accuracy: 0.7810 - val_loss: 0.5355 - val_accuracy: 0.7530\n",
      "Epoch 26/300\n",
      "2858/2858 [==============================] - 1s 222us/sample - loss: 0.5063 - accuracy: 0.7799 - val_loss: 0.5345 - val_accuracy: 0.7560\n",
      "Epoch 27/300\n",
      "2858/2858 [==============================] - 1s 209us/sample - loss: 0.5047 - accuracy: 0.7792 - val_loss: 0.5334 - val_accuracy: 0.7574\n",
      "Epoch 28/300\n",
      "2858/2858 [==============================] - 1s 187us/sample - loss: 0.4986 - accuracy: 0.7866 - val_loss: 0.5326 - val_accuracy: 0.7574\n",
      "Epoch 29/300\n",
      "2858/2858 [==============================] - 1s 240us/sample - loss: 0.4946 - accuracy: 0.7964 - val_loss: 0.5318 - val_accuracy: 0.7574\n",
      "Epoch 30/300\n",
      "2858/2858 [==============================] - 1s 223us/sample - loss: 0.4940 - accuracy: 0.7873 - val_loss: 0.5310 - val_accuracy: 0.7560\n",
      "Epoch 31/300\n",
      "2858/2858 [==============================] - 1s 232us/sample - loss: 0.4895 - accuracy: 0.7911 - val_loss: 0.5303 - val_accuracy: 0.7560\n",
      "Epoch 32/300\n",
      "2858/2858 [==============================] - 1s 226us/sample - loss: 0.4859 - accuracy: 0.7922 - val_loss: 0.5296 - val_accuracy: 0.7574\n",
      "Epoch 33/300\n",
      "2858/2858 [==============================] - 1s 225us/sample - loss: 0.4829 - accuracy: 0.7950 - val_loss: 0.5292 - val_accuracy: 0.7560\n",
      "Epoch 34/300\n",
      "2858/2858 [==============================] - 1s 246us/sample - loss: 0.4806 - accuracy: 0.7911 - val_loss: 0.5287 - val_accuracy: 0.7574\n",
      "Epoch 35/300\n",
      "2858/2858 [==============================] - 1s 215us/sample - loss: 0.4797 - accuracy: 0.7943 - val_loss: 0.5284 - val_accuracy: 0.7574\n",
      "Epoch 36/300\n",
      "2858/2858 [==============================] - 1s 230us/sample - loss: 0.4761 - accuracy: 0.7953 - val_loss: 0.5280 - val_accuracy: 0.7574\n",
      "Epoch 37/300\n",
      "2858/2858 [==============================] - 1s 204us/sample - loss: 0.4717 - accuracy: 0.8013 - val_loss: 0.5277 - val_accuracy: 0.7589\n",
      "Epoch 38/300\n",
      "2858/2858 [==============================] - 1s 226us/sample - loss: 0.4730 - accuracy: 0.7974 - val_loss: 0.5276 - val_accuracy: 0.7574\n",
      "Epoch 39/300\n",
      "2858/2858 [==============================] - 1s 198us/sample - loss: 0.4691 - accuracy: 0.7985 - val_loss: 0.5273 - val_accuracy: 0.7589\n",
      "Epoch 40/300\n",
      "2858/2858 [==============================] - 1s 227us/sample - loss: 0.4716 - accuracy: 0.7992 - val_loss: 0.5271 - val_accuracy: 0.7589\n",
      "Epoch 41/300\n",
      "2858/2858 [==============================] - 1s 251us/sample - loss: 0.4677 - accuracy: 0.7988 - val_loss: 0.5269 - val_accuracy: 0.7589\n",
      "Epoch 42/300\n",
      "2858/2858 [==============================] - 1s 230us/sample - loss: 0.4636 - accuracy: 0.8023 - val_loss: 0.5269 - val_accuracy: 0.7589\n",
      "Epoch 43/300\n",
      "2858/2858 [==============================] - 1s 217us/sample - loss: 0.4624 - accuracy: 0.8006 - val_loss: 0.5269 - val_accuracy: 0.7589\n",
      "Epoch 44/300\n",
      "2858/2858 [==============================] - 1s 217us/sample - loss: 0.4579 - accuracy: 0.7992 - val_loss: 0.5269 - val_accuracy: 0.7589\n",
      "Epoch 45/300\n",
      "2858/2858 [==============================] - 1s 206us/sample - loss: 0.4576 - accuracy: 0.8079 - val_loss: 0.5269 - val_accuracy: 0.7589\n",
      "Epoch 46/300\n",
      "2858/2858 [==============================] - 1s 198us/sample - loss: 0.4534 - accuracy: 0.8065 - val_loss: 0.5270 - val_accuracy: 0.7604\n",
      "Epoch 47/300\n",
      "2858/2858 [==============================] - 1s 248us/sample - loss: 0.4553 - accuracy: 0.8027 - val_loss: 0.5270 - val_accuracy: 0.7604\n",
      "Epoch 00047: early stopping\n",
      "119/119 [==============================] - 0s 3ms/sample - loss: 0.2840 - accuracy: 0.9412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [6:30:13, 1049.83s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.54s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.39s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 844.1953125 steps, validate for 196.8125 steps\n",
      "Epoch 1/300\n",
      "845/844 [==============================] - 25s 30ms/step - loss: 0.6690 - accuracy: 0.6273 - val_loss: 0.5431 - val_accuracy: 0.7777\n",
      "Epoch 2/300\n",
      "845/844 [==============================] - 24s 28ms/step - loss: 0.5137 - accuracy: 0.7719 - val_loss: 0.5477 - val_accuracy: 0.7762\n",
      "Epoch 3/300\n",
      "845/844 [==============================] - 24s 28ms/step - loss: 0.4960 - accuracy: 0.7784 - val_loss: 0.5480 - val_accuracy: 0.7762\n",
      "Epoch 4/300\n",
      "845/844 [==============================] - 24s 28ms/step - loss: 0.4839 - accuracy: 0.7838 - val_loss: 0.5500 - val_accuracy: 0.7724\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 844.1953125 steps, validate for 196.8125 steps\n",
      "Epoch 1/300\n",
      "845/844 [==============================] - 55s 65ms/step - loss: 0.4661 - accuracy: 0.7935 - val_loss: 0.5530 - val_accuracy: 0.7766\n",
      "Epoch 2/300\n",
      "845/844 [==============================] - 54s 64ms/step - loss: 0.4393 - accuracy: 0.8068 - val_loss: 0.5736 - val_accuracy: 0.7555\n",
      "Epoch 3/300\n",
      "845/844 [==============================] - 54s 63ms/step - loss: 0.4164 - accuracy: 0.8195 - val_loss: 0.5821 - val_accuracy: 0.7407\n",
      "Epoch 4/300\n",
      "845/844 [==============================] - 54s 64ms/step - loss: 0.3959 - accuracy: 0.8298 - val_loss: 0.5757 - val_accuracy: 0.7627\n",
      "Epoch 00004: early stopping\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 0.3605 - accuracy: 0.8820\n",
      "154/154 [==============================] - 0s 243us/sample - loss: 0.3836 - accuracy: 0.8896\n",
      "151/151 [==============================] - 0s 237us/sample - loss: 0.3197 - accuracy: 0.9205\n",
      "146/146 [==============================] - 0s 260us/sample - loss: 0.2835 - accuracy: 0.9178\n",
      "147/147 [==============================] - 0s 219us/sample - loss: 0.2572 - accuracy: 0.9184\n",
      "145/145 [==============================] - 0s 250us/sample - loss: 0.2411 - accuracy: 0.9310\n",
      "145/145 [==============================] - 0s 233us/sample - loss: 0.2399 - accuracy: 0.9517\n",
      "144/144 [==============================] - 0s 228us/sample - loss: 0.2407 - accuracy: 0.9167\n",
      "145/145 [==============================] - 0s 254us/sample - loss: 0.2417 - accuracy: 0.9310\n",
      "143/143 [==============================] - 0s 222us/sample - loss: 0.2581 - accuracy: 0.9441\n",
      "142/142 [==============================] - 0s 266us/sample - loss: 0.2452 - accuracy: 0.9296\n",
      "140/140 [==============================] - 0s 244us/sample - loss: 0.2123 - accuracy: 0.9500\n",
      "138/138 [==============================] - 0s 238us/sample - loss: 0.2291 - accuracy: 0.9565\n",
      "138/138 [==============================] - 0s 239us/sample - loss: 0.2077 - accuracy: 0.9493\n",
      "137/137 [==============================] - 0s 254us/sample - loss: 0.2000 - accuracy: 0.9781\n",
      "136/136 [==============================] - 0s 249us/sample - loss: 0.2160 - accuracy: 0.9559\n",
      "138/138 [==============================] - 0s 238us/sample - loss: 0.2257 - accuracy: 0.9493\n",
      "138/138 [==============================] - 0s 254us/sample - loss: 0.2772 - accuracy: 0.9130\n",
      "137/137 [==============================] - 0s 271us/sample - loss: 0.2145 - accuracy: 0.9708\n",
      "136/136 [==============================] - 0s 261us/sample - loss: 0.2256 - accuracy: 0.9632\n",
      "136/136 [==============================] - 0s 264us/sample - loss: 0.2210 - accuracy: 0.9779\n",
      "136/136 [==============================] - 0s 265us/sample - loss: 0.2350 - accuracy: 0.9559\n",
      "136/136 [==============================] - 0s 280us/sample - loss: 0.2375 - accuracy: 0.9559\n",
      "135/135 [==============================] - 0s 245us/sample - loss: 0.1993 - accuracy: 0.9778\n",
      "135/135 [==============================] - 0s 277us/sample - loss: 0.2348 - accuracy: 0.9556\n",
      "134/134 [==============================] - 0s 265us/sample - loss: 0.2221 - accuracy: 0.9627\n",
      "133/133 [==============================] - 0s 244us/sample - loss: 0.2159 - accuracy: 0.9624\n",
      "125/125 [==============================] - 0s 253us/sample - loss: 0.2470 - accuracy: 0.9440\n",
      "124/124 [==============================] - 0s 256us/sample - loss: 0.2024 - accuracy: 0.9677\n",
      "122/122 [==============================] - 0s 245us/sample - loss: 0.2383 - accuracy: 0.9672\n",
      "119/119 [==============================] - 0s 273us/sample - loss: 0.2291 - accuracy: 0.9580\n",
      "117/117 [==============================] - 0s 246us/sample - loss: 0.2565 - accuracy: 0.9573\n",
      "116/116 [==============================] - 0s 248us/sample - loss: 0.2530 - accuracy: 0.9655\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2870 samples, validate on 671 samples\n",
      "Epoch 1/300\n",
      "2870/2870 [==============================] - 3s 879us/sample - loss: 0.6748 - accuracy: 0.5760 - val_loss: 0.6531 - val_accuracy: 0.6200\n",
      "Epoch 2/300\n",
      "2870/2870 [==============================] - 1s 262us/sample - loss: 0.6375 - accuracy: 0.6331 - val_loss: 0.6306 - val_accuracy: 0.6617\n",
      "Epoch 3/300\n",
      "2870/2870 [==============================] - 1s 247us/sample - loss: 0.6171 - accuracy: 0.6666 - val_loss: 0.6152 - val_accuracy: 0.6885\n",
      "Epoch 4/300\n",
      "2870/2870 [==============================] - 1s 221us/sample - loss: 0.5983 - accuracy: 0.6847 - val_loss: 0.6038 - val_accuracy: 0.7079\n",
      "Epoch 5/300\n",
      "2870/2870 [==============================] - 1s 240us/sample - loss: 0.5864 - accuracy: 0.7007 - val_loss: 0.5946 - val_accuracy: 0.7213\n",
      "Epoch 6/300\n",
      "2870/2870 [==============================] - 1s 230us/sample - loss: 0.5769 - accuracy: 0.7160 - val_loss: 0.5870 - val_accuracy: 0.7273\n",
      "Epoch 7/300\n",
      "2870/2870 [==============================] - 1s 227us/sample - loss: 0.5685 - accuracy: 0.7213 - val_loss: 0.5805 - val_accuracy: 0.7317\n",
      "Epoch 8/300\n",
      "2870/2870 [==============================] - 1s 253us/sample - loss: 0.5596 - accuracy: 0.7355 - val_loss: 0.5746 - val_accuracy: 0.7347\n",
      "Epoch 9/300\n",
      "2870/2870 [==============================] - 1s 235us/sample - loss: 0.5538 - accuracy: 0.7401 - val_loss: 0.5696 - val_accuracy: 0.7407\n",
      "Epoch 10/300\n",
      "2870/2870 [==============================] - 1s 227us/sample - loss: 0.5458 - accuracy: 0.7495 - val_loss: 0.5651 - val_accuracy: 0.7481\n",
      "Epoch 11/300\n",
      "2870/2870 [==============================] - 1s 265us/sample - loss: 0.5437 - accuracy: 0.7467 - val_loss: 0.5612 - val_accuracy: 0.7556\n",
      "Epoch 12/300\n",
      "2870/2870 [==============================] - 1s 252us/sample - loss: 0.5366 - accuracy: 0.7509 - val_loss: 0.5575 - val_accuracy: 0.7630\n",
      "Epoch 13/300\n",
      "2870/2870 [==============================] - 1s 211us/sample - loss: 0.5290 - accuracy: 0.7697 - val_loss: 0.5544 - val_accuracy: 0.7645\n",
      "Epoch 14/300\n",
      "2870/2870 [==============================] - 1s 210us/sample - loss: 0.5253 - accuracy: 0.7672 - val_loss: 0.5516 - val_accuracy: 0.7675\n",
      "Epoch 15/300\n",
      "2870/2870 [==============================] - 1s 215us/sample - loss: 0.5227 - accuracy: 0.7645 - val_loss: 0.5490 - val_accuracy: 0.7660\n",
      "Epoch 16/300\n",
      "2870/2870 [==============================] - 1s 236us/sample - loss: 0.5145 - accuracy: 0.7679 - val_loss: 0.5468 - val_accuracy: 0.7660\n",
      "Epoch 17/300\n",
      "2870/2870 [==============================] - 1s 239us/sample - loss: 0.5127 - accuracy: 0.7801 - val_loss: 0.5449 - val_accuracy: 0.7690\n",
      "Epoch 18/300\n",
      "2870/2870 [==============================] - 1s 238us/sample - loss: 0.5074 - accuracy: 0.7725 - val_loss: 0.5430 - val_accuracy: 0.7705\n",
      "Epoch 19/300\n",
      "2870/2870 [==============================] - 1s 235us/sample - loss: 0.5049 - accuracy: 0.7749 - val_loss: 0.5414 - val_accuracy: 0.7750\n",
      "Epoch 20/300\n",
      "2870/2870 [==============================] - 1s 204us/sample - loss: 0.5035 - accuracy: 0.7763 - val_loss: 0.5400 - val_accuracy: 0.7765\n",
      "Epoch 21/300\n",
      "2870/2870 [==============================] - 1s 222us/sample - loss: 0.4968 - accuracy: 0.7826 - val_loss: 0.5386 - val_accuracy: 0.7779\n",
      "Epoch 22/300\n",
      "2870/2870 [==============================] - 1s 226us/sample - loss: 0.4964 - accuracy: 0.7774 - val_loss: 0.5375 - val_accuracy: 0.7794\n",
      "Epoch 23/300\n",
      "2870/2870 [==============================] - 1s 258us/sample - loss: 0.4906 - accuracy: 0.7794 - val_loss: 0.5364 - val_accuracy: 0.7794\n",
      "Epoch 24/300\n",
      "2870/2870 [==============================] - 1s 260us/sample - loss: 0.4847 - accuracy: 0.7847 - val_loss: 0.5355 - val_accuracy: 0.7809\n",
      "Epoch 25/300\n",
      "2870/2870 [==============================] - 1s 233us/sample - loss: 0.4871 - accuracy: 0.7794 - val_loss: 0.5347 - val_accuracy: 0.7809\n",
      "Epoch 26/300\n",
      "2870/2870 [==============================] - 1s 239us/sample - loss: 0.4886 - accuracy: 0.7829 - val_loss: 0.5340 - val_accuracy: 0.7809\n",
      "Epoch 27/300\n",
      "2870/2870 [==============================] - 1s 256us/sample - loss: 0.4848 - accuracy: 0.7875 - val_loss: 0.5334 - val_accuracy: 0.7824\n",
      "Epoch 28/300\n",
      "2870/2870 [==============================] - 1s 233us/sample - loss: 0.4804 - accuracy: 0.7801 - val_loss: 0.5327 - val_accuracy: 0.7824\n",
      "Epoch 29/300\n",
      "2870/2870 [==============================] - 1s 248us/sample - loss: 0.4775 - accuracy: 0.7875 - val_loss: 0.5322 - val_accuracy: 0.7839\n",
      "Epoch 30/300\n",
      "2870/2870 [==============================] - 1s 253us/sample - loss: 0.4750 - accuracy: 0.7916 - val_loss: 0.5319 - val_accuracy: 0.7854\n",
      "Epoch 31/300\n",
      "2870/2870 [==============================] - 1s 236us/sample - loss: 0.4717 - accuracy: 0.7948 - val_loss: 0.5316 - val_accuracy: 0.7854\n",
      "Epoch 32/300\n",
      "2870/2870 [==============================] - 1s 213us/sample - loss: 0.4691 - accuracy: 0.7965 - val_loss: 0.5313 - val_accuracy: 0.7854\n",
      "Epoch 33/300\n",
      "2870/2870 [==============================] - 1s 235us/sample - loss: 0.4652 - accuracy: 0.8000 - val_loss: 0.5310 - val_accuracy: 0.7854\n",
      "Epoch 34/300\n",
      "2870/2870 [==============================] - 1s 240us/sample - loss: 0.4642 - accuracy: 0.7979 - val_loss: 0.5310 - val_accuracy: 0.7854\n",
      "Epoch 35/300\n",
      "2870/2870 [==============================] - 1s 233us/sample - loss: 0.4625 - accuracy: 0.7920 - val_loss: 0.5309 - val_accuracy: 0.7854\n",
      "Epoch 36/300\n",
      "2870/2870 [==============================] - 1s 252us/sample - loss: 0.4628 - accuracy: 0.7951 - val_loss: 0.5309 - val_accuracy: 0.7854\n",
      "Epoch 37/300\n",
      "2870/2870 [==============================] - 1s 240us/sample - loss: 0.4591 - accuracy: 0.8000 - val_loss: 0.5309 - val_accuracy: 0.7854\n",
      "Epoch 38/300\n",
      "2870/2870 [==============================] - 1s 220us/sample - loss: 0.4557 - accuracy: 0.8042 - val_loss: 0.5309 - val_accuracy: 0.7854\n",
      "Epoch 39/300\n",
      "2870/2870 [==============================] - 1s 235us/sample - loss: 0.4541 - accuracy: 0.8021 - val_loss: 0.5310 - val_accuracy: 0.7854\n",
      "Epoch 40/300\n",
      "2870/2870 [==============================] - 1s 244us/sample - loss: 0.4540 - accuracy: 0.7993 - val_loss: 0.5312 - val_accuracy: 0.7854\n",
      "Epoch 00040: early stopping\n",
      "108/108 [==============================] - 0s 199us/sample - loss: 0.2688 - accuracy: 0.9444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [6:46:40, 1031.13s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.72s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.34s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 846.5703125 steps, validate for 195.578125 steps\n",
      "Epoch 1/300\n",
      "847/846 [==============================] - 25s 29ms/step - loss: 0.5485 - accuracy: 0.7505 - val_loss: 0.5511 - val_accuracy: 0.7765\n",
      "Epoch 2/300\n",
      "847/846 [==============================] - 24s 28ms/step - loss: 0.5093 - accuracy: 0.7719 - val_loss: 0.5541 - val_accuracy: 0.7736\n",
      "Epoch 3/300\n",
      "847/846 [==============================] - 24s 28ms/step - loss: 0.4946 - accuracy: 0.7770 - val_loss: 0.5537 - val_accuracy: 0.7726\n",
      "Epoch 4/300\n",
      "847/846 [==============================] - 24s 28ms/step - loss: 0.4837 - accuracy: 0.7825 - val_loss: 0.5601 - val_accuracy: 0.7717\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 846.5703125 steps, validate for 195.578125 steps\n",
      "Epoch 1/300\n",
      "847/846 [==============================] - 55s 65ms/step - loss: 0.4640 - accuracy: 0.7923 - val_loss: 0.5660 - val_accuracy: 0.7608\n",
      "Epoch 2/300\n",
      "847/846 [==============================] - 54s 64ms/step - loss: 0.4359 - accuracy: 0.8076 - val_loss: 0.5818 - val_accuracy: 0.7723\n",
      "Epoch 3/300\n",
      "847/846 [==============================] - 54s 64ms/step - loss: 0.4124 - accuracy: 0.8201 - val_loss: 0.5782 - val_accuracy: 0.7770\n",
      "Epoch 4/300\n",
      "847/846 [==============================] - 54s 64ms/step - loss: 0.3902 - accuracy: 0.8322 - val_loss: 0.5997 - val_accuracy: 0.7290\n",
      "Epoch 00004: early stopping\n",
      "148/148 [==============================] - 0s 1ms/sample - loss: 0.2768 - accuracy: 0.9527\n",
      "147/147 [==============================] - 0s 210us/sample - loss: 0.2944 - accuracy: 0.9184\n",
      "146/146 [==============================] - 0s 228us/sample - loss: 0.2828 - accuracy: 0.9247\n",
      "144/144 [==============================] - 0s 232us/sample - loss: 0.2710 - accuracy: 0.9514\n",
      "144/144 [==============================] - 0s 221us/sample - loss: 0.2977 - accuracy: 0.9444\n",
      "140/140 [==============================] - 0s 223us/sample - loss: 0.2898 - accuracy: 0.9071\n",
      "139/139 [==============================] - 0s 215us/sample - loss: 0.3162 - accuracy: 0.9281\n",
      "138/138 [==============================] - 0s 238us/sample - loss: 0.2890 - accuracy: 0.9420\n",
      "135/135 [==============================] - 0s 235us/sample - loss: 0.2998 - accuracy: 0.9259\n",
      "135/135 [==============================] - 0s 216us/sample - loss: 0.2536 - accuracy: 0.9556\n",
      "135/135 [==============================] - 0s 240us/sample - loss: 0.2800 - accuracy: 0.9185\n",
      "132/132 [==============================] - 0s 254us/sample - loss: 0.3013 - accuracy: 0.9242\n",
      "132/132 [==============================] - 0s 276us/sample - loss: 0.3143 - accuracy: 0.9242\n",
      "131/131 [==============================] - 0s 291us/sample - loss: 0.3026 - accuracy: 0.9160\n",
      "130/130 [==============================] - 0s 264us/sample - loss: 0.2653 - accuracy: 0.9692\n",
      "131/131 [==============================] - 0s 288us/sample - loss: 0.3037 - accuracy: 0.9466\n",
      "130/130 [==============================] - 0s 279us/sample - loss: 0.2599 - accuracy: 0.9538\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.3177 - accuracy: 0.8828\n",
      "130/130 [==============================] - 0s 291us/sample - loss: 0.3243 - accuracy: 0.8846\n",
      "130/130 [==============================] - 0s 255us/sample - loss: 0.3185 - accuracy: 0.9231\n",
      "131/131 [==============================] - 0s 241us/sample - loss: 0.3203 - accuracy: 0.9160\n",
      "131/131 [==============================] - 0s 247us/sample - loss: 0.3001 - accuracy: 0.9313\n",
      "131/131 [==============================] - 0s 273us/sample - loss: 0.3235 - accuracy: 0.8931\n",
      "130/130 [==============================] - 0s 254us/sample - loss: 0.2902 - accuracy: 0.9385\n",
      "129/129 [==============================] - 0s 272us/sample - loss: 0.3293 - accuracy: 0.8915\n",
      "128/128 [==============================] - 0s 261us/sample - loss: 0.3035 - accuracy: 0.9297\n",
      "129/129 [==============================] - 0s 257us/sample - loss: 0.3290 - accuracy: 0.8837\n",
      "127/127 [==============================] - 0s 254us/sample - loss: 0.2977 - accuracy: 0.9213\n",
      "128/128 [==============================] - 0s 241us/sample - loss: 0.3300 - accuracy: 0.8906\n",
      "126/126 [==============================] - 0s 250us/sample - loss: 0.2791 - accuracy: 0.9206\n",
      "124/124 [==============================] - 0s 261us/sample - loss: 0.3084 - accuracy: 0.9194\n",
      "122/122 [==============================] - 0s 278us/sample - loss: 0.3190 - accuracy: 0.9180\n",
      "122/122 [==============================] - 0s 251us/sample - loss: 0.2974 - accuracy: 0.9180\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2863 samples, validate on 670 samples\n",
      "Epoch 1/300\n",
      "2863/2863 [==============================] - 2s 818us/sample - loss: 0.6377 - accuracy: 0.6336 - val_loss: 0.6554 - val_accuracy: 0.6194\n",
      "Epoch 2/300\n",
      "2863/2863 [==============================] - 1s 214us/sample - loss: 0.6092 - accuracy: 0.6853 - val_loss: 0.6393 - val_accuracy: 0.6478\n",
      "Epoch 3/300\n",
      "2863/2863 [==============================] - 1s 207us/sample - loss: 0.5983 - accuracy: 0.6898 - val_loss: 0.6286 - val_accuracy: 0.6716\n",
      "Epoch 4/300\n",
      "2863/2863 [==============================] - 1s 235us/sample - loss: 0.5812 - accuracy: 0.7223 - val_loss: 0.6207 - val_accuracy: 0.6866\n",
      "Epoch 5/300\n",
      "2863/2863 [==============================] - 1s 234us/sample - loss: 0.5726 - accuracy: 0.7258 - val_loss: 0.6142 - val_accuracy: 0.6955\n",
      "Epoch 6/300\n",
      "2863/2863 [==============================] - 1s 217us/sample - loss: 0.5666 - accuracy: 0.7384 - val_loss: 0.6090 - val_accuracy: 0.7000\n",
      "Epoch 7/300\n",
      "2863/2863 [==============================] - 1s 226us/sample - loss: 0.5575 - accuracy: 0.7478 - val_loss: 0.6044 - val_accuracy: 0.7104\n",
      "Epoch 8/300\n",
      "2863/2863 [==============================] - 1s 217us/sample - loss: 0.5520 - accuracy: 0.7478 - val_loss: 0.6004 - val_accuracy: 0.7164\n",
      "Epoch 9/300\n",
      "2863/2863 [==============================] - 1s 241us/sample - loss: 0.5456 - accuracy: 0.7552 - val_loss: 0.5972 - val_accuracy: 0.7224\n",
      "Epoch 10/300\n",
      "2863/2863 [==============================] - 1s 217us/sample - loss: 0.5413 - accuracy: 0.7586 - val_loss: 0.5940 - val_accuracy: 0.7224\n",
      "Epoch 11/300\n",
      "2863/2863 [==============================] - 1s 232us/sample - loss: 0.5384 - accuracy: 0.7600 - val_loss: 0.5913 - val_accuracy: 0.7254\n",
      "Epoch 12/300\n",
      "2863/2863 [==============================] - 1s 230us/sample - loss: 0.5309 - accuracy: 0.7702 - val_loss: 0.5888 - val_accuracy: 0.7284\n",
      "Epoch 13/300\n",
      "2863/2863 [==============================] - 1s 209us/sample - loss: 0.5245 - accuracy: 0.7705 - val_loss: 0.5866 - val_accuracy: 0.7343\n",
      "Epoch 14/300\n",
      "2863/2863 [==============================] - 1s 238us/sample - loss: 0.5217 - accuracy: 0.7716 - val_loss: 0.5845 - val_accuracy: 0.7373\n",
      "Epoch 15/300\n",
      "2863/2863 [==============================] - 1s 237us/sample - loss: 0.5154 - accuracy: 0.7824 - val_loss: 0.5827 - val_accuracy: 0.7343\n",
      "Epoch 16/300\n",
      "2863/2863 [==============================] - 1s 239us/sample - loss: 0.5115 - accuracy: 0.7845 - val_loss: 0.5810 - val_accuracy: 0.7343\n",
      "Epoch 17/300\n",
      "2863/2863 [==============================] - 1s 218us/sample - loss: 0.5153 - accuracy: 0.7779 - val_loss: 0.5795 - val_accuracy: 0.7373\n",
      "Epoch 18/300\n",
      "2863/2863 [==============================] - 1s 250us/sample - loss: 0.5089 - accuracy: 0.7813 - val_loss: 0.5782 - val_accuracy: 0.7388\n",
      "Epoch 19/300\n",
      "2863/2863 [==============================] - 1s 254us/sample - loss: 0.5055 - accuracy: 0.7866 - val_loss: 0.5770 - val_accuracy: 0.7403\n",
      "Epoch 20/300\n",
      "2863/2863 [==============================] - 1s 256us/sample - loss: 0.4967 - accuracy: 0.7915 - val_loss: 0.5758 - val_accuracy: 0.7418\n",
      "Epoch 21/300\n",
      "2863/2863 [==============================] - 1s 252us/sample - loss: 0.4937 - accuracy: 0.7890 - val_loss: 0.5748 - val_accuracy: 0.7433\n",
      "Epoch 22/300\n",
      "2863/2863 [==============================] - 1s 250us/sample - loss: 0.4927 - accuracy: 0.7904 - val_loss: 0.5740 - val_accuracy: 0.7433\n",
      "Epoch 23/300\n",
      "2863/2863 [==============================] - 1s 226us/sample - loss: 0.4920 - accuracy: 0.7950 - val_loss: 0.5731 - val_accuracy: 0.7448\n",
      "Epoch 24/300\n",
      "2863/2863 [==============================] - 1s 254us/sample - loss: 0.4880 - accuracy: 0.7929 - val_loss: 0.5723 - val_accuracy: 0.7463\n",
      "Epoch 25/300\n",
      "2863/2863 [==============================] - 1s 254us/sample - loss: 0.4847 - accuracy: 0.7995 - val_loss: 0.5717 - val_accuracy: 0.7463\n",
      "Epoch 26/300\n",
      "2863/2863 [==============================] - 1s 228us/sample - loss: 0.4809 - accuracy: 0.8009 - val_loss: 0.5710 - val_accuracy: 0.7463\n",
      "Epoch 27/300\n",
      "2863/2863 [==============================] - 1s 222us/sample - loss: 0.4775 - accuracy: 0.7992 - val_loss: 0.5705 - val_accuracy: 0.7463\n",
      "Epoch 28/300\n",
      "2863/2863 [==============================] - 1s 240us/sample - loss: 0.4752 - accuracy: 0.8051 - val_loss: 0.5701 - val_accuracy: 0.7478\n",
      "Epoch 29/300\n",
      "2863/2863 [==============================] - 1s 246us/sample - loss: 0.4726 - accuracy: 0.8044 - val_loss: 0.5698 - val_accuracy: 0.7463\n",
      "Epoch 30/300\n",
      "2863/2863 [==============================] - 1s 259us/sample - loss: 0.4701 - accuracy: 0.7985 - val_loss: 0.5695 - val_accuracy: 0.7463\n",
      "Epoch 31/300\n",
      "2863/2863 [==============================] - 1s 201us/sample - loss: 0.4661 - accuracy: 0.8086 - val_loss: 0.5692 - val_accuracy: 0.7478\n",
      "Epoch 32/300\n",
      "2863/2863 [==============================] - 1s 234us/sample - loss: 0.4657 - accuracy: 0.8086 - val_loss: 0.5691 - val_accuracy: 0.7478\n",
      "Epoch 33/300\n",
      "2863/2863 [==============================] - 1s 220us/sample - loss: 0.4657 - accuracy: 0.8110 - val_loss: 0.5690 - val_accuracy: 0.7478\n",
      "Epoch 34/300\n",
      "2863/2863 [==============================] - 1s 201us/sample - loss: 0.4572 - accuracy: 0.8170 - val_loss: 0.5689 - val_accuracy: 0.7493\n",
      "Epoch 35/300\n",
      "2863/2863 [==============================] - 1s 222us/sample - loss: 0.4566 - accuracy: 0.8114 - val_loss: 0.5689 - val_accuracy: 0.7493\n",
      "Epoch 36/300\n",
      "2863/2863 [==============================] - 1s 236us/sample - loss: 0.4543 - accuracy: 0.8117 - val_loss: 0.5689 - val_accuracy: 0.7478\n",
      "Epoch 37/300\n",
      "2863/2863 [==============================] - 1s 236us/sample - loss: 0.4508 - accuracy: 0.8163 - val_loss: 0.5691 - val_accuracy: 0.7478\n",
      "Epoch 38/300\n",
      "2863/2863 [==============================] - 1s 197us/sample - loss: 0.4494 - accuracy: 0.8191 - val_loss: 0.5692 - val_accuracy: 0.7463\n",
      "Epoch 39/300\n",
      "2863/2863 [==============================] - 1s 220us/sample - loss: 0.4431 - accuracy: 0.8191 - val_loss: 0.5693 - val_accuracy: 0.7463\n",
      "Epoch 00039: early stopping\n",
      "116/116 [==============================] - 0s 183us/sample - loss: 0.2763 - accuracy: 0.9655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [7:03:11, 1015.65s/it]\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.54s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.37s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 821.78125 steps, validate for 209.03125 steps\n",
      "Epoch 1/300\n",
      "822/821 [==============================] - 24s 30ms/step - loss: 0.5984 - accuracy: 0.6951 - val_loss: 0.5346 - val_accuracy: 0.7672\n",
      "Epoch 2/300\n",
      "822/821 [==============================] - 23s 28ms/step - loss: 0.5147 - accuracy: 0.7724 - val_loss: 0.5289 - val_accuracy: 0.7685\n",
      "Epoch 3/300\n",
      "822/821 [==============================] - 24s 29ms/step - loss: 0.4995 - accuracy: 0.7776 - val_loss: 0.5311 - val_accuracy: 0.7678\n",
      "Epoch 4/300\n",
      "822/821 [==============================] - 24s 29ms/step - loss: 0.4887 - accuracy: 0.7816 - val_loss: 0.5305 - val_accuracy: 0.7669\n",
      "Epoch 5/300\n",
      "822/821 [==============================] - 23s 28ms/step - loss: 0.4793 - accuracy: 0.7860 - val_loss: 0.5395 - val_accuracy: 0.7634\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 821.78125 steps, validate for 209.03125 steps\n",
      "Epoch 1/300\n",
      "822/821 [==============================] - 54s 65ms/step - loss: 0.4623 - accuracy: 0.7937 - val_loss: 0.5542 - val_accuracy: 0.7513\n",
      "Epoch 2/300\n",
      "822/821 [==============================] - 52s 64ms/step - loss: 0.4359 - accuracy: 0.8069 - val_loss: 0.5628 - val_accuracy: 0.7469\n",
      "Epoch 3/300\n",
      "822/821 [==============================] - 53s 64ms/step - loss: 0.4139 - accuracy: 0.8188 - val_loss: 0.5764 - val_accuracy: 0.7159\n",
      "Epoch 4/300\n",
      "822/821 [==============================] - 53s 64ms/step - loss: 0.3941 - accuracy: 0.8300 - val_loss: 0.5696 - val_accuracy: 0.7649\n",
      "Epoch 00004: early stopping\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.2568 - accuracy: 0.9604\n",
      "196/196 [==============================] - 0s 231us/sample - loss: 0.2363 - accuracy: 0.9592\n",
      "193/193 [==============================] - 0s 238us/sample - loss: 0.2486 - accuracy: 0.9534\n",
      "190/190 [==============================] - 0s 214us/sample - loss: 0.2437 - accuracy: 0.9632\n",
      "190/190 [==============================] - 0s 225us/sample - loss: 0.2360 - accuracy: 0.9684\n",
      "187/187 [==============================] - 0s 233us/sample - loss: 0.2123 - accuracy: 0.9733\n",
      "184/184 [==============================] - 0s 222us/sample - loss: 0.2227 - accuracy: 0.9728\n",
      "183/183 [==============================] - 0s 230us/sample - loss: 0.2131 - accuracy: 0.9781\n",
      "182/182 [==============================] - 0s 260us/sample - loss: 0.1999 - accuracy: 0.9670\n",
      "181/181 [==============================] - 0s 245us/sample - loss: 0.1854 - accuracy: 0.9834\n",
      "177/177 [==============================] - 0s 224us/sample - loss: 0.2124 - accuracy: 0.9831\n",
      "178/178 [==============================] - 0s 220us/sample - loss: 0.2490 - accuracy: 0.9270\n",
      "178/178 [==============================] - 0s 232us/sample - loss: 0.2108 - accuracy: 0.9775\n",
      "176/176 [==============================] - 0s 231us/sample - loss: 0.2358 - accuracy: 0.9545\n",
      "175/175 [==============================] - 0s 239us/sample - loss: 0.2217 - accuracy: 0.9657\n",
      "176/176 [==============================] - 0s 236us/sample - loss: 0.2137 - accuracy: 0.9659\n",
      "173/173 [==============================] - 0s 248us/sample - loss: 0.2172 - accuracy: 0.9827\n",
      "172/172 [==============================] - 0s 253us/sample - loss: 0.2324 - accuracy: 0.9593\n",
      "171/171 [==============================] - 0s 240us/sample - loss: 0.2442 - accuracy: 0.9708\n",
      "171/171 [==============================] - 0s 242us/sample - loss: 0.2364 - accuracy: 0.9766\n",
      "171/171 [==============================] - 0s 243us/sample - loss: 0.2087 - accuracy: 0.9766\n",
      "170/170 [==============================] - 0s 246us/sample - loss: 0.2255 - accuracy: 0.9706\n",
      "171/171 [==============================] - 0s 255us/sample - loss: 0.2283 - accuracy: 0.9708\n",
      "170/170 [==============================] - 0s 257us/sample - loss: 0.2046 - accuracy: 0.9824\n",
      "170/170 [==============================] - 0s 267us/sample - loss: 0.2202 - accuracy: 0.9588\n",
      "171/171 [==============================] - 0s 252us/sample - loss: 0.2398 - accuracy: 0.9298\n",
      "168/168 [==============================] - 0s 266us/sample - loss: 0.2404 - accuracy: 0.9286\n",
      "169/169 [==============================] - 0s 260us/sample - loss: 0.2161 - accuracy: 0.9586\n",
      "169/169 [==============================] - 0s 294us/sample - loss: 0.2155 - accuracy: 0.9467\n",
      "167/167 [==============================] - 0s 262us/sample - loss: 0.2257 - accuracy: 0.9521\n",
      "168/168 [==============================] - 0s 266us/sample - loss: 0.2239 - accuracy: 0.9583\n",
      "169/169 [==============================] - 0s 241us/sample - loss: 0.2286 - accuracy: 0.9408\n",
      "166/166 [==============================] - 0s 261us/sample - loss: 0.2364 - accuracy: 0.9639\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2784 samples, validate on 706 samples\n",
      "Epoch 1/300\n",
      "2784/2784 [==============================] - 2s 843us/sample - loss: 0.6392 - accuracy: 0.6340 - val_loss: 0.6256 - val_accuracy: 0.6586\n",
      "Epoch 2/300\n",
      "2784/2784 [==============================] - 1s 228us/sample - loss: 0.5991 - accuracy: 0.6818 - val_loss: 0.6088 - val_accuracy: 0.6969\n",
      "Epoch 3/300\n",
      "2784/2784 [==============================] - 1s 206us/sample - loss: 0.5813 - accuracy: 0.7123 - val_loss: 0.5980 - val_accuracy: 0.7082\n",
      "Epoch 4/300\n",
      "2784/2784 [==============================] - 1s 228us/sample - loss: 0.5649 - accuracy: 0.7335 - val_loss: 0.5904 - val_accuracy: 0.7096\n",
      "Epoch 5/300\n",
      "2784/2784 [==============================] - 1s 199us/sample - loss: 0.5601 - accuracy: 0.7392 - val_loss: 0.5841 - val_accuracy: 0.7181\n",
      "Epoch 6/300\n",
      "2784/2784 [==============================] - 1s 207us/sample - loss: 0.5487 - accuracy: 0.7428 - val_loss: 0.5793 - val_accuracy: 0.7224\n",
      "Epoch 7/300\n",
      "2784/2784 [==============================] - 0s 174us/sample - loss: 0.5423 - accuracy: 0.7504 - val_loss: 0.5752 - val_accuracy: 0.7280\n",
      "Epoch 8/300\n",
      "2784/2784 [==============================] - 1s 192us/sample - loss: 0.5322 - accuracy: 0.7601 - val_loss: 0.5717 - val_accuracy: 0.7323\n",
      "Epoch 9/300\n",
      "2784/2784 [==============================] - 1s 205us/sample - loss: 0.5311 - accuracy: 0.7629 - val_loss: 0.5686 - val_accuracy: 0.7408\n",
      "Epoch 10/300\n",
      "2784/2784 [==============================] - 1s 185us/sample - loss: 0.5239 - accuracy: 0.7680 - val_loss: 0.5662 - val_accuracy: 0.7408\n",
      "Epoch 11/300\n",
      "2784/2784 [==============================] - 0s 176us/sample - loss: 0.5184 - accuracy: 0.7690 - val_loss: 0.5639 - val_accuracy: 0.7465\n",
      "Epoch 12/300\n",
      "2784/2784 [==============================] - 0s 162us/sample - loss: 0.5163 - accuracy: 0.7672 - val_loss: 0.5619 - val_accuracy: 0.7450\n",
      "Epoch 13/300\n",
      "2784/2784 [==============================] - 1s 192us/sample - loss: 0.5087 - accuracy: 0.7766 - val_loss: 0.5602 - val_accuracy: 0.7450\n",
      "Epoch 14/300\n",
      "2784/2784 [==============================] - 1s 217us/sample - loss: 0.5102 - accuracy: 0.7755 - val_loss: 0.5586 - val_accuracy: 0.7450\n",
      "Epoch 15/300\n",
      "2784/2784 [==============================] - 1s 212us/sample - loss: 0.5052 - accuracy: 0.7751 - val_loss: 0.5570 - val_accuracy: 0.7465\n",
      "Epoch 16/300\n",
      "2784/2784 [==============================] - 1s 224us/sample - loss: 0.4996 - accuracy: 0.7809 - val_loss: 0.5557 - val_accuracy: 0.7493\n",
      "Epoch 17/300\n",
      "2784/2784 [==============================] - 1s 209us/sample - loss: 0.4945 - accuracy: 0.7802 - val_loss: 0.5546 - val_accuracy: 0.7493\n",
      "Epoch 18/300\n",
      "2784/2784 [==============================] - 0s 175us/sample - loss: 0.4925 - accuracy: 0.7863 - val_loss: 0.5535 - val_accuracy: 0.7507\n",
      "Epoch 19/300\n",
      "2784/2784 [==============================] - 1s 197us/sample - loss: 0.4984 - accuracy: 0.7809 - val_loss: 0.5525 - val_accuracy: 0.7507\n",
      "Epoch 20/300\n",
      "2784/2784 [==============================] - 1s 189us/sample - loss: 0.4876 - accuracy: 0.7859 - val_loss: 0.5516 - val_accuracy: 0.7507\n",
      "Epoch 21/300\n",
      "2784/2784 [==============================] - 1s 241us/sample - loss: 0.4861 - accuracy: 0.7870 - val_loss: 0.5508 - val_accuracy: 0.7507\n",
      "Epoch 22/300\n",
      "2784/2784 [==============================] - 1s 220us/sample - loss: 0.4800 - accuracy: 0.7942 - val_loss: 0.5500 - val_accuracy: 0.7521\n",
      "Epoch 23/300\n",
      "2784/2784 [==============================] - 1s 216us/sample - loss: 0.4768 - accuracy: 0.7902 - val_loss: 0.5493 - val_accuracy: 0.7521\n",
      "Epoch 24/300\n",
      "2784/2784 [==============================] - 1s 201us/sample - loss: 0.4762 - accuracy: 0.7935 - val_loss: 0.5486 - val_accuracy: 0.7535\n",
      "Epoch 25/300\n",
      "2784/2784 [==============================] - 1s 212us/sample - loss: 0.4742 - accuracy: 0.7881 - val_loss: 0.5480 - val_accuracy: 0.7521\n",
      "Epoch 26/300\n",
      "2784/2784 [==============================] - 1s 201us/sample - loss: 0.4770 - accuracy: 0.7856 - val_loss: 0.5473 - val_accuracy: 0.7507\n",
      "Epoch 27/300\n",
      "2784/2784 [==============================] - 1s 212us/sample - loss: 0.4698 - accuracy: 0.7978 - val_loss: 0.5468 - val_accuracy: 0.7507\n",
      "Epoch 28/300\n",
      "2784/2784 [==============================] - 1s 196us/sample - loss: 0.4700 - accuracy: 0.7967 - val_loss: 0.5462 - val_accuracy: 0.7507\n",
      "Epoch 29/300\n",
      "2784/2784 [==============================] - 1s 205us/sample - loss: 0.4672 - accuracy: 0.7935 - val_loss: 0.5457 - val_accuracy: 0.7507\n",
      "Epoch 30/300\n",
      "2784/2784 [==============================] - 1s 186us/sample - loss: 0.4607 - accuracy: 0.7974 - val_loss: 0.5453 - val_accuracy: 0.7493\n",
      "Epoch 31/300\n",
      "2784/2784 [==============================] - 1s 222us/sample - loss: 0.4651 - accuracy: 0.7967 - val_loss: 0.5448 - val_accuracy: 0.7493\n",
      "Epoch 32/300\n",
      "2784/2784 [==============================] - 1s 221us/sample - loss: 0.4565 - accuracy: 0.7971 - val_loss: 0.5443 - val_accuracy: 0.7479\n",
      "Epoch 33/300\n",
      "2784/2784 [==============================] - 1s 216us/sample - loss: 0.4590 - accuracy: 0.7953 - val_loss: 0.5439 - val_accuracy: 0.7465\n",
      "Epoch 34/300\n",
      "2784/2784 [==============================] - 1s 243us/sample - loss: 0.4569 - accuracy: 0.7963 - val_loss: 0.5436 - val_accuracy: 0.7479\n",
      "Epoch 35/300\n",
      "2784/2784 [==============================] - 1s 240us/sample - loss: 0.4518 - accuracy: 0.8028 - val_loss: 0.5432 - val_accuracy: 0.7479\n",
      "Epoch 36/300\n",
      "2784/2784 [==============================] - 1s 224us/sample - loss: 0.4535 - accuracy: 0.8010 - val_loss: 0.5429 - val_accuracy: 0.7465\n",
      "Epoch 37/300\n",
      "2784/2784 [==============================] - 1s 238us/sample - loss: 0.4551 - accuracy: 0.7981 - val_loss: 0.5425 - val_accuracy: 0.7465\n",
      "Epoch 38/300\n",
      "2784/2784 [==============================] - 1s 223us/sample - loss: 0.4479 - accuracy: 0.8010 - val_loss: 0.5422 - val_accuracy: 0.7465\n",
      "Epoch 39/300\n",
      "2784/2784 [==============================] - 1s 199us/sample - loss: 0.4480 - accuracy: 0.8024 - val_loss: 0.5418 - val_accuracy: 0.7465\n",
      "Epoch 40/300\n",
      "2784/2784 [==============================] - 1s 187us/sample - loss: 0.4451 - accuracy: 0.8046 - val_loss: 0.5416 - val_accuracy: 0.7450\n",
      "Epoch 41/300\n",
      "2784/2784 [==============================] - 1s 203us/sample - loss: 0.4443 - accuracy: 0.8035 - val_loss: 0.5412 - val_accuracy: 0.7436\n",
      "Epoch 42/300\n",
      "2784/2784 [==============================] - 0s 177us/sample - loss: 0.4407 - accuracy: 0.8053 - val_loss: 0.5409 - val_accuracy: 0.7436\n",
      "Epoch 43/300\n",
      "2784/2784 [==============================] - 1s 200us/sample - loss: 0.4394 - accuracy: 0.8064 - val_loss: 0.5406 - val_accuracy: 0.7436\n",
      "Epoch 44/300\n",
      "2784/2784 [==============================] - 1s 204us/sample - loss: 0.4417 - accuracy: 0.8089 - val_loss: 0.5403 - val_accuracy: 0.7436\n",
      "Epoch 45/300\n",
      "2784/2784 [==============================] - 1s 243us/sample - loss: 0.4359 - accuracy: 0.8085 - val_loss: 0.5401 - val_accuracy: 0.7465\n",
      "Epoch 46/300\n",
      "2784/2784 [==============================] - 1s 231us/sample - loss: 0.4349 - accuracy: 0.8100 - val_loss: 0.5398 - val_accuracy: 0.7465\n",
      "Epoch 47/300\n",
      "2784/2784 [==============================] - 1s 224us/sample - loss: 0.4312 - accuracy: 0.8114 - val_loss: 0.5396 - val_accuracy: 0.7479\n",
      "Epoch 48/300\n",
      "2784/2784 [==============================] - 1s 234us/sample - loss: 0.4318 - accuracy: 0.8107 - val_loss: 0.5393 - val_accuracy: 0.7479\n",
      "Epoch 49/300\n",
      "2784/2784 [==============================] - 1s 219us/sample - loss: 0.4287 - accuracy: 0.8096 - val_loss: 0.5393 - val_accuracy: 0.7479\n",
      "Epoch 50/300\n",
      "2784/2784 [==============================] - 1s 203us/sample - loss: 0.4261 - accuracy: 0.8165 - val_loss: 0.5391 - val_accuracy: 0.7479\n",
      "Epoch 51/300\n",
      "2784/2784 [==============================] - 1s 216us/sample - loss: 0.4250 - accuracy: 0.8147 - val_loss: 0.5389 - val_accuracy: 0.7479\n",
      "Epoch 52/300\n",
      "2784/2784 [==============================] - 1s 221us/sample - loss: 0.4241 - accuracy: 0.8147 - val_loss: 0.5389 - val_accuracy: 0.7479\n",
      "Epoch 53/300\n",
      "2784/2784 [==============================] - 1s 185us/sample - loss: 0.4242 - accuracy: 0.8218 - val_loss: 0.5387 - val_accuracy: 0.7507\n",
      "Epoch 54/300\n",
      "2784/2784 [==============================] - 1s 218us/sample - loss: 0.4195 - accuracy: 0.8157 - val_loss: 0.5386 - val_accuracy: 0.7507\n",
      "Epoch 55/300\n",
      "2784/2784 [==============================] - 1s 212us/sample - loss: 0.4210 - accuracy: 0.8161 - val_loss: 0.5384 - val_accuracy: 0.7507\n",
      "Epoch 56/300\n",
      "2784/2784 [==============================] - 1s 195us/sample - loss: 0.4190 - accuracy: 0.8179 - val_loss: 0.5384 - val_accuracy: 0.7493\n",
      "Epoch 57/300\n",
      "2784/2784 [==============================] - 1s 201us/sample - loss: 0.4163 - accuracy: 0.8204 - val_loss: 0.5383 - val_accuracy: 0.7493\n",
      "Epoch 58/300\n",
      "2784/2784 [==============================] - 0s 176us/sample - loss: 0.4152 - accuracy: 0.8200 - val_loss: 0.5381 - val_accuracy: 0.7493\n",
      "Epoch 59/300\n",
      "2784/2784 [==============================] - 1s 183us/sample - loss: 0.4116 - accuracy: 0.8211 - val_loss: 0.5380 - val_accuracy: 0.7493\n",
      "Epoch 60/300\n",
      "2784/2784 [==============================] - 1s 205us/sample - loss: 0.4165 - accuracy: 0.8172 - val_loss: 0.5379 - val_accuracy: 0.7493\n",
      "Epoch 61/300\n",
      "2784/2784 [==============================] - 1s 201us/sample - loss: 0.4102 - accuracy: 0.8208 - val_loss: 0.5380 - val_accuracy: 0.7493\n",
      "Epoch 62/300\n",
      "2784/2784 [==============================] - 1s 219us/sample - loss: 0.4054 - accuracy: 0.8233 - val_loss: 0.5379 - val_accuracy: 0.7479\n",
      "Epoch 63/300\n",
      "2784/2784 [==============================] - 1s 222us/sample - loss: 0.4094 - accuracy: 0.8258 - val_loss: 0.5380 - val_accuracy: 0.7493\n",
      "Epoch 00063: early stopping\n",
      "159/159 [==============================] - 0s 155us/sample - loss: 0.2873 - accuracy: 0.9308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [16:54, 1014.73s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.76s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.37s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 824.875 steps, validate for 212.609375 steps\n",
      "Epoch 1/300\n",
      "825/824 [==============================] - 24s 30ms/step - loss: 0.5511 - accuracy: 0.7578 - val_loss: 0.5447 - val_accuracy: 0.7644\n",
      "Epoch 2/300\n",
      "825/824 [==============================] - 23s 28ms/step - loss: 0.5164 - accuracy: 0.7719 - val_loss: 0.5344 - val_accuracy: 0.7664\n",
      "Epoch 3/300\n",
      "825/824 [==============================] - 24s 29ms/step - loss: 0.5015 - accuracy: 0.7770 - val_loss: 0.5339 - val_accuracy: 0.7662\n",
      "Epoch 4/300\n",
      "825/824 [==============================] - 24s 29ms/step - loss: 0.4903 - accuracy: 0.7812 - val_loss: 0.5362 - val_accuracy: 0.7655\n",
      "Epoch 5/300\n",
      "825/824 [==============================] - 24s 29ms/step - loss: 0.4806 - accuracy: 0.7847 - val_loss: 0.5389 - val_accuracy: 0.7641\n",
      "Epoch 6/300\n",
      "825/824 [==============================] - 24s 29ms/step - loss: 0.4721 - accuracy: 0.7895 - val_loss: 0.5467 - val_accuracy: 0.7596\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 824.875 steps, validate for 212.609375 steps\n",
      "Epoch 1/300\n",
      "825/824 [==============================] - 54s 65ms/step - loss: 0.4560 - accuracy: 0.7971 - val_loss: 0.5542 - val_accuracy: 0.7512\n",
      "Epoch 2/300\n",
      "825/824 [==============================] - 53s 65ms/step - loss: 0.4297 - accuracy: 0.8108 - val_loss: 0.5638 - val_accuracy: 0.7573\n",
      "Epoch 3/300\n",
      "825/824 [==============================] - 53s 64ms/step - loss: 0.4088 - accuracy: 0.8226 - val_loss: 0.5560 - val_accuracy: 0.7458\n",
      "Epoch 4/300\n",
      "825/824 [==============================] - 53s 64ms/step - loss: 0.3882 - accuracy: 0.8331 - val_loss: 0.5745 - val_accuracy: 0.7403\n",
      "Epoch 00004: early stopping\n",
      "167/167 [==============================] - 0s 1ms/sample - loss: 0.2335 - accuracy: 0.9521\n",
      "164/164 [==============================] - 0s 230us/sample - loss: 0.2545 - accuracy: 0.9329\n",
      "162/162 [==============================] - 0s 226us/sample - loss: 0.2652 - accuracy: 0.9691\n",
      "162/162 [==============================] - 0s 230us/sample - loss: 0.2364 - accuracy: 0.9444\n",
      "162/162 [==============================] - 0s 242us/sample - loss: 0.2559 - accuracy: 0.9691\n",
      "161/161 [==============================] - 0s 240us/sample - loss: 0.2387 - accuracy: 0.9689\n",
      "162/162 [==============================] - 0s 246us/sample - loss: 0.2442 - accuracy: 0.9630\n",
      "162/162 [==============================] - 0s 247us/sample - loss: 0.2408 - accuracy: 0.9691\n",
      "157/157 [==============================] - 0s 259us/sample - loss: 0.2548 - accuracy: 0.9490\n",
      "158/158 [==============================] - 0s 228us/sample - loss: 0.2372 - accuracy: 0.9557\n",
      "157/157 [==============================] - 0s 221us/sample - loss: 0.2648 - accuracy: 0.9554\n",
      "157/157 [==============================] - 0s 240us/sample - loss: 0.2655 - accuracy: 0.9427\n",
      "157/157 [==============================] - 0s 250us/sample - loss: 0.2794 - accuracy: 0.9236\n",
      "155/155 [==============================] - 0s 247us/sample - loss: 0.2881 - accuracy: 0.9355\n",
      "152/152 [==============================] - 0s 257us/sample - loss: 0.2744 - accuracy: 0.9737\n",
      "153/153 [==============================] - 0s 252us/sample - loss: 0.2988 - accuracy: 0.9346\n",
      "150/150 [==============================] - 0s 260us/sample - loss: 0.2752 - accuracy: 0.9267\n",
      "149/149 [==============================] - 0s 250us/sample - loss: 0.2985 - accuracy: 0.9060\n",
      "147/147 [==============================] - 0s 261us/sample - loss: 0.2866 - accuracy: 0.9456\n",
      "147/147 [==============================] - 0s 262us/sample - loss: 0.3017 - accuracy: 0.9252\n",
      "146/146 [==============================] - 0s 257us/sample - loss: 0.3055 - accuracy: 0.9041\n",
      "145/145 [==============================] - 0s 244us/sample - loss: 0.2790 - accuracy: 0.9379\n",
      "145/145 [==============================] - 0s 247us/sample - loss: 0.3255 - accuracy: 0.9241\n",
      "144/144 [==============================] - 0s 268us/sample - loss: 0.3515 - accuracy: 0.9028\n",
      "141/141 [==============================] - 0s 273us/sample - loss: 0.3321 - accuracy: 0.9149\n",
      "140/140 [==============================] - 0s 251us/sample - loss: 0.3269 - accuracy: 0.9071\n",
      "140/140 [==============================] - 0s 289us/sample - loss: 0.3589 - accuracy: 0.8357\n",
      "140/140 [==============================] - 0s 270us/sample - loss: 0.3603 - accuracy: 0.8643\n",
      "140/140 [==============================] - 0s 253us/sample - loss: 0.3802 - accuracy: 0.8714\n",
      "140/140 [==============================] - 0s 261us/sample - loss: 0.3568 - accuracy: 0.8571\n",
      "141/141 [==============================] - 0s 253us/sample - loss: 0.3068 - accuracy: 0.9574\n",
      "139/139 [==============================] - 0s 272us/sample - loss: 0.3170 - accuracy: 0.9209\n",
      "138/138 [==============================] - 0s 266us/sample - loss: 0.3604 - accuracy: 0.8696\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2797 samples, validate on 718 samples\n",
      "Epoch 1/300\n",
      "2797/2797 [==============================] - 2s 867us/sample - loss: 0.7666 - accuracy: 0.4469 - val_loss: 0.7160 - val_accuracy: 0.5195\n",
      "Epoch 2/300\n",
      "2797/2797 [==============================] - 1s 201us/sample - loss: 0.7192 - accuracy: 0.5188 - val_loss: 0.6877 - val_accuracy: 0.5613\n",
      "Epoch 3/300\n",
      "2797/2797 [==============================] - 1s 207us/sample - loss: 0.6942 - accuracy: 0.5667 - val_loss: 0.6683 - val_accuracy: 0.6058\n",
      "Epoch 4/300\n",
      "2797/2797 [==============================] - 1s 220us/sample - loss: 0.6713 - accuracy: 0.5978 - val_loss: 0.6539 - val_accuracy: 0.6421\n",
      "Epoch 5/300\n",
      "2797/2797 [==============================] - 1s 220us/sample - loss: 0.6638 - accuracy: 0.6267 - val_loss: 0.6420 - val_accuracy: 0.6713\n",
      "Epoch 6/300\n",
      "2797/2797 [==============================] - 1s 223us/sample - loss: 0.6496 - accuracy: 0.6489 - val_loss: 0.6321 - val_accuracy: 0.6811\n",
      "Epoch 7/300\n",
      "2797/2797 [==============================] - 1s 241us/sample - loss: 0.6342 - accuracy: 0.6664 - val_loss: 0.6237 - val_accuracy: 0.6866\n",
      "Epoch 8/300\n",
      "2797/2797 [==============================] - 1s 245us/sample - loss: 0.6344 - accuracy: 0.6657 - val_loss: 0.6163 - val_accuracy: 0.6922\n",
      "Epoch 9/300\n",
      "2797/2797 [==============================] - 1s 255us/sample - loss: 0.6208 - accuracy: 0.6832 - val_loss: 0.6096 - val_accuracy: 0.6978\n",
      "Epoch 10/300\n",
      "2797/2797 [==============================] - 1s 231us/sample - loss: 0.6146 - accuracy: 0.6990 - val_loss: 0.6037 - val_accuracy: 0.7075\n",
      "Epoch 11/300\n",
      "2797/2797 [==============================] - 1s 260us/sample - loss: 0.6084 - accuracy: 0.6990 - val_loss: 0.5982 - val_accuracy: 0.7201\n",
      "Epoch 12/300\n",
      "2797/2797 [==============================] - 1s 231us/sample - loss: 0.6033 - accuracy: 0.7058 - val_loss: 0.5932 - val_accuracy: 0.7326\n",
      "Epoch 13/300\n",
      "2797/2797 [==============================] - 1s 253us/sample - loss: 0.5941 - accuracy: 0.7165 - val_loss: 0.5888 - val_accuracy: 0.7396\n",
      "Epoch 14/300\n",
      "2797/2797 [==============================] - 1s 264us/sample - loss: 0.5888 - accuracy: 0.7179 - val_loss: 0.5848 - val_accuracy: 0.7451\n",
      "Epoch 15/300\n",
      "2797/2797 [==============================] - 1s 263us/sample - loss: 0.5819 - accuracy: 0.7347 - val_loss: 0.5810 - val_accuracy: 0.7493\n",
      "Epoch 16/300\n",
      "2797/2797 [==============================] - 1s 233us/sample - loss: 0.5763 - accuracy: 0.7433 - val_loss: 0.5774 - val_accuracy: 0.7521\n",
      "Epoch 17/300\n",
      "2797/2797 [==============================] - 1s 232us/sample - loss: 0.5708 - accuracy: 0.7429 - val_loss: 0.5743 - val_accuracy: 0.7535\n",
      "Epoch 18/300\n",
      "2797/2797 [==============================] - 1s 236us/sample - loss: 0.5686 - accuracy: 0.7390 - val_loss: 0.5711 - val_accuracy: 0.7563\n",
      "Epoch 19/300\n",
      "2797/2797 [==============================] - 1s 245us/sample - loss: 0.5652 - accuracy: 0.7383 - val_loss: 0.5682 - val_accuracy: 0.7577\n",
      "Epoch 20/300\n",
      "2797/2797 [==============================] - 1s 219us/sample - loss: 0.5659 - accuracy: 0.7476 - val_loss: 0.5654 - val_accuracy: 0.7577\n",
      "Epoch 21/300\n",
      "2797/2797 [==============================] - 1s 203us/sample - loss: 0.5555 - accuracy: 0.7483 - val_loss: 0.5630 - val_accuracy: 0.7604\n",
      "Epoch 22/300\n",
      "2797/2797 [==============================] - 1s 204us/sample - loss: 0.5545 - accuracy: 0.7544 - val_loss: 0.5605 - val_accuracy: 0.7632\n",
      "Epoch 23/300\n",
      "2797/2797 [==============================] - 1s 255us/sample - loss: 0.5508 - accuracy: 0.7555 - val_loss: 0.5584 - val_accuracy: 0.7618\n",
      "Epoch 24/300\n",
      "2797/2797 [==============================] - 1s 219us/sample - loss: 0.5455 - accuracy: 0.7590 - val_loss: 0.5563 - val_accuracy: 0.7646\n",
      "Epoch 25/300\n",
      "2797/2797 [==============================] - 1s 233us/sample - loss: 0.5431 - accuracy: 0.7644 - val_loss: 0.5544 - val_accuracy: 0.7674\n",
      "Epoch 26/300\n",
      "2797/2797 [==============================] - 1s 243us/sample - loss: 0.5414 - accuracy: 0.7601 - val_loss: 0.5525 - val_accuracy: 0.7660\n",
      "Epoch 27/300\n",
      "2797/2797 [==============================] - 1s 241us/sample - loss: 0.5377 - accuracy: 0.7615 - val_loss: 0.5508 - val_accuracy: 0.7646\n",
      "Epoch 28/300\n",
      "2797/2797 [==============================] - 1s 221us/sample - loss: 0.5327 - accuracy: 0.7619 - val_loss: 0.5492 - val_accuracy: 0.7646\n",
      "Epoch 29/300\n",
      "2797/2797 [==============================] - 1s 257us/sample - loss: 0.5329 - accuracy: 0.7637 - val_loss: 0.5476 - val_accuracy: 0.7660\n",
      "Epoch 30/300\n",
      "2797/2797 [==============================] - 1s 266us/sample - loss: 0.5311 - accuracy: 0.7658 - val_loss: 0.5462 - val_accuracy: 0.7674\n",
      "Epoch 31/300\n",
      "2797/2797 [==============================] - 1s 254us/sample - loss: 0.5253 - accuracy: 0.7651 - val_loss: 0.5448 - val_accuracy: 0.7674\n",
      "Epoch 32/300\n",
      "2797/2797 [==============================] - 1s 250us/sample - loss: 0.5222 - accuracy: 0.7644 - val_loss: 0.5435 - val_accuracy: 0.7688\n",
      "Epoch 33/300\n",
      "2797/2797 [==============================] - 1s 270us/sample - loss: 0.5186 - accuracy: 0.7708 - val_loss: 0.5422 - val_accuracy: 0.7688\n",
      "Epoch 34/300\n",
      "2797/2797 [==============================] - 1s 242us/sample - loss: 0.5134 - accuracy: 0.7715 - val_loss: 0.5411 - val_accuracy: 0.7674\n",
      "Epoch 35/300\n",
      "2797/2797 [==============================] - 1s 257us/sample - loss: 0.5134 - accuracy: 0.7780 - val_loss: 0.5400 - val_accuracy: 0.7660\n",
      "Epoch 36/300\n",
      "2797/2797 [==============================] - 1s 242us/sample - loss: 0.5137 - accuracy: 0.7812 - val_loss: 0.5389 - val_accuracy: 0.7674\n",
      "Epoch 37/300\n",
      "2797/2797 [==============================] - 1s 264us/sample - loss: 0.5095 - accuracy: 0.7755 - val_loss: 0.5379 - val_accuracy: 0.7688\n",
      "Epoch 38/300\n",
      "2797/2797 [==============================] - 1s 265us/sample - loss: 0.5090 - accuracy: 0.7790 - val_loss: 0.5370 - val_accuracy: 0.7688\n",
      "Epoch 39/300\n",
      "2797/2797 [==============================] - 1s 235us/sample - loss: 0.5034 - accuracy: 0.7765 - val_loss: 0.5361 - val_accuracy: 0.7688\n",
      "Epoch 40/300\n",
      "2797/2797 [==============================] - 1s 237us/sample - loss: 0.5044 - accuracy: 0.7751 - val_loss: 0.5353 - val_accuracy: 0.7688\n",
      "Epoch 41/300\n",
      "2797/2797 [==============================] - 1s 266us/sample - loss: 0.5002 - accuracy: 0.7826 - val_loss: 0.5345 - val_accuracy: 0.7688\n",
      "Epoch 42/300\n",
      "2797/2797 [==============================] - 1s 235us/sample - loss: 0.4995 - accuracy: 0.7780 - val_loss: 0.5337 - val_accuracy: 0.7688\n",
      "Epoch 43/300\n",
      "2797/2797 [==============================] - 1s 212us/sample - loss: 0.4984 - accuracy: 0.7765 - val_loss: 0.5330 - val_accuracy: 0.7688\n",
      "Epoch 44/300\n",
      "2797/2797 [==============================] - 1s 250us/sample - loss: 0.4947 - accuracy: 0.7848 - val_loss: 0.5324 - val_accuracy: 0.7702\n",
      "Epoch 45/300\n",
      "2797/2797 [==============================] - 1s 225us/sample - loss: 0.4878 - accuracy: 0.7833 - val_loss: 0.5316 - val_accuracy: 0.7716\n",
      "Epoch 46/300\n",
      "2797/2797 [==============================] - 1s 226us/sample - loss: 0.4854 - accuracy: 0.7844 - val_loss: 0.5311 - val_accuracy: 0.7716\n",
      "Epoch 47/300\n",
      "2797/2797 [==============================] - 1s 226us/sample - loss: 0.4870 - accuracy: 0.7837 - val_loss: 0.5305 - val_accuracy: 0.7730\n",
      "Epoch 48/300\n",
      "2797/2797 [==============================] - 1s 273us/sample - loss: 0.4841 - accuracy: 0.7841 - val_loss: 0.5300 - val_accuracy: 0.7730\n",
      "Epoch 49/300\n",
      "2797/2797 [==============================] - 1s 231us/sample - loss: 0.4855 - accuracy: 0.7844 - val_loss: 0.5295 - val_accuracy: 0.7730\n",
      "Epoch 50/300\n",
      "2797/2797 [==============================] - 1s 245us/sample - loss: 0.4826 - accuracy: 0.7823 - val_loss: 0.5290 - val_accuracy: 0.7730\n",
      "Epoch 51/300\n",
      "2797/2797 [==============================] - 1s 243us/sample - loss: 0.4800 - accuracy: 0.7851 - val_loss: 0.5285 - val_accuracy: 0.7730\n",
      "Epoch 52/300\n",
      "2797/2797 [==============================] - 1s 248us/sample - loss: 0.4796 - accuracy: 0.7901 - val_loss: 0.5280 - val_accuracy: 0.7730\n",
      "Epoch 53/300\n",
      "2797/2797 [==============================] - 1s 233us/sample - loss: 0.4743 - accuracy: 0.7873 - val_loss: 0.5277 - val_accuracy: 0.7688\n",
      "Epoch 54/300\n",
      "2797/2797 [==============================] - 1s 216us/sample - loss: 0.4727 - accuracy: 0.7833 - val_loss: 0.5273 - val_accuracy: 0.7702\n",
      "Epoch 55/300\n",
      "2797/2797 [==============================] - 1s 240us/sample - loss: 0.4718 - accuracy: 0.7930 - val_loss: 0.5269 - val_accuracy: 0.7674\n",
      "Epoch 56/300\n",
      "2797/2797 [==============================] - 1s 213us/sample - loss: 0.4670 - accuracy: 0.7908 - val_loss: 0.5266 - val_accuracy: 0.7674\n",
      "Epoch 57/300\n",
      "2797/2797 [==============================] - 1s 241us/sample - loss: 0.4657 - accuracy: 0.7926 - val_loss: 0.5262 - val_accuracy: 0.7674\n",
      "Epoch 58/300\n",
      "2797/2797 [==============================] - 1s 230us/sample - loss: 0.4617 - accuracy: 0.7937 - val_loss: 0.5259 - val_accuracy: 0.7674\n",
      "Epoch 59/300\n",
      "2797/2797 [==============================] - 1s 229us/sample - loss: 0.4619 - accuracy: 0.7969 - val_loss: 0.5256 - val_accuracy: 0.7688\n",
      "Epoch 60/300\n",
      "2797/2797 [==============================] - 1s 226us/sample - loss: 0.4586 - accuracy: 0.7916 - val_loss: 0.5253 - val_accuracy: 0.7688\n",
      "Epoch 61/300\n",
      "2797/2797 [==============================] - 1s 235us/sample - loss: 0.4593 - accuracy: 0.7912 - val_loss: 0.5251 - val_accuracy: 0.7688\n",
      "Epoch 62/300\n",
      "2797/2797 [==============================] - 1s 238us/sample - loss: 0.4596 - accuracy: 0.7934 - val_loss: 0.5249 - val_accuracy: 0.7688\n",
      "Epoch 63/300\n",
      "2797/2797 [==============================] - 1s 242us/sample - loss: 0.4561 - accuracy: 0.7991 - val_loss: 0.5246 - val_accuracy: 0.7688\n",
      "Epoch 64/300\n",
      "2797/2797 [==============================] - 1s 233us/sample - loss: 0.4525 - accuracy: 0.8023 - val_loss: 0.5244 - val_accuracy: 0.7688\n",
      "Epoch 65/300\n",
      "2797/2797 [==============================] - 1s 181us/sample - loss: 0.4523 - accuracy: 0.7994 - val_loss: 0.5242 - val_accuracy: 0.7674\n",
      "Epoch 66/300\n",
      "2797/2797 [==============================] - 0s 169us/sample - loss: 0.4501 - accuracy: 0.7994 - val_loss: 0.5242 - val_accuracy: 0.7674\n",
      "Epoch 67/300\n",
      "2797/2797 [==============================] - 0s 172us/sample - loss: 0.4458 - accuracy: 0.7980 - val_loss: 0.5240 - val_accuracy: 0.7674\n",
      "Epoch 68/300\n",
      "2797/2797 [==============================] - 1s 202us/sample - loss: 0.4419 - accuracy: 0.7980 - val_loss: 0.5239 - val_accuracy: 0.7688\n",
      "Epoch 69/300\n",
      "2797/2797 [==============================] - 1s 188us/sample - loss: 0.4425 - accuracy: 0.8009 - val_loss: 0.5238 - val_accuracy: 0.7688\n",
      "Epoch 70/300\n",
      "2797/2797 [==============================] - 1s 202us/sample - loss: 0.4404 - accuracy: 0.8084 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 71/300\n",
      "2797/2797 [==============================] - 1s 238us/sample - loss: 0.4347 - accuracy: 0.8073 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
      "Epoch 72/300\n",
      "2797/2797 [==============================] - 1s 249us/sample - loss: 0.4375 - accuracy: 0.8037 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
      "Epoch 73/300\n",
      "2797/2797 [==============================] - 1s 266us/sample - loss: 0.4378 - accuracy: 0.8016 - val_loss: 0.5236 - val_accuracy: 0.7646\n",
      "Epoch 74/300\n",
      "2797/2797 [==============================] - 1s 218us/sample - loss: 0.4339 - accuracy: 0.8034 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 75/300\n",
      "2797/2797 [==============================] - 1s 221us/sample - loss: 0.4283 - accuracy: 0.8026 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 76/300\n",
      "2797/2797 [==============================] - 1s 232us/sample - loss: 0.4324 - accuracy: 0.8077 - val_loss: 0.5235 - val_accuracy: 0.7646\n",
      "Epoch 77/300\n",
      "2797/2797 [==============================] - 1s 233us/sample - loss: 0.4267 - accuracy: 0.8116 - val_loss: 0.5235 - val_accuracy: 0.7632\n",
      "Epoch 78/300\n",
      "2797/2797 [==============================] - 1s 219us/sample - loss: 0.4230 - accuracy: 0.8091 - val_loss: 0.5236 - val_accuracy: 0.7632\n",
      "Epoch 79/300\n",
      "2797/2797 [==============================] - 1s 206us/sample - loss: 0.4209 - accuracy: 0.8112 - val_loss: 0.5237 - val_accuracy: 0.7632\n",
      "Epoch 00079: early stopping\n",
      "134/134 [==============================] - 0s 117us/sample - loss: 0.2687 - accuracy: 0.9701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [34:30, 1026.91s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.58s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.26s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 838.125 steps, validate for 215.6640625 steps\n",
      "Epoch 1/300\n",
      "839/838 [==============================] - 25s 30ms/step - loss: 0.6549 - accuracy: 0.6359 - val_loss: 0.5324 - val_accuracy: 0.7724\n",
      "Epoch 2/300\n",
      "839/838 [==============================] - 24s 29ms/step - loss: 0.5156 - accuracy: 0.7734 - val_loss: 0.5296 - val_accuracy: 0.7721\n",
      "Epoch 3/300\n",
      "839/838 [==============================] - 24s 29ms/step - loss: 0.4996 - accuracy: 0.7794 - val_loss: 0.5270 - val_accuracy: 0.7733\n",
      "Epoch 4/300\n",
      "839/838 [==============================] - 24s 29ms/step - loss: 0.4884 - accuracy: 0.7835 - val_loss: 0.5287 - val_accuracy: 0.7710\n",
      "Epoch 5/300\n",
      "839/838 [==============================] - 24s 28ms/step - loss: 0.4786 - accuracy: 0.7876 - val_loss: 0.5309 - val_accuracy: 0.7688\n",
      "Epoch 6/300\n",
      "839/838 [==============================] - 24s 29ms/step - loss: 0.4698 - accuracy: 0.7923 - val_loss: 0.5308 - val_accuracy: 0.7687\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 838.125 steps, validate for 215.6640625 steps\n",
      "Epoch 1/300\n",
      "839/838 [==============================] - 55s 66ms/step - loss: 0.4536 - accuracy: 0.8005 - val_loss: 0.5568 - val_accuracy: 0.7600\n",
      "Epoch 2/300\n",
      "839/838 [==============================] - 53s 64ms/step - loss: 0.4285 - accuracy: 0.8133 - val_loss: 0.5489 - val_accuracy: 0.7640\n",
      "Epoch 3/300\n",
      "839/838 [==============================] - 54s 64ms/step - loss: 0.4068 - accuracy: 0.8245 - val_loss: 0.5643 - val_accuracy: 0.7371\n",
      "Epoch 4/300\n",
      "839/838 [==============================] - 54s 64ms/step - loss: 0.3875 - accuracy: 0.8357 - val_loss: 0.5519 - val_accuracy: 0.7532\n",
      "Epoch 5/300\n",
      "839/838 [==============================] - 54s 65ms/step - loss: 0.3693 - accuracy: 0.8454 - val_loss: 0.5630 - val_accuracy: 0.7374\n",
      "Epoch 00005: early stopping\n",
      "106/106 [==============================] - 0s 2ms/sample - loss: 0.2177 - accuracy: 0.9811\n",
      "107/107 [==============================] - 0s 247us/sample - loss: 0.1978 - accuracy: 0.9907\n",
      "106/106 [==============================] - 0s 269us/sample - loss: 0.2285 - accuracy: 0.9623\n",
      "104/104 [==============================] - 0s 226us/sample - loss: 0.2048 - accuracy: 0.9808\n",
      "103/103 [==============================] - 0s 230us/sample - loss: 0.2640 - accuracy: 0.9417\n",
      "102/102 [==============================] - 0s 268us/sample - loss: 0.2540 - accuracy: 0.9412\n",
      "100/100 [==============================] - 0s 273us/sample - loss: 0.2731 - accuracy: 0.9400\n",
      "99/99 [==============================] - 0s 235us/sample - loss: 0.2577 - accuracy: 0.9596\n",
      "97/97 [==============================] - 0s 250us/sample - loss: 0.2741 - accuracy: 0.9588\n",
      "98/98 [==============================] - 0s 244us/sample - loss: 0.2914 - accuracy: 0.9388\n",
      "98/98 [==============================] - 0s 245us/sample - loss: 0.2653 - accuracy: 0.9490\n",
      "92/92 [==============================] - 0s 233us/sample - loss: 0.2704 - accuracy: 0.9565\n",
      "95/95 [==============================] - 0s 244us/sample - loss: 0.2587 - accuracy: 0.9579\n",
      "94/94 [==============================] - 0s 276us/sample - loss: 0.2765 - accuracy: 0.9362\n",
      "90/90 [==============================] - 0s 273us/sample - loss: 0.2287 - accuracy: 0.9889\n",
      "91/91 [==============================] - 0s 274us/sample - loss: 0.2684 - accuracy: 0.9231\n",
      "87/87 [==============================] - 0s 294us/sample - loss: 0.2404 - accuracy: 0.9655\n",
      "87/87 [==============================] - 0s 262us/sample - loss: 0.2884 - accuracy: 0.8851\n",
      "87/87 [==============================] - 0s 294us/sample - loss: 0.2768 - accuracy: 0.9425\n",
      "77/77 [==============================] - 0s 333us/sample - loss: 0.2388 - accuracy: 0.9481\n",
      "77/77 [==============================] - 0s 311us/sample - loss: 0.2603 - accuracy: 0.9740\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.2899 - accuracy: 0.9733\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.2937 - accuracy: 0.9333\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.2517 - accuracy: 0.9600\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.2678 - accuracy: 0.9333\n",
      "75/75 [==============================] - 0s 328us/sample - loss: 0.3171 - accuracy: 0.9067\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.2616 - accuracy: 0.9600\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 0.2888 - accuracy: 0.9067\n",
      "74/74 [==============================] - 0s 294us/sample - loss: 0.2628 - accuracy: 0.9459\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.3061 - accuracy: 0.9333\n",
      "74/74 [==============================] - 0s 289us/sample - loss: 0.3203 - accuracy: 0.9054\n",
      "74/74 [==============================] - 0s 328us/sample - loss: 0.2982 - accuracy: 0.9324\n",
      "74/74 [==============================] - 0s 291us/sample - loss: 0.2892 - accuracy: 0.8919\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2852 samples, validate on 730 samples\n",
      "Epoch 1/300\n",
      "2852/2852 [==============================] - 2s 856us/sample - loss: 0.7297 - accuracy: 0.4649 - val_loss: 0.7246 - val_accuracy: 0.4589\n",
      "Epoch 2/300\n",
      "2852/2852 [==============================] - 1s 222us/sample - loss: 0.6983 - accuracy: 0.5305 - val_loss: 0.7046 - val_accuracy: 0.5014\n",
      "Epoch 3/300\n",
      "2852/2852 [==============================] - 1s 203us/sample - loss: 0.6805 - accuracy: 0.5565 - val_loss: 0.6905 - val_accuracy: 0.5397\n",
      "Epoch 4/300\n",
      "2852/2852 [==============================] - 1s 206us/sample - loss: 0.6667 - accuracy: 0.5989 - val_loss: 0.6787 - val_accuracy: 0.5781\n",
      "Epoch 5/300\n",
      "2852/2852 [==============================] - 1s 217us/sample - loss: 0.6532 - accuracy: 0.6259 - val_loss: 0.6692 - val_accuracy: 0.6055\n",
      "Epoch 6/300\n",
      "2852/2852 [==============================] - 1s 197us/sample - loss: 0.6417 - accuracy: 0.6487 - val_loss: 0.6607 - val_accuracy: 0.6274\n",
      "Epoch 7/300\n",
      "2852/2852 [==============================] - 1s 203us/sample - loss: 0.6327 - accuracy: 0.6665 - val_loss: 0.6531 - val_accuracy: 0.6452\n",
      "Epoch 8/300\n",
      "2852/2852 [==============================] - 1s 224us/sample - loss: 0.6238 - accuracy: 0.6757 - val_loss: 0.6462 - val_accuracy: 0.6603\n",
      "Epoch 9/300\n",
      "2852/2852 [==============================] - 1s 252us/sample - loss: 0.6144 - accuracy: 0.6999 - val_loss: 0.6398 - val_accuracy: 0.6753\n",
      "Epoch 10/300\n",
      "2852/2852 [==============================] - 1s 254us/sample - loss: 0.6092 - accuracy: 0.7034 - val_loss: 0.6340 - val_accuracy: 0.6918\n",
      "Epoch 11/300\n",
      "2852/2852 [==============================] - 1s 250us/sample - loss: 0.5998 - accuracy: 0.7248 - val_loss: 0.6285 - val_accuracy: 0.7041\n",
      "Epoch 12/300\n",
      "2852/2852 [==============================] - 1s 259us/sample - loss: 0.5924 - accuracy: 0.7367 - val_loss: 0.6234 - val_accuracy: 0.7137\n",
      "Epoch 13/300\n",
      "2852/2852 [==============================] - 1s 258us/sample - loss: 0.5858 - accuracy: 0.7426 - val_loss: 0.6185 - val_accuracy: 0.7192\n",
      "Epoch 14/300\n",
      "2852/2852 [==============================] - 1s 263us/sample - loss: 0.5831 - accuracy: 0.7433 - val_loss: 0.6139 - val_accuracy: 0.7219\n",
      "Epoch 15/300\n",
      "2852/2852 [==============================] - 1s 211us/sample - loss: 0.5779 - accuracy: 0.7514 - val_loss: 0.6096 - val_accuracy: 0.7301\n",
      "Epoch 16/300\n",
      "2852/2852 [==============================] - 1s 231us/sample - loss: 0.5700 - accuracy: 0.7539 - val_loss: 0.6054 - val_accuracy: 0.7288\n",
      "Epoch 17/300\n",
      "2852/2852 [==============================] - 1s 211us/sample - loss: 0.5634 - accuracy: 0.7672 - val_loss: 0.6015 - val_accuracy: 0.7329\n",
      "Epoch 18/300\n",
      "2852/2852 [==============================] - 1s 218us/sample - loss: 0.5581 - accuracy: 0.7735 - val_loss: 0.5977 - val_accuracy: 0.7384\n",
      "Epoch 19/300\n",
      "2852/2852 [==============================] - 1s 214us/sample - loss: 0.5504 - accuracy: 0.7773 - val_loss: 0.5941 - val_accuracy: 0.7411\n",
      "Epoch 20/300\n",
      "2852/2852 [==============================] - 1s 245us/sample - loss: 0.5480 - accuracy: 0.7756 - val_loss: 0.5907 - val_accuracy: 0.7438\n",
      "Epoch 21/300\n",
      "2852/2852 [==============================] - 1s 218us/sample - loss: 0.5436 - accuracy: 0.7784 - val_loss: 0.5874 - val_accuracy: 0.7466\n",
      "Epoch 22/300\n",
      "2852/2852 [==============================] - 1s 212us/sample - loss: 0.5388 - accuracy: 0.7781 - val_loss: 0.5843 - val_accuracy: 0.7479\n",
      "Epoch 23/300\n",
      "2852/2852 [==============================] - 1s 266us/sample - loss: 0.5321 - accuracy: 0.7851 - val_loss: 0.5815 - val_accuracy: 0.7507\n",
      "Epoch 24/300\n",
      "2852/2852 [==============================] - 1s 260us/sample - loss: 0.5264 - accuracy: 0.7896 - val_loss: 0.5787 - val_accuracy: 0.7534\n",
      "Epoch 25/300\n",
      "2852/2852 [==============================] - 1s 222us/sample - loss: 0.5243 - accuracy: 0.7910 - val_loss: 0.5760 - val_accuracy: 0.7534\n",
      "Epoch 26/300\n",
      "2852/2852 [==============================] - 1s 214us/sample - loss: 0.5208 - accuracy: 0.7844 - val_loss: 0.5733 - val_accuracy: 0.7534\n",
      "Epoch 27/300\n",
      "2852/2852 [==============================] - 1s 219us/sample - loss: 0.5187 - accuracy: 0.7896 - val_loss: 0.5709 - val_accuracy: 0.7548\n",
      "Epoch 28/300\n",
      "2852/2852 [==============================] - 1s 241us/sample - loss: 0.5131 - accuracy: 0.7910 - val_loss: 0.5686 - val_accuracy: 0.7562\n",
      "Epoch 29/300\n",
      "2852/2852 [==============================] - 1s 262us/sample - loss: 0.5093 - accuracy: 0.7966 - val_loss: 0.5664 - val_accuracy: 0.7562\n",
      "Epoch 30/300\n",
      "2852/2852 [==============================] - 1s 242us/sample - loss: 0.5026 - accuracy: 0.7970 - val_loss: 0.5642 - val_accuracy: 0.7562\n",
      "Epoch 31/300\n",
      "2852/2852 [==============================] - 1s 240us/sample - loss: 0.5002 - accuracy: 0.7991 - val_loss: 0.5622 - val_accuracy: 0.7562\n",
      "Epoch 32/300\n",
      "2852/2852 [==============================] - 1s 216us/sample - loss: 0.4953 - accuracy: 0.8033 - val_loss: 0.5603 - val_accuracy: 0.7575\n",
      "Epoch 33/300\n",
      "2852/2852 [==============================] - 1s 214us/sample - loss: 0.4895 - accuracy: 0.8015 - val_loss: 0.5586 - val_accuracy: 0.7575\n",
      "Epoch 34/300\n",
      "2852/2852 [==============================] - 1s 202us/sample - loss: 0.4879 - accuracy: 0.8022 - val_loss: 0.5570 - val_accuracy: 0.7575\n",
      "Epoch 35/300\n",
      "2852/2852 [==============================] - 1s 219us/sample - loss: 0.4831 - accuracy: 0.8054 - val_loss: 0.5554 - val_accuracy: 0.7575\n",
      "Epoch 36/300\n",
      "2852/2852 [==============================] - 1s 212us/sample - loss: 0.4798 - accuracy: 0.8121 - val_loss: 0.5538 - val_accuracy: 0.7589\n",
      "Epoch 37/300\n",
      "2852/2852 [==============================] - 1s 223us/sample - loss: 0.4784 - accuracy: 0.8096 - val_loss: 0.5525 - val_accuracy: 0.7589\n",
      "Epoch 38/300\n",
      "2852/2852 [==============================] - 1s 231us/sample - loss: 0.4729 - accuracy: 0.8107 - val_loss: 0.5512 - val_accuracy: 0.7603\n",
      "Epoch 39/300\n",
      "2852/2852 [==============================] - 1s 240us/sample - loss: 0.4713 - accuracy: 0.8107 - val_loss: 0.5499 - val_accuracy: 0.7616\n",
      "Epoch 40/300\n",
      "2852/2852 [==============================] - 1s 200us/sample - loss: 0.4683 - accuracy: 0.8128 - val_loss: 0.5488 - val_accuracy: 0.7616\n",
      "Epoch 41/300\n",
      "2852/2852 [==============================] - 1s 251us/sample - loss: 0.4634 - accuracy: 0.8173 - val_loss: 0.5479 - val_accuracy: 0.7616\n",
      "Epoch 42/300\n",
      "2852/2852 [==============================] - 1s 221us/sample - loss: 0.4589 - accuracy: 0.8166 - val_loss: 0.5470 - val_accuracy: 0.7603\n",
      "Epoch 43/300\n",
      "2852/2852 [==============================] - 1s 223us/sample - loss: 0.4550 - accuracy: 0.8103 - val_loss: 0.5461 - val_accuracy: 0.7603\n",
      "Epoch 44/300\n",
      "2852/2852 [==============================] - 1s 258us/sample - loss: 0.4524 - accuracy: 0.8187 - val_loss: 0.5453 - val_accuracy: 0.7616\n",
      "Epoch 45/300\n",
      "2852/2852 [==============================] - 1s 240us/sample - loss: 0.4479 - accuracy: 0.8152 - val_loss: 0.5446 - val_accuracy: 0.7616\n",
      "Epoch 46/300\n",
      "2852/2852 [==============================] - 1s 243us/sample - loss: 0.4458 - accuracy: 0.8201 - val_loss: 0.5439 - val_accuracy: 0.7630\n",
      "Epoch 47/300\n",
      "2852/2852 [==============================] - 1s 235us/sample - loss: 0.4459 - accuracy: 0.8184 - val_loss: 0.5434 - val_accuracy: 0.7630\n",
      "Epoch 48/300\n",
      "2852/2852 [==============================] - 1s 256us/sample - loss: 0.4414 - accuracy: 0.8194 - val_loss: 0.5429 - val_accuracy: 0.7630\n",
      "Epoch 49/300\n",
      "2852/2852 [==============================] - 1s 240us/sample - loss: 0.4390 - accuracy: 0.8194 - val_loss: 0.5424 - val_accuracy: 0.7630\n",
      "Epoch 50/300\n",
      "2852/2852 [==============================] - 1s 251us/sample - loss: 0.4344 - accuracy: 0.8254 - val_loss: 0.5421 - val_accuracy: 0.7616\n",
      "Epoch 51/300\n",
      "2852/2852 [==============================] - 1s 267us/sample - loss: 0.4292 - accuracy: 0.8233 - val_loss: 0.5418 - val_accuracy: 0.7644\n",
      "Epoch 52/300\n",
      "2852/2852 [==============================] - ETA: 0s - loss: 0.4288 - accuracy: 0.82 - 1s 240us/sample - loss: 0.4269 - accuracy: 0.8222 - val_loss: 0.5416 - val_accuracy: 0.7630\n",
      "Epoch 53/300\n",
      "2852/2852 [==============================] - 1s 263us/sample - loss: 0.4247 - accuracy: 0.8292 - val_loss: 0.5415 - val_accuracy: 0.7644\n",
      "Epoch 54/300\n",
      "2852/2852 [==============================] - 1s 243us/sample - loss: 0.4231 - accuracy: 0.8320 - val_loss: 0.5414 - val_accuracy: 0.7644\n",
      "Epoch 55/300\n",
      "2852/2852 [==============================] - 1s 197us/sample - loss: 0.4199 - accuracy: 0.8285 - val_loss: 0.5414 - val_accuracy: 0.7644\n",
      "Epoch 56/300\n",
      "2852/2852 [==============================] - 1s 219us/sample - loss: 0.4165 - accuracy: 0.8285 - val_loss: 0.5415 - val_accuracy: 0.7644\n",
      "Epoch 57/300\n",
      "2852/2852 [==============================] - 1s 242us/sample - loss: 0.4115 - accuracy: 0.8349 - val_loss: 0.5415 - val_accuracy: 0.7644\n",
      "Epoch 58/300\n",
      "2852/2852 [==============================] - 1s 242us/sample - loss: 0.4099 - accuracy: 0.8310 - val_loss: 0.5417 - val_accuracy: 0.7644\n",
      "Epoch 00058: early stopping\n",
      "67/67 [==============================] - 0s 202us/sample - loss: 0.2520 - accuracy: 0.9701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [52:53, 1049.80s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.46s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.34s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 821.625 steps, validate for 207.3515625 steps\n",
      "Epoch 1/300\n",
      "822/821 [==============================] - 24s 30ms/step - loss: 0.5920 - accuracy: 0.7035 - val_loss: 0.5411 - val_accuracy: 0.7617\n",
      "Epoch 2/300\n",
      "822/821 [==============================] - 23s 28ms/step - loss: 0.5212 - accuracy: 0.7695 - val_loss: 0.5386 - val_accuracy: 0.7601\n",
      "Epoch 3/300\n",
      "822/821 [==============================] - 23s 29ms/step - loss: 0.5071 - accuracy: 0.7740 - val_loss: 0.5343 - val_accuracy: 0.7625\n",
      "Epoch 4/300\n",
      "822/821 [==============================] - 24s 29ms/step - loss: 0.4966 - accuracy: 0.7772 - val_loss: 0.5409 - val_accuracy: 0.7597\n",
      "Epoch 5/300\n",
      "822/821 [==============================] - 24s 29ms/step - loss: 0.4874 - accuracy: 0.7812 - val_loss: 0.5428 - val_accuracy: 0.7577\n",
      "Epoch 6/300\n",
      "822/821 [==============================] - 24s 29ms/step - loss: 0.4789 - accuracy: 0.7849 - val_loss: 0.5428 - val_accuracy: 0.7559\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 821.625 steps, validate for 207.3515625 steps\n",
      "Epoch 1/300\n",
      "822/821 [==============================] - 54s 66ms/step - loss: 0.4621 - accuracy: 0.7930 - val_loss: 0.5566 - val_accuracy: 0.7574\n",
      "Epoch 2/300\n",
      "822/821 [==============================] - 53s 64ms/step - loss: 0.4348 - accuracy: 0.8079 - val_loss: 0.5587 - val_accuracy: 0.7564\n",
      "Epoch 3/300\n",
      "822/821 [==============================] - 53s 64ms/step - loss: 0.4120 - accuracy: 0.8206 - val_loss: 0.5683 - val_accuracy: 0.7465\n",
      "Epoch 4/300\n",
      "822/821 [==============================] - 53s 65ms/step - loss: 0.3901 - accuracy: 0.8331 - val_loss: 0.5819 - val_accuracy: 0.7461\n",
      "Epoch 00004: early stopping\n",
      "207/207 [==============================] - 0s 1ms/sample - loss: 0.1992 - accuracy: 0.9662\n",
      "204/204 [==============================] - 0s 275us/sample - loss: 0.1896 - accuracy: 0.9804\n",
      "205/205 [==============================] - 0s 218us/sample - loss: 0.2111 - accuracy: 0.9463\n",
      "202/202 [==============================] - 0s 228us/sample - loss: 0.1999 - accuracy: 0.9554\n",
      "201/201 [==============================] - 0s 235us/sample - loss: 0.1994 - accuracy: 0.9751\n",
      "200/200 [==============================] - 0s 237us/sample - loss: 0.2053 - accuracy: 0.9800\n",
      "196/196 [==============================] - 0s 238us/sample - loss: 0.2025 - accuracy: 0.9643\n",
      "195/195 [==============================] - 0s 225us/sample - loss: 0.1841 - accuracy: 0.9795\n",
      "193/193 [==============================] - 0s 262us/sample - loss: 0.2057 - accuracy: 0.9637\n",
      "189/189 [==============================] - 0s 222us/sample - loss: 0.2083 - accuracy: 0.9735\n",
      "186/186 [==============================] - 0s 218us/sample - loss: 0.2141 - accuracy: 0.9731\n",
      "187/187 [==============================] - 0s 239us/sample - loss: 0.2198 - accuracy: 0.9465\n",
      "185/185 [==============================] - 0s 248us/sample - loss: 0.2295 - accuracy: 0.9459\n",
      "184/184 [==============================] - 0s 242us/sample - loss: 0.2344 - accuracy: 0.9674\n",
      "182/182 [==============================] - 0s 241us/sample - loss: 0.2235 - accuracy: 0.9725\n",
      "183/183 [==============================] - 0s 229us/sample - loss: 0.2398 - accuracy: 0.9563\n",
      "182/182 [==============================] - 0s 221us/sample - loss: 0.2372 - accuracy: 0.9451\n",
      "181/181 [==============================] - 0s 235us/sample - loss: 0.2375 - accuracy: 0.9558\n",
      "182/182 [==============================] - 0s 227us/sample - loss: 0.2446 - accuracy: 0.9451\n",
      "180/180 [==============================] - 0s 261us/sample - loss: 0.2672 - accuracy: 0.9333\n",
      "179/179 [==============================] - 0s 254us/sample - loss: 0.2481 - accuracy: 0.9385\n",
      "176/176 [==============================] - 0s 257us/sample - loss: 0.2542 - accuracy: 0.9261\n",
      "174/174 [==============================] - 0s 279us/sample - loss: 0.2623 - accuracy: 0.9368\n",
      "174/174 [==============================] - 0s 247us/sample - loss: 0.2385 - accuracy: 0.9655\n",
      "174/174 [==============================] - 0s 271us/sample - loss: 0.2536 - accuracy: 0.9368\n",
      "172/172 [==============================] - 0s 342us/sample - loss: 0.2632 - accuracy: 0.9244\n",
      "174/174 [==============================] - 0s 275us/sample - loss: 0.2404 - accuracy: 0.9598\n",
      "172/172 [==============================] - 0s 257us/sample - loss: 0.2692 - accuracy: 0.9477\n",
      "171/171 [==============================] - 0s 262us/sample - loss: 0.2730 - accuracy: 0.9357\n",
      "171/171 [==============================] - 0s 244us/sample - loss: 0.2614 - accuracy: 0.9591\n",
      "170/170 [==============================] - 0s 270us/sample - loss: 0.2614 - accuracy: 0.9353\n",
      "169/169 [==============================] - 0s 268us/sample - loss: 0.2458 - accuracy: 0.9586\n",
      "169/169 [==============================] - 0s 262us/sample - loss: 0.2458 - accuracy: 0.9586\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2785 samples, validate on 702 samples\n",
      "Epoch 1/300\n",
      "2785/2785 [==============================] - 3s 923us/sample - loss: 0.7316 - accuracy: 0.5077 - val_loss: 0.7045 - val_accuracy: 0.5142\n",
      "Epoch 2/300\n",
      "2785/2785 [==============================] - 1s 219us/sample - loss: 0.6875 - accuracy: 0.5558 - val_loss: 0.6782 - val_accuracy: 0.5584\n",
      "Epoch 3/300\n",
      "2785/2785 [==============================] - 1s 211us/sample - loss: 0.6635 - accuracy: 0.5917 - val_loss: 0.6603 - val_accuracy: 0.6068\n",
      "Epoch 4/300\n",
      "2785/2785 [==============================] - 1s 216us/sample - loss: 0.6447 - accuracy: 0.6233 - val_loss: 0.6473 - val_accuracy: 0.6282\n",
      "Epoch 5/300\n",
      "2785/2785 [==============================] - 1s 214us/sample - loss: 0.6324 - accuracy: 0.6467 - val_loss: 0.6363 - val_accuracy: 0.6481\n",
      "Epoch 6/300\n",
      "2785/2785 [==============================] - 1s 234us/sample - loss: 0.6168 - accuracy: 0.6790 - val_loss: 0.6269 - val_accuracy: 0.6724\n",
      "Epoch 7/300\n",
      "2785/2785 [==============================] - 1s 257us/sample - loss: 0.6060 - accuracy: 0.6934 - val_loss: 0.6185 - val_accuracy: 0.6866\n",
      "Epoch 8/300\n",
      "2785/2785 [==============================] - 1s 266us/sample - loss: 0.5989 - accuracy: 0.7013 - val_loss: 0.6110 - val_accuracy: 0.6994\n",
      "Epoch 9/300\n",
      "2785/2785 [==============================] - 1s 238us/sample - loss: 0.5904 - accuracy: 0.7023 - val_loss: 0.6044 - val_accuracy: 0.7137\n",
      "Epoch 10/300\n",
      "2785/2785 [==============================] - 1s 246us/sample - loss: 0.5835 - accuracy: 0.7178 - val_loss: 0.5985 - val_accuracy: 0.7179\n",
      "Epoch 11/300\n",
      "2785/2785 [==============================] - 1s 250us/sample - loss: 0.5715 - accuracy: 0.7318 - val_loss: 0.5933 - val_accuracy: 0.7236\n",
      "Epoch 12/300\n",
      "2785/2785 [==============================] - 1s 216us/sample - loss: 0.5661 - accuracy: 0.7379 - val_loss: 0.5886 - val_accuracy: 0.7322\n",
      "Epoch 13/300\n",
      "2785/2785 [==============================] - 1s 209us/sample - loss: 0.5596 - accuracy: 0.7458 - val_loss: 0.5843 - val_accuracy: 0.7464\n",
      "Epoch 14/300\n",
      "2785/2785 [==============================] - 1s 197us/sample - loss: 0.5529 - accuracy: 0.7501 - val_loss: 0.5803 - val_accuracy: 0.7464\n",
      "Epoch 15/300\n",
      "2785/2785 [==============================] - 1s 222us/sample - loss: 0.5486 - accuracy: 0.7526 - val_loss: 0.5764 - val_accuracy: 0.7507\n",
      "Epoch 16/300\n",
      "2785/2785 [==============================] - 1s 220us/sample - loss: 0.5467 - accuracy: 0.7551 - val_loss: 0.5729 - val_accuracy: 0.7521\n",
      "Epoch 17/300\n",
      "2785/2785 [==============================] - 1s 223us/sample - loss: 0.5411 - accuracy: 0.7576 - val_loss: 0.5698 - val_accuracy: 0.7564\n",
      "Epoch 18/300\n",
      "2785/2785 [==============================] - 1s 184us/sample - loss: 0.5357 - accuracy: 0.7627 - val_loss: 0.5670 - val_accuracy: 0.7564\n",
      "Epoch 19/300\n",
      "2785/2785 [==============================] - 1s 202us/sample - loss: 0.5354 - accuracy: 0.7637 - val_loss: 0.5643 - val_accuracy: 0.7621\n",
      "Epoch 20/300\n",
      "2785/2785 [==============================] - 1s 267us/sample - loss: 0.5287 - accuracy: 0.7634 - val_loss: 0.5617 - val_accuracy: 0.7635\n",
      "Epoch 21/300\n",
      "2785/2785 [==============================] - 1s 275us/sample - loss: 0.5276 - accuracy: 0.7662 - val_loss: 0.5594 - val_accuracy: 0.7650\n",
      "Epoch 22/300\n",
      "2785/2785 [==============================] - 1s 249us/sample - loss: 0.5226 - accuracy: 0.7727 - val_loss: 0.5573 - val_accuracy: 0.7678\n",
      "Epoch 23/300\n",
      "2785/2785 [==============================] - 1s 252us/sample - loss: 0.5144 - accuracy: 0.7752 - val_loss: 0.5554 - val_accuracy: 0.7664\n",
      "Epoch 24/300\n",
      "2785/2785 [==============================] - 1s 248us/sample - loss: 0.5123 - accuracy: 0.7759 - val_loss: 0.5537 - val_accuracy: 0.7664\n",
      "Epoch 25/300\n",
      "2785/2785 [==============================] - 1s 246us/sample - loss: 0.5112 - accuracy: 0.7738 - val_loss: 0.5520 - val_accuracy: 0.7664\n",
      "Epoch 26/300\n",
      "2785/2785 [==============================] - 1s 266us/sample - loss: 0.5033 - accuracy: 0.7835 - val_loss: 0.5505 - val_accuracy: 0.7692\n",
      "Epoch 27/300\n",
      "2785/2785 [==============================] - 1s 262us/sample - loss: 0.5002 - accuracy: 0.7824 - val_loss: 0.5491 - val_accuracy: 0.7678\n",
      "Epoch 28/300\n",
      "2785/2785 [==============================] - 1s 232us/sample - loss: 0.5018 - accuracy: 0.7820 - val_loss: 0.5478 - val_accuracy: 0.7664\n",
      "Epoch 29/300\n",
      "2785/2785 [==============================] - 1s 240us/sample - loss: 0.4955 - accuracy: 0.7899 - val_loss: 0.5466 - val_accuracy: 0.7664\n",
      "Epoch 30/300\n",
      "2785/2785 [==============================] - 1s 227us/sample - loss: 0.4919 - accuracy: 0.7824 - val_loss: 0.5454 - val_accuracy: 0.7678\n",
      "Epoch 31/300\n",
      "2785/2785 [==============================] - 1s 202us/sample - loss: 0.4938 - accuracy: 0.7824 - val_loss: 0.5443 - val_accuracy: 0.7664\n",
      "Epoch 32/300\n",
      "2785/2785 [==============================] - 1s 205us/sample - loss: 0.4919 - accuracy: 0.7853 - val_loss: 0.5434 - val_accuracy: 0.7664\n",
      "Epoch 33/300\n",
      "2785/2785 [==============================] - 1s 240us/sample - loss: 0.4914 - accuracy: 0.7867 - val_loss: 0.5425 - val_accuracy: 0.7664\n",
      "Epoch 34/300\n",
      "2785/2785 [==============================] - 1s 223us/sample - loss: 0.4861 - accuracy: 0.7885 - val_loss: 0.5418 - val_accuracy: 0.7664\n",
      "Epoch 35/300\n",
      "2785/2785 [==============================] - 1s 217us/sample - loss: 0.4827 - accuracy: 0.7831 - val_loss: 0.5410 - val_accuracy: 0.7650\n",
      "Epoch 36/300\n",
      "2785/2785 [==============================] - 1s 215us/sample - loss: 0.4809 - accuracy: 0.7885 - val_loss: 0.5403 - val_accuracy: 0.7664\n",
      "Epoch 37/300\n",
      "2785/2785 [==============================] - 1s 214us/sample - loss: 0.4826 - accuracy: 0.7928 - val_loss: 0.5396 - val_accuracy: 0.7664\n",
      "Epoch 38/300\n",
      "2785/2785 [==============================] - 1s 235us/sample - loss: 0.4807 - accuracy: 0.7892 - val_loss: 0.5390 - val_accuracy: 0.7678\n",
      "Epoch 39/300\n",
      "2785/2785 [==============================] - 1s 234us/sample - loss: 0.4767 - accuracy: 0.7910 - val_loss: 0.5384 - val_accuracy: 0.7678\n",
      "Epoch 40/300\n",
      "2785/2785 [==============================] - 1s 242us/sample - loss: 0.4802 - accuracy: 0.7935 - val_loss: 0.5379 - val_accuracy: 0.7678\n",
      "Epoch 41/300\n",
      "2785/2785 [==============================] - 1s 262us/sample - loss: 0.4741 - accuracy: 0.7892 - val_loss: 0.5375 - val_accuracy: 0.7678\n",
      "Epoch 42/300\n",
      "2785/2785 [==============================] - 1s 238us/sample - loss: 0.4716 - accuracy: 0.7943 - val_loss: 0.5370 - val_accuracy: 0.7650\n",
      "Epoch 43/300\n",
      "2785/2785 [==============================] - 1s 228us/sample - loss: 0.4636 - accuracy: 0.8007 - val_loss: 0.5366 - val_accuracy: 0.7650\n",
      "Epoch 44/300\n",
      "2785/2785 [==============================] - 1s 238us/sample - loss: 0.4643 - accuracy: 0.7982 - val_loss: 0.5362 - val_accuracy: 0.7650\n",
      "Epoch 45/300\n",
      "2785/2785 [==============================] - 1s 244us/sample - loss: 0.4636 - accuracy: 0.7957 - val_loss: 0.5358 - val_accuracy: 0.7664\n",
      "Epoch 46/300\n",
      "2785/2785 [==============================] - 1s 242us/sample - loss: 0.4621 - accuracy: 0.8007 - val_loss: 0.5355 - val_accuracy: 0.7664\n",
      "Epoch 47/300\n",
      "2785/2785 [==============================] - 1s 264us/sample - loss: 0.4597 - accuracy: 0.7971 - val_loss: 0.5352 - val_accuracy: 0.7664\n",
      "Epoch 48/300\n",
      "2785/2785 [==============================] - 1s 279us/sample - loss: 0.4583 - accuracy: 0.7961 - val_loss: 0.5349 - val_accuracy: 0.7664\n",
      "Epoch 49/300\n",
      "2785/2785 [==============================] - 1s 231us/sample - loss: 0.4602 - accuracy: 0.7953 - val_loss: 0.5346 - val_accuracy: 0.7664\n",
      "Epoch 50/300\n",
      "2785/2785 [==============================] - 1s 258us/sample - loss: 0.4543 - accuracy: 0.8004 - val_loss: 0.5344 - val_accuracy: 0.7664\n",
      "Epoch 51/300\n",
      "2785/2785 [==============================] - 1s 244us/sample - loss: 0.4532 - accuracy: 0.7971 - val_loss: 0.5342 - val_accuracy: 0.7678\n",
      "Epoch 52/300\n",
      "2785/2785 [==============================] - 1s 264us/sample - loss: 0.4510 - accuracy: 0.8025 - val_loss: 0.5340 - val_accuracy: 0.7692\n",
      "Epoch 53/300\n",
      "2785/2785 [==============================] - 1s 245us/sample - loss: 0.4449 - accuracy: 0.8057 - val_loss: 0.5338 - val_accuracy: 0.7692\n",
      "Epoch 54/300\n",
      "2785/2785 [==============================] - 1s 235us/sample - loss: 0.4474 - accuracy: 0.8036 - val_loss: 0.5337 - val_accuracy: 0.7678\n",
      "Epoch 55/300\n",
      "2785/2785 [==============================] - 1s 231us/sample - loss: 0.4459 - accuracy: 0.8057 - val_loss: 0.5336 - val_accuracy: 0.7664\n",
      "Epoch 56/300\n",
      "2785/2785 [==============================] - 1s 255us/sample - loss: 0.4465 - accuracy: 0.8054 - val_loss: 0.5335 - val_accuracy: 0.7635\n",
      "Epoch 57/300\n",
      "2785/2785 [==============================] - 1s 215us/sample - loss: 0.4427 - accuracy: 0.8057 - val_loss: 0.5333 - val_accuracy: 0.7635\n",
      "Epoch 58/300\n",
      "2785/2785 [==============================] - 1s 195us/sample - loss: 0.4409 - accuracy: 0.8050 - val_loss: 0.5332 - val_accuracy: 0.7635\n",
      "Epoch 59/300\n",
      "2785/2785 [==============================] - 1s 222us/sample - loss: 0.4395 - accuracy: 0.8090 - val_loss: 0.5331 - val_accuracy: 0.7635\n",
      "Epoch 60/300\n",
      "2785/2785 [==============================] - 1s 214us/sample - loss: 0.4363 - accuracy: 0.8122 - val_loss: 0.5332 - val_accuracy: 0.7635\n",
      "Epoch 61/300\n",
      "2785/2785 [==============================] - 1s 216us/sample - loss: 0.4334 - accuracy: 0.8108 - val_loss: 0.5332 - val_accuracy: 0.7650\n",
      "Epoch 62/300\n",
      "2785/2785 [==============================] - 1s 240us/sample - loss: 0.4321 - accuracy: 0.8126 - val_loss: 0.5332 - val_accuracy: 0.7621\n",
      "Epoch 00062: early stopping\n",
      "162/162 [==============================] - 0s 138us/sample - loss: 0.2714 - accuracy: 0.9691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [1:10:13, 1046.98s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.59s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.41s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 831.359375 steps, validate for 213.8828125 steps\n",
      "Epoch 1/300\n",
      "832/831 [==============================] - 25s 30ms/step - loss: 0.6423 - accuracy: 0.6588 - val_loss: 0.5283 - val_accuracy: 0.7725\n",
      "Epoch 2/300\n",
      "832/831 [==============================] - 24s 28ms/step - loss: 0.5175 - accuracy: 0.7729 - val_loss: 0.5262 - val_accuracy: 0.7710\n",
      "Epoch 3/300\n",
      "832/831 [==============================] - 24s 29ms/step - loss: 0.5024 - accuracy: 0.7777 - val_loss: 0.5239 - val_accuracy: 0.7716\n",
      "Epoch 4/300\n",
      "832/831 [==============================] - 24s 29ms/step - loss: 0.4919 - accuracy: 0.7819 - val_loss: 0.5270 - val_accuracy: 0.7680\n",
      "Epoch 5/300\n",
      "832/831 [==============================] - 24s 28ms/step - loss: 0.4825 - accuracy: 0.7857 - val_loss: 0.5265 - val_accuracy: 0.7689\n",
      "Epoch 6/300\n",
      "832/831 [==============================] - 24s 29ms/step - loss: 0.4738 - accuracy: 0.7900 - val_loss: 0.5295 - val_accuracy: 0.7666\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 831.359375 steps, validate for 213.8828125 steps\n",
      "Epoch 1/300\n",
      "832/831 [==============================] - 55s 66ms/step - loss: 0.4574 - accuracy: 0.7977 - val_loss: 0.5297 - val_accuracy: 0.7699\n",
      "Epoch 2/300\n",
      "832/831 [==============================] - 53s 64ms/step - loss: 0.4312 - accuracy: 0.8112 - val_loss: 0.5551 - val_accuracy: 0.7666\n",
      "Epoch 3/300\n",
      "832/831 [==============================] - 53s 64ms/step - loss: 0.4093 - accuracy: 0.8238 - val_loss: 0.5337 - val_accuracy: 0.7614\n",
      "Epoch 4/300\n",
      "832/831 [==============================] - 53s 64ms/step - loss: 0.3888 - accuracy: 0.8346 - val_loss: 0.5810 - val_accuracy: 0.7159\n",
      "Epoch 00004: early stopping\n",
      "139/139 [==============================] - 0s 2ms/sample - loss: 0.5110 - accuracy: 0.7554\n",
      "135/135 [==============================] - 0s 240us/sample - loss: 0.4202 - accuracy: 0.8593\n",
      "131/131 [==============================] - 0s 260us/sample - loss: 0.4059 - accuracy: 0.8550\n",
      "130/130 [==============================] - 0s 266us/sample - loss: 0.4756 - accuracy: 0.8154\n",
      "129/129 [==============================] - 0s 235us/sample - loss: 0.5251 - accuracy: 0.7829\n",
      "130/130 [==============================] - 0s 243us/sample - loss: 0.4877 - accuracy: 0.8000\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.4852 - accuracy: 0.7812\n",
      "128/128 [==============================] - 0s 197us/sample - loss: 0.5027 - accuracy: 0.8047\n",
      "126/126 [==============================] - 0s 252us/sample - loss: 0.4777 - accuracy: 0.7857\n",
      "128/128 [==============================] - 0s 221us/sample - loss: 0.5078 - accuracy: 0.7969\n",
      "127/127 [==============================] - 0s 267us/sample - loss: 0.4883 - accuracy: 0.8110\n",
      "126/126 [==============================] - 0s 249us/sample - loss: 0.4863 - accuracy: 0.8175\n",
      "125/125 [==============================] - 0s 243us/sample - loss: 0.4480 - accuracy: 0.8240\n",
      "126/126 [==============================] - 0s 267us/sample - loss: 0.4738 - accuracy: 0.8571\n",
      "124/124 [==============================] - 0s 264us/sample - loss: 0.4903 - accuracy: 0.7823\n",
      "123/123 [==============================] - 0s 275us/sample - loss: 0.4980 - accuracy: 0.8374\n",
      "121/121 [==============================] - 0s 244us/sample - loss: 0.4693 - accuracy: 0.8347\n",
      "119/119 [==============================] - 0s 244us/sample - loss: 0.4602 - accuracy: 0.7983\n",
      "121/121 [==============================] - 0s 251us/sample - loss: 0.4760 - accuracy: 0.7851\n",
      "118/118 [==============================] - 0s 239us/sample - loss: 0.5102 - accuracy: 0.7966\n",
      "117/117 [==============================] - 0s 248us/sample - loss: 0.4857 - accuracy: 0.8034\n",
      "117/117 [==============================] - 0s 249us/sample - loss: 0.4975 - accuracy: 0.8120\n",
      "114/114 [==============================] - 0s 255us/sample - loss: 0.4531 - accuracy: 0.8421\n",
      "113/113 [==============================] - 0s 251us/sample - loss: 0.4698 - accuracy: 0.8142\n",
      "113/113 [==============================] - 0s 279us/sample - loss: 0.4700 - accuracy: 0.8142\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 0.4884 - accuracy: 0.7768\n",
      "112/112 [==============================] - 0s 288us/sample - loss: 0.4661 - accuracy: 0.8393\n",
      "110/110 [==============================] - 0s 261us/sample - loss: 0.4475 - accuracy: 0.8364\n",
      "110/110 [==============================] - 0s 254us/sample - loss: 0.4905 - accuracy: 0.7818\n",
      "109/109 [==============================] - 0s 264us/sample - loss: 0.5309 - accuracy: 0.7890\n",
      "110/110 [==============================] - 0s 250us/sample - loss: 0.4758 - accuracy: 0.7909\n",
      "109/109 [==============================] - 0s 296us/sample - loss: 0.4593 - accuracy: 0.8073\n",
      "107/107 [==============================] - 0s 264us/sample - loss: 0.4950 - accuracy: 0.7850\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2823 samples, validate on 723 samples\n",
      "Epoch 1/300\n",
      "2823/2823 [==============================] - 2s 874us/sample - loss: 0.6719 - accuracy: 0.5845 - val_loss: 0.6789 - val_accuracy: 0.5906\n",
      "Epoch 2/300\n",
      "2823/2823 [==============================] - 1s 226us/sample - loss: 0.6489 - accuracy: 0.6305 - val_loss: 0.6646 - val_accuracy: 0.6196\n",
      "Epoch 3/300\n",
      "2823/2823 [==============================] - 1s 246us/sample - loss: 0.6348 - accuracy: 0.6490 - val_loss: 0.6546 - val_accuracy: 0.6445\n",
      "Epoch 4/300\n",
      "2823/2823 [==============================] - 1s 251us/sample - loss: 0.6234 - accuracy: 0.6709 - val_loss: 0.6466 - val_accuracy: 0.6515\n",
      "Epoch 5/300\n",
      "2823/2823 [==============================] - 1s 253us/sample - loss: 0.6176 - accuracy: 0.6769 - val_loss: 0.6400 - val_accuracy: 0.6584\n",
      "Epoch 6/300\n",
      "2823/2823 [==============================] - 1s 226us/sample - loss: 0.6094 - accuracy: 0.6932 - val_loss: 0.6341 - val_accuracy: 0.6639\n",
      "Epoch 7/300\n",
      "2823/2823 [==============================] - 1s 234us/sample - loss: 0.6029 - accuracy: 0.6908 - val_loss: 0.6289 - val_accuracy: 0.6777\n",
      "Epoch 8/300\n",
      "2823/2823 [==============================] - 1s 249us/sample - loss: 0.5985 - accuracy: 0.7028 - val_loss: 0.6243 - val_accuracy: 0.6916\n",
      "Epoch 9/300\n",
      "2823/2823 [==============================] - 1s 213us/sample - loss: 0.5921 - accuracy: 0.7134 - val_loss: 0.6201 - val_accuracy: 0.6999\n",
      "Epoch 10/300\n",
      "2823/2823 [==============================] - 1s 213us/sample - loss: 0.5887 - accuracy: 0.7156 - val_loss: 0.6162 - val_accuracy: 0.7095\n",
      "Epoch 11/300\n",
      "2823/2823 [==============================] - 1s 202us/sample - loss: 0.5837 - accuracy: 0.7184 - val_loss: 0.6124 - val_accuracy: 0.7192\n",
      "Epoch 12/300\n",
      "2823/2823 [==============================] - 1s 207us/sample - loss: 0.5769 - accuracy: 0.7322 - val_loss: 0.6090 - val_accuracy: 0.7248\n",
      "Epoch 13/300\n",
      "2823/2823 [==============================] - 1s 212us/sample - loss: 0.5713 - accuracy: 0.7287 - val_loss: 0.6057 - val_accuracy: 0.7220\n",
      "Epoch 14/300\n",
      "2823/2823 [==============================] - 1s 233us/sample - loss: 0.5684 - accuracy: 0.7322 - val_loss: 0.6027 - val_accuracy: 0.7248\n",
      "Epoch 15/300\n",
      "2823/2823 [==============================] - 1s 266us/sample - loss: 0.5611 - accuracy: 0.7425 - val_loss: 0.6000 - val_accuracy: 0.7289\n",
      "Epoch 16/300\n",
      "2823/2823 [==============================] - 1s 250us/sample - loss: 0.5611 - accuracy: 0.7379 - val_loss: 0.5973 - val_accuracy: 0.7289\n",
      "Epoch 17/300\n",
      "2823/2823 [==============================] - 1s 245us/sample - loss: 0.5562 - accuracy: 0.7488 - val_loss: 0.5948 - val_accuracy: 0.7331\n",
      "Epoch 18/300\n",
      "2823/2823 [==============================] - 1s 265us/sample - loss: 0.5506 - accuracy: 0.7488 - val_loss: 0.5924 - val_accuracy: 0.7386\n",
      "Epoch 19/300\n",
      "2823/2823 [==============================] - 1s 259us/sample - loss: 0.5466 - accuracy: 0.7577 - val_loss: 0.5901 - val_accuracy: 0.7427\n",
      "Epoch 20/300\n",
      "2823/2823 [==============================] - 1s 253us/sample - loss: 0.5446 - accuracy: 0.7598 - val_loss: 0.5880 - val_accuracy: 0.7441\n",
      "Epoch 21/300\n",
      "2823/2823 [==============================] - 1s 245us/sample - loss: 0.5399 - accuracy: 0.7676 - val_loss: 0.5859 - val_accuracy: 0.7469\n",
      "Epoch 22/300\n",
      "2823/2823 [==============================] - 1s 220us/sample - loss: 0.5397 - accuracy: 0.7616 - val_loss: 0.5838 - val_accuracy: 0.7497\n",
      "Epoch 23/300\n",
      "2823/2823 [==============================] - 1s 210us/sample - loss: 0.5371 - accuracy: 0.7602 - val_loss: 0.5820 - val_accuracy: 0.7538\n",
      "Epoch 24/300\n",
      "2823/2823 [==============================] - 1s 211us/sample - loss: 0.5334 - accuracy: 0.7659 - val_loss: 0.5803 - val_accuracy: 0.7538\n",
      "Epoch 25/300\n",
      "2823/2823 [==============================] - 1s 230us/sample - loss: 0.5306 - accuracy: 0.7644 - val_loss: 0.5787 - val_accuracy: 0.7538\n",
      "Epoch 26/300\n",
      "2823/2823 [==============================] - 1s 213us/sample - loss: 0.5262 - accuracy: 0.7775 - val_loss: 0.5771 - val_accuracy: 0.7538\n",
      "Epoch 27/300\n",
      "2823/2823 [==============================] - 1s 227us/sample - loss: 0.5252 - accuracy: 0.7726 - val_loss: 0.5756 - val_accuracy: 0.7552\n",
      "Epoch 28/300\n",
      "2823/2823 [==============================] - 1s 179us/sample - loss: 0.5217 - accuracy: 0.7722 - val_loss: 0.5742 - val_accuracy: 0.7566\n",
      "Epoch 29/300\n",
      "2823/2823 [==============================] - 1s 202us/sample - loss: 0.5200 - accuracy: 0.7740 - val_loss: 0.5729 - val_accuracy: 0.7566\n",
      "Epoch 30/300\n",
      "2823/2823 [==============================] - 1s 222us/sample - loss: 0.5158 - accuracy: 0.7804 - val_loss: 0.5716 - val_accuracy: 0.7580\n",
      "Epoch 31/300\n",
      "2823/2823 [==============================] - 1s 231us/sample - loss: 0.5136 - accuracy: 0.7790 - val_loss: 0.5704 - val_accuracy: 0.7607\n",
      "Epoch 32/300\n",
      "2823/2823 [==============================] - 1s 247us/sample - loss: 0.5122 - accuracy: 0.7747 - val_loss: 0.5692 - val_accuracy: 0.7621\n",
      "Epoch 33/300\n",
      "2823/2823 [==============================] - 1s 235us/sample - loss: 0.5091 - accuracy: 0.7811 - val_loss: 0.5681 - val_accuracy: 0.7607\n",
      "Epoch 34/300\n",
      "2823/2823 [==============================] - 1s 249us/sample - loss: 0.5069 - accuracy: 0.7797 - val_loss: 0.5672 - val_accuracy: 0.7607\n",
      "Epoch 35/300\n",
      "2823/2823 [==============================] - 1s 261us/sample - loss: 0.5050 - accuracy: 0.7829 - val_loss: 0.5662 - val_accuracy: 0.7621\n",
      "Epoch 36/300\n",
      "2823/2823 [==============================] - 1s 276us/sample - loss: 0.5024 - accuracy: 0.7832 - val_loss: 0.5653 - val_accuracy: 0.7621\n",
      "Epoch 37/300\n",
      "2823/2823 [==============================] - 1s 254us/sample - loss: 0.4973 - accuracy: 0.7821 - val_loss: 0.5644 - val_accuracy: 0.7635\n",
      "Epoch 38/300\n",
      "2823/2823 [==============================] - 1s 250us/sample - loss: 0.4994 - accuracy: 0.7821 - val_loss: 0.5635 - val_accuracy: 0.7635\n",
      "Epoch 39/300\n",
      "2823/2823 [==============================] - 1s 251us/sample - loss: 0.4947 - accuracy: 0.7871 - val_loss: 0.5628 - val_accuracy: 0.7621\n",
      "Epoch 40/300\n",
      "2823/2823 [==============================] - 1s 220us/sample - loss: 0.4901 - accuracy: 0.7931 - val_loss: 0.5620 - val_accuracy: 0.7635\n",
      "Epoch 41/300\n",
      "2823/2823 [==============================] - 1s 218us/sample - loss: 0.4907 - accuracy: 0.7868 - val_loss: 0.5613 - val_accuracy: 0.7621\n",
      "Epoch 42/300\n",
      "2823/2823 [==============================] - 1s 226us/sample - loss: 0.4855 - accuracy: 0.7899 - val_loss: 0.5607 - val_accuracy: 0.7621\n",
      "Epoch 43/300\n",
      "2823/2823 [==============================] - 1s 228us/sample - loss: 0.4829 - accuracy: 0.7899 - val_loss: 0.5601 - val_accuracy: 0.7621\n",
      "Epoch 44/300\n",
      "2823/2823 [==============================] - 1s 244us/sample - loss: 0.4820 - accuracy: 0.7914 - val_loss: 0.5595 - val_accuracy: 0.7621\n",
      "Epoch 45/300\n",
      "2823/2823 [==============================] - 1s 253us/sample - loss: 0.4777 - accuracy: 0.7963 - val_loss: 0.5591 - val_accuracy: 0.7649\n",
      "Epoch 46/300\n",
      "2823/2823 [==============================] - 1s 221us/sample - loss: 0.4765 - accuracy: 0.7949 - val_loss: 0.5586 - val_accuracy: 0.7635\n",
      "Epoch 47/300\n",
      "2823/2823 [==============================] - 1s 240us/sample - loss: 0.4757 - accuracy: 0.7953 - val_loss: 0.5583 - val_accuracy: 0.7635\n",
      "Epoch 48/300\n",
      "2823/2823 [==============================] - 1s 243us/sample - loss: 0.4713 - accuracy: 0.7995 - val_loss: 0.5578 - val_accuracy: 0.7635\n",
      "Epoch 49/300\n",
      "2823/2823 [==============================] - 1s 227us/sample - loss: 0.4722 - accuracy: 0.8006 - val_loss: 0.5575 - val_accuracy: 0.7635\n",
      "Epoch 50/300\n",
      "2823/2823 [==============================] - 1s 240us/sample - loss: 0.4687 - accuracy: 0.7974 - val_loss: 0.5572 - val_accuracy: 0.7635\n",
      "Epoch 51/300\n",
      "2823/2823 [==============================] - 1s 252us/sample - loss: 0.4654 - accuracy: 0.8030 - val_loss: 0.5569 - val_accuracy: 0.7635\n",
      "Epoch 52/300\n",
      "2823/2823 [==============================] - 1s 260us/sample - loss: 0.4660 - accuracy: 0.8009 - val_loss: 0.5567 - val_accuracy: 0.7635\n",
      "Epoch 53/300\n",
      "2823/2823 [==============================] - 1s 270us/sample - loss: 0.4647 - accuracy: 0.8080 - val_loss: 0.5565 - val_accuracy: 0.7635\n",
      "Epoch 54/300\n",
      "2823/2823 [==============================] - 1s 267us/sample - loss: 0.4594 - accuracy: 0.8055 - val_loss: 0.5565 - val_accuracy: 0.7635\n",
      "Epoch 55/300\n",
      "2823/2823 [==============================] - 1s 259us/sample - loss: 0.4580 - accuracy: 0.8059 - val_loss: 0.5563 - val_accuracy: 0.7635\n",
      "Epoch 56/300\n",
      "2823/2823 [==============================] - 1s 257us/sample - loss: 0.4557 - accuracy: 0.8084 - val_loss: 0.5562 - val_accuracy: 0.7635\n",
      "Epoch 57/300\n",
      "2823/2823 [==============================] - 1s 253us/sample - loss: 0.4512 - accuracy: 0.8133 - val_loss: 0.5562 - val_accuracy: 0.7635\n",
      "Epoch 58/300\n",
      "2823/2823 [==============================] - 1s 234us/sample - loss: 0.4510 - accuracy: 0.8030 - val_loss: 0.5561 - val_accuracy: 0.7635\n",
      "Epoch 59/300\n",
      "2823/2823 [==============================] - 1s 260us/sample - loss: 0.4508 - accuracy: 0.8094 - val_loss: 0.5561 - val_accuracy: 0.7635\n",
      "Epoch 60/300\n",
      "2823/2823 [==============================] - 1s 233us/sample - loss: 0.4493 - accuracy: 0.8119 - val_loss: 0.5561 - val_accuracy: 0.7635\n",
      "Epoch 61/300\n",
      "2823/2823 [==============================] - 1s 240us/sample - loss: 0.4431 - accuracy: 0.8112 - val_loss: 0.5562 - val_accuracy: 0.7635\n",
      "Epoch 62/300\n",
      "2823/2823 [==============================] - 1s 250us/sample - loss: 0.4428 - accuracy: 0.8137 - val_loss: 0.5562 - val_accuracy: 0.7635\n",
      "Epoch 63/300\n",
      "2823/2823 [==============================] - 1s 231us/sample - loss: 0.4439 - accuracy: 0.8140 - val_loss: 0.5563 - val_accuracy: 0.7635\n",
      "Epoch 00063: early stopping\n",
      "103/103 [==============================] - 0s 177us/sample - loss: 0.2425 - accuracy: 0.9709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [1:27:43, 1047.78s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.46s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.21s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 837.78125 steps, validate for 215.2734375 steps\n",
      "Epoch 1/300\n",
      "838/837 [==============================] - 25s 30ms/step - loss: 0.5879 - accuracy: 0.7065 - val_loss: 0.5433 - val_accuracy: 0.7678\n",
      "Epoch 2/300\n",
      "838/837 [==============================] - 24s 28ms/step - loss: 0.5143 - accuracy: 0.7753 - val_loss: 0.5389 - val_accuracy: 0.7684\n",
      "Epoch 3/300\n",
      "838/837 [==============================] - 24s 29ms/step - loss: 0.4986 - accuracy: 0.7802 - val_loss: 0.5354 - val_accuracy: 0.7692\n",
      "Epoch 4/300\n",
      "838/837 [==============================] - 24s 29ms/step - loss: 0.4870 - accuracy: 0.7849 - val_loss: 0.5338 - val_accuracy: 0.7683\n",
      "Epoch 5/300\n",
      "838/837 [==============================] - 24s 29ms/step - loss: 0.4772 - accuracy: 0.7893 - val_loss: 0.5353 - val_accuracy: 0.7669\n",
      "Epoch 6/300\n",
      "838/837 [==============================] - 24s 29ms/step - loss: 0.4681 - accuracy: 0.7933 - val_loss: 0.5372 - val_accuracy: 0.7656\n",
      "Epoch 7/300\n",
      "838/837 [==============================] - 24s 29ms/step - loss: 0.4600 - accuracy: 0.7977 - val_loss: 0.5451 - val_accuracy: 0.7626\n",
      "Epoch 00007: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 837.78125 steps, validate for 215.2734375 steps\n",
      "Epoch 1/300\n",
      "838/837 [==============================] - 55s 66ms/step - loss: 0.4444 - accuracy: 0.8055 - val_loss: 0.5615 - val_accuracy: 0.7377\n",
      "Epoch 2/300\n",
      "838/837 [==============================] - 54s 64ms/step - loss: 0.4192 - accuracy: 0.8183 - val_loss: 0.5476 - val_accuracy: 0.7576\n",
      "Epoch 3/300\n",
      "838/837 [==============================] - 54s 65ms/step - loss: 0.3973 - accuracy: 0.8288 - val_loss: 0.5651 - val_accuracy: 0.7665\n",
      "Epoch 4/300\n",
      "838/837 [==============================] - 54s 64ms/step - loss: 0.3776 - accuracy: 0.8397 - val_loss: 0.5725 - val_accuracy: 0.7603\n",
      "Epoch 5/300\n",
      "838/837 [==============================] - 54s 65ms/step - loss: 0.3589 - accuracy: 0.8503 - val_loss: 0.5690 - val_accuracy: 0.7550\n",
      "Epoch 00005: early stopping\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.2764 - accuracy: 0.9286\n",
      "103/103 [==============================] - 0s 290us/sample - loss: 0.2989 - accuracy: 0.9223\n",
      "98/98 [==============================] - 0s 273us/sample - loss: 0.2813 - accuracy: 0.9184\n",
      "97/97 [==============================] - 0s 293us/sample - loss: 0.3004 - accuracy: 0.9381\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.3014 - accuracy: 0.9167\n",
      "96/96 [==============================] - 0s 197us/sample - loss: 0.3350 - accuracy: 0.8958\n",
      "96/96 [==============================] - 0s 235us/sample - loss: 0.3188 - accuracy: 0.9167\n",
      "92/92 [==============================] - 0s 225us/sample - loss: 0.3126 - accuracy: 0.9239\n",
      "91/91 [==============================] - 0s 242us/sample - loss: 0.3190 - accuracy: 0.9341\n",
      "92/92 [==============================] - 0s 269us/sample - loss: 0.3088 - accuracy: 0.8913\n",
      "91/91 [==============================] - 0s 251us/sample - loss: 0.2954 - accuracy: 0.9231\n",
      "90/90 [==============================] - 0s 230us/sample - loss: 0.3137 - accuracy: 0.9000\n",
      "90/90 [==============================] - 0s 263us/sample - loss: 0.3332 - accuracy: 0.8222\n",
      "89/89 [==============================] - 0s 261us/sample - loss: 0.3263 - accuracy: 0.8876\n",
      "89/89 [==============================] - 0s 245us/sample - loss: 0.3271 - accuracy: 0.8876\n",
      "88/88 [==============================] - 0s 262us/sample - loss: 0.3002 - accuracy: 0.9205\n",
      "88/88 [==============================] - 0s 259us/sample - loss: 0.3145 - accuracy: 0.9432\n",
      "88/88 [==============================] - 0s 271us/sample - loss: 0.3161 - accuracy: 0.9091\n",
      "89/89 [==============================] - 0s 260us/sample - loss: 0.2883 - accuracy: 0.9438\n",
      "87/87 [==============================] - 0s 273us/sample - loss: 0.3184 - accuracy: 0.9195\n",
      "88/88 [==============================] - 0s 288us/sample - loss: 0.3300 - accuracy: 0.8864\n",
      "88/88 [==============================] - 0s 363us/sample - loss: 0.3371 - accuracy: 0.9091\n",
      "86/86 [==============================] - 0s 295us/sample - loss: 0.3444 - accuracy: 0.9186\n",
      "86/86 [==============================] - 0s 284us/sample - loss: 0.3554 - accuracy: 0.8605\n",
      "87/87 [==============================] - 0s 264us/sample - loss: 0.2777 - accuracy: 0.9885\n",
      "87/87 [==============================] - 0s 276us/sample - loss: 0.3051 - accuracy: 0.8966\n",
      "86/86 [==============================] - 0s 251us/sample - loss: 0.3415 - accuracy: 0.9070\n",
      "87/87 [==============================] - 0s 269us/sample - loss: 0.2838 - accuracy: 0.9310\n",
      "85/85 [==============================] - 0s 278us/sample - loss: 0.3423 - accuracy: 0.9059\n",
      "87/87 [==============================] - 0s 268us/sample - loss: 0.3631 - accuracy: 0.8621\n",
      "86/86 [==============================] - 0s 286us/sample - loss: 0.3207 - accuracy: 0.8953\n",
      "86/86 [==============================] - 0s 270us/sample - loss: 0.3196 - accuracy: 0.9186\n",
      "86/86 [==============================] - 0s 279us/sample - loss: 0.3396 - accuracy: 0.8953\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2839 samples, validate on 728 samples\n",
      "Epoch 1/300\n",
      "2839/2839 [==============================] - 3s 905us/sample - loss: 0.7499 - accuracy: 0.4480 - val_loss: 0.6990 - val_accuracy: 0.5316\n",
      "Epoch 2/300\n",
      "2839/2839 [==============================] - 1s 266us/sample - loss: 0.7114 - accuracy: 0.5291 - val_loss: 0.6769 - val_accuracy: 0.5604\n",
      "Epoch 3/300\n",
      "2839/2839 [==============================] - 1s 254us/sample - loss: 0.6880 - accuracy: 0.5502 - val_loss: 0.6612 - val_accuracy: 0.5893\n",
      "Epoch 4/300\n",
      "2839/2839 [==============================] - 1s 237us/sample - loss: 0.6689 - accuracy: 0.6020 - val_loss: 0.6489 - val_accuracy: 0.6223\n",
      "Epoch 5/300\n",
      "2839/2839 [==============================] - 1s 196us/sample - loss: 0.6543 - accuracy: 0.6256 - val_loss: 0.6385 - val_accuracy: 0.6497\n",
      "Epoch 6/300\n",
      "2839/2839 [==============================] - 1s 178us/sample - loss: 0.6393 - accuracy: 0.6344 - val_loss: 0.6296 - val_accuracy: 0.6676\n",
      "Epoch 7/300\n",
      "2839/2839 [==============================] - 1s 196us/sample - loss: 0.6292 - accuracy: 0.6643 - val_loss: 0.6220 - val_accuracy: 0.6937\n",
      "Epoch 8/300\n",
      "2839/2839 [==============================] - 1s 228us/sample - loss: 0.6158 - accuracy: 0.6819 - val_loss: 0.6150 - val_accuracy: 0.7074\n",
      "Epoch 9/300\n",
      "2839/2839 [==============================] - 1s 203us/sample - loss: 0.6070 - accuracy: 0.6950 - val_loss: 0.6087 - val_accuracy: 0.7280\n",
      "Epoch 10/300\n",
      "2839/2839 [==============================] - 1s 238us/sample - loss: 0.6011 - accuracy: 0.7069 - val_loss: 0.6031 - val_accuracy: 0.7349\n",
      "Epoch 11/300\n",
      "2839/2839 [==============================] - 1s 271us/sample - loss: 0.5936 - accuracy: 0.7200 - val_loss: 0.5978 - val_accuracy: 0.7500\n",
      "Epoch 12/300\n",
      "2839/2839 [==============================] - 1s 254us/sample - loss: 0.5857 - accuracy: 0.7238 - val_loss: 0.5929 - val_accuracy: 0.7527\n",
      "Epoch 13/300\n",
      "2839/2839 [==============================] - 1s 252us/sample - loss: 0.5783 - accuracy: 0.7344 - val_loss: 0.5883 - val_accuracy: 0.7527\n",
      "Epoch 14/300\n",
      "2839/2839 [==============================] - 1s 241us/sample - loss: 0.5680 - accuracy: 0.7471 - val_loss: 0.5840 - val_accuracy: 0.7569\n",
      "Epoch 15/300\n",
      "2839/2839 [==============================] - 1s 269us/sample - loss: 0.5622 - accuracy: 0.7577 - val_loss: 0.5800 - val_accuracy: 0.7596\n",
      "Epoch 16/300\n",
      "2839/2839 [==============================] - 1s 216us/sample - loss: 0.5564 - accuracy: 0.7594 - val_loss: 0.5763 - val_accuracy: 0.7637\n",
      "Epoch 17/300\n",
      "2839/2839 [==============================] - 1s 210us/sample - loss: 0.5501 - accuracy: 0.7615 - val_loss: 0.5726 - val_accuracy: 0.7665\n",
      "Epoch 18/300\n",
      "2839/2839 [==============================] - 1s 211us/sample - loss: 0.5458 - accuracy: 0.7608 - val_loss: 0.5693 - val_accuracy: 0.7734\n",
      "Epoch 19/300\n",
      "2839/2839 [==============================] - 1s 230us/sample - loss: 0.5379 - accuracy: 0.7753 - val_loss: 0.5661 - val_accuracy: 0.7734\n",
      "Epoch 20/300\n",
      "2839/2839 [==============================] - 1s 217us/sample - loss: 0.5367 - accuracy: 0.7700 - val_loss: 0.5632 - val_accuracy: 0.7747\n",
      "Epoch 21/300\n",
      "2839/2839 [==============================] - 1s 210us/sample - loss: 0.5280 - accuracy: 0.7820 - val_loss: 0.5604 - val_accuracy: 0.7734\n",
      "Epoch 22/300\n",
      "2839/2839 [==============================] - 1s 213us/sample - loss: 0.5253 - accuracy: 0.7784 - val_loss: 0.5577 - val_accuracy: 0.7802\n",
      "Epoch 23/300\n",
      "2839/2839 [==============================] - 1s 259us/sample - loss: 0.5208 - accuracy: 0.7788 - val_loss: 0.5552 - val_accuracy: 0.7775\n",
      "Epoch 24/300\n",
      "2839/2839 [==============================] - 1s 257us/sample - loss: 0.5157 - accuracy: 0.7841 - val_loss: 0.5529 - val_accuracy: 0.7775\n",
      "Epoch 25/300\n",
      "2839/2839 [==============================] - 1s 255us/sample - loss: 0.5089 - accuracy: 0.7880 - val_loss: 0.5506 - val_accuracy: 0.7775\n",
      "Epoch 26/300\n",
      "2839/2839 [==============================] - 1s 246us/sample - loss: 0.5049 - accuracy: 0.7929 - val_loss: 0.5485 - val_accuracy: 0.7775\n",
      "Epoch 27/300\n",
      "2839/2839 [==============================] - 1s 262us/sample - loss: 0.5026 - accuracy: 0.7932 - val_loss: 0.5465 - val_accuracy: 0.7788\n",
      "Epoch 28/300\n",
      "2839/2839 [==============================] - 1s 243us/sample - loss: 0.4945 - accuracy: 0.7957 - val_loss: 0.5446 - val_accuracy: 0.7788\n",
      "Epoch 29/300\n",
      "2839/2839 [==============================] - 1s 245us/sample - loss: 0.4942 - accuracy: 0.7918 - val_loss: 0.5428 - val_accuracy: 0.7788\n",
      "Epoch 30/300\n",
      "2839/2839 [==============================] - 1s 258us/sample - loss: 0.4872 - accuracy: 0.7922 - val_loss: 0.5411 - val_accuracy: 0.7788\n",
      "Epoch 31/300\n",
      "2839/2839 [==============================] - 1s 189us/sample - loss: 0.4820 - accuracy: 0.7996 - val_loss: 0.5395 - val_accuracy: 0.7788\n",
      "Epoch 32/300\n",
      "2839/2839 [==============================] - 1s 234us/sample - loss: 0.4794 - accuracy: 0.8045 - val_loss: 0.5380 - val_accuracy: 0.7802\n",
      "Epoch 33/300\n",
      "2839/2839 [==============================] - 1s 242us/sample - loss: 0.4798 - accuracy: 0.8035 - val_loss: 0.5366 - val_accuracy: 0.7802\n",
      "Epoch 34/300\n",
      "2839/2839 [==============================] - 1s 240us/sample - loss: 0.4729 - accuracy: 0.8010 - val_loss: 0.5353 - val_accuracy: 0.7802\n",
      "Epoch 35/300\n",
      "2839/2839 [==============================] - 1s 223us/sample - loss: 0.4693 - accuracy: 0.8006 - val_loss: 0.5340 - val_accuracy: 0.7788\n",
      "Epoch 36/300\n",
      "2839/2839 [==============================] - 1s 213us/sample - loss: 0.4662 - accuracy: 0.8091 - val_loss: 0.5328 - val_accuracy: 0.7761\n",
      "Epoch 37/300\n",
      "2839/2839 [==============================] - 1s 201us/sample - loss: 0.4614 - accuracy: 0.8087 - val_loss: 0.5317 - val_accuracy: 0.7775\n",
      "Epoch 38/300\n",
      "2839/2839 [==============================] - 1s 237us/sample - loss: 0.4612 - accuracy: 0.8101 - val_loss: 0.5307 - val_accuracy: 0.7775\n",
      "Epoch 39/300\n",
      "2839/2839 [==============================] - 1s 222us/sample - loss: 0.4570 - accuracy: 0.8144 - val_loss: 0.5297 - val_accuracy: 0.7747\n",
      "Epoch 40/300\n",
      "2839/2839 [==============================] - 1s 250us/sample - loss: 0.4541 - accuracy: 0.8087 - val_loss: 0.5288 - val_accuracy: 0.7761\n",
      "Epoch 41/300\n",
      "2839/2839 [==============================] - 1s 267us/sample - loss: 0.4483 - accuracy: 0.8172 - val_loss: 0.5279 - val_accuracy: 0.7761\n",
      "Epoch 42/300\n",
      "2839/2839 [==============================] - 1s 249us/sample - loss: 0.4491 - accuracy: 0.8119 - val_loss: 0.5270 - val_accuracy: 0.7775\n",
      "Epoch 43/300\n",
      "2839/2839 [==============================] - 1s 204us/sample - loss: 0.4429 - accuracy: 0.8165 - val_loss: 0.5263 - val_accuracy: 0.7761\n",
      "Epoch 44/300\n",
      "2839/2839 [==============================] - 1s 228us/sample - loss: 0.4435 - accuracy: 0.8158 - val_loss: 0.5256 - val_accuracy: 0.7788\n",
      "Epoch 45/300\n",
      "2839/2839 [==============================] - 1s 253us/sample - loss: 0.4384 - accuracy: 0.8165 - val_loss: 0.5250 - val_accuracy: 0.7788\n",
      "Epoch 46/300\n",
      "2839/2839 [==============================] - 1s 211us/sample - loss: 0.4357 - accuracy: 0.8123 - val_loss: 0.5244 - val_accuracy: 0.7775\n",
      "Epoch 47/300\n",
      "2839/2839 [==============================] - 1s 249us/sample - loss: 0.4311 - accuracy: 0.8200 - val_loss: 0.5239 - val_accuracy: 0.7775\n",
      "Epoch 48/300\n",
      "2839/2839 [==============================] - 1s 256us/sample - loss: 0.4265 - accuracy: 0.8232 - val_loss: 0.5235 - val_accuracy: 0.7775\n",
      "Epoch 49/300\n",
      "2839/2839 [==============================] - 1s 251us/sample - loss: 0.4242 - accuracy: 0.8232 - val_loss: 0.5230 - val_accuracy: 0.7761\n",
      "Epoch 50/300\n",
      "2839/2839 [==============================] - 1s 233us/sample - loss: 0.4182 - accuracy: 0.8299 - val_loss: 0.5226 - val_accuracy: 0.7761\n",
      "Epoch 51/300\n",
      "2839/2839 [==============================] - 1s 235us/sample - loss: 0.4182 - accuracy: 0.8288 - val_loss: 0.5223 - val_accuracy: 0.7761\n",
      "Epoch 52/300\n",
      "2839/2839 [==============================] - 1s 215us/sample - loss: 0.4130 - accuracy: 0.8281 - val_loss: 0.5220 - val_accuracy: 0.7761\n",
      "Epoch 53/300\n",
      "2839/2839 [==============================] - 1s 246us/sample - loss: 0.4105 - accuracy: 0.8256 - val_loss: 0.5218 - val_accuracy: 0.7734\n",
      "Epoch 54/300\n",
      "2839/2839 [==============================] - 1s 229us/sample - loss: 0.4120 - accuracy: 0.8288 - val_loss: 0.5216 - val_accuracy: 0.7706\n",
      "Epoch 55/300\n",
      "2839/2839 [==============================] - 1s 214us/sample - loss: 0.4079 - accuracy: 0.8306 - val_loss: 0.5214 - val_accuracy: 0.7720\n",
      "Epoch 56/300\n",
      "2839/2839 [==============================] - 1s 232us/sample - loss: 0.4024 - accuracy: 0.8306 - val_loss: 0.5213 - val_accuracy: 0.7720\n",
      "Epoch 57/300\n",
      "2839/2839 [==============================] - 1s 250us/sample - loss: 0.4021 - accuracy: 0.8341 - val_loss: 0.5212 - val_accuracy: 0.7706\n",
      "Epoch 58/300\n",
      "2839/2839 [==============================] - 1s 245us/sample - loss: 0.3969 - accuracy: 0.8337 - val_loss: 0.5212 - val_accuracy: 0.7720\n",
      "Epoch 59/300\n",
      "2839/2839 [==============================] - 1s 224us/sample - loss: 0.3952 - accuracy: 0.8397 - val_loss: 0.5212 - val_accuracy: 0.7706\n",
      "Epoch 60/300\n",
      "2839/2839 [==============================] - 1s 237us/sample - loss: 0.3927 - accuracy: 0.8401 - val_loss: 0.5212 - val_accuracy: 0.7706\n",
      "Epoch 61/300\n",
      "2839/2839 [==============================] - 1s 215us/sample - loss: 0.3913 - accuracy: 0.8369 - val_loss: 0.5213 - val_accuracy: 0.7692\n",
      "Epoch 62/300\n",
      "2839/2839 [==============================] - 1s 242us/sample - loss: 0.3874 - accuracy: 0.8401 - val_loss: 0.5214 - val_accuracy: 0.7706\n",
      "Epoch 00062: early stopping\n",
      "82/82 [==============================] - 0s 198us/sample - loss: 0.3376 - accuracy: 0.9268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [1:46:29, 1071.38s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.43s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.29s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 827.34375 steps, validate for 211.3671875 steps\n",
      "Epoch 1/300\n",
      "828/827 [==============================] - 25s 30ms/step - loss: 0.5767 - accuracy: 0.7256 - val_loss: 0.5443 - val_accuracy: 0.7668\n",
      "Epoch 2/300\n",
      "828/827 [==============================] - 23s 28ms/step - loss: 0.5180 - accuracy: 0.7726 - val_loss: 0.5363 - val_accuracy: 0.7661\n",
      "Epoch 3/300\n",
      "828/827 [==============================] - 24s 29ms/step - loss: 0.5040 - accuracy: 0.7768 - val_loss: 0.5355 - val_accuracy: 0.7652\n",
      "Epoch 4/300\n",
      "828/827 [==============================] - 24s 29ms/step - loss: 0.4930 - accuracy: 0.7809 - val_loss: 0.5377 - val_accuracy: 0.7633\n",
      "Epoch 5/300\n",
      "828/827 [==============================] - 24s 29ms/step - loss: 0.4832 - accuracy: 0.7850 - val_loss: 0.5435 - val_accuracy: 0.7578\n",
      "Epoch 6/300\n",
      "828/827 [==============================] - 24s 29ms/step - loss: 0.4745 - accuracy: 0.7891 - val_loss: 0.5437 - val_accuracy: 0.7597\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 827.34375 steps, validate for 211.3671875 steps\n",
      "Epoch 1/300\n",
      "828/827 [==============================] - 55s 66ms/step - loss: 0.4581 - accuracy: 0.7969 - val_loss: 0.5580 - val_accuracy: 0.7543\n",
      "Epoch 2/300\n",
      "828/827 [==============================] - 53s 65ms/step - loss: 0.4322 - accuracy: 0.8102 - val_loss: 0.5591 - val_accuracy: 0.7597\n",
      "Epoch 3/300\n",
      "828/827 [==============================] - 53s 64ms/step - loss: 0.4101 - accuracy: 0.8222 - val_loss: 0.5619 - val_accuracy: 0.7555\n",
      "Epoch 4/300\n",
      "828/827 [==============================] - 53s 65ms/step - loss: 0.3898 - accuracy: 0.8331 - val_loss: 0.6775 - val_accuracy: 0.6395\n",
      "Epoch 00004: early stopping\n",
      "162/162 [==============================] - 0s 2ms/sample - loss: 0.6040 - accuracy: 0.6975\n",
      "160/160 [==============================] - 0s 1ms/sample - loss: 0.5526 - accuracy: 0.7125\n",
      "158/158 [==============================] - 0s 205us/sample - loss: 0.6235 - accuracy: 0.6646\n",
      "155/155 [==============================] - 0s 208us/sample - loss: 0.6348 - accuracy: 0.6581\n",
      "153/153 [==============================] - 0s 264us/sample - loss: 0.6471 - accuracy: 0.6340\n",
      "153/153 [==============================] - 0s 238us/sample - loss: 0.6128 - accuracy: 0.6732\n",
      "150/150 [==============================] - 0s 210us/sample - loss: 0.6476 - accuracy: 0.6467\n",
      "150/150 [==============================] - 0s 217us/sample - loss: 0.6851 - accuracy: 0.6267\n",
      "152/152 [==============================] - 0s 252us/sample - loss: 0.7215 - accuracy: 0.6053\n",
      "150/150 [==============================] - 0s 235us/sample - loss: 0.7135 - accuracy: 0.6467\n",
      "150/150 [==============================] - 0s 236us/sample - loss: 0.6866 - accuracy: 0.6533\n",
      "147/147 [==============================] - 0s 239us/sample - loss: 0.6552 - accuracy: 0.5986\n",
      "148/148 [==============================] - 0s 258us/sample - loss: 0.6943 - accuracy: 0.6149\n",
      "146/146 [==============================] - 0s 244us/sample - loss: 0.7423 - accuracy: 0.6301\n",
      "145/145 [==============================] - 0s 239us/sample - loss: 0.7478 - accuracy: 0.5793\n",
      "146/146 [==============================] - 0s 238us/sample - loss: 0.6594 - accuracy: 0.6233\n",
      "145/145 [==============================] - 0s 232us/sample - loss: 0.7157 - accuracy: 0.5655\n",
      "143/143 [==============================] - 0s 229us/sample - loss: 0.7927 - accuracy: 0.5175\n",
      "141/141 [==============================] - 0s 237us/sample - loss: 0.7128 - accuracy: 0.5603\n",
      "141/141 [==============================] - 0s 248us/sample - loss: 0.6966 - accuracy: 0.6312\n",
      "142/142 [==============================] - 0s 233us/sample - loss: 0.7109 - accuracy: 0.6268\n",
      "142/142 [==============================] - 0s 246us/sample - loss: 0.6208 - accuracy: 0.6901\n",
      "143/143 [==============================] - 0s 265us/sample - loss: 0.5999 - accuracy: 0.6923\n",
      "140/140 [==============================] - 0s 256us/sample - loss: 0.7144 - accuracy: 0.6286\n",
      "143/143 [==============================] - 0s 242us/sample - loss: 0.7455 - accuracy: 0.6364\n",
      "142/142 [==============================] - 0s 282us/sample - loss: 0.7509 - accuracy: 0.6197\n",
      "141/141 [==============================] - 0s 283us/sample - loss: 0.7406 - accuracy: 0.6099\n",
      "140/140 [==============================] - 0s 266us/sample - loss: 0.6752 - accuracy: 0.6786\n",
      "140/140 [==============================] - 0s 239us/sample - loss: 0.7267 - accuracy: 0.5857\n",
      "139/139 [==============================] - 0s 243us/sample - loss: 0.7861 - accuracy: 0.5971\n",
      "138/138 [==============================] - 0s 273us/sample - loss: 0.7504 - accuracy: 0.6087\n",
      "139/139 [==============================] - 0s 260us/sample - loss: 0.7103 - accuracy: 0.6619\n",
      "139/139 [==============================] - 0s 249us/sample - loss: 0.6987 - accuracy: 0.6403\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2805 samples, validate on 714 samples\n",
      "Epoch 1/300\n",
      "2805/2805 [==============================] - 2s 850us/sample - loss: 0.6983 - accuracy: 0.5437 - val_loss: 0.6909 - val_accuracy: 0.5532\n",
      "Epoch 2/300\n",
      "2805/2805 [==============================] - 1s 197us/sample - loss: 0.6714 - accuracy: 0.6007 - val_loss: 0.6741 - val_accuracy: 0.5924\n",
      "Epoch 3/300\n",
      "2805/2805 [==============================] - 1s 216us/sample - loss: 0.6551 - accuracy: 0.6250 - val_loss: 0.6625 - val_accuracy: 0.6317\n",
      "Epoch 4/300\n",
      "2805/2805 [==============================] - 1s 201us/sample - loss: 0.6433 - accuracy: 0.6485 - val_loss: 0.6533 - val_accuracy: 0.6485\n",
      "Epoch 5/300\n",
      "2805/2805 [==============================] - 1s 237us/sample - loss: 0.6348 - accuracy: 0.6674 - val_loss: 0.6458 - val_accuracy: 0.6611\n",
      "Epoch 6/300\n",
      "2805/2805 [==============================] - 1s 204us/sample - loss: 0.6274 - accuracy: 0.6774 - val_loss: 0.6393 - val_accuracy: 0.6737\n",
      "Epoch 7/300\n",
      "2805/2805 [==============================] - 1s 245us/sample - loss: 0.6189 - accuracy: 0.6916 - val_loss: 0.6336 - val_accuracy: 0.6849\n",
      "Epoch 8/300\n",
      "2805/2805 [==============================] - 1s 239us/sample - loss: 0.6090 - accuracy: 0.6948 - val_loss: 0.6283 - val_accuracy: 0.6961\n",
      "Epoch 9/300\n",
      "2805/2805 [==============================] - 1s 248us/sample - loss: 0.6075 - accuracy: 0.7055 - val_loss: 0.6238 - val_accuracy: 0.7059\n",
      "Epoch 10/300\n",
      "2805/2805 [==============================] - 1s 256us/sample - loss: 0.6025 - accuracy: 0.7084 - val_loss: 0.6196 - val_accuracy: 0.7143\n",
      "Epoch 11/300\n",
      "2805/2805 [==============================] - 1s 211us/sample - loss: 0.5950 - accuracy: 0.7176 - val_loss: 0.6156 - val_accuracy: 0.7241\n",
      "Epoch 12/300\n",
      "2805/2805 [==============================] - 1s 234us/sample - loss: 0.5909 - accuracy: 0.7316 - val_loss: 0.6120 - val_accuracy: 0.7241\n",
      "Epoch 13/300\n",
      "2805/2805 [==============================] - 1s 247us/sample - loss: 0.5860 - accuracy: 0.7430 - val_loss: 0.6088 - val_accuracy: 0.7269\n",
      "Epoch 14/300\n",
      "2805/2805 [==============================] - 1s 276us/sample - loss: 0.5871 - accuracy: 0.7348 - val_loss: 0.6056 - val_accuracy: 0.7297\n",
      "Epoch 15/300\n",
      "2805/2805 [==============================] - 1s 251us/sample - loss: 0.5801 - accuracy: 0.7326 - val_loss: 0.6028 - val_accuracy: 0.7311\n",
      "Epoch 16/300\n",
      "2805/2805 [==============================] - 1s 248us/sample - loss: 0.5792 - accuracy: 0.7401 - val_loss: 0.6000 - val_accuracy: 0.7353\n",
      "Epoch 17/300\n",
      "2805/2805 [==============================] - 1s 207us/sample - loss: 0.5753 - accuracy: 0.7398 - val_loss: 0.5973 - val_accuracy: 0.7381\n",
      "Epoch 18/300\n",
      "2805/2805 [==============================] - 1s 224us/sample - loss: 0.5705 - accuracy: 0.7487 - val_loss: 0.5948 - val_accuracy: 0.7437\n",
      "Epoch 19/300\n",
      "2805/2805 [==============================] - 1s 246us/sample - loss: 0.5675 - accuracy: 0.7476 - val_loss: 0.5925 - val_accuracy: 0.7423\n",
      "Epoch 20/300\n",
      "2805/2805 [==============================] - 1s 200us/sample - loss: 0.5628 - accuracy: 0.7508 - val_loss: 0.5903 - val_accuracy: 0.7465\n",
      "Epoch 21/300\n",
      "2805/2805 [==============================] - 1s 231us/sample - loss: 0.5600 - accuracy: 0.7540 - val_loss: 0.5882 - val_accuracy: 0.7465\n",
      "Epoch 22/300\n",
      "2805/2805 [==============================] - 1s 252us/sample - loss: 0.5564 - accuracy: 0.7512 - val_loss: 0.5862 - val_accuracy: 0.7507\n",
      "Epoch 23/300\n",
      "2805/2805 [==============================] - 1s 257us/sample - loss: 0.5557 - accuracy: 0.7508 - val_loss: 0.5842 - val_accuracy: 0.7521\n",
      "Epoch 24/300\n",
      "2805/2805 [==============================] - 1s 211us/sample - loss: 0.5554 - accuracy: 0.7526 - val_loss: 0.5824 - val_accuracy: 0.7535\n",
      "Epoch 25/300\n",
      "2805/2805 [==============================] - 1s 188us/sample - loss: 0.5507 - accuracy: 0.7611 - val_loss: 0.5806 - val_accuracy: 0.7535\n",
      "Epoch 26/300\n",
      "2805/2805 [==============================] - 1s 234us/sample - loss: 0.5494 - accuracy: 0.7633 - val_loss: 0.5789 - val_accuracy: 0.7535\n",
      "Epoch 27/300\n",
      "2805/2805 [==============================] - 1s 230us/sample - loss: 0.5472 - accuracy: 0.7583 - val_loss: 0.5773 - val_accuracy: 0.7535\n",
      "Epoch 28/300\n",
      "2805/2805 [==============================] - 1s 233us/sample - loss: 0.5439 - accuracy: 0.7611 - val_loss: 0.5756 - val_accuracy: 0.7535\n",
      "Epoch 29/300\n",
      "2805/2805 [==============================] - 1s 246us/sample - loss: 0.5423 - accuracy: 0.7647 - val_loss: 0.5741 - val_accuracy: 0.7549\n",
      "Epoch 30/300\n",
      "2805/2805 [==============================] - 1s 248us/sample - loss: 0.5375 - accuracy: 0.7643 - val_loss: 0.5726 - val_accuracy: 0.7535\n",
      "Epoch 31/300\n",
      "2805/2805 [==============================] - 1s 247us/sample - loss: 0.5366 - accuracy: 0.7701 - val_loss: 0.5712 - val_accuracy: 0.7535\n",
      "Epoch 32/300\n",
      "2805/2805 [==============================] - 1s 238us/sample - loss: 0.5295 - accuracy: 0.7672 - val_loss: 0.5699 - val_accuracy: 0.7549\n",
      "Epoch 33/300\n",
      "2805/2805 [==============================] - 1s 217us/sample - loss: 0.5304 - accuracy: 0.7683 - val_loss: 0.5686 - val_accuracy: 0.7549\n",
      "Epoch 34/300\n",
      "2805/2805 [==============================] - 1s 207us/sample - loss: 0.5268 - accuracy: 0.7672 - val_loss: 0.5673 - val_accuracy: 0.7563\n",
      "Epoch 35/300\n",
      "2805/2805 [==============================] - 1s 235us/sample - loss: 0.5249 - accuracy: 0.7661 - val_loss: 0.5661 - val_accuracy: 0.7563\n",
      "Epoch 36/300\n",
      "2805/2805 [==============================] - 1s 251us/sample - loss: 0.5228 - accuracy: 0.7743 - val_loss: 0.5648 - val_accuracy: 0.7563\n",
      "Epoch 37/300\n",
      "2805/2805 [==============================] - 1s 209us/sample - loss: 0.5224 - accuracy: 0.7718 - val_loss: 0.5636 - val_accuracy: 0.7563\n",
      "Epoch 38/300\n",
      "2805/2805 [==============================] - 1s 204us/sample - loss: 0.5208 - accuracy: 0.7683 - val_loss: 0.5625 - val_accuracy: 0.7563\n",
      "Epoch 39/300\n",
      "2805/2805 [==============================] - 1s 212us/sample - loss: 0.5186 - accuracy: 0.7672 - val_loss: 0.5615 - val_accuracy: 0.7563\n",
      "Epoch 40/300\n",
      "2805/2805 [==============================] - 1s 230us/sample - loss: 0.5131 - accuracy: 0.7672 - val_loss: 0.5604 - val_accuracy: 0.7563\n",
      "Epoch 41/300\n",
      "2805/2805 [==============================] - 1s 236us/sample - loss: 0.5156 - accuracy: 0.7704 - val_loss: 0.5594 - val_accuracy: 0.7563\n",
      "Epoch 42/300\n",
      "2805/2805 [==============================] - 1s 244us/sample - loss: 0.5101 - accuracy: 0.7747 - val_loss: 0.5584 - val_accuracy: 0.7563\n",
      "Epoch 43/300\n",
      "2805/2805 [==============================] - 1s 228us/sample - loss: 0.5089 - accuracy: 0.7768 - val_loss: 0.5574 - val_accuracy: 0.7549\n",
      "Epoch 44/300\n",
      "2805/2805 [==============================] - 1s 256us/sample - loss: 0.5061 - accuracy: 0.7740 - val_loss: 0.5564 - val_accuracy: 0.7549\n",
      "Epoch 45/300\n",
      "2805/2805 [==============================] - 1s 261us/sample - loss: 0.5087 - accuracy: 0.7786 - val_loss: 0.5555 - val_accuracy: 0.7549\n",
      "Epoch 46/300\n",
      "2805/2805 [==============================] - 1s 257us/sample - loss: 0.5016 - accuracy: 0.7768 - val_loss: 0.5545 - val_accuracy: 0.7549\n",
      "Epoch 47/300\n",
      "2805/2805 [==============================] - 1s 212us/sample - loss: 0.5025 - accuracy: 0.7754 - val_loss: 0.5537 - val_accuracy: 0.7549\n",
      "Epoch 48/300\n",
      "2805/2805 [==============================] - 1s 252us/sample - loss: 0.5008 - accuracy: 0.7797 - val_loss: 0.5528 - val_accuracy: 0.7549\n",
      "Epoch 49/300\n",
      "2805/2805 [==============================] - 1s 248us/sample - loss: 0.4948 - accuracy: 0.7815 - val_loss: 0.5520 - val_accuracy: 0.7549\n",
      "Epoch 50/300\n",
      "2805/2805 [==============================] - 1s 251us/sample - loss: 0.4945 - accuracy: 0.7736 - val_loss: 0.5512 - val_accuracy: 0.7549\n",
      "Epoch 51/300\n",
      "2805/2805 [==============================] - 1s 262us/sample - loss: 0.4941 - accuracy: 0.7822 - val_loss: 0.5504 - val_accuracy: 0.7549\n",
      "Epoch 52/300\n",
      "2805/2805 [==============================] - 1s 243us/sample - loss: 0.4899 - accuracy: 0.7807 - val_loss: 0.5496 - val_accuracy: 0.7549\n",
      "Epoch 53/300\n",
      "2805/2805 [==============================] - 1s 246us/sample - loss: 0.4835 - accuracy: 0.7832 - val_loss: 0.5489 - val_accuracy: 0.7549\n",
      "Epoch 54/300\n",
      "2805/2805 [==============================] - 1s 226us/sample - loss: 0.4832 - accuracy: 0.7829 - val_loss: 0.5481 - val_accuracy: 0.7549\n",
      "Epoch 55/300\n",
      "2805/2805 [==============================] - 1s 235us/sample - loss: 0.4835 - accuracy: 0.7843 - val_loss: 0.5475 - val_accuracy: 0.7549\n",
      "Epoch 56/300\n",
      "2805/2805 [==============================] - 1s 248us/sample - loss: 0.4830 - accuracy: 0.7815 - val_loss: 0.5468 - val_accuracy: 0.7563\n",
      "Epoch 57/300\n",
      "2805/2805 [==============================] - 1s 229us/sample - loss: 0.4791 - accuracy: 0.7854 - val_loss: 0.5461 - val_accuracy: 0.7563\n",
      "Epoch 58/300\n",
      "2805/2805 [==============================] - 1s 208us/sample - loss: 0.4764 - accuracy: 0.7861 - val_loss: 0.5455 - val_accuracy: 0.7549\n",
      "Epoch 59/300\n",
      "2805/2805 [==============================] - 1s 266us/sample - loss: 0.4776 - accuracy: 0.7865 - val_loss: 0.5449 - val_accuracy: 0.7549\n",
      "Epoch 60/300\n",
      "2805/2805 [==============================] - 1s 259us/sample - loss: 0.4763 - accuracy: 0.7857 - val_loss: 0.5443 - val_accuracy: 0.7549\n",
      "Epoch 61/300\n",
      "2805/2805 [==============================] - 1s 248us/sample - loss: 0.4705 - accuracy: 0.7882 - val_loss: 0.5437 - val_accuracy: 0.7549\n",
      "Epoch 62/300\n",
      "2805/2805 [==============================] - 1s 228us/sample - loss: 0.4710 - accuracy: 0.7868 - val_loss: 0.5432 - val_accuracy: 0.7549\n",
      "Epoch 63/300\n",
      "2805/2805 [==============================] - 1s 265us/sample - loss: 0.4670 - accuracy: 0.7872 - val_loss: 0.5427 - val_accuracy: 0.7549\n",
      "Epoch 64/300\n",
      "2805/2805 [==============================] - 1s 257us/sample - loss: 0.4677 - accuracy: 0.7886 - val_loss: 0.5422 - val_accuracy: 0.7549\n",
      "Epoch 65/300\n",
      "2805/2805 [==============================] - 1s 243us/sample - loss: 0.4618 - accuracy: 0.7897 - val_loss: 0.5416 - val_accuracy: 0.7549\n",
      "Epoch 66/300\n",
      "2805/2805 [==============================] - 1s 255us/sample - loss: 0.4630 - accuracy: 0.7907 - val_loss: 0.5413 - val_accuracy: 0.7549\n",
      "Epoch 67/300\n",
      "2805/2805 [==============================] - 1s 220us/sample - loss: 0.4593 - accuracy: 0.7911 - val_loss: 0.5409 - val_accuracy: 0.7563\n",
      "Epoch 68/300\n",
      "2805/2805 [==============================] - 1s 273us/sample - loss: 0.4591 - accuracy: 0.7947 - val_loss: 0.5405 - val_accuracy: 0.7535\n",
      "Epoch 69/300\n",
      "2805/2805 [==============================] - 1s 263us/sample - loss: 0.4523 - accuracy: 0.7947 - val_loss: 0.5401 - val_accuracy: 0.7535\n",
      "Epoch 70/300\n",
      "2805/2805 [==============================] - 1s 251us/sample - loss: 0.4561 - accuracy: 0.7950 - val_loss: 0.5398 - val_accuracy: 0.7535\n",
      "Epoch 71/300\n",
      "2805/2805 [==============================] - 1s 223us/sample - loss: 0.4517 - accuracy: 0.7989 - val_loss: 0.5395 - val_accuracy: 0.7535\n",
      "Epoch 72/300\n",
      "2805/2805 [==============================] - 1s 188us/sample - loss: 0.4482 - accuracy: 0.7961 - val_loss: 0.5392 - val_accuracy: 0.7535\n",
      "Epoch 73/300\n",
      "2805/2805 [==============================] - 1s 225us/sample - loss: 0.4481 - accuracy: 0.7943 - val_loss: 0.5390 - val_accuracy: 0.7521\n",
      "Epoch 74/300\n",
      "2805/2805 [==============================] - 1s 227us/sample - loss: 0.4405 - accuracy: 0.7993 - val_loss: 0.5388 - val_accuracy: 0.7521\n",
      "Epoch 75/300\n",
      "2805/2805 [==============================] - 1s 245us/sample - loss: 0.4411 - accuracy: 0.8039 - val_loss: 0.5386 - val_accuracy: 0.7535\n",
      "Epoch 76/300\n",
      "2805/2805 [==============================] - 1s 237us/sample - loss: 0.4425 - accuracy: 0.8057 - val_loss: 0.5384 - val_accuracy: 0.7549\n",
      "Epoch 77/300\n",
      "2805/2805 [==============================] - 1s 262us/sample - loss: 0.4375 - accuracy: 0.8068 - val_loss: 0.5383 - val_accuracy: 0.7549\n",
      "Epoch 78/300\n",
      "2805/2805 [==============================] - 1s 224us/sample - loss: 0.4350 - accuracy: 0.8089 - val_loss: 0.5382 - val_accuracy: 0.7535\n",
      "Epoch 79/300\n",
      "2805/2805 [==============================] - 1s 215us/sample - loss: 0.4347 - accuracy: 0.8103 - val_loss: 0.5382 - val_accuracy: 0.7507\n",
      "Epoch 80/300\n",
      "2805/2805 [==============================] - 1s 245us/sample - loss: 0.4306 - accuracy: 0.8075 - val_loss: 0.5381 - val_accuracy: 0.7493\n",
      "Epoch 81/300\n",
      "2805/2805 [==============================] - 1s 266us/sample - loss: 0.4273 - accuracy: 0.8046 - val_loss: 0.5382 - val_accuracy: 0.7507\n",
      "Epoch 82/300\n",
      "2805/2805 [==============================] - 1s 259us/sample - loss: 0.4260 - accuracy: 0.8089 - val_loss: 0.5382 - val_accuracy: 0.7507\n",
      "Epoch 83/300\n",
      "2805/2805 [==============================] - 1s 276us/sample - loss: 0.4235 - accuracy: 0.8121 - val_loss: 0.5383 - val_accuracy: 0.7521\n",
      "Epoch 00083: early stopping\n",
      "130/130 [==============================] - 0s 173us/sample - loss: 0.2278 - accuracy: 0.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [2:04:09, 1068.01s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.74s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.37s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 838.046875 steps, validate for 213.3359375 steps\n",
      "Epoch 1/300\n",
      "839/838 [==============================] - 25s 29ms/step - loss: 0.5572 - accuracy: 0.7461 - val_loss: 0.5373 - val_accuracy: 0.7695\n",
      "Epoch 2/300\n",
      "839/838 [==============================] - 24s 28ms/step - loss: 0.5119 - accuracy: 0.7756 - val_loss: 0.5359 - val_accuracy: 0.7700\n",
      "Epoch 3/300\n",
      "839/838 [==============================] - 24s 28ms/step - loss: 0.4976 - accuracy: 0.7801 - val_loss: 0.5335 - val_accuracy: 0.7699\n",
      "Epoch 4/300\n",
      "839/838 [==============================] - 24s 28ms/step - loss: 0.4869 - accuracy: 0.7845 - val_loss: 0.5393 - val_accuracy: 0.7692\n",
      "Epoch 5/300\n",
      "839/838 [==============================] - 24s 28ms/step - loss: 0.4773 - accuracy: 0.7879 - val_loss: 0.5382 - val_accuracy: 0.7668\n",
      "Epoch 6/300\n",
      "839/838 [==============================] - 24s 28ms/step - loss: 0.4688 - accuracy: 0.7925 - val_loss: 0.5459 - val_accuracy: 0.7657\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 838.046875 steps, validate for 213.3359375 steps\n",
      "Epoch 1/300\n",
      "839/838 [==============================] - 55s 65ms/step - loss: 0.4532 - accuracy: 0.8001 - val_loss: 0.5454 - val_accuracy: 0.7630\n",
      "Epoch 2/300\n",
      "839/838 [==============================] - 54s 64ms/step - loss: 0.4267 - accuracy: 0.8139 - val_loss: 0.5553 - val_accuracy: 0.7652\n",
      "Epoch 3/300\n",
      "839/838 [==============================] - 54s 64ms/step - loss: 0.4045 - accuracy: 0.8251 - val_loss: 0.5729 - val_accuracy: 0.7640\n",
      "Epoch 4/300\n",
      "839/838 [==============================] - 54s 64ms/step - loss: 0.3844 - accuracy: 0.8356 - val_loss: 0.5725 - val_accuracy: 0.7580\n",
      "Epoch 00004: early stopping\n",
      "118/118 [==============================] - 0s 2ms/sample - loss: 0.1505 - accuracy: 1.0000\n",
      "116/116 [==============================] - 0s 224us/sample - loss: 0.1601 - accuracy: 0.9914\n",
      "114/114 [==============================] - 0s 232us/sample - loss: 0.1773 - accuracy: 1.0000\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 0.1922 - accuracy: 0.9821\n",
      "110/110 [==============================] - 0s 269us/sample - loss: 0.1766 - accuracy: 0.9818\n",
      "109/109 [==============================] - 0s 252us/sample - loss: 0.1907 - accuracy: 0.9908\n",
      "108/108 [==============================] - 0s 333us/sample - loss: 0.1950 - accuracy: 0.9815\n",
      "105/105 [==============================] - 0s 261us/sample - loss: 0.1878 - accuracy: 0.9905\n",
      "102/102 [==============================] - 0s 260us/sample - loss: 0.1838 - accuracy: 1.0000\n",
      "101/101 [==============================] - 0s 285us/sample - loss: 0.2071 - accuracy: 0.9802\n",
      "99/99 [==============================] - 0s 252us/sample - loss: 0.1984 - accuracy: 0.9899\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.2415 - accuracy: 0.9688\n",
      "94/94 [==============================] - 0s 300us/sample - loss: 0.2507 - accuracy: 0.9468\n",
      "94/94 [==============================] - 0s 280us/sample - loss: 0.2513 - accuracy: 0.9574\n",
      "93/93 [==============================] - 0s 264us/sample - loss: 0.2342 - accuracy: 0.9677\n",
      "92/92 [==============================] - 0s 271us/sample - loss: 0.2311 - accuracy: 0.9674\n",
      "93/93 [==============================] - 0s 247us/sample - loss: 0.2520 - accuracy: 0.9892\n",
      "93/93 [==============================] - 0s 255us/sample - loss: 0.2355 - accuracy: 0.9785\n",
      "92/92 [==============================] - 0s 252us/sample - loss: 0.2125 - accuracy: 0.9891\n",
      "92/92 [==============================] - 0s 246us/sample - loss: 0.2798 - accuracy: 0.9022\n",
      "91/91 [==============================] - 0s 258us/sample - loss: 0.2228 - accuracy: 0.9560\n",
      "92/92 [==============================] - 0s 249us/sample - loss: 0.2311 - accuracy: 0.9783\n",
      "91/91 [==============================] - 0s 249us/sample - loss: 0.2248 - accuracy: 1.0000\n",
      "90/90 [==============================] - 0s 255us/sample - loss: 0.2143 - accuracy: 0.9778\n",
      "89/89 [==============================] - 0s 239us/sample - loss: 0.2500 - accuracy: 0.9438\n",
      "88/88 [==============================] - 0s 284us/sample - loss: 0.2445 - accuracy: 0.9659\n",
      "89/89 [==============================] - 0s 297us/sample - loss: 0.2706 - accuracy: 0.9326\n",
      "89/89 [==============================] - 0s 299us/sample - loss: 0.2693 - accuracy: 0.9438\n",
      "89/89 [==============================] - 0s 284us/sample - loss: 0.2343 - accuracy: 0.9663\n",
      "90/90 [==============================] - 0s 281us/sample - loss: 0.2511 - accuracy: 0.9556\n",
      "90/90 [==============================] - 0s 248us/sample - loss: 0.2270 - accuracy: 0.9889\n",
      "91/91 [==============================] - 0s 257us/sample - loss: 0.2408 - accuracy: 0.9890\n",
      "89/89 [==============================] - 0s 273us/sample - loss: 0.2697 - accuracy: 0.9551\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2841 samples, validate on 721 samples\n",
      "Epoch 1/300\n",
      "2841/2841 [==============================] - 2s 875us/sample - loss: 0.6501 - accuracy: 0.6350 - val_loss: 0.6359 - val_accuracy: 0.6533\n",
      "Epoch 2/300\n",
      "2841/2841 [==============================] - 1s 223us/sample - loss: 0.6242 - accuracy: 0.6839 - val_loss: 0.6215 - val_accuracy: 0.6824\n",
      "Epoch 3/300\n",
      "2841/2841 [==============================] - 1s 204us/sample - loss: 0.6081 - accuracy: 0.7008 - val_loss: 0.6120 - val_accuracy: 0.6935\n",
      "Epoch 4/300\n",
      "2841/2841 [==============================] - 1s 240us/sample - loss: 0.5948 - accuracy: 0.7209 - val_loss: 0.6046 - val_accuracy: 0.7032\n",
      "Epoch 5/300\n",
      "2841/2841 [==============================] - 1s 204us/sample - loss: 0.5861 - accuracy: 0.7251 - val_loss: 0.5988 - val_accuracy: 0.7046\n",
      "Epoch 6/300\n",
      "2841/2841 [==============================] - 1s 240us/sample - loss: 0.5762 - accuracy: 0.7399 - val_loss: 0.5939 - val_accuracy: 0.7074\n",
      "Epoch 7/300\n",
      "2841/2841 [==============================] - 1s 269us/sample - loss: 0.5667 - accuracy: 0.7452 - val_loss: 0.5897 - val_accuracy: 0.7143\n",
      "Epoch 8/300\n",
      "2841/2841 [==============================] - 1s 202us/sample - loss: 0.5595 - accuracy: 0.7518 - val_loss: 0.5860 - val_accuracy: 0.7171\n",
      "Epoch 9/300\n",
      "2841/2841 [==============================] - 1s 202us/sample - loss: 0.5555 - accuracy: 0.7554 - val_loss: 0.5828 - val_accuracy: 0.7226\n",
      "Epoch 10/300\n",
      "2841/2841 [==============================] - 1s 227us/sample - loss: 0.5503 - accuracy: 0.7606 - val_loss: 0.5799 - val_accuracy: 0.7268\n",
      "Epoch 11/300\n",
      "2841/2841 [==============================] - 1s 214us/sample - loss: 0.5478 - accuracy: 0.7606 - val_loss: 0.5774 - val_accuracy: 0.7337\n",
      "Epoch 12/300\n",
      "2841/2841 [==============================] - 1s 233us/sample - loss: 0.5402 - accuracy: 0.7617 - val_loss: 0.5751 - val_accuracy: 0.7337\n",
      "Epoch 13/300\n",
      "2841/2841 [==============================] - 1s 194us/sample - loss: 0.5313 - accuracy: 0.7719 - val_loss: 0.5730 - val_accuracy: 0.7365\n",
      "Epoch 14/300\n",
      "2841/2841 [==============================] - 1s 183us/sample - loss: 0.5319 - accuracy: 0.7694 - val_loss: 0.5710 - val_accuracy: 0.7351\n",
      "Epoch 15/300\n",
      "2841/2841 [==============================] - 1s 197us/sample - loss: 0.5265 - accuracy: 0.7744 - val_loss: 0.5693 - val_accuracy: 0.7379\n",
      "Epoch 16/300\n",
      "2841/2841 [==============================] - 1s 211us/sample - loss: 0.5237 - accuracy: 0.7691 - val_loss: 0.5677 - val_accuracy: 0.7393\n",
      "Epoch 17/300\n",
      "2841/2841 [==============================] - 1s 236us/sample - loss: 0.5194 - accuracy: 0.7737 - val_loss: 0.5662 - val_accuracy: 0.7406\n",
      "Epoch 18/300\n",
      "2841/2841 [==============================] - 1s 228us/sample - loss: 0.5147 - accuracy: 0.7811 - val_loss: 0.5650 - val_accuracy: 0.7406\n",
      "Epoch 19/300\n",
      "2841/2841 [==============================] - 1s 234us/sample - loss: 0.5120 - accuracy: 0.7814 - val_loss: 0.5637 - val_accuracy: 0.7420\n",
      "Epoch 20/300\n",
      "2841/2841 [==============================] - 1s 227us/sample - loss: 0.5097 - accuracy: 0.7800 - val_loss: 0.5626 - val_accuracy: 0.7434\n",
      "Epoch 21/300\n",
      "2841/2841 [==============================] - 1s 225us/sample - loss: 0.5063 - accuracy: 0.7793 - val_loss: 0.5616 - val_accuracy: 0.7434\n",
      "Epoch 22/300\n",
      "2841/2841 [==============================] - 1s 198us/sample - loss: 0.5021 - accuracy: 0.7814 - val_loss: 0.5606 - val_accuracy: 0.7448\n",
      "Epoch 23/300\n",
      "2841/2841 [==============================] - 1s 215us/sample - loss: 0.4993 - accuracy: 0.7828 - val_loss: 0.5598 - val_accuracy: 0.7476\n",
      "Epoch 24/300\n",
      "2841/2841 [==============================] - 1s 214us/sample - loss: 0.4930 - accuracy: 0.7878 - val_loss: 0.5590 - val_accuracy: 0.7476\n",
      "Epoch 25/300\n",
      "2841/2841 [==============================] - 1s 178us/sample - loss: 0.4905 - accuracy: 0.7913 - val_loss: 0.5582 - val_accuracy: 0.7490\n",
      "Epoch 26/300\n",
      "2841/2841 [==============================] - 1s 213us/sample - loss: 0.4907 - accuracy: 0.7881 - val_loss: 0.5575 - val_accuracy: 0.7476\n",
      "Epoch 27/300\n",
      "2841/2841 [==============================] - 1s 206us/sample - loss: 0.4834 - accuracy: 0.7902 - val_loss: 0.5569 - val_accuracy: 0.7476\n",
      "Epoch 28/300\n",
      "2841/2841 [==============================] - 1s 200us/sample - loss: 0.4849 - accuracy: 0.7870 - val_loss: 0.5563 - val_accuracy: 0.7490\n",
      "Epoch 29/300\n",
      "2841/2841 [==============================] - 1s 230us/sample - loss: 0.4812 - accuracy: 0.7951 - val_loss: 0.5558 - val_accuracy: 0.7476\n",
      "Epoch 30/300\n",
      "2841/2841 [==============================] - 1s 220us/sample - loss: 0.4806 - accuracy: 0.7895 - val_loss: 0.5554 - val_accuracy: 0.7476\n",
      "Epoch 31/300\n",
      "2841/2841 [==============================] - 1s 217us/sample - loss: 0.4750 - accuracy: 0.7962 - val_loss: 0.5549 - val_accuracy: 0.7476\n",
      "Epoch 32/300\n",
      "2841/2841 [==============================] - 1s 221us/sample - loss: 0.4739 - accuracy: 0.7962 - val_loss: 0.5546 - val_accuracy: 0.7462\n",
      "Epoch 33/300\n",
      "2841/2841 [==============================] - 1s 220us/sample - loss: 0.4707 - accuracy: 0.7909 - val_loss: 0.5543 - val_accuracy: 0.7448\n",
      "Epoch 34/300\n",
      "2841/2841 [==============================] - 1s 245us/sample - loss: 0.4679 - accuracy: 0.7994 - val_loss: 0.5539 - val_accuracy: 0.7462\n",
      "Epoch 35/300\n",
      "2841/2841 [==============================] - 1s 220us/sample - loss: 0.4685 - accuracy: 0.7980 - val_loss: 0.5537 - val_accuracy: 0.7476\n",
      "Epoch 36/300\n",
      "2841/2841 [==============================] - 1s 223us/sample - loss: 0.4649 - accuracy: 0.7997 - val_loss: 0.5535 - val_accuracy: 0.7476\n",
      "Epoch 37/300\n",
      "2841/2841 [==============================] - 1s 224us/sample - loss: 0.4598 - accuracy: 0.8036 - val_loss: 0.5533 - val_accuracy: 0.7476\n",
      "Epoch 38/300\n",
      "2841/2841 [==============================] - 1s 203us/sample - loss: 0.4593 - accuracy: 0.7994 - val_loss: 0.5531 - val_accuracy: 0.7476\n",
      "Epoch 39/300\n",
      "2841/2841 [==============================] - 1s 205us/sample - loss: 0.4562 - accuracy: 0.8039 - val_loss: 0.5530 - val_accuracy: 0.7476\n",
      "Epoch 40/300\n",
      "2841/2841 [==============================] - 1s 192us/sample - loss: 0.4516 - accuracy: 0.8078 - val_loss: 0.5528 - val_accuracy: 0.7448\n",
      "Epoch 41/300\n",
      "2841/2841 [==============================] - 1s 209us/sample - loss: 0.4532 - accuracy: 0.8018 - val_loss: 0.5527 - val_accuracy: 0.7462\n",
      "Epoch 42/300\n",
      "2841/2841 [==============================] - 1s 218us/sample - loss: 0.4503 - accuracy: 0.8082 - val_loss: 0.5526 - val_accuracy: 0.7462\n",
      "Epoch 43/300\n",
      "2841/2841 [==============================] - 1s 222us/sample - loss: 0.4442 - accuracy: 0.8071 - val_loss: 0.5526 - val_accuracy: 0.7462\n",
      "Epoch 44/300\n",
      "2841/2841 [==============================] - 1s 237us/sample - loss: 0.4438 - accuracy: 0.8085 - val_loss: 0.5526 - val_accuracy: 0.7462\n",
      "Epoch 45/300\n",
      "2841/2841 [==============================] - 1s 209us/sample - loss: 0.4430 - accuracy: 0.8085 - val_loss: 0.5527 - val_accuracy: 0.7462\n",
      "Epoch 46/300\n",
      "2841/2841 [==============================] - 1s 214us/sample - loss: 0.4381 - accuracy: 0.8110 - val_loss: 0.5527 - val_accuracy: 0.7462\n",
      "Epoch 00046: early stopping\n",
      "87/87 [==============================] - 0s 207us/sample - loss: 0.3218 - accuracy: 0.9540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [2:21:31, 1060.20s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.58s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.30s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 832.84375 steps, validate for 216.1640625 steps\n",
      "Epoch 1/300\n",
      "833/832 [==============================] - 25s 30ms/step - loss: 0.5633 - accuracy: 0.7405 - val_loss: 0.5336 - val_accuracy: 0.7751\n",
      "Epoch 2/300\n",
      "833/832 [==============================] - 24s 29ms/step - loss: 0.5161 - accuracy: 0.7746 - val_loss: 0.5275 - val_accuracy: 0.7731\n",
      "Epoch 3/300\n",
      "833/832 [==============================] - 24s 29ms/step - loss: 0.5016 - accuracy: 0.7792 - val_loss: 0.5262 - val_accuracy: 0.7701\n",
      "Epoch 4/300\n",
      "833/832 [==============================] - 24s 29ms/step - loss: 0.4911 - accuracy: 0.7824 - val_loss: 0.5227 - val_accuracy: 0.7706\n",
      "Epoch 5/300\n",
      "833/832 [==============================] - 24s 28ms/step - loss: 0.4815 - accuracy: 0.7863 - val_loss: 0.5243 - val_accuracy: 0.7689\n",
      "Epoch 6/300\n",
      "833/832 [==============================] - 24s 29ms/step - loss: 0.4725 - accuracy: 0.7900 - val_loss: 0.5339 - val_accuracy: 0.7649\n",
      "Epoch 7/300\n",
      "833/832 [==============================] - 24s 28ms/step - loss: 0.4637 - accuracy: 0.7941 - val_loss: 0.5276 - val_accuracy: 0.7664\n",
      "Epoch 00007: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 832.84375 steps, validate for 216.1640625 steps\n",
      "Epoch 1/300\n",
      "833/832 [==============================] - 55s 66ms/step - loss: 0.4483 - accuracy: 0.8014 - val_loss: 0.5432 - val_accuracy: 0.7693\n",
      "Epoch 2/300\n",
      "833/832 [==============================] - 54s 65ms/step - loss: 0.4235 - accuracy: 0.8148 - val_loss: 0.5549 - val_accuracy: 0.7655\n",
      "Epoch 3/300\n",
      "833/832 [==============================] - 54s 64ms/step - loss: 0.4024 - accuracy: 0.8255 - val_loss: 0.5589 - val_accuracy: 0.7568\n",
      "Epoch 4/300\n",
      "833/832 [==============================] - 54s 65ms/step - loss: 0.3829 - accuracy: 0.8366 - val_loss: 0.5507 - val_accuracy: 0.7626\n",
      "Epoch 00004: early stopping\n",
      "118/118 [==============================] - 0s 2ms/sample - loss: 0.1899 - accuracy: 0.9746\n",
      "113/113 [==============================] - 0s 239us/sample - loss: 0.2063 - accuracy: 0.9558\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.2202 - accuracy: 0.9375\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 0.2254 - accuracy: 0.9643\n",
      "111/111 [==============================] - 0s 235us/sample - loss: 0.2279 - accuracy: 0.9459\n",
      "111/111 [==============================] - 0s 263us/sample - loss: 0.2172 - accuracy: 0.9640\n",
      "108/108 [==============================] - 0s 256us/sample - loss: 0.2205 - accuracy: 0.9630\n",
      "109/109 [==============================] - 0s 265us/sample - loss: 0.1925 - accuracy: 0.9725\n",
      "106/106 [==============================] - 0s 254us/sample - loss: 0.2150 - accuracy: 0.9811\n",
      "104/104 [==============================] - 0s 244us/sample - loss: 0.2145 - accuracy: 0.9519\n",
      "104/104 [==============================] - 0s 267us/sample - loss: 0.2389 - accuracy: 0.9231\n",
      "105/105 [==============================] - 0s 282us/sample - loss: 0.2143 - accuracy: 0.9619\n",
      "104/104 [==============================] - 0s 283us/sample - loss: 0.2274 - accuracy: 0.9519\n",
      "104/104 [==============================] - 0s 271us/sample - loss: 0.2214 - accuracy: 0.9808\n",
      "103/103 [==============================] - 0s 290us/sample - loss: 0.2321 - accuracy: 0.9320\n",
      "102/102 [==============================] - 0s 275us/sample - loss: 0.2313 - accuracy: 0.9510\n",
      "101/101 [==============================] - 0s 263us/sample - loss: 0.2350 - accuracy: 0.9406\n",
      "102/102 [==============================] - 0s 274us/sample - loss: 0.2333 - accuracy: 0.9608\n",
      "105/105 [==============================] - 0s 273us/sample - loss: 0.2522 - accuracy: 0.9429\n",
      "103/103 [==============================] - 0s 256us/sample - loss: 0.2321 - accuracy: 0.9320\n",
      "104/104 [==============================] - 0s 278us/sample - loss: 0.2133 - accuracy: 0.9808\n",
      "105/105 [==============================] - 0s 262us/sample - loss: 0.2272 - accuracy: 0.9524\n",
      "103/103 [==============================] - 0s 323us/sample - loss: 0.2480 - accuracy: 0.9417\n",
      "104/104 [==============================] - 0s 281us/sample - loss: 0.2297 - accuracy: 0.9615\n",
      "105/105 [==============================] - 0s 291us/sample - loss: 0.2062 - accuracy: 0.9810\n",
      "105/105 [==============================] - 0s 286us/sample - loss: 0.2239 - accuracy: 0.9714\n",
      "105/105 [==============================] - 0s 243us/sample - loss: 0.2392 - accuracy: 0.9714\n",
      "106/106 [==============================] - 0s 274us/sample - loss: 0.2312 - accuracy: 0.9528\n",
      "104/104 [==============================] - 0s 266us/sample - loss: 0.2098 - accuracy: 0.9712\n",
      "106/106 [==============================] - 0s 279us/sample - loss: 0.2188 - accuracy: 0.9528\n",
      "107/107 [==============================] - 0s 285us/sample - loss: 0.2394 - accuracy: 0.9439\n",
      "108/108 [==============================] - 0s 278us/sample - loss: 0.2141 - accuracy: 0.9630\n",
      "106/106 [==============================] - 0s 257us/sample - loss: 0.2209 - accuracy: 0.9528\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2821 samples, validate on 730 samples\n",
      "Epoch 1/300\n",
      "2821/2821 [==============================] - 2s 861us/sample - loss: 0.6828 - accuracy: 0.5601 - val_loss: 0.6702 - val_accuracy: 0.5726\n",
      "Epoch 2/300\n",
      "2821/2821 [==============================] - 1s 272us/sample - loss: 0.6539 - accuracy: 0.6122 - val_loss: 0.6511 - val_accuracy: 0.6274\n",
      "Epoch 3/300\n",
      "2821/2821 [==============================] - 1s 238us/sample - loss: 0.6352 - accuracy: 0.6352 - val_loss: 0.6375 - val_accuracy: 0.6466\n",
      "Epoch 4/300\n",
      "2821/2821 [==============================] - 1s 218us/sample - loss: 0.6225 - accuracy: 0.6678 - val_loss: 0.6269 - val_accuracy: 0.6658\n",
      "Epoch 5/300\n",
      "2821/2821 [==============================] - 1s 281us/sample - loss: 0.6100 - accuracy: 0.6810 - val_loss: 0.6177 - val_accuracy: 0.6767\n",
      "Epoch 6/300\n",
      "2821/2821 [==============================] - 1s 257us/sample - loss: 0.6034 - accuracy: 0.7037 - val_loss: 0.6098 - val_accuracy: 0.6986\n",
      "Epoch 7/300\n",
      "2821/2821 [==============================] - 1s 239us/sample - loss: 0.5910 - accuracy: 0.7104 - val_loss: 0.6027 - val_accuracy: 0.7055\n",
      "Epoch 8/300\n",
      "2821/2821 [==============================] - 1s 236us/sample - loss: 0.5838 - accuracy: 0.7380 - val_loss: 0.5964 - val_accuracy: 0.7096\n",
      "Epoch 9/300\n",
      "2821/2821 [==============================] - 1s 248us/sample - loss: 0.5793 - accuracy: 0.7370 - val_loss: 0.5905 - val_accuracy: 0.7110\n",
      "Epoch 10/300\n",
      "2821/2821 [==============================] - 1s 230us/sample - loss: 0.5678 - accuracy: 0.7451 - val_loss: 0.5851 - val_accuracy: 0.7192\n",
      "Epoch 11/300\n",
      "2821/2821 [==============================] - 1s 252us/sample - loss: 0.5593 - accuracy: 0.7497 - val_loss: 0.5800 - val_accuracy: 0.7315\n",
      "Epoch 12/300\n",
      "2821/2821 [==============================] - 1s 233us/sample - loss: 0.5545 - accuracy: 0.7675 - val_loss: 0.5753 - val_accuracy: 0.7397\n",
      "Epoch 13/300\n",
      "2821/2821 [==============================] - 1s 223us/sample - loss: 0.5501 - accuracy: 0.7636 - val_loss: 0.5710 - val_accuracy: 0.7438\n",
      "Epoch 14/300\n",
      "2821/2821 [==============================] - 1s 242us/sample - loss: 0.5439 - accuracy: 0.7660 - val_loss: 0.5669 - val_accuracy: 0.7479\n",
      "Epoch 15/300\n",
      "2821/2821 [==============================] - 1s 246us/sample - loss: 0.5409 - accuracy: 0.7745 - val_loss: 0.5630 - val_accuracy: 0.7521\n",
      "Epoch 16/300\n",
      "2821/2821 [==============================] - 1s 221us/sample - loss: 0.5332 - accuracy: 0.7877 - val_loss: 0.5594 - val_accuracy: 0.7534\n",
      "Epoch 17/300\n",
      "2821/2821 [==============================] - 1s 245us/sample - loss: 0.5276 - accuracy: 0.7870 - val_loss: 0.5560 - val_accuracy: 0.7562\n",
      "Epoch 18/300\n",
      "2821/2821 [==============================] - 1s 229us/sample - loss: 0.5223 - accuracy: 0.7923 - val_loss: 0.5528 - val_accuracy: 0.7616\n",
      "Epoch 19/300\n",
      "2821/2821 [==============================] - 1s 214us/sample - loss: 0.5217 - accuracy: 0.7930 - val_loss: 0.5497 - val_accuracy: 0.7658\n",
      "Epoch 20/300\n",
      "2821/2821 [==============================] - 1s 245us/sample - loss: 0.5129 - accuracy: 0.7901 - val_loss: 0.5468 - val_accuracy: 0.7671\n",
      "Epoch 21/300\n",
      "2821/2821 [==============================] - 1s 252us/sample - loss: 0.5095 - accuracy: 0.7955 - val_loss: 0.5440 - val_accuracy: 0.7685\n",
      "Epoch 22/300\n",
      "2821/2821 [==============================] - 1s 248us/sample - loss: 0.5062 - accuracy: 0.8004 - val_loss: 0.5414 - val_accuracy: 0.7726\n",
      "Epoch 23/300\n",
      "2821/2821 [==============================] - 1s 201us/sample - loss: 0.5031 - accuracy: 0.7965 - val_loss: 0.5390 - val_accuracy: 0.7712\n",
      "Epoch 24/300\n",
      "2821/2821 [==============================] - 1s 185us/sample - loss: 0.4995 - accuracy: 0.8015 - val_loss: 0.5367 - val_accuracy: 0.7740\n",
      "Epoch 25/300\n",
      "2821/2821 [==============================] - 1s 180us/sample - loss: 0.4956 - accuracy: 0.8008 - val_loss: 0.5345 - val_accuracy: 0.7767\n",
      "Epoch 26/300\n",
      "2821/2821 [==============================] - 1s 209us/sample - loss: 0.4906 - accuracy: 0.8036 - val_loss: 0.5326 - val_accuracy: 0.7753\n",
      "Epoch 27/300\n",
      "2821/2821 [==============================] - 1s 220us/sample - loss: 0.4895 - accuracy: 0.8001 - val_loss: 0.5306 - val_accuracy: 0.7753\n",
      "Epoch 28/300\n",
      "2821/2821 [==============================] - 1s 212us/sample - loss: 0.4828 - accuracy: 0.8036 - val_loss: 0.5288 - val_accuracy: 0.7753\n",
      "Epoch 29/300\n",
      "2821/2821 [==============================] - 1s 181us/sample - loss: 0.4830 - accuracy: 0.8057 - val_loss: 0.5270 - val_accuracy: 0.7781\n",
      "Epoch 30/300\n",
      "2821/2821 [==============================] - 1s 228us/sample - loss: 0.4840 - accuracy: 0.8075 - val_loss: 0.5254 - val_accuracy: 0.7767\n",
      "Epoch 31/300\n",
      "2821/2821 [==============================] - 1s 216us/sample - loss: 0.4716 - accuracy: 0.8167 - val_loss: 0.5239 - val_accuracy: 0.7740\n",
      "Epoch 32/300\n",
      "2821/2821 [==============================] - 1s 201us/sample - loss: 0.4737 - accuracy: 0.8121 - val_loss: 0.5224 - val_accuracy: 0.7740\n",
      "Epoch 33/300\n",
      "2821/2821 [==============================] - 1s 243us/sample - loss: 0.4674 - accuracy: 0.8164 - val_loss: 0.5211 - val_accuracy: 0.7740\n",
      "Epoch 34/300\n",
      "2821/2821 [==============================] - 1s 241us/sample - loss: 0.4660 - accuracy: 0.8096 - val_loss: 0.5198 - val_accuracy: 0.7740\n",
      "Epoch 35/300\n",
      "2821/2821 [==============================] - 1s 206us/sample - loss: 0.4645 - accuracy: 0.8079 - val_loss: 0.5187 - val_accuracy: 0.7740\n",
      "Epoch 36/300\n",
      "2821/2821 [==============================] - 1s 204us/sample - loss: 0.4623 - accuracy: 0.8139 - val_loss: 0.5175 - val_accuracy: 0.7753\n",
      "Epoch 37/300\n",
      "2821/2821 [==============================] - 1s 215us/sample - loss: 0.4621 - accuracy: 0.8118 - val_loss: 0.5164 - val_accuracy: 0.7767\n",
      "Epoch 38/300\n",
      "2821/2821 [==============================] - 1s 209us/sample - loss: 0.4588 - accuracy: 0.8150 - val_loss: 0.5154 - val_accuracy: 0.7767\n",
      "Epoch 39/300\n",
      "2821/2821 [==============================] - 1s 241us/sample - loss: 0.4532 - accuracy: 0.8178 - val_loss: 0.5145 - val_accuracy: 0.7767\n",
      "Epoch 40/300\n",
      "2821/2821 [==============================] - 1s 196us/sample - loss: 0.4499 - accuracy: 0.8206 - val_loss: 0.5136 - val_accuracy: 0.7767\n",
      "Epoch 41/300\n",
      "2821/2821 [==============================] - 1s 220us/sample - loss: 0.4482 - accuracy: 0.8217 - val_loss: 0.5129 - val_accuracy: 0.7767\n",
      "Epoch 42/300\n",
      "2821/2821 [==============================] - 1s 238us/sample - loss: 0.4464 - accuracy: 0.8178 - val_loss: 0.5121 - val_accuracy: 0.7767\n",
      "Epoch 43/300\n",
      "2821/2821 [==============================] - 1s 212us/sample - loss: 0.4435 - accuracy: 0.8213 - val_loss: 0.5115 - val_accuracy: 0.7753\n",
      "Epoch 44/300\n",
      "2821/2821 [==============================] - 1s 196us/sample - loss: 0.4384 - accuracy: 0.8238 - val_loss: 0.5110 - val_accuracy: 0.7753\n",
      "Epoch 45/300\n",
      "2821/2821 [==============================] - 1s 186us/sample - loss: 0.4397 - accuracy: 0.8199 - val_loss: 0.5104 - val_accuracy: 0.7753\n",
      "Epoch 46/300\n",
      "2821/2821 [==============================] - 1s 224us/sample - loss: 0.4370 - accuracy: 0.8220 - val_loss: 0.5099 - val_accuracy: 0.7740\n",
      "Epoch 47/300\n",
      "2821/2821 [==============================] - 1s 206us/sample - loss: 0.4347 - accuracy: 0.8192 - val_loss: 0.5094 - val_accuracy: 0.7753\n",
      "Epoch 48/300\n",
      "2821/2821 [==============================] - 1s 202us/sample - loss: 0.4303 - accuracy: 0.8256 - val_loss: 0.5090 - val_accuracy: 0.7753\n",
      "Epoch 49/300\n",
      "2821/2821 [==============================] - 1s 199us/sample - loss: 0.4298 - accuracy: 0.8263 - val_loss: 0.5087 - val_accuracy: 0.7753\n",
      "Epoch 50/300\n",
      "2821/2821 [==============================] - 1s 184us/sample - loss: 0.4296 - accuracy: 0.8270 - val_loss: 0.5084 - val_accuracy: 0.7753\n",
      "Epoch 51/300\n",
      "2821/2821 [==============================] - 1s 207us/sample - loss: 0.4261 - accuracy: 0.8288 - val_loss: 0.5081 - val_accuracy: 0.7740\n",
      "Epoch 52/300\n",
      "2821/2821 [==============================] - 1s 211us/sample - loss: 0.4243 - accuracy: 0.8270 - val_loss: 0.5079 - val_accuracy: 0.7740\n",
      "Epoch 53/300\n",
      "2821/2821 [==============================] - 1s 232us/sample - loss: 0.4216 - accuracy: 0.8235 - val_loss: 0.5078 - val_accuracy: 0.7740\n",
      "Epoch 54/300\n",
      "2821/2821 [==============================] - 1s 219us/sample - loss: 0.4182 - accuracy: 0.8284 - val_loss: 0.5076 - val_accuracy: 0.7726\n",
      "Epoch 55/300\n",
      "2821/2821 [==============================] - 1s 212us/sample - loss: 0.4177 - accuracy: 0.8334 - val_loss: 0.5075 - val_accuracy: 0.7740\n",
      "Epoch 56/300\n",
      "2821/2821 [==============================] - 1s 219us/sample - loss: 0.4153 - accuracy: 0.8295 - val_loss: 0.5074 - val_accuracy: 0.7726\n",
      "Epoch 57/300\n",
      "2821/2821 [==============================] - 1s 198us/sample - loss: 0.4133 - accuracy: 0.8327 - val_loss: 0.5073 - val_accuracy: 0.7726\n",
      "Epoch 58/300\n",
      "2821/2821 [==============================] - 1s 213us/sample - loss: 0.4116 - accuracy: 0.8316 - val_loss: 0.5073 - val_accuracy: 0.7685\n",
      "Epoch 59/300\n",
      "2821/2821 [==============================] - 1s 228us/sample - loss: 0.4110 - accuracy: 0.8284 - val_loss: 0.5073 - val_accuracy: 0.7685\n",
      "Epoch 60/300\n",
      "2821/2821 [==============================] - 1s 220us/sample - loss: 0.4067 - accuracy: 0.8366 - val_loss: 0.5074 - val_accuracy: 0.7671\n",
      "Epoch 00060: early stopping\n",
      "98/98 [==============================] - 0s 178us/sample - loss: 0.2250 - accuracy: 0.9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [2:39:23, 1063.74s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.46s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.31s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 843.53125 steps, validate for 214.515625 steps\n",
      "Epoch 1/300\n",
      "844/843 [==============================] - 25s 30ms/step - loss: 0.5571 - accuracy: 0.7443 - val_loss: 0.5334 - val_accuracy: 0.7721\n",
      "Epoch 2/300\n",
      "844/843 [==============================] - 24s 28ms/step - loss: 0.5103 - accuracy: 0.7763 - val_loss: 0.5291 - val_accuracy: 0.7722\n",
      "Epoch 3/300\n",
      "844/843 [==============================] - 24s 28ms/step - loss: 0.4953 - accuracy: 0.7802 - val_loss: 0.5316 - val_accuracy: 0.7704\n",
      "Epoch 4/300\n",
      "844/843 [==============================] - 24s 29ms/step - loss: 0.4841 - accuracy: 0.7845 - val_loss: 0.5346 - val_accuracy: 0.7678\n",
      "Epoch 5/300\n",
      "844/843 [==============================] - 24s 28ms/step - loss: 0.4744 - accuracy: 0.7885 - val_loss: 0.5399 - val_accuracy: 0.7661\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 843.53125 steps, validate for 214.515625 steps\n",
      "Epoch 1/300\n",
      "844/843 [==============================] - 56s 66ms/step - loss: 0.4573 - accuracy: 0.7961 - val_loss: 0.5480 - val_accuracy: 0.7493\n",
      "Epoch 2/300\n",
      "844/843 [==============================] - 54s 64ms/step - loss: 0.4311 - accuracy: 0.8091 - val_loss: 0.5340 - val_accuracy: 0.7647\n",
      "Epoch 3/300\n",
      "844/843 [==============================] - 54s 64ms/step - loss: 0.4099 - accuracy: 0.8211 - val_loss: 0.5624 - val_accuracy: 0.7558\n",
      "Epoch 4/300\n",
      "844/843 [==============================] - 54s 64ms/step - loss: 0.3906 - accuracy: 0.8315 - val_loss: 0.5784 - val_accuracy: 0.7171\n",
      "Epoch 5/300\n",
      "844/843 [==============================] - 54s 64ms/step - loss: 0.3729 - accuracy: 0.8401 - val_loss: 0.5607 - val_accuracy: 0.7632\n",
      "Epoch 00005: early stopping\n",
      "87/87 [==============================] - 0s 3ms/sample - loss: 0.1995 - accuracy: 0.9885\n",
      "84/84 [==============================] - 0s 246us/sample - loss: 0.1977 - accuracy: 0.9643\n",
      "82/82 [==============================] - 0s 263us/sample - loss: 0.2145 - accuracy: 0.9634\n",
      "80/80 [==============================] - 0s 249us/sample - loss: 0.2137 - accuracy: 0.9625\n",
      "78/78 [==============================] - 0s 233us/sample - loss: 0.2323 - accuracy: 0.9615\n",
      "79/79 [==============================] - 0s 242us/sample - loss: 0.2253 - accuracy: 0.9620\n",
      "79/79 [==============================] - 0s 278us/sample - loss: 0.2184 - accuracy: 0.9620\n",
      "75/75 [==============================] - 0s 245us/sample - loss: 0.2305 - accuracy: 0.9333\n",
      "72/72 [==============================] - 0s 265us/sample - loss: 0.2338 - accuracy: 0.9167\n",
      "72/72 [==============================] - 0s 298us/sample - loss: 0.2210 - accuracy: 0.9583\n",
      "73/73 [==============================] - 0s 240us/sample - loss: 0.2194 - accuracy: 0.9589\n",
      "74/74 [==============================] - 0s 271us/sample - loss: 0.2351 - accuracy: 0.9459\n",
      "73/73 [==============================] - 0s 282us/sample - loss: 0.2672 - accuracy: 0.9315\n",
      "70/70 [==============================] - 0s 302us/sample - loss: 0.2366 - accuracy: 0.9714\n",
      "70/70 [==============================] - 0s 284us/sample - loss: 0.2054 - accuracy: 0.9714\n",
      "71/71 [==============================] - 0s 291us/sample - loss: 0.2175 - accuracy: 0.9577\n",
      "72/72 [==============================] - 0s 275us/sample - loss: 0.2116 - accuracy: 0.9583\n",
      "73/73 [==============================] - 0s 265us/sample - loss: 0.1878 - accuracy: 0.9863\n",
      "70/70 [==============================] - 0s 422us/sample - loss: 0.1765 - accuracy: 0.9857\n",
      "70/70 [==============================] - 0s 278us/sample - loss: 0.1910 - accuracy: 0.9857\n",
      "68/68 [==============================] - 0s 288us/sample - loss: 0.2053 - accuracy: 0.9706\n",
      "66/66 [==============================] - 0s 293us/sample - loss: 0.2474 - accuracy: 0.9545\n",
      "67/67 [==============================] - 0s 279us/sample - loss: 0.2039 - accuracy: 0.9701\n",
      "66/66 [==============================] - 0s 322us/sample - loss: 0.1958 - accuracy: 0.9697\n",
      "65/65 [==============================] - 0s 338us/sample - loss: 0.2324 - accuracy: 0.9231\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.2168 - accuracy: 0.9531\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.2432 - accuracy: 0.9531\n",
      "65/65 [==============================] - 0s 284us/sample - loss: 0.2339 - accuracy: 0.9538\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 0.2472 - accuracy: 0.9531\n",
      "63/63 [==============================] - 0s 278us/sample - loss: 0.2638 - accuracy: 0.8730\n",
      "64/64 [==============================] - 0s 247us/sample - loss: 0.2141 - accuracy: 0.9688\n",
      "64/64 [==============================] - 0s 245us/sample - loss: 0.1794 - accuracy: 0.9844\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 0.1963 - accuracy: 0.9688\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2863 samples, validate on 726 samples\n",
      "Epoch 1/300\n",
      "2863/2863 [==============================] - 3s 914us/sample - loss: 0.6992 - accuracy: 0.5365 - val_loss: 0.6745 - val_accuracy: 0.5675\n",
      "Epoch 2/300\n",
      "2863/2863 [==============================] - 1s 201us/sample - loss: 0.6680 - accuracy: 0.5899 - val_loss: 0.6550 - val_accuracy: 0.6143\n",
      "Epoch 3/300\n",
      "2863/2863 [==============================] - 1s 195us/sample - loss: 0.6458 - accuracy: 0.6298 - val_loss: 0.6417 - val_accuracy: 0.6433\n",
      "Epoch 4/300\n",
      "2863/2863 [==============================] - 1s 197us/sample - loss: 0.6274 - accuracy: 0.6598 - val_loss: 0.6314 - val_accuracy: 0.6584\n",
      "Epoch 5/300\n",
      "2863/2863 [==============================] - 1s 184us/sample - loss: 0.6186 - accuracy: 0.6856 - val_loss: 0.6229 - val_accuracy: 0.6791\n",
      "Epoch 6/300\n",
      "2863/2863 [==============================] - 1s 257us/sample - loss: 0.6066 - accuracy: 0.6895 - val_loss: 0.6157 - val_accuracy: 0.6873\n",
      "Epoch 7/300\n",
      "2863/2863 [==============================] - 1s 194us/sample - loss: 0.5969 - accuracy: 0.7031 - val_loss: 0.6093 - val_accuracy: 0.6970\n",
      "Epoch 8/300\n",
      "2863/2863 [==============================] - 1s 226us/sample - loss: 0.5902 - accuracy: 0.7143 - val_loss: 0.6038 - val_accuracy: 0.7066\n",
      "Epoch 9/300\n",
      "2863/2863 [==============================] - 1s 233us/sample - loss: 0.5827 - accuracy: 0.7216 - val_loss: 0.5987 - val_accuracy: 0.7121\n",
      "Epoch 10/300\n",
      "2863/2863 [==============================] - 1s 212us/sample - loss: 0.5759 - accuracy: 0.7279 - val_loss: 0.5943 - val_accuracy: 0.7204\n",
      "Epoch 11/300\n",
      "2863/2863 [==============================] - 1s 192us/sample - loss: 0.5674 - accuracy: 0.7314 - val_loss: 0.5901 - val_accuracy: 0.7218\n",
      "Epoch 12/300\n",
      "2863/2863 [==============================] - 1s 203us/sample - loss: 0.5611 - accuracy: 0.7363 - val_loss: 0.5862 - val_accuracy: 0.7314\n",
      "Epoch 13/300\n",
      "2863/2863 [==============================] - 1s 184us/sample - loss: 0.5571 - accuracy: 0.7408 - val_loss: 0.5828 - val_accuracy: 0.7355\n",
      "Epoch 14/300\n",
      "2863/2863 [==============================] - 1s 210us/sample - loss: 0.5511 - accuracy: 0.7503 - val_loss: 0.5796 - val_accuracy: 0.7355\n",
      "Epoch 15/300\n",
      "2863/2863 [==============================] - 1s 205us/sample - loss: 0.5422 - accuracy: 0.7621 - val_loss: 0.5765 - val_accuracy: 0.7369\n",
      "Epoch 16/300\n",
      "2863/2863 [==============================] - 1s 193us/sample - loss: 0.5421 - accuracy: 0.7576 - val_loss: 0.5737 - val_accuracy: 0.7410\n",
      "Epoch 17/300\n",
      "2863/2863 [==============================] - 1s 243us/sample - loss: 0.5359 - accuracy: 0.7593 - val_loss: 0.5711 - val_accuracy: 0.7410\n",
      "Epoch 18/300\n",
      "2863/2863 [==============================] - 1s 259us/sample - loss: 0.5295 - accuracy: 0.7674 - val_loss: 0.5686 - val_accuracy: 0.7452\n",
      "Epoch 19/300\n",
      "2863/2863 [==============================] - 1s 228us/sample - loss: 0.5223 - accuracy: 0.7716 - val_loss: 0.5663 - val_accuracy: 0.7466\n",
      "Epoch 20/300\n",
      "2863/2863 [==============================] - 1s 198us/sample - loss: 0.5259 - accuracy: 0.7730 - val_loss: 0.5642 - val_accuracy: 0.7466\n",
      "Epoch 21/300\n",
      "2863/2863 [==============================] - 1s 252us/sample - loss: 0.5157 - accuracy: 0.7800 - val_loss: 0.5622 - val_accuracy: 0.7466\n",
      "Epoch 22/300\n",
      "2863/2863 [==============================] - 1s 243us/sample - loss: 0.5152 - accuracy: 0.7730 - val_loss: 0.5604 - val_accuracy: 0.7479\n",
      "Epoch 23/300\n",
      "2863/2863 [==============================] - 1s 188us/sample - loss: 0.5098 - accuracy: 0.7841 - val_loss: 0.5586 - val_accuracy: 0.7493\n",
      "Epoch 24/300\n",
      "2863/2863 [==============================] - 1s 207us/sample - loss: 0.5053 - accuracy: 0.7827 - val_loss: 0.5569 - val_accuracy: 0.7507\n",
      "Epoch 25/300\n",
      "2863/2863 [==============================] - 1s 234us/sample - loss: 0.5032 - accuracy: 0.7869 - val_loss: 0.5554 - val_accuracy: 0.7507\n",
      "Epoch 26/300\n",
      "2863/2863 [==============================] - 1s 214us/sample - loss: 0.4998 - accuracy: 0.7820 - val_loss: 0.5539 - val_accuracy: 0.7507\n",
      "Epoch 27/300\n",
      "2863/2863 [==============================] - 1s 255us/sample - loss: 0.4942 - accuracy: 0.7831 - val_loss: 0.5525 - val_accuracy: 0.7521\n",
      "Epoch 28/300\n",
      "2863/2863 [==============================] - 1s 217us/sample - loss: 0.4912 - accuracy: 0.7925 - val_loss: 0.5512 - val_accuracy: 0.7548\n",
      "Epoch 29/300\n",
      "2863/2863 [==============================] - 1s 207us/sample - loss: 0.4889 - accuracy: 0.7908 - val_loss: 0.5500 - val_accuracy: 0.7562\n",
      "Epoch 30/300\n",
      "2863/2863 [==============================] - 1s 209us/sample - loss: 0.4798 - accuracy: 0.7964 - val_loss: 0.5489 - val_accuracy: 0.7562\n",
      "Epoch 31/300\n",
      "2863/2863 [==============================] - 1s 216us/sample - loss: 0.4805 - accuracy: 0.7953 - val_loss: 0.5479 - val_accuracy: 0.7576\n",
      "Epoch 32/300\n",
      "2863/2863 [==============================] - 1s 205us/sample - loss: 0.4754 - accuracy: 0.7950 - val_loss: 0.5468 - val_accuracy: 0.7562\n",
      "Epoch 33/300\n",
      "2863/2863 [==============================] - 1s 240us/sample - loss: 0.4738 - accuracy: 0.7988 - val_loss: 0.5459 - val_accuracy: 0.7548\n",
      "Epoch 34/300\n",
      "2863/2863 [==============================] - 1s 208us/sample - loss: 0.4692 - accuracy: 0.8044 - val_loss: 0.5450 - val_accuracy: 0.7548\n",
      "Epoch 35/300\n",
      "2863/2863 [==============================] - 1s 205us/sample - loss: 0.4671 - accuracy: 0.7992 - val_loss: 0.5442 - val_accuracy: 0.7576\n",
      "Epoch 36/300\n",
      "2863/2863 [==============================] - 1s 208us/sample - loss: 0.4645 - accuracy: 0.8020 - val_loss: 0.5435 - val_accuracy: 0.7576\n",
      "Epoch 37/300\n",
      "2863/2863 [==============================] - 1s 268us/sample - loss: 0.4649 - accuracy: 0.8020 - val_loss: 0.5428 - val_accuracy: 0.7576\n",
      "Epoch 38/300\n",
      "2863/2863 [==============================] - 1s 243us/sample - loss: 0.4610 - accuracy: 0.8054 - val_loss: 0.5421 - val_accuracy: 0.7590\n",
      "Epoch 39/300\n",
      "2863/2863 [==============================] - 1s 228us/sample - loss: 0.4571 - accuracy: 0.8061 - val_loss: 0.5415 - val_accuracy: 0.7590\n",
      "Epoch 40/300\n",
      "2863/2863 [==============================] - 1s 252us/sample - loss: 0.4527 - accuracy: 0.8041 - val_loss: 0.5410 - val_accuracy: 0.7590\n",
      "Epoch 41/300\n",
      "2863/2863 [==============================] - 1s 220us/sample - loss: 0.4506 - accuracy: 0.8121 - val_loss: 0.5405 - val_accuracy: 0.7590\n",
      "Epoch 42/300\n",
      "2863/2863 [==============================] - 1s 231us/sample - loss: 0.4513 - accuracy: 0.8065 - val_loss: 0.5401 - val_accuracy: 0.7590\n",
      "Epoch 43/300\n",
      "2863/2863 [==============================] - 1s 210us/sample - loss: 0.4456 - accuracy: 0.8131 - val_loss: 0.5397 - val_accuracy: 0.7590\n",
      "Epoch 44/300\n",
      "2863/2863 [==============================] - 1s 230us/sample - loss: 0.4397 - accuracy: 0.8096 - val_loss: 0.5393 - val_accuracy: 0.7590\n",
      "Epoch 45/300\n",
      "2863/2863 [==============================] - 1s 194us/sample - loss: 0.4384 - accuracy: 0.8075 - val_loss: 0.5389 - val_accuracy: 0.7590\n",
      "Epoch 46/300\n",
      "2863/2863 [==============================] - 1s 216us/sample - loss: 0.4340 - accuracy: 0.8135 - val_loss: 0.5387 - val_accuracy: 0.7590\n",
      "Epoch 47/300\n",
      "2863/2863 [==============================] - 1s 195us/sample - loss: 0.4352 - accuracy: 0.8170 - val_loss: 0.5385 - val_accuracy: 0.7590\n",
      "Epoch 48/300\n",
      "2863/2863 [==============================] - 1s 211us/sample - loss: 0.4296 - accuracy: 0.8152 - val_loss: 0.5383 - val_accuracy: 0.7590\n",
      "Epoch 49/300\n",
      "2863/2863 [==============================] - 1s 225us/sample - loss: 0.4338 - accuracy: 0.8152 - val_loss: 0.5381 - val_accuracy: 0.7603\n",
      "Epoch 50/300\n",
      "2863/2863 [==============================] - 1s 211us/sample - loss: 0.4253 - accuracy: 0.8191 - val_loss: 0.5379 - val_accuracy: 0.7603\n",
      "Epoch 51/300\n",
      "2863/2863 [==============================] - 1s 217us/sample - loss: 0.4242 - accuracy: 0.8198 - val_loss: 0.5378 - val_accuracy: 0.7576\n",
      "Epoch 52/300\n",
      "2863/2863 [==============================] - 1s 219us/sample - loss: 0.4211 - accuracy: 0.8191 - val_loss: 0.5378 - val_accuracy: 0.7576\n",
      "Epoch 53/300\n",
      "2863/2863 [==============================] - 1s 211us/sample - loss: 0.4180 - accuracy: 0.8205 - val_loss: 0.5377 - val_accuracy: 0.7590\n",
      "Epoch 54/300\n",
      "2863/2863 [==============================] - 1s 230us/sample - loss: 0.4121 - accuracy: 0.8261 - val_loss: 0.5377 - val_accuracy: 0.7590\n",
      "Epoch 55/300\n",
      "2863/2863 [==============================] - 1s 214us/sample - loss: 0.4140 - accuracy: 0.8233 - val_loss: 0.5377 - val_accuracy: 0.7590\n",
      "Epoch 56/300\n",
      "2863/2863 [==============================] - 1s 227us/sample - loss: 0.4126 - accuracy: 0.8285 - val_loss: 0.5377 - val_accuracy: 0.7576\n",
      "Epoch 00056: early stopping\n",
      "60/60 [==============================] - 0s 226us/sample - loss: 0.2807 - accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [2:57:17, 1066.80s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.56s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.27s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 834.4921875 steps, validate for 216.2109375 steps\n",
      "Epoch 1/300\n",
      "835/834 [==============================] - 25s 30ms/step - loss: 0.6209 - accuracy: 0.6727 - val_loss: 0.5304 - val_accuracy: 0.7694\n",
      "Epoch 2/300\n",
      "835/834 [==============================] - 24s 28ms/step - loss: 0.5173 - accuracy: 0.7728 - val_loss: 0.5266 - val_accuracy: 0.7701\n",
      "Epoch 3/300\n",
      "835/834 [==============================] - 24s 29ms/step - loss: 0.5011 - accuracy: 0.7779 - val_loss: 0.5237 - val_accuracy: 0.7711\n",
      "Epoch 4/300\n",
      "835/834 [==============================] - 24s 29ms/step - loss: 0.4892 - accuracy: 0.7826 - val_loss: 0.5287 - val_accuracy: 0.7686\n",
      "Epoch 5/300\n",
      "835/834 [==============================] - 24s 29ms/step - loss: 0.4787 - accuracy: 0.7865 - val_loss: 0.5271 - val_accuracy: 0.7691\n",
      "Epoch 6/300\n",
      "835/834 [==============================] - 24s 29ms/step - loss: 0.4692 - accuracy: 0.7909 - val_loss: 0.5317 - val_accuracy: 0.7655\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 834.4921875 steps, validate for 216.2109375 steps\n",
      "Epoch 1/300\n",
      "835/834 [==============================] - 55s 66ms/step - loss: 0.4531 - accuracy: 0.8000 - val_loss: 0.5595 - val_accuracy: 0.7368\n",
      "Epoch 2/300\n",
      "835/834 [==============================] - 54s 64ms/step - loss: 0.4273 - accuracy: 0.8129 - val_loss: 0.5489 - val_accuracy: 0.7686\n",
      "Epoch 3/300\n",
      "835/834 [==============================] - 54s 64ms/step - loss: 0.4059 - accuracy: 0.8245 - val_loss: 0.5622 - val_accuracy: 0.7437\n",
      "Epoch 4/300\n",
      "835/834 [==============================] - 54s 64ms/step - loss: 0.3865 - accuracy: 0.8361 - val_loss: 0.5734 - val_accuracy: 0.7666\n",
      "Epoch 5/300\n",
      "835/834 [==============================] - 54s 64ms/step - loss: 0.3680 - accuracy: 0.8455 - val_loss: 0.5722 - val_accuracy: 0.7654\n",
      "Epoch 00005: early stopping\n",
      "127/127 [==============================] - 0s 2ms/sample - loss: 0.2264 - accuracy: 0.9528\n",
      "126/126 [==============================] - 0s 234us/sample - loss: 0.2112 - accuracy: 0.9762\n",
      "126/126 [==============================] - 0s 212us/sample - loss: 0.2295 - accuracy: 0.9444\n",
      "126/126 [==============================] - 0s 217us/sample - loss: 0.2097 - accuracy: 0.9762\n",
      "118/118 [==============================] - 0s 240us/sample - loss: 0.2103 - accuracy: 0.9576\n",
      "110/110 [==============================] - 0s 245us/sample - loss: 0.2217 - accuracy: 0.9727\n",
      "108/108 [==============================] - 0s 244us/sample - loss: 0.2102 - accuracy: 1.0000\n",
      "103/103 [==============================] - 0s 245us/sample - loss: 0.2245 - accuracy: 0.9612\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 0.2111 - accuracy: 0.9700\n",
      "98/98 [==============================] - 0s 277us/sample - loss: 0.1975 - accuracy: 0.9796\n",
      "98/98 [==============================] - 0s 238us/sample - loss: 0.2076 - accuracy: 0.9898\n",
      "97/97 [==============================] - 0s 272us/sample - loss: 0.2167 - accuracy: 0.9691\n",
      "97/97 [==============================] - 0s 264us/sample - loss: 0.2340 - accuracy: 0.9381\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1808 - accuracy: 0.9896\n",
      "97/97 [==============================] - 0s 279us/sample - loss: 0.2431 - accuracy: 0.9381\n",
      "96/96 [==============================] - 0s 242us/sample - loss: 0.2137 - accuracy: 0.9688\n",
      "94/94 [==============================] - 0s 279us/sample - loss: 0.2161 - accuracy: 0.9787\n",
      "94/94 [==============================] - 0s 272us/sample - loss: 0.2051 - accuracy: 0.9894\n",
      "92/92 [==============================] - 0s 275us/sample - loss: 0.2313 - accuracy: 0.9674\n",
      "94/94 [==============================] - 0s 258us/sample - loss: 0.1772 - accuracy: 1.0000\n",
      "92/92 [==============================] - 0s 353us/sample - loss: 0.2095 - accuracy: 0.9674\n",
      "90/90 [==============================] - 0s 249us/sample - loss: 0.1879 - accuracy: 0.9889\n",
      "92/92 [==============================] - 0s 290us/sample - loss: 0.2145 - accuracy: 0.9783\n",
      "92/92 [==============================] - 0s 261us/sample - loss: 0.2208 - accuracy: 0.9674\n",
      "94/94 [==============================] - 0s 238us/sample - loss: 0.2098 - accuracy: 0.9894\n",
      "93/93 [==============================] - 0s 242us/sample - loss: 0.2167 - accuracy: 0.9677\n",
      "94/94 [==============================] - 0s 264us/sample - loss: 0.2362 - accuracy: 0.9681\n",
      "93/93 [==============================] - 0s 246us/sample - loss: 0.1869 - accuracy: 1.0000\n",
      "91/91 [==============================] - 0s 252us/sample - loss: 0.2040 - accuracy: 0.9670\n",
      "92/92 [==============================] - 0s 255us/sample - loss: 0.2060 - accuracy: 0.9783\n",
      "90/90 [==============================] - 0s 263us/sample - loss: 0.1943 - accuracy: 0.9889\n",
      "89/89 [==============================] - 0s 262us/sample - loss: 0.2161 - accuracy: 0.9438\n",
      "89/89 [==============================] - 0s 269us/sample - loss: 0.2616 - accuracy: 0.9438\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2840 samples, validate on 734 samples\n",
      "Epoch 1/300\n",
      "2840/2840 [==============================] - 3s 955us/sample - loss: 0.7103 - accuracy: 0.5338 - val_loss: 0.6622 - val_accuracy: 0.5967\n",
      "Epoch 2/300\n",
      "2840/2840 [==============================] - 1s 234us/sample - loss: 0.6650 - accuracy: 0.6074 - val_loss: 0.6397 - val_accuracy: 0.6294\n",
      "Epoch 3/300\n",
      "2840/2840 [==============================] - 1s 236us/sample - loss: 0.6397 - accuracy: 0.6496 - val_loss: 0.6243 - val_accuracy: 0.6717\n",
      "Epoch 4/300\n",
      "2840/2840 [==============================] - 1s 241us/sample - loss: 0.6258 - accuracy: 0.6711 - val_loss: 0.6128 - val_accuracy: 0.6921\n",
      "Epoch 5/300\n",
      "2840/2840 [==============================] - 1s 260us/sample - loss: 0.6099 - accuracy: 0.6838 - val_loss: 0.6040 - val_accuracy: 0.7030\n",
      "Epoch 6/300\n",
      "2840/2840 [==============================] - 1s 258us/sample - loss: 0.5980 - accuracy: 0.7018 - val_loss: 0.5963 - val_accuracy: 0.7166\n",
      "Epoch 7/300\n",
      "2840/2840 [==============================] - 1s 244us/sample - loss: 0.5826 - accuracy: 0.7306 - val_loss: 0.5900 - val_accuracy: 0.7234\n",
      "Epoch 8/300\n",
      "2840/2840 [==============================] - 1s 230us/sample - loss: 0.5754 - accuracy: 0.7264 - val_loss: 0.5845 - val_accuracy: 0.7262\n",
      "Epoch 9/300\n",
      "2840/2840 [==============================] - 1s 233us/sample - loss: 0.5679 - accuracy: 0.7384 - val_loss: 0.5797 - val_accuracy: 0.7275\n",
      "Epoch 10/300\n",
      "2840/2840 [==============================] - 1s 223us/sample - loss: 0.5581 - accuracy: 0.7458 - val_loss: 0.5756 - val_accuracy: 0.7330\n",
      "Epoch 11/300\n",
      "2840/2840 [==============================] - 1s 223us/sample - loss: 0.5516 - accuracy: 0.7468 - val_loss: 0.5719 - val_accuracy: 0.7371\n",
      "Epoch 12/300\n",
      "2840/2840 [==============================] - 1s 215us/sample - loss: 0.5469 - accuracy: 0.7546 - val_loss: 0.5687 - val_accuracy: 0.7452\n",
      "Epoch 13/300\n",
      "2840/2840 [==============================] - 1s 238us/sample - loss: 0.5419 - accuracy: 0.7570 - val_loss: 0.5657 - val_accuracy: 0.7452\n",
      "Epoch 14/300\n",
      "2840/2840 [==============================] - 1s 224us/sample - loss: 0.5335 - accuracy: 0.7676 - val_loss: 0.5630 - val_accuracy: 0.7439\n",
      "Epoch 15/300\n",
      "2840/2840 [==============================] - 1s 259us/sample - loss: 0.5266 - accuracy: 0.7739 - val_loss: 0.5608 - val_accuracy: 0.7452\n",
      "Epoch 16/300\n",
      "2840/2840 [==============================] - 1s 226us/sample - loss: 0.5210 - accuracy: 0.7718 - val_loss: 0.5587 - val_accuracy: 0.7452\n",
      "Epoch 17/300\n",
      "2840/2840 [==============================] - 1s 236us/sample - loss: 0.5196 - accuracy: 0.7782 - val_loss: 0.5569 - val_accuracy: 0.7493\n",
      "Epoch 18/300\n",
      "2840/2840 [==============================] - 1s 216us/sample - loss: 0.5139 - accuracy: 0.7746 - val_loss: 0.5552 - val_accuracy: 0.7480\n",
      "Epoch 19/300\n",
      "2840/2840 [==============================] - 1s 251us/sample - loss: 0.5118 - accuracy: 0.7778 - val_loss: 0.5537 - val_accuracy: 0.7480\n",
      "Epoch 20/300\n",
      "2840/2840 [==============================] - 1s 257us/sample - loss: 0.5053 - accuracy: 0.7806 - val_loss: 0.5524 - val_accuracy: 0.7480\n",
      "Epoch 21/300\n",
      "2840/2840 [==============================] - 1s 251us/sample - loss: 0.5017 - accuracy: 0.7838 - val_loss: 0.5512 - val_accuracy: 0.7507\n",
      "Epoch 22/300\n",
      "2840/2840 [==============================] - 1s 223us/sample - loss: 0.4945 - accuracy: 0.7842 - val_loss: 0.5502 - val_accuracy: 0.7534\n",
      "Epoch 23/300\n",
      "2840/2840 [==============================] - 1s 229us/sample - loss: 0.4933 - accuracy: 0.7845 - val_loss: 0.5492 - val_accuracy: 0.7548\n",
      "Epoch 24/300\n",
      "2840/2840 [==============================] - 1s 267us/sample - loss: 0.4859 - accuracy: 0.7926 - val_loss: 0.5484 - val_accuracy: 0.7548\n",
      "Epoch 25/300\n",
      "2840/2840 [==============================] - 1s 265us/sample - loss: 0.4833 - accuracy: 0.7905 - val_loss: 0.5478 - val_accuracy: 0.7548\n",
      "Epoch 26/300\n",
      "2840/2840 [==============================] - 1s 240us/sample - loss: 0.4811 - accuracy: 0.7923 - val_loss: 0.5471 - val_accuracy: 0.7548\n",
      "Epoch 27/300\n",
      "2840/2840 [==============================] - 1s 226us/sample - loss: 0.4797 - accuracy: 0.7954 - val_loss: 0.5466 - val_accuracy: 0.7534\n",
      "Epoch 28/300\n",
      "2840/2840 [==============================] - 1s 273us/sample - loss: 0.4734 - accuracy: 0.8004 - val_loss: 0.5461 - val_accuracy: 0.7575\n",
      "Epoch 29/300\n",
      "2840/2840 [==============================] - 1s 235us/sample - loss: 0.4737 - accuracy: 0.7958 - val_loss: 0.5457 - val_accuracy: 0.7575\n",
      "Epoch 30/300\n",
      "2840/2840 [==============================] - 1s 255us/sample - loss: 0.4680 - accuracy: 0.7954 - val_loss: 0.5454 - val_accuracy: 0.7561\n",
      "Epoch 31/300\n",
      "2840/2840 [==============================] - 1s 246us/sample - loss: 0.4664 - accuracy: 0.7923 - val_loss: 0.5451 - val_accuracy: 0.7561\n",
      "Epoch 32/300\n",
      "2840/2840 [==============================] - 1s 266us/sample - loss: 0.4617 - accuracy: 0.8046 - val_loss: 0.5448 - val_accuracy: 0.7561\n",
      "Epoch 33/300\n",
      "2840/2840 [==============================] - 1s 235us/sample - loss: 0.4607 - accuracy: 0.8039 - val_loss: 0.5446 - val_accuracy: 0.7561\n",
      "Epoch 34/300\n",
      "2840/2840 [==============================] - 1s 206us/sample - loss: 0.4577 - accuracy: 0.8035 - val_loss: 0.5444 - val_accuracy: 0.7561\n",
      "Epoch 35/300\n",
      "2840/2840 [==============================] - 1s 232us/sample - loss: 0.4541 - accuracy: 0.8085 - val_loss: 0.5443 - val_accuracy: 0.7575\n",
      "Epoch 36/300\n",
      "2840/2840 [==============================] - 1s 199us/sample - loss: 0.4510 - accuracy: 0.8039 - val_loss: 0.5442 - val_accuracy: 0.7575\n",
      "Epoch 37/300\n",
      "2840/2840 [==============================] - 1s 250us/sample - loss: 0.4465 - accuracy: 0.8060 - val_loss: 0.5442 - val_accuracy: 0.7575\n",
      "Epoch 38/300\n",
      "2840/2840 [==============================] - 1s 239us/sample - loss: 0.4474 - accuracy: 0.8092 - val_loss: 0.5442 - val_accuracy: 0.7589\n",
      "Epoch 39/300\n",
      "2840/2840 [==============================] - 1s 240us/sample - loss: 0.4431 - accuracy: 0.8085 - val_loss: 0.5442 - val_accuracy: 0.7589\n",
      "Epoch 40/300\n",
      "2840/2840 [==============================] - 1s 231us/sample - loss: 0.4407 - accuracy: 0.8102 - val_loss: 0.5443 - val_accuracy: 0.7589\n",
      "Epoch 41/300\n",
      "2840/2840 [==============================] - 1s 220us/sample - loss: 0.4419 - accuracy: 0.8081 - val_loss: 0.5444 - val_accuracy: 0.7589\n",
      "Epoch 00041: early stopping\n",
      "75/75 [==============================] - 0s 167us/sample - loss: 0.2939 - accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [3:15:29, 1074.28s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.63s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.30s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 828.0859375 steps, validate for 214.6015625 steps\n",
      "Epoch 1/300\n",
      "829/828 [==============================] - 25s 30ms/step - loss: 0.6973 - accuracy: 0.6070 - val_loss: 0.5384 - val_accuracy: 0.7707\n",
      "Epoch 2/300\n",
      "829/828 [==============================] - 24s 29ms/step - loss: 0.5175 - accuracy: 0.7725 - val_loss: 0.5370 - val_accuracy: 0.7693\n",
      "Epoch 3/300\n",
      "829/828 [==============================] - 24s 29ms/step - loss: 0.5011 - accuracy: 0.7783 - val_loss: 0.5344 - val_accuracy: 0.7692\n",
      "Epoch 4/300\n",
      "829/828 [==============================] - 24s 29ms/step - loss: 0.4895 - accuracy: 0.7828 - val_loss: 0.5359 - val_accuracy: 0.7671\n",
      "Epoch 5/300\n",
      "829/828 [==============================] - 24s 29ms/step - loss: 0.4796 - accuracy: 0.7876 - val_loss: 0.5367 - val_accuracy: 0.7665\n",
      "Epoch 6/300\n",
      "829/828 [==============================] - 24s 29ms/step - loss: 0.4707 - accuracy: 0.7920 - val_loss: 0.5394 - val_accuracy: 0.7654\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 828.0859375 steps, validate for 214.6015625 steps\n",
      "Epoch 1/300\n",
      "829/828 [==============================] - 55s 66ms/step - loss: 0.4544 - accuracy: 0.7994 - val_loss: 0.5535 - val_accuracy: 0.7418\n",
      "Epoch 2/300\n",
      "829/828 [==============================] - 53s 64ms/step - loss: 0.4284 - accuracy: 0.8139 - val_loss: 0.5482 - val_accuracy: 0.7543\n",
      "Epoch 3/300\n",
      "829/828 [==============================] - 53s 65ms/step - loss: 0.4067 - accuracy: 0.8252 - val_loss: 0.5640 - val_accuracy: 0.7415\n",
      "Epoch 4/300\n",
      "829/828 [==============================] - 53s 64ms/step - loss: 0.3874 - accuracy: 0.8357 - val_loss: 0.6143 - val_accuracy: 0.7697\n",
      "Epoch 5/300\n",
      "829/828 [==============================] - 53s 64ms/step - loss: 0.3689 - accuracy: 0.8455 - val_loss: 0.5569 - val_accuracy: 0.7535\n",
      "Epoch 00005: early stopping\n",
      "144/144 [==============================] - 0s 2ms/sample - loss: 0.2888 - accuracy: 0.9236\n",
      "138/138 [==============================] - 0s 236us/sample - loss: 0.3184 - accuracy: 0.9058\n",
      "138/138 [==============================] - 0s 258us/sample - loss: 0.3277 - accuracy: 0.9130\n",
      "137/137 [==============================] - 0s 286us/sample - loss: 0.3135 - accuracy: 0.9051\n",
      "137/137 [==============================] - 0s 268us/sample - loss: 0.3415 - accuracy: 0.8978\n",
      "137/137 [==============================] - 0s 220us/sample - loss: 0.2998 - accuracy: 0.9270\n",
      "136/136 [==============================] - 0s 239us/sample - loss: 0.3122 - accuracy: 0.9265\n",
      "135/135 [==============================] - 0s 257us/sample - loss: 0.3396 - accuracy: 0.8963\n",
      "133/133 [==============================] - 0s 229us/sample - loss: 0.3230 - accuracy: 0.9023\n",
      "134/134 [==============================] - 0s 340us/sample - loss: 0.3661 - accuracy: 0.8806\n",
      "134/134 [==============================] - 0s 241us/sample - loss: 0.3051 - accuracy: 0.9403\n",
      "133/133 [==============================] - 0s 263us/sample - loss: 0.3632 - accuracy: 0.8722\n",
      "133/133 [==============================] - 0s 287us/sample - loss: 0.3143 - accuracy: 0.8947\n",
      "133/133 [==============================] - 0s 248us/sample - loss: 0.3391 - accuracy: 0.8872\n",
      "129/129 [==============================] - 0s 305us/sample - loss: 0.3136 - accuracy: 0.9457\n",
      "129/129 [==============================] - 0s 296us/sample - loss: 0.3759 - accuracy: 0.8837\n",
      "132/132 [==============================] - 0s 254us/sample - loss: 0.3196 - accuracy: 0.9318\n",
      "129/129 [==============================] - 0s 283us/sample - loss: 0.3681 - accuracy: 0.8682\n",
      "131/131 [==============================] - 0s 255us/sample - loss: 0.3292 - accuracy: 0.9160\n",
      "130/130 [==============================] - 0s 328us/sample - loss: 0.3209 - accuracy: 0.9077\n",
      "129/129 [==============================] - 0s 253us/sample - loss: 0.3626 - accuracy: 0.8915\n",
      "127/127 [==============================] - 0s 267us/sample - loss: 0.3319 - accuracy: 0.9134\n",
      "124/124 [==============================] - 0s 269us/sample - loss: 0.3869 - accuracy: 0.8871\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.3411 - accuracy: 0.8750\n",
      "128/128 [==============================] - 0s 255us/sample - loss: 0.3890 - accuracy: 0.8594\n",
      "126/126 [==============================] - 0s 248us/sample - loss: 0.3725 - accuracy: 0.8492\n",
      "124/124 [==============================] - 0s 236us/sample - loss: 0.3428 - accuracy: 0.8548\n",
      "124/124 [==============================] - 0s 260us/sample - loss: 0.3555 - accuracy: 0.8710\n",
      "124/124 [==============================] - 0s 243us/sample - loss: 0.3461 - accuracy: 0.9032\n",
      "125/125 [==============================] - 0s 233us/sample - loss: 0.3214 - accuracy: 0.8960\n",
      "126/126 [==============================] - 0s 250us/sample - loss: 0.3211 - accuracy: 0.9127\n",
      "123/123 [==============================] - 0s 294us/sample - loss: 0.3139 - accuracy: 0.9187\n",
      "124/124 [==============================] - 0s 246us/sample - loss: 0.3137 - accuracy: 0.9032\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2806 samples, validate on 726 samples\n",
      "Epoch 1/300\n",
      "2806/2806 [==============================] - 2s 861us/sample - loss: 0.6868 - accuracy: 0.5577 - val_loss: 0.6700 - val_accuracy: 0.5813\n",
      "Epoch 2/300\n",
      "2806/2806 [==============================] - 1s 218us/sample - loss: 0.6473 - accuracy: 0.6283 - val_loss: 0.6486 - val_accuracy: 0.6433\n",
      "Epoch 3/300\n",
      "2806/2806 [==============================] - 1s 223us/sample - loss: 0.6289 - accuracy: 0.6547 - val_loss: 0.6336 - val_accuracy: 0.6667\n",
      "Epoch 4/300\n",
      "2806/2806 [==============================] - 1s 257us/sample - loss: 0.6054 - accuracy: 0.7088 - val_loss: 0.6224 - val_accuracy: 0.6915\n",
      "Epoch 5/300\n",
      "2806/2806 [==============================] - 1s 225us/sample - loss: 0.5917 - accuracy: 0.7252 - val_loss: 0.6128 - val_accuracy: 0.7080\n",
      "Epoch 6/300\n",
      "2806/2806 [==============================] - 1s 253us/sample - loss: 0.5787 - accuracy: 0.7406 - val_loss: 0.6048 - val_accuracy: 0.7163\n",
      "Epoch 7/300\n",
      "2806/2806 [==============================] - 1s 225us/sample - loss: 0.5682 - accuracy: 0.7587 - val_loss: 0.5978 - val_accuracy: 0.7190\n",
      "Epoch 8/300\n",
      "2806/2806 [==============================] - 0s 168us/sample - loss: 0.5549 - accuracy: 0.7744 - val_loss: 0.5915 - val_accuracy: 0.7300\n",
      "Epoch 9/300\n",
      "2806/2806 [==============================] - 0s 170us/sample - loss: 0.5449 - accuracy: 0.7716 - val_loss: 0.5859 - val_accuracy: 0.7355\n",
      "Epoch 10/300\n",
      "2806/2806 [==============================] - 1s 203us/sample - loss: 0.5394 - accuracy: 0.7819 - val_loss: 0.5808 - val_accuracy: 0.7438\n",
      "Epoch 11/300\n",
      "2806/2806 [==============================] - 1s 215us/sample - loss: 0.5308 - accuracy: 0.7872 - val_loss: 0.5763 - val_accuracy: 0.7507\n",
      "Epoch 12/300\n",
      "2806/2806 [==============================] - 1s 221us/sample - loss: 0.5254 - accuracy: 0.7904 - val_loss: 0.5721 - val_accuracy: 0.7548\n",
      "Epoch 13/300\n",
      "2806/2806 [==============================] - 1s 223us/sample - loss: 0.5121 - accuracy: 0.7986 - val_loss: 0.5684 - val_accuracy: 0.7562\n",
      "Epoch 14/300\n",
      "2806/2806 [==============================] - 1s 210us/sample - loss: 0.5069 - accuracy: 0.7969 - val_loss: 0.5649 - val_accuracy: 0.7603\n",
      "Epoch 15/300\n",
      "2806/2806 [==============================] - 1s 235us/sample - loss: 0.5037 - accuracy: 0.8036 - val_loss: 0.5616 - val_accuracy: 0.7631\n",
      "Epoch 16/300\n",
      "2806/2806 [==============================] - 1s 229us/sample - loss: 0.4929 - accuracy: 0.8125 - val_loss: 0.5588 - val_accuracy: 0.7658\n",
      "Epoch 17/300\n",
      "2806/2806 [==============================] - 1s 254us/sample - loss: 0.4881 - accuracy: 0.8022 - val_loss: 0.5562 - val_accuracy: 0.7658\n",
      "Epoch 18/300\n",
      "2806/2806 [==============================] - 1s 224us/sample - loss: 0.4873 - accuracy: 0.8140 - val_loss: 0.5537 - val_accuracy: 0.7686\n",
      "Epoch 19/300\n",
      "2806/2806 [==============================] - 1s 213us/sample - loss: 0.4784 - accuracy: 0.8079 - val_loss: 0.5515 - val_accuracy: 0.7686\n",
      "Epoch 20/300\n",
      "2806/2806 [==============================] - 1s 232us/sample - loss: 0.4772 - accuracy: 0.8122 - val_loss: 0.5494 - val_accuracy: 0.7686\n",
      "Epoch 21/300\n",
      "2806/2806 [==============================] - 1s 224us/sample - loss: 0.4701 - accuracy: 0.8168 - val_loss: 0.5476 - val_accuracy: 0.7686\n",
      "Epoch 22/300\n",
      "2806/2806 [==============================] - 1s 208us/sample - loss: 0.4640 - accuracy: 0.8154 - val_loss: 0.5460 - val_accuracy: 0.7686\n",
      "Epoch 23/300\n",
      "2806/2806 [==============================] - 1s 193us/sample - loss: 0.4579 - accuracy: 0.8140 - val_loss: 0.5445 - val_accuracy: 0.7727\n",
      "Epoch 24/300\n",
      "2806/2806 [==============================] - 1s 205us/sample - loss: 0.4560 - accuracy: 0.8154 - val_loss: 0.5432 - val_accuracy: 0.7713\n",
      "Epoch 25/300\n",
      "2806/2806 [==============================] - 1s 229us/sample - loss: 0.4506 - accuracy: 0.8207 - val_loss: 0.5420 - val_accuracy: 0.7741\n",
      "Epoch 26/300\n",
      "2806/2806 [==============================] - 1s 216us/sample - loss: 0.4458 - accuracy: 0.8272 - val_loss: 0.5410 - val_accuracy: 0.7727\n",
      "Epoch 27/300\n",
      "2806/2806 [==============================] - 1s 203us/sample - loss: 0.4409 - accuracy: 0.8247 - val_loss: 0.5400 - val_accuracy: 0.7727\n",
      "Epoch 28/300\n",
      "2806/2806 [==============================] - 1s 212us/sample - loss: 0.4367 - accuracy: 0.8300 - val_loss: 0.5392 - val_accuracy: 0.7741\n",
      "Epoch 29/300\n",
      "2806/2806 [==============================] - 1s 249us/sample - loss: 0.4340 - accuracy: 0.8264 - val_loss: 0.5385 - val_accuracy: 0.7741\n",
      "Epoch 30/300\n",
      "2806/2806 [==============================] - 1s 221us/sample - loss: 0.4261 - accuracy: 0.8325 - val_loss: 0.5379 - val_accuracy: 0.7727\n",
      "Epoch 31/300\n",
      "2806/2806 [==============================] - 1s 199us/sample - loss: 0.4250 - accuracy: 0.8289 - val_loss: 0.5374 - val_accuracy: 0.7727\n",
      "Epoch 32/300\n",
      "2806/2806 [==============================] - 1s 211us/sample - loss: 0.4209 - accuracy: 0.8314 - val_loss: 0.5370 - val_accuracy: 0.7713\n",
      "Epoch 33/300\n",
      "2806/2806 [==============================] - 1s 226us/sample - loss: 0.4178 - accuracy: 0.8343 - val_loss: 0.5367 - val_accuracy: 0.7700\n",
      "Epoch 34/300\n",
      "2806/2806 [==============================] - 1s 230us/sample - loss: 0.4185 - accuracy: 0.8279 - val_loss: 0.5365 - val_accuracy: 0.7700\n",
      "Epoch 35/300\n",
      "2806/2806 [==============================] - 1s 205us/sample - loss: 0.4120 - accuracy: 0.8361 - val_loss: 0.5364 - val_accuracy: 0.7700\n",
      "Epoch 36/300\n",
      "2806/2806 [==============================] - 1s 202us/sample - loss: 0.4073 - accuracy: 0.8357 - val_loss: 0.5363 - val_accuracy: 0.7686\n",
      "Epoch 37/300\n",
      "2806/2806 [==============================] - 1s 207us/sample - loss: 0.4050 - accuracy: 0.8371 - val_loss: 0.5364 - val_accuracy: 0.7686\n",
      "Epoch 38/300\n",
      "2806/2806 [==============================] - 1s 223us/sample - loss: 0.4022 - accuracy: 0.8368 - val_loss: 0.5364 - val_accuracy: 0.7686\n",
      "Epoch 39/300\n",
      "2806/2806 [==============================] - 1s 238us/sample - loss: 0.3959 - accuracy: 0.8378 - val_loss: 0.5365 - val_accuracy: 0.7672\n",
      "Epoch 00039: early stopping\n",
      "117/117 [==============================] - 0s 198us/sample - loss: 0.2655 - accuracy: 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [3:33:34, 1077.35s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.48s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.34s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 833.46875 steps, validate for 210.9609375 steps\n",
      "Epoch 1/300\n",
      "834/833 [==============================] - 25s 30ms/step - loss: 0.5618 - accuracy: 0.7396 - val_loss: 0.5422 - val_accuracy: 0.7675\n",
      "Epoch 2/300\n",
      "834/833 [==============================] - 24s 28ms/step - loss: 0.5149 - accuracy: 0.7726 - val_loss: 0.5412 - val_accuracy: 0.7650\n",
      "Epoch 3/300\n",
      "834/833 [==============================] - 23s 28ms/step - loss: 0.5004 - accuracy: 0.7781 - val_loss: 0.5404 - val_accuracy: 0.7640\n",
      "Epoch 4/300\n",
      "834/833 [==============================] - 24s 29ms/step - loss: 0.4888 - accuracy: 0.7821 - val_loss: 0.5424 - val_accuracy: 0.7605\n",
      "Epoch 5/300\n",
      "834/833 [==============================] - 24s 29ms/step - loss: 0.4789 - accuracy: 0.7867 - val_loss: 0.5439 - val_accuracy: 0.7571\n",
      "Epoch 6/300\n",
      "834/833 [==============================] - 24s 29ms/step - loss: 0.4703 - accuracy: 0.7914 - val_loss: 0.5426 - val_accuracy: 0.7569\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 833.46875 steps, validate for 210.9609375 steps\n",
      "Epoch 1/300\n",
      "834/833 [==============================] - 55s 66ms/step - loss: 0.4535 - accuracy: 0.7995 - val_loss: 0.5526 - val_accuracy: 0.7440\n",
      "Epoch 2/300\n",
      "834/833 [==============================] - 54s 64ms/step - loss: 0.4273 - accuracy: 0.8134 - val_loss: 0.5526 - val_accuracy: 0.7491\n",
      "Epoch 3/300\n",
      "834/833 [==============================] - 54s 64ms/step - loss: 0.4056 - accuracy: 0.8240 - val_loss: 0.5965 - val_accuracy: 0.7596\n",
      "Epoch 4/300\n",
      "834/833 [==============================] - 54s 65ms/step - loss: 0.3858 - accuracy: 0.8352 - val_loss: 0.5529 - val_accuracy: 0.7546\n",
      "Epoch 00004: early stopping\n",
      "134/134 [==============================] - 0s 2ms/sample - loss: 0.2527 - accuracy: 0.9776\n",
      "134/134 [==============================] - 0s 255us/sample - loss: 0.2753 - accuracy: 0.9328\n",
      "131/131 [==============================] - 0s 281us/sample - loss: 0.2939 - accuracy: 0.9313\n",
      "129/129 [==============================] - 0s 354us/sample - loss: 0.2985 - accuracy: 0.9225\n",
      "129/129 [==============================] - 0s 321us/sample - loss: 0.2803 - accuracy: 0.9457\n",
      "129/129 [==============================] - 0s 261us/sample - loss: 0.2913 - accuracy: 0.9380\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.3067 - accuracy: 0.9453\n",
      "126/126 [==============================] - 0s 249us/sample - loss: 0.3257 - accuracy: 0.9048\n",
      "125/125 [==============================] - 0s 251us/sample - loss: 0.3004 - accuracy: 0.9360\n",
      "126/126 [==============================] - 0s 206us/sample - loss: 0.3217 - accuracy: 0.8730\n",
      "126/126 [==============================] - 0s 267us/sample - loss: 0.3276 - accuracy: 0.9048\n",
      "126/126 [==============================] - 0s 275us/sample - loss: 0.3150 - accuracy: 0.9206\n",
      "125/125 [==============================] - 0s 259us/sample - loss: 0.3414 - accuracy: 0.9040\n",
      "126/126 [==============================] - 0s 261us/sample - loss: 0.3699 - accuracy: 0.8571\n",
      "123/123 [==============================] - 0s 266us/sample - loss: 0.3571 - accuracy: 0.8455\n",
      "121/121 [==============================] - 0s 251us/sample - loss: 0.3220 - accuracy: 0.9091\n",
      "122/122 [==============================] - 0s 281us/sample - loss: 0.3462 - accuracy: 0.8689\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.3552 - accuracy: 0.8667\n",
      "121/121 [==============================] - 0s 252us/sample - loss: 0.3389 - accuracy: 0.9256\n",
      "121/121 [==============================] - 0s 255us/sample - loss: 0.3463 - accuracy: 0.8760\n",
      "123/123 [==============================] - 0s 258us/sample - loss: 0.3500 - accuracy: 0.8862\n",
      "123/123 [==============================] - 0s 268us/sample - loss: 0.4051 - accuracy: 0.8537\n",
      "123/123 [==============================] - 0s 256us/sample - loss: 0.3435 - accuracy: 0.8862\n",
      "122/122 [==============================] - 0s 257us/sample - loss: 0.3314 - accuracy: 0.9016\n",
      "122/122 [==============================] - 0s 239us/sample - loss: 0.3592 - accuracy: 0.8689\n",
      "121/121 [==============================] - 0s 254us/sample - loss: 0.4097 - accuracy: 0.8595\n",
      "119/119 [==============================] - 0s 233us/sample - loss: 0.3631 - accuracy: 0.8908\n",
      "119/119 [==============================] - 0s 258us/sample - loss: 0.3871 - accuracy: 0.8403\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.3743 - accuracy: 0.8500\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.3518 - accuracy: 0.9167\n",
      "119/119 [==============================] - 0s 260us/sample - loss: 0.3406 - accuracy: 0.9160\n",
      "118/118 [==============================] - 0s 246us/sample - loss: 0.3403 - accuracy: 0.8898\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 0.3604 - accuracy: 0.8833\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2827 samples, validate on 712 samples\n",
      "Epoch 1/300\n",
      "2827/2827 [==============================] - 2s 838us/sample - loss: 0.7077 - accuracy: 0.5246 - val_loss: 0.6824 - val_accuracy: 0.5674\n",
      "Epoch 2/300\n",
      "2827/2827 [==============================] - 1s 225us/sample - loss: 0.6783 - accuracy: 0.5706 - val_loss: 0.6637 - val_accuracy: 0.5871\n",
      "Epoch 3/300\n",
      "2827/2827 [==============================] - 1s 232us/sample - loss: 0.6603 - accuracy: 0.6035 - val_loss: 0.6507 - val_accuracy: 0.6152\n",
      "Epoch 4/300\n",
      "2827/2827 [==============================] - 1s 201us/sample - loss: 0.6478 - accuracy: 0.6364 - val_loss: 0.6406 - val_accuracy: 0.6264\n",
      "Epoch 5/300\n",
      "2827/2827 [==============================] - 1s 204us/sample - loss: 0.6327 - accuracy: 0.6590 - val_loss: 0.6320 - val_accuracy: 0.6489\n",
      "Epoch 6/300\n",
      "2827/2827 [==============================] - 1s 243us/sample - loss: 0.6263 - accuracy: 0.6841 - val_loss: 0.6249 - val_accuracy: 0.6713\n",
      "Epoch 7/300\n",
      "2827/2827 [==============================] - 1s 252us/sample - loss: 0.6197 - accuracy: 0.6763 - val_loss: 0.6186 - val_accuracy: 0.6826\n",
      "Epoch 8/300\n",
      "2827/2827 [==============================] - 1s 191us/sample - loss: 0.6085 - accuracy: 0.6926 - val_loss: 0.6130 - val_accuracy: 0.6952\n",
      "Epoch 9/300\n",
      "2827/2827 [==============================] - 1s 246us/sample - loss: 0.6035 - accuracy: 0.7071 - val_loss: 0.6079 - val_accuracy: 0.7079\n",
      "Epoch 10/300\n",
      "2827/2827 [==============================] - 1s 242us/sample - loss: 0.5977 - accuracy: 0.7152 - val_loss: 0.6032 - val_accuracy: 0.7163\n",
      "Epoch 11/300\n",
      "2827/2827 [==============================] - 1s 203us/sample - loss: 0.5941 - accuracy: 0.7124 - val_loss: 0.5989 - val_accuracy: 0.7205\n",
      "Epoch 12/300\n",
      "2827/2827 [==============================] - 1s 183us/sample - loss: 0.5827 - accuracy: 0.7340 - val_loss: 0.5950 - val_accuracy: 0.7233\n",
      "Epoch 13/300\n",
      "2827/2827 [==============================] - 1s 222us/sample - loss: 0.5748 - accuracy: 0.7379 - val_loss: 0.5912 - val_accuracy: 0.7289\n",
      "Epoch 14/300\n",
      "2827/2827 [==============================] - 1s 197us/sample - loss: 0.5754 - accuracy: 0.7354 - val_loss: 0.5878 - val_accuracy: 0.7261\n",
      "Epoch 15/300\n",
      "2827/2827 [==============================] - 1s 215us/sample - loss: 0.5694 - accuracy: 0.7460 - val_loss: 0.5846 - val_accuracy: 0.7275\n",
      "Epoch 16/300\n",
      "2827/2827 [==============================] - 1s 242us/sample - loss: 0.5640 - accuracy: 0.7538 - val_loss: 0.5815 - val_accuracy: 0.7331\n",
      "Epoch 17/300\n",
      "2827/2827 [==============================] - 1s 216us/sample - loss: 0.5597 - accuracy: 0.7513 - val_loss: 0.5787 - val_accuracy: 0.7317\n",
      "Epoch 18/300\n",
      "2827/2827 [==============================] - 1s 210us/sample - loss: 0.5552 - accuracy: 0.7588 - val_loss: 0.5760 - val_accuracy: 0.7331\n",
      "Epoch 19/300\n",
      "2827/2827 [==============================] - 1s 218us/sample - loss: 0.5506 - accuracy: 0.7563 - val_loss: 0.5735 - val_accuracy: 0.7374\n",
      "Epoch 20/300\n",
      "2827/2827 [==============================] - 1s 241us/sample - loss: 0.5473 - accuracy: 0.7637 - val_loss: 0.5710 - val_accuracy: 0.7388\n",
      "Epoch 21/300\n",
      "2827/2827 [==============================] - 1s 250us/sample - loss: 0.5459 - accuracy: 0.7623 - val_loss: 0.5687 - val_accuracy: 0.7374\n",
      "Epoch 22/300\n",
      "2827/2827 [==============================] - 1s 232us/sample - loss: 0.5431 - accuracy: 0.7641 - val_loss: 0.5665 - val_accuracy: 0.7402\n",
      "Epoch 23/300\n",
      "2827/2827 [==============================] - 1s 231us/sample - loss: 0.5370 - accuracy: 0.7715 - val_loss: 0.5644 - val_accuracy: 0.7388\n",
      "Epoch 24/300\n",
      "2827/2827 [==============================] - 1s 213us/sample - loss: 0.5346 - accuracy: 0.7715 - val_loss: 0.5624 - val_accuracy: 0.7388\n",
      "Epoch 25/300\n",
      "2827/2827 [==============================] - 1s 198us/sample - loss: 0.5298 - accuracy: 0.7722 - val_loss: 0.5606 - val_accuracy: 0.7374\n",
      "Epoch 26/300\n",
      "2827/2827 [==============================] - 1s 207us/sample - loss: 0.5286 - accuracy: 0.7711 - val_loss: 0.5588 - val_accuracy: 0.7374\n",
      "Epoch 27/300\n",
      "2827/2827 [==============================] - 1s 224us/sample - loss: 0.5252 - accuracy: 0.7786 - val_loss: 0.5571 - val_accuracy: 0.7388\n",
      "Epoch 28/300\n",
      "2827/2827 [==============================] - 1s 189us/sample - loss: 0.5221 - accuracy: 0.7711 - val_loss: 0.5555 - val_accuracy: 0.7402\n",
      "Epoch 29/300\n",
      "2827/2827 [==============================] - 1s 195us/sample - loss: 0.5201 - accuracy: 0.7704 - val_loss: 0.5539 - val_accuracy: 0.7430\n",
      "Epoch 30/300\n",
      "2827/2827 [==============================] - 1s 213us/sample - loss: 0.5135 - accuracy: 0.7775 - val_loss: 0.5524 - val_accuracy: 0.7458\n",
      "Epoch 31/300\n",
      "2827/2827 [==============================] - 1s 201us/sample - loss: 0.5166 - accuracy: 0.7835 - val_loss: 0.5510 - val_accuracy: 0.7472\n",
      "Epoch 32/300\n",
      "2827/2827 [==============================] - 1s 216us/sample - loss: 0.5115 - accuracy: 0.7779 - val_loss: 0.5496 - val_accuracy: 0.7486\n",
      "Epoch 33/300\n",
      "2827/2827 [==============================] - 1s 205us/sample - loss: 0.5057 - accuracy: 0.7871 - val_loss: 0.5484 - val_accuracy: 0.7500\n",
      "Epoch 34/300\n",
      "2827/2827 [==============================] - 1s 197us/sample - loss: 0.5099 - accuracy: 0.7796 - val_loss: 0.5471 - val_accuracy: 0.7514\n",
      "Epoch 35/300\n",
      "2827/2827 [==============================] - 1s 220us/sample - loss: 0.5032 - accuracy: 0.7849 - val_loss: 0.5459 - val_accuracy: 0.7528\n",
      "Epoch 36/300\n",
      "2827/2827 [==============================] - 1s 202us/sample - loss: 0.5002 - accuracy: 0.7842 - val_loss: 0.5448 - val_accuracy: 0.7528\n",
      "Epoch 37/300\n",
      "2827/2827 [==============================] - 1s 214us/sample - loss: 0.4972 - accuracy: 0.7892 - val_loss: 0.5438 - val_accuracy: 0.7556\n",
      "Epoch 38/300\n",
      "2827/2827 [==============================] - 1s 267us/sample - loss: 0.4949 - accuracy: 0.7853 - val_loss: 0.5428 - val_accuracy: 0.7556\n",
      "Epoch 39/300\n",
      "2827/2827 [==============================] - 1s 237us/sample - loss: 0.4935 - accuracy: 0.7885 - val_loss: 0.5417 - val_accuracy: 0.7570\n",
      "Epoch 40/300\n",
      "2827/2827 [==============================] - 1s 228us/sample - loss: 0.4904 - accuracy: 0.7881 - val_loss: 0.5408 - val_accuracy: 0.7598\n",
      "Epoch 41/300\n",
      "2827/2827 [==============================] - 1s 260us/sample - loss: 0.4877 - accuracy: 0.7927 - val_loss: 0.5399 - val_accuracy: 0.7584\n",
      "Epoch 42/300\n",
      "2827/2827 [==============================] - 1s 221us/sample - loss: 0.4837 - accuracy: 0.7945 - val_loss: 0.5391 - val_accuracy: 0.7584\n",
      "Epoch 43/300\n",
      "2827/2827 [==============================] - 1s 230us/sample - loss: 0.4811 - accuracy: 0.7973 - val_loss: 0.5383 - val_accuracy: 0.7598\n",
      "Epoch 44/300\n",
      "2827/2827 [==============================] - 1s 196us/sample - loss: 0.4771 - accuracy: 0.7994 - val_loss: 0.5376 - val_accuracy: 0.7598\n",
      "Epoch 45/300\n",
      "2827/2827 [==============================] - 1s 195us/sample - loss: 0.4736 - accuracy: 0.8001 - val_loss: 0.5369 - val_accuracy: 0.7598\n",
      "Epoch 46/300\n",
      "2827/2827 [==============================] - 1s 186us/sample - loss: 0.4733 - accuracy: 0.7963 - val_loss: 0.5362 - val_accuracy: 0.7598\n",
      "Epoch 47/300\n",
      "2827/2827 [==============================] - 1s 205us/sample - loss: 0.4718 - accuracy: 0.8033 - val_loss: 0.5355 - val_accuracy: 0.7598\n",
      "Epoch 48/300\n",
      "2827/2827 [==============================] - 1s 228us/sample - loss: 0.4658 - accuracy: 0.8047 - val_loss: 0.5349 - val_accuracy: 0.7612\n",
      "Epoch 49/300\n",
      "2827/2827 [==============================] - 1s 267us/sample - loss: 0.4680 - accuracy: 0.8005 - val_loss: 0.5344 - val_accuracy: 0.7612\n",
      "Epoch 50/300\n",
      "2827/2827 [==============================] - 1s 271us/sample - loss: 0.4641 - accuracy: 0.8023 - val_loss: 0.5339 - val_accuracy: 0.7640\n",
      "Epoch 51/300\n",
      "2827/2827 [==============================] - 1s 264us/sample - loss: 0.4618 - accuracy: 0.8047 - val_loss: 0.5334 - val_accuracy: 0.7626\n",
      "Epoch 52/300\n",
      "2827/2827 [==============================] - 1s 220us/sample - loss: 0.4640 - accuracy: 0.8001 - val_loss: 0.5329 - val_accuracy: 0.7626\n",
      "Epoch 53/300\n",
      "2827/2827 [==============================] - 1s 222us/sample - loss: 0.4622 - accuracy: 0.7973 - val_loss: 0.5325 - val_accuracy: 0.7626\n",
      "Epoch 54/300\n",
      "2827/2827 [==============================] - 1s 186us/sample - loss: 0.4556 - accuracy: 0.8083 - val_loss: 0.5320 - val_accuracy: 0.7654\n",
      "Epoch 55/300\n",
      "2827/2827 [==============================] - 1s 204us/sample - loss: 0.4532 - accuracy: 0.8062 - val_loss: 0.5316 - val_accuracy: 0.7654\n",
      "Epoch 56/300\n",
      "2827/2827 [==============================] - 1s 201us/sample - loss: 0.4536 - accuracy: 0.8037 - val_loss: 0.5312 - val_accuracy: 0.7669\n",
      "Epoch 57/300\n",
      "2827/2827 [==============================] - 1s 209us/sample - loss: 0.4488 - accuracy: 0.8090 - val_loss: 0.5309 - val_accuracy: 0.7669\n",
      "Epoch 58/300\n",
      "2827/2827 [==============================] - 1s 211us/sample - loss: 0.4487 - accuracy: 0.8069 - val_loss: 0.5306 - val_accuracy: 0.7669\n",
      "Epoch 59/300\n",
      "2827/2827 [==============================] - 1s 232us/sample - loss: 0.4437 - accuracy: 0.8122 - val_loss: 0.5303 - val_accuracy: 0.7669\n",
      "Epoch 60/300\n",
      "2827/2827 [==============================] - 1s 253us/sample - loss: 0.4431 - accuracy: 0.8129 - val_loss: 0.5300 - val_accuracy: 0.7683\n",
      "Epoch 61/300\n",
      "2827/2827 [==============================] - 1s 256us/sample - loss: 0.4344 - accuracy: 0.8129 - val_loss: 0.5298 - val_accuracy: 0.7669\n",
      "Epoch 62/300\n",
      "2827/2827 [==============================] - 1s 239us/sample - loss: 0.4400 - accuracy: 0.8111 - val_loss: 0.5296 - val_accuracy: 0.7683\n",
      "Epoch 63/300\n",
      "2827/2827 [==============================] - 1s 276us/sample - loss: 0.4364 - accuracy: 0.8146 - val_loss: 0.5294 - val_accuracy: 0.7683\n",
      "Epoch 64/300\n",
      "2827/2827 [==============================] - 1s 268us/sample - loss: 0.4345 - accuracy: 0.8150 - val_loss: 0.5293 - val_accuracy: 0.7683\n",
      "Epoch 65/300\n",
      "2827/2827 [==============================] - 1s 265us/sample - loss: 0.4331 - accuracy: 0.8210 - val_loss: 0.5292 - val_accuracy: 0.7669\n",
      "Epoch 66/300\n",
      "2827/2827 [==============================] - 1s 251us/sample - loss: 0.4317 - accuracy: 0.8178 - val_loss: 0.5290 - val_accuracy: 0.7669\n",
      "Epoch 67/300\n",
      "2827/2827 [==============================] - 1s 245us/sample - loss: 0.4277 - accuracy: 0.8224 - val_loss: 0.5289 - val_accuracy: 0.7654\n",
      "Epoch 68/300\n",
      "2827/2827 [==============================] - 1s 204us/sample - loss: 0.4225 - accuracy: 0.8207 - val_loss: 0.5288 - val_accuracy: 0.7669\n",
      "Epoch 69/300\n",
      "2827/2827 [==============================] - 1s 207us/sample - loss: 0.4240 - accuracy: 0.8214 - val_loss: 0.5288 - val_accuracy: 0.7654\n",
      "Epoch 70/300\n",
      "2827/2827 [==============================] - 1s 224us/sample - loss: 0.4196 - accuracy: 0.8238 - val_loss: 0.5288 - val_accuracy: 0.7654\n",
      "Epoch 71/300\n",
      "2827/2827 [==============================] - 1s 191us/sample - loss: 0.4177 - accuracy: 0.8253 - val_loss: 0.5288 - val_accuracy: 0.7654\n",
      "Epoch 72/300\n",
      "2827/2827 [==============================] - 1s 225us/sample - loss: 0.4160 - accuracy: 0.8217 - val_loss: 0.5288 - val_accuracy: 0.7654\n",
      "Epoch 73/300\n",
      "2827/2827 [==============================] - 1s 228us/sample - loss: 0.4147 - accuracy: 0.8207 - val_loss: 0.5289 - val_accuracy: 0.7654\n",
      "Epoch 00073: early stopping\n",
      "110/110 [==============================] - 0s 141us/sample - loss: 0.3027 - accuracy: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [3:51:10, 1070.96s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.36s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.17s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 827.0 steps, validate for 212.8515625 steps\n",
      "Epoch 1/300\n",
      "827/827 [==============================] - 25s 30ms/step - loss: 0.6170 - accuracy: 0.6784 - val_loss: 0.5327 - val_accuracy: 0.7694\n",
      "Epoch 2/300\n",
      "827/827 [==============================] - 23s 28ms/step - loss: 0.5193 - accuracy: 0.7713 - val_loss: 0.5326 - val_accuracy: 0.7681\n",
      "Epoch 3/300\n",
      "827/827 [==============================] - 24s 29ms/step - loss: 0.5038 - accuracy: 0.7767 - val_loss: 0.5277 - val_accuracy: 0.7706\n",
      "Epoch 4/300\n",
      "827/827 [==============================] - 24s 29ms/step - loss: 0.4930 - accuracy: 0.7811 - val_loss: 0.5321 - val_accuracy: 0.7685\n",
      "Epoch 5/300\n",
      "827/827 [==============================] - 24s 29ms/step - loss: 0.4838 - accuracy: 0.7853 - val_loss: 0.5345 - val_accuracy: 0.7678\n",
      "Epoch 6/300\n",
      "827/827 [==============================] - 24s 29ms/step - loss: 0.4753 - accuracy: 0.7892 - val_loss: 0.5379 - val_accuracy: 0.7671\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 827.0 steps, validate for 212.8515625 steps\n",
      "Epoch 1/300\n",
      "827/827 [==============================] - 54s 65ms/step - loss: 0.4589 - accuracy: 0.7967 - val_loss: 0.5766 - val_accuracy: 0.7158\n",
      "Epoch 2/300\n",
      "827/827 [==============================] - 53s 64ms/step - loss: 0.4316 - accuracy: 0.8105 - val_loss: 0.5506 - val_accuracy: 0.7540\n",
      "Epoch 3/300\n",
      "827/827 [==============================] - 53s 64ms/step - loss: 0.4093 - accuracy: 0.8218 - val_loss: 0.5869 - val_accuracy: 0.7643\n",
      "Epoch 4/300\n",
      "827/827 [==============================] - 53s 65ms/step - loss: 0.3888 - accuracy: 0.8328 - val_loss: 0.5712 - val_accuracy: 0.7347\n",
      "Epoch 5/300\n",
      "827/827 [==============================] - 53s 64ms/step - loss: 0.3693 - accuracy: 0.8433 - val_loss: 0.6154 - val_accuracy: 0.6924\n",
      "Epoch 00005: early stopping\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 0.4260 - accuracy: 0.8447\n",
      "155/155 [==============================] - 0s 251us/sample - loss: 0.5205 - accuracy: 0.7742\n",
      "153/153 [==============================] - 0s 227us/sample - loss: 0.5137 - accuracy: 0.7778\n",
      "153/153 [==============================] - 0s 250us/sample - loss: 0.5396 - accuracy: 0.7516\n",
      "151/151 [==============================] - 0s 213us/sample - loss: 0.5137 - accuracy: 0.7550\n",
      "149/149 [==============================] - 0s 248us/sample - loss: 0.4899 - accuracy: 0.7852\n",
      "149/149 [==============================] - 0s 250us/sample - loss: 0.4962 - accuracy: 0.8188\n",
      "149/149 [==============================] - 0s 229us/sample - loss: 0.5318 - accuracy: 0.7114\n",
      "149/149 [==============================] - 0s 251us/sample - loss: 0.4778 - accuracy: 0.7919\n",
      "149/149 [==============================] - 0s 266us/sample - loss: 0.5406 - accuracy: 0.7584\n",
      "149/149 [==============================] - 0s 276us/sample - loss: 0.5230 - accuracy: 0.7584\n",
      "146/146 [==============================] - 0s 293us/sample - loss: 0.5132 - accuracy: 0.7740\n",
      "146/146 [==============================] - 0s 284us/sample - loss: 0.4694 - accuracy: 0.7945\n",
      "141/141 [==============================] - 0s 254us/sample - loss: 0.4366 - accuracy: 0.8440\n",
      "142/142 [==============================] - 0s 273us/sample - loss: 0.4165 - accuracy: 0.8662\n",
      "140/140 [==============================] - 0s 285us/sample - loss: 0.4504 - accuracy: 0.8143\n",
      "139/139 [==============================] - 0s 238us/sample - loss: 0.4311 - accuracy: 0.8489\n",
      "140/140 [==============================] - 0s 273us/sample - loss: 0.4588 - accuracy: 0.7857\n",
      "135/135 [==============================] - 0s 258us/sample - loss: 0.4298 - accuracy: 0.8370\n",
      "136/136 [==============================] - 0s 248us/sample - loss: 0.4093 - accuracy: 0.8309\n",
      "137/137 [==============================] - 0s 312us/sample - loss: 0.4079 - accuracy: 0.8540\n",
      "137/137 [==============================] - 0s 255us/sample - loss: 0.4304 - accuracy: 0.8248\n",
      "135/135 [==============================] - 0s 258us/sample - loss: 0.4368 - accuracy: 0.8296\n",
      "136/136 [==============================] - 0s 257us/sample - loss: 0.4119 - accuracy: 0.8309\n",
      "136/136 [==============================] - 0s 282us/sample - loss: 0.4085 - accuracy: 0.8456\n",
      "134/134 [==============================] - 0s 267us/sample - loss: 0.4220 - accuracy: 0.8433\n",
      "134/134 [==============================] - 0s 240us/sample - loss: 0.3977 - accuracy: 0.8433\n",
      "134/134 [==============================] - 0s 261us/sample - loss: 0.4115 - accuracy: 0.8507\n",
      "136/136 [==============================] - 0s 261us/sample - loss: 0.3960 - accuracy: 0.8603\n",
      "134/134 [==============================] - 0s 284us/sample - loss: 0.3864 - accuracy: 0.8731\n",
      "133/133 [==============================] - 0s 280us/sample - loss: 0.3945 - accuracy: 0.8496\n",
      "129/129 [==============================] - 0s 268us/sample - loss: 0.3979 - accuracy: 0.8527\n",
      "130/130 [==============================] - 0s 273us/sample - loss: 0.3628 - accuracy: 0.8769\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2809 samples, validate on 720 samples\n",
      "Epoch 1/300\n",
      "2809/2809 [==============================] - 2s 882us/sample - loss: 0.6905 - accuracy: 0.5507 - val_loss: 0.6661 - val_accuracy: 0.5792\n",
      "Epoch 2/300\n",
      "2809/2809 [==============================] - 1s 235us/sample - loss: 0.6538 - accuracy: 0.6184 - val_loss: 0.6463 - val_accuracy: 0.6250\n",
      "Epoch 3/300\n",
      "2809/2809 [==============================] - 1s 210us/sample - loss: 0.6339 - accuracy: 0.6333 - val_loss: 0.6330 - val_accuracy: 0.6556\n",
      "Epoch 4/300\n",
      "2809/2809 [==============================] - 1s 201us/sample - loss: 0.6144 - accuracy: 0.6782 - val_loss: 0.6231 - val_accuracy: 0.6667\n",
      "Epoch 5/300\n",
      "2809/2809 [==============================] - 1s 237us/sample - loss: 0.6014 - accuracy: 0.6892 - val_loss: 0.6151 - val_accuracy: 0.6764\n",
      "Epoch 6/300\n",
      "2809/2809 [==============================] - 1s 255us/sample - loss: 0.5921 - accuracy: 0.7052 - val_loss: 0.6084 - val_accuracy: 0.6875\n",
      "Epoch 7/300\n",
      "2809/2809 [==============================] - 1s 244us/sample - loss: 0.5784 - accuracy: 0.7223 - val_loss: 0.6028 - val_accuracy: 0.6889\n",
      "Epoch 8/300\n",
      "2809/2809 [==============================] - 1s 234us/sample - loss: 0.5739 - accuracy: 0.7266 - val_loss: 0.5979 - val_accuracy: 0.6944\n",
      "Epoch 9/300\n",
      "2809/2809 [==============================] - 1s 205us/sample - loss: 0.5679 - accuracy: 0.7326 - val_loss: 0.5936 - val_accuracy: 0.7000\n",
      "Epoch 10/300\n",
      "2809/2809 [==============================] - 1s 197us/sample - loss: 0.5603 - accuracy: 0.7373 - val_loss: 0.5897 - val_accuracy: 0.7042\n",
      "Epoch 11/300\n",
      "2809/2809 [==============================] - 1s 222us/sample - loss: 0.5561 - accuracy: 0.7419 - val_loss: 0.5863 - val_accuracy: 0.7153\n",
      "Epoch 12/300\n",
      "2809/2809 [==============================] - 1s 252us/sample - loss: 0.5487 - accuracy: 0.7504 - val_loss: 0.5835 - val_accuracy: 0.7167\n",
      "Epoch 13/300\n",
      "2809/2809 [==============================] - 1s 225us/sample - loss: 0.5409 - accuracy: 0.7522 - val_loss: 0.5808 - val_accuracy: 0.7167\n",
      "Epoch 14/300\n",
      "2809/2809 [==============================] - 1s 253us/sample - loss: 0.5397 - accuracy: 0.7554 - val_loss: 0.5783 - val_accuracy: 0.7194\n",
      "Epoch 15/300\n",
      "2809/2809 [==============================] - 1s 257us/sample - loss: 0.5316 - accuracy: 0.7636 - val_loss: 0.5761 - val_accuracy: 0.7236\n",
      "Epoch 16/300\n",
      "2809/2809 [==============================] - 1s 246us/sample - loss: 0.5298 - accuracy: 0.7650 - val_loss: 0.5741 - val_accuracy: 0.7278\n",
      "Epoch 17/300\n",
      "2809/2809 [==============================] - 1s 235us/sample - loss: 0.5226 - accuracy: 0.7697 - val_loss: 0.5724 - val_accuracy: 0.7347\n",
      "Epoch 18/300\n",
      "2809/2809 [==============================] - 1s 241us/sample - loss: 0.5148 - accuracy: 0.7743 - val_loss: 0.5708 - val_accuracy: 0.7361\n",
      "Epoch 19/300\n",
      "2809/2809 [==============================] - 1s 242us/sample - loss: 0.5134 - accuracy: 0.7732 - val_loss: 0.5694 - val_accuracy: 0.7375\n",
      "Epoch 20/300\n",
      "2809/2809 [==============================] - 1s 254us/sample - loss: 0.5135 - accuracy: 0.7714 - val_loss: 0.5680 - val_accuracy: 0.7389\n",
      "Epoch 21/300\n",
      "2809/2809 [==============================] - 1s 208us/sample - loss: 0.5108 - accuracy: 0.7747 - val_loss: 0.5668 - val_accuracy: 0.7417\n",
      "Epoch 22/300\n",
      "2809/2809 [==============================] - 1s 232us/sample - loss: 0.5033 - accuracy: 0.7846 - val_loss: 0.5656 - val_accuracy: 0.7417\n",
      "Epoch 23/300\n",
      "2809/2809 [==============================] - 1s 237us/sample - loss: 0.5035 - accuracy: 0.7839 - val_loss: 0.5646 - val_accuracy: 0.7417\n",
      "Epoch 24/300\n",
      "2809/2809 [==============================] - 1s 233us/sample - loss: 0.5000 - accuracy: 0.7860 - val_loss: 0.5636 - val_accuracy: 0.7458\n",
      "Epoch 25/300\n",
      "2809/2809 [==============================] - 1s 232us/sample - loss: 0.5004 - accuracy: 0.7800 - val_loss: 0.5628 - val_accuracy: 0.7486\n",
      "Epoch 26/300\n",
      "2809/2809 [==============================] - 1s 266us/sample - loss: 0.4947 - accuracy: 0.7811 - val_loss: 0.5620 - val_accuracy: 0.7514\n",
      "Epoch 27/300\n",
      "2809/2809 [==============================] - 1s 230us/sample - loss: 0.4870 - accuracy: 0.7882 - val_loss: 0.5612 - val_accuracy: 0.7514\n",
      "Epoch 28/300\n",
      "2809/2809 [==============================] - 1s 223us/sample - loss: 0.4844 - accuracy: 0.7921 - val_loss: 0.5605 - val_accuracy: 0.7514\n",
      "Epoch 29/300\n",
      "2809/2809 [==============================] - 1s 245us/sample - loss: 0.4859 - accuracy: 0.7910 - val_loss: 0.5598 - val_accuracy: 0.7514\n",
      "Epoch 30/300\n",
      "2809/2809 [==============================] - 1s 213us/sample - loss: 0.4827 - accuracy: 0.7946 - val_loss: 0.5593 - val_accuracy: 0.7514\n",
      "Epoch 31/300\n",
      "2809/2809 [==============================] - 1s 212us/sample - loss: 0.4776 - accuracy: 0.7932 - val_loss: 0.5587 - val_accuracy: 0.7514\n",
      "Epoch 32/300\n",
      "2809/2809 [==============================] - 1s 256us/sample - loss: 0.4767 - accuracy: 0.7949 - val_loss: 0.5582 - val_accuracy: 0.7514\n",
      "Epoch 33/300\n",
      "2809/2809 [==============================] - 1s 236us/sample - loss: 0.4715 - accuracy: 0.7925 - val_loss: 0.5577 - val_accuracy: 0.7542\n",
      "Epoch 34/300\n",
      "2809/2809 [==============================] - 1s 250us/sample - loss: 0.4703 - accuracy: 0.8014 - val_loss: 0.5573 - val_accuracy: 0.7556\n",
      "Epoch 35/300\n",
      "2809/2809 [==============================] - 1s 261us/sample - loss: 0.4688 - accuracy: 0.8014 - val_loss: 0.5569 - val_accuracy: 0.7583\n",
      "Epoch 36/300\n",
      "2809/2809 [==============================] - 1s 252us/sample - loss: 0.4669 - accuracy: 0.8010 - val_loss: 0.5565 - val_accuracy: 0.7597\n",
      "Epoch 37/300\n",
      "2809/2809 [==============================] - 1s 248us/sample - loss: 0.4643 - accuracy: 0.8053 - val_loss: 0.5561 - val_accuracy: 0.7597\n",
      "Epoch 38/300\n",
      "2809/2809 [==============================] - 1s 243us/sample - loss: 0.4591 - accuracy: 0.8024 - val_loss: 0.5558 - val_accuracy: 0.7597\n",
      "Epoch 39/300\n",
      "2809/2809 [==============================] - 1s 256us/sample - loss: 0.4582 - accuracy: 0.8056 - val_loss: 0.5555 - val_accuracy: 0.7597\n",
      "Epoch 40/300\n",
      "2809/2809 [==============================] - 1s 228us/sample - loss: 0.4550 - accuracy: 0.8070 - val_loss: 0.5551 - val_accuracy: 0.7597\n",
      "Epoch 41/300\n",
      "2809/2809 [==============================] - 1s 233us/sample - loss: 0.4515 - accuracy: 0.8106 - val_loss: 0.5548 - val_accuracy: 0.7597\n",
      "Epoch 42/300\n",
      "2809/2809 [==============================] - 1s 249us/sample - loss: 0.4514 - accuracy: 0.8081 - val_loss: 0.5546 - val_accuracy: 0.7597\n",
      "Epoch 43/300\n",
      "2809/2809 [==============================] - 1s 208us/sample - loss: 0.4488 - accuracy: 0.8085 - val_loss: 0.5543 - val_accuracy: 0.7611\n",
      "Epoch 44/300\n",
      "2809/2809 [==============================] - 1s 229us/sample - loss: 0.4475 - accuracy: 0.8135 - val_loss: 0.5540 - val_accuracy: 0.7611\n",
      "Epoch 45/300\n",
      "2809/2809 [==============================] - 1s 264us/sample - loss: 0.4483 - accuracy: 0.8095 - val_loss: 0.5539 - val_accuracy: 0.7597\n",
      "Epoch 46/300\n",
      "2809/2809 [==============================] - 1s 245us/sample - loss: 0.4419 - accuracy: 0.8103 - val_loss: 0.5535 - val_accuracy: 0.7583\n",
      "Epoch 47/300\n",
      "2809/2809 [==============================] - 1s 244us/sample - loss: 0.4408 - accuracy: 0.8135 - val_loss: 0.5534 - val_accuracy: 0.7583\n",
      "Epoch 48/300\n",
      "2809/2809 [==============================] - 1s 244us/sample - loss: 0.4389 - accuracy: 0.8145 - val_loss: 0.5532 - val_accuracy: 0.7583\n",
      "Epoch 49/300\n",
      "2809/2809 [==============================] - 1s 215us/sample - loss: 0.4339 - accuracy: 0.8163 - val_loss: 0.5530 - val_accuracy: 0.7583\n",
      "Epoch 50/300\n",
      "2809/2809 [==============================] - 1s 229us/sample - loss: 0.4325 - accuracy: 0.8167 - val_loss: 0.5528 - val_accuracy: 0.7569\n",
      "Epoch 51/300\n",
      "2809/2809 [==============================] - 1s 232us/sample - loss: 0.4309 - accuracy: 0.8181 - val_loss: 0.5526 - val_accuracy: 0.7583\n",
      "Epoch 52/300\n",
      "2809/2809 [==============================] - 1s 222us/sample - loss: 0.4274 - accuracy: 0.8159 - val_loss: 0.5526 - val_accuracy: 0.7569\n",
      "Epoch 53/300\n",
      "2809/2809 [==============================] - 1s 239us/sample - loss: 0.4213 - accuracy: 0.8177 - val_loss: 0.5525 - val_accuracy: 0.7542\n",
      "Epoch 54/300\n",
      "2809/2809 [==============================] - 1s 236us/sample - loss: 0.4222 - accuracy: 0.8195 - val_loss: 0.5524 - val_accuracy: 0.7569\n",
      "Epoch 55/300\n",
      "2809/2809 [==============================] - 1s 202us/sample - loss: 0.4203 - accuracy: 0.8184 - val_loss: 0.5524 - val_accuracy: 0.7542\n",
      "Epoch 56/300\n",
      "2809/2809 [==============================] - 1s 244us/sample - loss: 0.4215 - accuracy: 0.8188 - val_loss: 0.5524 - val_accuracy: 0.7542\n",
      "Epoch 57/300\n",
      "2809/2809 [==============================] - 1s 243us/sample - loss: 0.4146 - accuracy: 0.8248 - val_loss: 0.5524 - val_accuracy: 0.7542\n",
      "Epoch 58/300\n",
      "2809/2809 [==============================] - 1s 248us/sample - loss: 0.4118 - accuracy: 0.8270 - val_loss: 0.5525 - val_accuracy: 0.7556\n",
      "Epoch 00058: early stopping\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.2366 - accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [4:09:29, 1079.38s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.46s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.22s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 835.1796875 steps, validate for 213.09375 steps\n",
      "Epoch 1/300\n",
      "836/835 [==============================] - 25s 30ms/step - loss: 0.5674 - accuracy: 0.7319 - val_loss: 0.5355 - val_accuracy: 0.7719\n",
      "Epoch 2/300\n",
      "836/835 [==============================] - 24s 29ms/step - loss: 0.5116 - accuracy: 0.7758 - val_loss: 0.5325 - val_accuracy: 0.7708\n",
      "Epoch 3/300\n",
      "836/835 [==============================] - 24s 29ms/step - loss: 0.4969 - accuracy: 0.7811 - val_loss: 0.5329 - val_accuracy: 0.7693\n",
      "Epoch 4/300\n",
      "836/835 [==============================] - 24s 29ms/step - loss: 0.4857 - accuracy: 0.7854 - val_loss: 0.5368 - val_accuracy: 0.7673\n",
      "Epoch 5/300\n",
      "836/835 [==============================] - 24s 28ms/step - loss: 0.4761 - accuracy: 0.7894 - val_loss: 0.5367 - val_accuracy: 0.7668\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 835.1796875 steps, validate for 213.09375 steps\n",
      "Epoch 1/300\n",
      "836/835 [==============================] - 55s 66ms/step - loss: 0.4589 - accuracy: 0.7975 - val_loss: 0.5470 - val_accuracy: 0.7541\n",
      "Epoch 2/300\n",
      "836/835 [==============================] - 54s 64ms/step - loss: 0.4335 - accuracy: 0.8097 - val_loss: 0.5533 - val_accuracy: 0.7676\n",
      "Epoch 3/300\n",
      "836/835 [==============================] - 54s 64ms/step - loss: 0.4114 - accuracy: 0.8209 - val_loss: 0.5594 - val_accuracy: 0.7313\n",
      "Epoch 4/300\n",
      "836/835 [==============================] - 54s 65ms/step - loss: 0.3908 - accuracy: 0.8335 - val_loss: 0.5585 - val_accuracy: 0.7645\n",
      "Epoch 00004: early stopping\n",
      "144/144 [==============================] - 0s 2ms/sample - loss: 0.6370 - accuracy: 0.7847\n",
      "130/130 [==============================] - 0s 288us/sample - loss: 0.6516 - accuracy: 0.8000\n",
      "118/118 [==============================] - 0s 246us/sample - loss: 0.6908 - accuracy: 0.7627\n",
      "115/115 [==============================] - 0s 243us/sample - loss: 0.6815 - accuracy: 0.8087\n",
      "114/114 [==============================] - 0s 234us/sample - loss: 0.6361 - accuracy: 0.8158\n",
      "113/113 [==============================] - 0s 255us/sample - loss: 0.8233 - accuracy: 0.7257\n",
      "113/113 [==============================] - 0s 237us/sample - loss: 0.8101 - accuracy: 0.6726\n",
      "114/114 [==============================] - 0s 222us/sample - loss: 0.7374 - accuracy: 0.7105\n",
      "114/114 [==============================] - 0s 250us/sample - loss: 0.8101 - accuracy: 0.7018\n",
      "111/111 [==============================] - 0s 238us/sample - loss: 0.9066 - accuracy: 0.7297\n",
      "110/110 [==============================] - 0s 284us/sample - loss: 0.8977 - accuracy: 0.6727\n",
      "110/110 [==============================] - 0s 291us/sample - loss: 0.9202 - accuracy: 0.6545\n",
      "112/112 [==============================] - 0s 267us/sample - loss: 0.9019 - accuracy: 0.7054\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 0.8735 - accuracy: 0.6518\n",
      "113/113 [==============================] - 0s 258us/sample - loss: 1.1969 - accuracy: 0.6283\n",
      "114/114 [==============================] - 0s 235us/sample - loss: 1.1105 - accuracy: 0.5877\n",
      "111/111 [==============================] - 0s 270us/sample - loss: 1.1825 - accuracy: 0.6036\n",
      "107/107 [==============================] - 0s 262us/sample - loss: 1.3623 - accuracy: 0.6075\n",
      "107/107 [==============================] - 0s 251us/sample - loss: 1.0583 - accuracy: 0.6449\n",
      "106/106 [==============================] - 0s 245us/sample - loss: 1.0755 - accuracy: 0.6415\n",
      "103/103 [==============================] - 0s 241us/sample - loss: 1.3563 - accuracy: 0.6214\n",
      "104/104 [==============================] - 0s 260us/sample - loss: 1.0996 - accuracy: 0.6346\n",
      "103/103 [==============================] - 0s 264us/sample - loss: 1.3086 - accuracy: 0.6311\n",
      "104/104 [==============================] - 0s 260us/sample - loss: 1.0684 - accuracy: 0.6250\n",
      "103/103 [==============================] - 0s 262us/sample - loss: 1.0747 - accuracy: 0.6602\n",
      "102/102 [==============================] - 0s 257us/sample - loss: 1.3474 - accuracy: 0.5784\n",
      "100/100 [==============================] - 0s 255us/sample - loss: 1.1324 - accuracy: 0.6200\n",
      "101/101 [==============================] - 0s 293us/sample - loss: 1.0977 - accuracy: 0.6238\n",
      "101/101 [==============================] - 0s 248us/sample - loss: 0.9429 - accuracy: 0.6139\n",
      "99/99 [==============================] - 0s 290us/sample - loss: 0.9827 - accuracy: 0.6768\n",
      "98/98 [==============================] - 0s 335us/sample - loss: 1.0801 - accuracy: 0.6531\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 1.0011 - accuracy: 0.6875\n",
      "97/97 [==============================] - 0s 294us/sample - loss: 1.0807 - accuracy: 0.6907\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2835 samples, validate on 721 samples\n",
      "Epoch 1/300\n",
      "2835/2835 [==============================] - 3s 916us/sample - loss: 0.6720 - accuracy: 0.5880 - val_loss: 0.6613 - val_accuracy: 0.5784\n",
      "Epoch 2/300\n",
      "2835/2835 [==============================] - 1s 224us/sample - loss: 0.6317 - accuracy: 0.6571 - val_loss: 0.6375 - val_accuracy: 0.6214\n",
      "Epoch 3/300\n",
      "2835/2835 [==============================] - 1s 255us/sample - loss: 0.6092 - accuracy: 0.6769 - val_loss: 0.6215 - val_accuracy: 0.6533\n",
      "Epoch 4/300\n",
      "2835/2835 [==============================] - 1s 252us/sample - loss: 0.5931 - accuracy: 0.7016 - val_loss: 0.6096 - val_accuracy: 0.6782\n",
      "Epoch 5/300\n",
      "2835/2835 [==============================] - 1s 187us/sample - loss: 0.5837 - accuracy: 0.7199 - val_loss: 0.5997 - val_accuracy: 0.6976\n",
      "Epoch 6/300\n",
      "2835/2835 [==============================] - 1s 217us/sample - loss: 0.5679 - accuracy: 0.7365 - val_loss: 0.5916 - val_accuracy: 0.7046\n",
      "Epoch 7/300\n",
      "2835/2835 [==============================] - 1s 187us/sample - loss: 0.5624 - accuracy: 0.7365 - val_loss: 0.5845 - val_accuracy: 0.7087\n",
      "Epoch 8/300\n",
      "2835/2835 [==============================] - 1s 195us/sample - loss: 0.5514 - accuracy: 0.7520 - val_loss: 0.5789 - val_accuracy: 0.7171\n",
      "Epoch 9/300\n",
      "2835/2835 [==============================] - 1s 183us/sample - loss: 0.5444 - accuracy: 0.7538 - val_loss: 0.5734 - val_accuracy: 0.7282\n",
      "Epoch 10/300\n",
      "2835/2835 [==============================] - 1s 214us/sample - loss: 0.5367 - accuracy: 0.7658 - val_loss: 0.5688 - val_accuracy: 0.7323\n",
      "Epoch 11/300\n",
      "2835/2835 [==============================] - 1s 194us/sample - loss: 0.5306 - accuracy: 0.7679 - val_loss: 0.5647 - val_accuracy: 0.7379\n",
      "Epoch 12/300\n",
      "2835/2835 [==============================] - 1s 229us/sample - loss: 0.5261 - accuracy: 0.7697 - val_loss: 0.5609 - val_accuracy: 0.7406\n",
      "Epoch 13/300\n",
      "2835/2835 [==============================] - 1s 232us/sample - loss: 0.5228 - accuracy: 0.7792 - val_loss: 0.5578 - val_accuracy: 0.7420\n",
      "Epoch 14/300\n",
      "2835/2835 [==============================] - 1s 223us/sample - loss: 0.5169 - accuracy: 0.7799 - val_loss: 0.5548 - val_accuracy: 0.7448\n",
      "Epoch 15/300\n",
      "2835/2835 [==============================] - 1s 239us/sample - loss: 0.5079 - accuracy: 0.7831 - val_loss: 0.5522 - val_accuracy: 0.7448\n",
      "Epoch 16/300\n",
      "2835/2835 [==============================] - 1s 242us/sample - loss: 0.5077 - accuracy: 0.7827 - val_loss: 0.5498 - val_accuracy: 0.7490\n",
      "Epoch 17/300\n",
      "2835/2835 [==============================] - 1s 235us/sample - loss: 0.5016 - accuracy: 0.7898 - val_loss: 0.5475 - val_accuracy: 0.7517\n",
      "Epoch 18/300\n",
      "2835/2835 [==============================] - 1s 229us/sample - loss: 0.4967 - accuracy: 0.7926 - val_loss: 0.5457 - val_accuracy: 0.7517\n",
      "Epoch 19/300\n",
      "2835/2835 [==============================] - 1s 251us/sample - loss: 0.4969 - accuracy: 0.7891 - val_loss: 0.5439 - val_accuracy: 0.7531\n",
      "Epoch 20/300\n",
      "2835/2835 [==============================] - 1s 259us/sample - loss: 0.4944 - accuracy: 0.7891 - val_loss: 0.5423 - val_accuracy: 0.7545\n",
      "Epoch 21/300\n",
      "2835/2835 [==============================] - 1s 203us/sample - loss: 0.4891 - accuracy: 0.7944 - val_loss: 0.5409 - val_accuracy: 0.7559\n",
      "Epoch 22/300\n",
      "2835/2835 [==============================] - 1s 210us/sample - loss: 0.4792 - accuracy: 0.7996 - val_loss: 0.5396 - val_accuracy: 0.7587\n",
      "Epoch 23/300\n",
      "2835/2835 [==============================] - 1s 208us/sample - loss: 0.4808 - accuracy: 0.8014 - val_loss: 0.5384 - val_accuracy: 0.7614\n",
      "Epoch 24/300\n",
      "2835/2835 [==============================] - 1s 200us/sample - loss: 0.4802 - accuracy: 0.8004 - val_loss: 0.5373 - val_accuracy: 0.7628\n",
      "Epoch 25/300\n",
      "2835/2835 [==============================] - 1s 226us/sample - loss: 0.4791 - accuracy: 0.7947 - val_loss: 0.5363 - val_accuracy: 0.7642\n",
      "Epoch 26/300\n",
      "2835/2835 [==============================] - 1s 208us/sample - loss: 0.4733 - accuracy: 0.8014 - val_loss: 0.5354 - val_accuracy: 0.7656\n",
      "Epoch 27/300\n",
      "2835/2835 [==============================] - 1s 235us/sample - loss: 0.4736 - accuracy: 0.8014 - val_loss: 0.5347 - val_accuracy: 0.7698\n",
      "Epoch 28/300\n",
      "2835/2835 [==============================] - 1s 238us/sample - loss: 0.4686 - accuracy: 0.8042 - val_loss: 0.5339 - val_accuracy: 0.7698\n",
      "Epoch 29/300\n",
      "2835/2835 [==============================] - 1s 255us/sample - loss: 0.4657 - accuracy: 0.8014 - val_loss: 0.5333 - val_accuracy: 0.7698\n",
      "Epoch 30/300\n",
      "2835/2835 [==============================] - 1s 234us/sample - loss: 0.4624 - accuracy: 0.8095 - val_loss: 0.5327 - val_accuracy: 0.7712\n",
      "Epoch 31/300\n",
      "2835/2835 [==============================] - 1s 227us/sample - loss: 0.4653 - accuracy: 0.8028 - val_loss: 0.5321 - val_accuracy: 0.7712\n",
      "Epoch 32/300\n",
      "2835/2835 [==============================] - 1s 245us/sample - loss: 0.4574 - accuracy: 0.8085 - val_loss: 0.5317 - val_accuracy: 0.7712\n",
      "Epoch 33/300\n",
      "2835/2835 [==============================] - 1s 237us/sample - loss: 0.4576 - accuracy: 0.8063 - val_loss: 0.5313 - val_accuracy: 0.7725\n",
      "Epoch 34/300\n",
      "2835/2835 [==============================] - 1s 233us/sample - loss: 0.4534 - accuracy: 0.8116 - val_loss: 0.5309 - val_accuracy: 0.7725\n",
      "Epoch 35/300\n",
      "2835/2835 [==============================] - 1s 252us/sample - loss: 0.4569 - accuracy: 0.8095 - val_loss: 0.5306 - val_accuracy: 0.7739\n",
      "Epoch 36/300\n",
      "2835/2835 [==============================] - 1s 259us/sample - loss: 0.4458 - accuracy: 0.8141 - val_loss: 0.5303 - val_accuracy: 0.7739\n",
      "Epoch 37/300\n",
      "2835/2835 [==============================] - 1s 236us/sample - loss: 0.4454 - accuracy: 0.8138 - val_loss: 0.5301 - val_accuracy: 0.7739\n",
      "Epoch 38/300\n",
      "2835/2835 [==============================] - 1s 208us/sample - loss: 0.4423 - accuracy: 0.8127 - val_loss: 0.5299 - val_accuracy: 0.7725\n",
      "Epoch 39/300\n",
      "2835/2835 [==============================] - 1s 216us/sample - loss: 0.4479 - accuracy: 0.8131 - val_loss: 0.5297 - val_accuracy: 0.7739\n",
      "Epoch 40/300\n",
      "2835/2835 [==============================] - 1s 234us/sample - loss: 0.4474 - accuracy: 0.8155 - val_loss: 0.5297 - val_accuracy: 0.7725\n",
      "Epoch 41/300\n",
      "2835/2835 [==============================] - 1s 259us/sample - loss: 0.4452 - accuracy: 0.8131 - val_loss: 0.5295 - val_accuracy: 0.7712\n",
      "Epoch 42/300\n",
      "2835/2835 [==============================] - 1s 232us/sample - loss: 0.4374 - accuracy: 0.8176 - val_loss: 0.5295 - val_accuracy: 0.7712\n",
      "Epoch 43/300\n",
      "2835/2835 [==============================] - 1s 248us/sample - loss: 0.4339 - accuracy: 0.8212 - val_loss: 0.5294 - val_accuracy: 0.7712\n",
      "Epoch 44/300\n",
      "2835/2835 [==============================] - 1s 216us/sample - loss: 0.4345 - accuracy: 0.8208 - val_loss: 0.5294 - val_accuracy: 0.7698\n",
      "Epoch 45/300\n",
      "2835/2835 [==============================] - 1s 217us/sample - loss: 0.4320 - accuracy: 0.8212 - val_loss: 0.5294 - val_accuracy: 0.7698\n",
      "Epoch 46/300\n",
      "2835/2835 [==============================] - 1s 238us/sample - loss: 0.4307 - accuracy: 0.8254 - val_loss: 0.5294 - val_accuracy: 0.7684\n",
      "Epoch 47/300\n",
      "2835/2835 [==============================] - 1s 217us/sample - loss: 0.4331 - accuracy: 0.8187 - val_loss: 0.5295 - val_accuracy: 0.7684\n",
      "Epoch 00047: early stopping\n",
      "93/93 [==============================] - 0s 159us/sample - loss: 0.7926 - accuracy: 0.5484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [4:26:21, 1059.41s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.82s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.42s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 831.9375 steps, validate for 212.6015625 steps\n",
      "Epoch 1/300\n",
      "832/831 [==============================] - 25s 30ms/step - loss: 0.5618 - accuracy: 0.7384 - val_loss: 0.5327 - val_accuracy: 0.7685\n",
      "Epoch 2/300\n",
      "832/831 [==============================] - 23s 28ms/step - loss: 0.5126 - accuracy: 0.7747 - val_loss: 0.5280 - val_accuracy: 0.7681\n",
      "Epoch 3/300\n",
      "832/831 [==============================] - 24s 28ms/step - loss: 0.4980 - accuracy: 0.7794 - val_loss: 0.5294 - val_accuracy: 0.7685\n",
      "Epoch 4/300\n",
      "832/831 [==============================] - 24s 29ms/step - loss: 0.4869 - accuracy: 0.7839 - val_loss: 0.5309 - val_accuracy: 0.7660\n",
      "Epoch 5/300\n",
      "832/831 [==============================] - 24s 29ms/step - loss: 0.4772 - accuracy: 0.7881 - val_loss: 0.5327 - val_accuracy: 0.7661\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 831.9375 steps, validate for 212.6015625 steps\n",
      "Epoch 1/300\n",
      "832/831 [==============================] - 55s 66ms/step - loss: 0.4608 - accuracy: 0.7960 - val_loss: 0.5408 - val_accuracy: 0.7683\n",
      "Epoch 2/300\n",
      "832/831 [==============================] - 54s 64ms/step - loss: 0.4336 - accuracy: 0.8096 - val_loss: 0.5453 - val_accuracy: 0.7646\n",
      "Epoch 3/300\n",
      "832/831 [==============================] - 53s 64ms/step - loss: 0.4108 - accuracy: 0.8213 - val_loss: 0.5513 - val_accuracy: 0.7612\n",
      "Epoch 4/300\n",
      "832/831 [==============================] - 53s 64ms/step - loss: 0.3903 - accuracy: 0.8328 - val_loss: 0.5542 - val_accuracy: 0.7435\n",
      "Epoch 00004: early stopping\n",
      "146/146 [==============================] - 0s 2ms/sample - loss: 0.3618 - accuracy: 0.8699\n",
      "142/142 [==============================] - 0s 249us/sample - loss: 0.3603 - accuracy: 0.8592\n",
      "138/138 [==============================] - 0s 275us/sample - loss: 0.3885 - accuracy: 0.8333\n",
      "137/137 [==============================] - 0s 244us/sample - loss: 0.3621 - accuracy: 0.8832\n",
      "134/134 [==============================] - 0s 275us/sample - loss: 0.3473 - accuracy: 0.8955\n",
      "130/130 [==============================] - 0s 230us/sample - loss: 0.3373 - accuracy: 0.8923\n",
      "129/129 [==============================] - 0s 230us/sample - loss: 0.3477 - accuracy: 0.8760\n",
      "127/127 [==============================] - 0s 242us/sample - loss: 0.3388 - accuracy: 0.9134\n",
      "125/125 [==============================] - 0s 230us/sample - loss: 0.3655 - accuracy: 0.8720\n",
      "125/125 [==============================] - 0s 247us/sample - loss: 0.3572 - accuracy: 0.8960\n",
      "125/125 [==============================] - 0s 213us/sample - loss: 0.3153 - accuracy: 0.9200\n",
      "125/125 [==============================] - 0s 276us/sample - loss: 0.3478 - accuracy: 0.9120\n",
      "125/125 [==============================] - 0s 243us/sample - loss: 0.2950 - accuracy: 0.9520\n",
      "124/124 [==============================] - 0s 234us/sample - loss: 0.3605 - accuracy: 0.8790\n",
      "123/123 [==============================] - 0s 230us/sample - loss: 0.3547 - accuracy: 0.8862\n",
      "124/124 [==============================] - 0s 235us/sample - loss: 0.3456 - accuracy: 0.9113\n",
      "122/122 [==============================] - 0s 230us/sample - loss: 0.3619 - accuracy: 0.8934\n",
      "122/122 [==============================] - 0s 233us/sample - loss: 0.3557 - accuracy: 0.9262\n",
      "121/121 [==============================] - 0s 236us/sample - loss: 0.3395 - accuracy: 0.9339\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.3637 - accuracy: 0.9167\n",
      "117/117 [==============================] - 0s 269us/sample - loss: 0.3882 - accuracy: 0.8632\n",
      "115/115 [==============================] - 0s 256us/sample - loss: 0.3672 - accuracy: 0.8870\n",
      "119/119 [==============================] - 0s 235us/sample - loss: 0.3401 - accuracy: 0.9076\n",
      "119/119 [==============================] - 0s 239us/sample - loss: 0.3835 - accuracy: 0.8571\n",
      "117/117 [==============================] - 0s 236us/sample - loss: 0.3627 - accuracy: 0.9316\n",
      "116/116 [==============================] - 0s 254us/sample - loss: 0.3992 - accuracy: 0.8621\n",
      "117/117 [==============================] - 0s 248us/sample - loss: 0.3747 - accuracy: 0.8974\n",
      "117/117 [==============================] - 0s 263us/sample - loss: 0.3488 - accuracy: 0.9145\n",
      "116/116 [==============================] - 0s 255us/sample - loss: 0.3213 - accuracy: 0.9397\n",
      "115/115 [==============================] - 0s 246us/sample - loss: 0.3601 - accuracy: 0.9130\n",
      "116/116 [==============================] - 0s 262us/sample - loss: 0.3249 - accuracy: 0.9138\n",
      "116/116 [==============================] - 0s 271us/sample - loss: 0.3168 - accuracy: 0.9310\n",
      "113/113 [==============================] - 0s 234us/sample - loss: 0.3280 - accuracy: 0.9381\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2821 samples, validate on 720 samples\n",
      "Epoch 1/300\n",
      "2821/2821 [==============================] - 2s 828us/sample - loss: 0.6348 - accuracy: 0.6427 - val_loss: 0.6078 - val_accuracy: 0.6944\n",
      "Epoch 2/300\n",
      "2821/2821 [==============================] - 1s 237us/sample - loss: 0.6015 - accuracy: 0.6923 - val_loss: 0.5920 - val_accuracy: 0.7125\n",
      "Epoch 3/300\n",
      "2821/2821 [==============================] - 1s 244us/sample - loss: 0.5853 - accuracy: 0.7189 - val_loss: 0.5814 - val_accuracy: 0.7250\n",
      "Epoch 4/300\n",
      "2821/2821 [==============================] - 1s 196us/sample - loss: 0.5751 - accuracy: 0.7295 - val_loss: 0.5734 - val_accuracy: 0.7278\n",
      "Epoch 5/300\n",
      "2821/2821 [==============================] - 1s 183us/sample - loss: 0.5619 - accuracy: 0.7395 - val_loss: 0.5667 - val_accuracy: 0.7347\n",
      "Epoch 6/300\n",
      "2821/2821 [==============================] - 1s 217us/sample - loss: 0.5507 - accuracy: 0.7526 - val_loss: 0.5613 - val_accuracy: 0.7361\n",
      "Epoch 7/300\n",
      "2821/2821 [==============================] - 1s 208us/sample - loss: 0.5485 - accuracy: 0.7575 - val_loss: 0.5567 - val_accuracy: 0.7458\n",
      "Epoch 8/300\n",
      "2821/2821 [==============================] - 1s 238us/sample - loss: 0.5377 - accuracy: 0.7568 - val_loss: 0.5525 - val_accuracy: 0.7472\n",
      "Epoch 9/300\n",
      "2821/2821 [==============================] - 1s 251us/sample - loss: 0.5322 - accuracy: 0.7735 - val_loss: 0.5491 - val_accuracy: 0.7486\n",
      "Epoch 10/300\n",
      "2821/2821 [==============================] - 1s 249us/sample - loss: 0.5288 - accuracy: 0.7710 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 11/300\n",
      "2821/2821 [==============================] - 1s 239us/sample - loss: 0.5225 - accuracy: 0.7724 - val_loss: 0.5430 - val_accuracy: 0.7514\n",
      "Epoch 12/300\n",
      "2821/2821 [==============================] - 1s 263us/sample - loss: 0.5179 - accuracy: 0.7699 - val_loss: 0.5404 - val_accuracy: 0.7542\n",
      "Epoch 13/300\n",
      "2821/2821 [==============================] - 1s 230us/sample - loss: 0.5106 - accuracy: 0.7781 - val_loss: 0.5381 - val_accuracy: 0.7556\n",
      "Epoch 14/300\n",
      "2821/2821 [==============================] - 1s 193us/sample - loss: 0.5059 - accuracy: 0.7838 - val_loss: 0.5361 - val_accuracy: 0.7583\n",
      "Epoch 15/300\n",
      "2821/2821 [==============================] - 1s 197us/sample - loss: 0.5065 - accuracy: 0.7834 - val_loss: 0.5343 - val_accuracy: 0.7597\n",
      "Epoch 16/300\n",
      "2821/2821 [==============================] - 1s 232us/sample - loss: 0.5026 - accuracy: 0.7898 - val_loss: 0.5326 - val_accuracy: 0.7611\n",
      "Epoch 17/300\n",
      "2821/2821 [==============================] - 1s 213us/sample - loss: 0.4989 - accuracy: 0.7901 - val_loss: 0.5310 - val_accuracy: 0.7639\n",
      "Epoch 18/300\n",
      "2821/2821 [==============================] - 1s 199us/sample - loss: 0.4952 - accuracy: 0.7873 - val_loss: 0.5296 - val_accuracy: 0.7639\n",
      "Epoch 19/300\n",
      "2821/2821 [==============================] - 1s 204us/sample - loss: 0.4881 - accuracy: 0.7976 - val_loss: 0.5284 - val_accuracy: 0.7611\n",
      "Epoch 20/300\n",
      "2821/2821 [==============================] - 1s 212us/sample - loss: 0.4829 - accuracy: 0.7983 - val_loss: 0.5273 - val_accuracy: 0.7611\n",
      "Epoch 21/300\n",
      "2821/2821 [==============================] - 1s 206us/sample - loss: 0.4778 - accuracy: 0.8011 - val_loss: 0.5262 - val_accuracy: 0.7597\n",
      "Epoch 22/300\n",
      "2821/2821 [==============================] - 1s 207us/sample - loss: 0.4820 - accuracy: 0.7962 - val_loss: 0.5252 - val_accuracy: 0.7611\n",
      "Epoch 23/300\n",
      "2821/2821 [==============================] - 1s 201us/sample - loss: 0.4790 - accuracy: 0.7944 - val_loss: 0.5243 - val_accuracy: 0.7597\n",
      "Epoch 24/300\n",
      "2821/2821 [==============================] - 1s 204us/sample - loss: 0.4740 - accuracy: 0.7933 - val_loss: 0.5234 - val_accuracy: 0.7611\n",
      "Epoch 25/300\n",
      "2821/2821 [==============================] - 1s 242us/sample - loss: 0.4741 - accuracy: 0.8036 - val_loss: 0.5227 - val_accuracy: 0.7611\n",
      "Epoch 26/300\n",
      "2821/2821 [==============================] - 1s 205us/sample - loss: 0.4717 - accuracy: 0.8004 - val_loss: 0.5220 - val_accuracy: 0.7611\n",
      "Epoch 27/300\n",
      "2821/2821 [==============================] - 1s 212us/sample - loss: 0.4649 - accuracy: 0.8068 - val_loss: 0.5214 - val_accuracy: 0.7611\n",
      "Epoch 28/300\n",
      "2821/2821 [==============================] - 1s 268us/sample - loss: 0.4628 - accuracy: 0.8068 - val_loss: 0.5209 - val_accuracy: 0.7597\n",
      "Epoch 29/300\n",
      "2821/2821 [==============================] - 1s 191us/sample - loss: 0.4573 - accuracy: 0.8082 - val_loss: 0.5205 - val_accuracy: 0.7597\n",
      "Epoch 30/300\n",
      "2821/2821 [==============================] - 1s 209us/sample - loss: 0.4581 - accuracy: 0.8029 - val_loss: 0.5200 - val_accuracy: 0.7597\n",
      "Epoch 31/300\n",
      "2821/2821 [==============================] - 1s 246us/sample - loss: 0.4574 - accuracy: 0.8050 - val_loss: 0.5196 - val_accuracy: 0.7611\n",
      "Epoch 32/300\n",
      "2821/2821 [==============================] - 1s 219us/sample - loss: 0.4531 - accuracy: 0.8089 - val_loss: 0.5192 - val_accuracy: 0.7583\n",
      "Epoch 33/300\n",
      "2821/2821 [==============================] - 1s 223us/sample - loss: 0.4549 - accuracy: 0.8107 - val_loss: 0.5189 - val_accuracy: 0.7583\n",
      "Epoch 34/300\n",
      "2821/2821 [==============================] - 1s 240us/sample - loss: 0.4501 - accuracy: 0.8118 - val_loss: 0.5186 - val_accuracy: 0.7625\n",
      "Epoch 35/300\n",
      "2821/2821 [==============================] - 1s 207us/sample - loss: 0.4492 - accuracy: 0.8093 - val_loss: 0.5184 - val_accuracy: 0.7625\n",
      "Epoch 36/300\n",
      "2821/2821 [==============================] - 1s 221us/sample - loss: 0.4450 - accuracy: 0.8171 - val_loss: 0.5183 - val_accuracy: 0.7639\n",
      "Epoch 37/300\n",
      "2821/2821 [==============================] - 1s 194us/sample - loss: 0.4403 - accuracy: 0.8196 - val_loss: 0.5181 - val_accuracy: 0.7625\n",
      "Epoch 38/300\n",
      "2821/2821 [==============================] - 1s 186us/sample - loss: 0.4414 - accuracy: 0.8143 - val_loss: 0.5180 - val_accuracy: 0.7653\n",
      "Epoch 39/300\n",
      "2821/2821 [==============================] - 1s 211us/sample - loss: 0.4387 - accuracy: 0.8171 - val_loss: 0.5180 - val_accuracy: 0.7667\n",
      "Epoch 40/300\n",
      "2821/2821 [==============================] - 1s 233us/sample - loss: 0.4387 - accuracy: 0.8210 - val_loss: 0.5178 - val_accuracy: 0.7667\n",
      "Epoch 41/300\n",
      "2821/2821 [==============================] - 1s 254us/sample - loss: 0.4363 - accuracy: 0.8164 - val_loss: 0.5178 - val_accuracy: 0.7667\n",
      "Epoch 42/300\n",
      "2821/2821 [==============================] - 1s 262us/sample - loss: 0.4337 - accuracy: 0.8178 - val_loss: 0.5178 - val_accuracy: 0.7653\n",
      "Epoch 43/300\n",
      "2821/2821 [==============================] - 1s 244us/sample - loss: 0.4317 - accuracy: 0.8181 - val_loss: 0.5178 - val_accuracy: 0.7639\n",
      "Epoch 44/300\n",
      "2821/2821 [==============================] - 1s 242us/sample - loss: 0.4292 - accuracy: 0.8192 - val_loss: 0.5179 - val_accuracy: 0.7639\n",
      "Epoch 45/300\n",
      "2821/2821 [==============================] - 1s 212us/sample - loss: 0.4272 - accuracy: 0.8228 - val_loss: 0.5180 - val_accuracy: 0.7639\n",
      "Epoch 00045: early stopping\n",
      "108/108 [==============================] - 0s 131us/sample - loss: 0.3762 - accuracy: 0.9167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [4:43:16, 1045.96s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.43s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.33s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 832.203125 steps, validate for 214.265625 steps\n",
      "Epoch 1/300\n",
      "833/832 [==============================] - 25s 30ms/step - loss: 0.5842 - accuracy: 0.7171 - val_loss: 0.5398 - val_accuracy: 0.7656\n",
      "Epoch 2/300\n",
      "833/832 [==============================] - 24s 29ms/step - loss: 0.5133 - accuracy: 0.7741 - val_loss: 0.5362 - val_accuracy: 0.7684\n",
      "Epoch 3/300\n",
      "833/832 [==============================] - 24s 29ms/step - loss: 0.4979 - accuracy: 0.7784 - val_loss: 0.5370 - val_accuracy: 0.7678\n",
      "Epoch 4/300\n",
      "833/832 [==============================] - 24s 29ms/step - loss: 0.4867 - accuracy: 0.7830 - val_loss: 0.5371 - val_accuracy: 0.7651\n",
      "Epoch 5/300\n",
      "833/832 [==============================] - 24s 29ms/step - loss: 0.4771 - accuracy: 0.7868 - val_loss: 0.5414 - val_accuracy: 0.7616\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 832.203125 steps, validate for 214.265625 steps\n",
      "Epoch 1/300\n",
      "833/832 [==============================] - 55s 66ms/step - loss: 0.4600 - accuracy: 0.7952 - val_loss: 0.5545 - val_accuracy: 0.7493\n",
      "Epoch 2/300\n",
      "833/832 [==============================] - 54s 64ms/step - loss: 0.4329 - accuracy: 0.8084 - val_loss: 0.5595 - val_accuracy: 0.7467\n",
      "Epoch 3/300\n",
      "833/832 [==============================] - 53s 64ms/step - loss: 0.4097 - accuracy: 0.8204 - val_loss: 0.5559 - val_accuracy: 0.7532\n",
      "Epoch 4/300\n",
      "833/832 [==============================] - 53s 64ms/step - loss: 0.3885 - accuracy: 0.8321 - val_loss: 0.5656 - val_accuracy: 0.7541\n",
      "Epoch 00004: early stopping\n",
      "153/153 [==============================] - 0s 1ms/sample - loss: 0.1879 - accuracy: 0.9804\n",
      "147/147 [==============================] - 0s 234us/sample - loss: 0.1924 - accuracy: 0.9796\n",
      "141/141 [==============================] - 0s 230us/sample - loss: 0.1940 - accuracy: 0.9645\n",
      "136/136 [==============================] - 0s 325us/sample - loss: 0.2186 - accuracy: 0.9632\n",
      "129/129 [==============================] - 0s 232us/sample - loss: 0.1836 - accuracy: 0.9767\n",
      "128/128 [==============================] - 0s 1ms/sample - loss: 0.2307 - accuracy: 0.9297\n",
      "125/125 [==============================] - 0s 225us/sample - loss: 0.2397 - accuracy: 0.9520\n",
      "125/125 [==============================] - 0s 215us/sample - loss: 0.2399 - accuracy: 0.9520\n",
      "122/122 [==============================] - 0s 225us/sample - loss: 0.2320 - accuracy: 0.9426\n",
      "119/119 [==============================] - 0s 259us/sample - loss: 0.2068 - accuracy: 0.9664\n",
      "115/115 [==============================] - 0s 393us/sample - loss: 0.2060 - accuracy: 0.9739\n",
      "114/114 [==============================] - 0s 254us/sample - loss: 0.2307 - accuracy: 0.9649\n",
      "113/113 [==============================] - 0s 237us/sample - loss: 0.2086 - accuracy: 0.9558\n",
      "113/113 [==============================] - 0s 258us/sample - loss: 0.1715 - accuracy: 1.0000\n",
      "109/109 [==============================] - 0s 249us/sample - loss: 0.2260 - accuracy: 0.9450\n",
      "109/109 [==============================] - 0s 283us/sample - loss: 0.2339 - accuracy: 0.9541\n",
      "108/108 [==============================] - 0s 290us/sample - loss: 0.1885 - accuracy: 0.9815\n",
      "109/109 [==============================] - 0s 260us/sample - loss: 0.2097 - accuracy: 0.9541\n",
      "108/108 [==============================] - 0s 259us/sample - loss: 0.2388 - accuracy: 0.9537\n",
      "108/108 [==============================] - 0s 277us/sample - loss: 0.2343 - accuracy: 0.9630\n",
      "108/108 [==============================] - 0s 303us/sample - loss: 0.2519 - accuracy: 0.9352\n",
      "107/107 [==============================] - 0s 296us/sample - loss: 0.2172 - accuracy: 0.9720\n",
      "108/108 [==============================] - 0s 282us/sample - loss: 0.2341 - accuracy: 0.9444\n",
      "108/108 [==============================] - 0s 274us/sample - loss: 0.2621 - accuracy: 0.9352\n",
      "107/107 [==============================] - 0s 271us/sample - loss: 0.2300 - accuracy: 0.9533\n",
      "107/107 [==============================] - 0s 300us/sample - loss: 0.2575 - accuracy: 0.9159\n",
      "108/108 [==============================] - 0s 275us/sample - loss: 0.2390 - accuracy: 0.9630\n",
      "108/108 [==============================] - 0s 269us/sample - loss: 0.2274 - accuracy: 0.9630\n",
      "107/107 [==============================] - 0s 279us/sample - loss: 0.2557 - accuracy: 0.9439\n",
      "108/108 [==============================] - 0s 277us/sample - loss: 0.2640 - accuracy: 0.9352\n",
      "107/107 [==============================] - 0s 279us/sample - loss: 0.2586 - accuracy: 0.9439\n",
      "108/108 [==============================] - 0s 252us/sample - loss: 0.2296 - accuracy: 0.9537\n",
      "108/108 [==============================] - 0s 268us/sample - loss: 0.2487 - accuracy: 0.9537\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2822 samples, validate on 725 samples\n",
      "Epoch 1/300\n",
      "2822/2822 [==============================] - 3s 963us/sample - loss: 0.7108 - accuracy: 0.5326 - val_loss: 0.6864 - val_accuracy: 0.5490\n",
      "Epoch 2/300\n",
      "2822/2822 [==============================] - 1s 250us/sample - loss: 0.6661 - accuracy: 0.6056 - val_loss: 0.6563 - val_accuracy: 0.5986\n",
      "Epoch 3/300\n",
      "2822/2822 [==============================] - 1s 211us/sample - loss: 0.6429 - accuracy: 0.6410 - val_loss: 0.6369 - val_accuracy: 0.6441\n",
      "Epoch 4/300\n",
      "2822/2822 [==============================] - 1s 222us/sample - loss: 0.6267 - accuracy: 0.6577 - val_loss: 0.6214 - val_accuracy: 0.6634\n",
      "Epoch 5/300\n",
      "2822/2822 [==============================] - 1s 211us/sample - loss: 0.6119 - accuracy: 0.6782 - val_loss: 0.6093 - val_accuracy: 0.6869\n",
      "Epoch 6/300\n",
      "2822/2822 [==============================] - 1s 222us/sample - loss: 0.5968 - accuracy: 0.7080 - val_loss: 0.5995 - val_accuracy: 0.6952\n",
      "Epoch 7/300\n",
      "2822/2822 [==============================] - 1s 220us/sample - loss: 0.5881 - accuracy: 0.7133 - val_loss: 0.5907 - val_accuracy: 0.7172\n",
      "Epoch 8/300\n",
      "2822/2822 [==============================] - 1s 205us/sample - loss: 0.5795 - accuracy: 0.7250 - val_loss: 0.5830 - val_accuracy: 0.7255\n",
      "Epoch 9/300\n",
      "2822/2822 [==============================] - 1s 251us/sample - loss: 0.5723 - accuracy: 0.7328 - val_loss: 0.5762 - val_accuracy: 0.7393\n",
      "Epoch 10/300\n",
      "2822/2822 [==============================] - 1s 226us/sample - loss: 0.5639 - accuracy: 0.7413 - val_loss: 0.5704 - val_accuracy: 0.7407\n",
      "Epoch 11/300\n",
      "2822/2822 [==============================] - 1s 222us/sample - loss: 0.5565 - accuracy: 0.7505 - val_loss: 0.5650 - val_accuracy: 0.7448\n",
      "Epoch 12/300\n",
      "2822/2822 [==============================] - 1s 207us/sample - loss: 0.5530 - accuracy: 0.7512 - val_loss: 0.5604 - val_accuracy: 0.7434\n",
      "Epoch 13/300\n",
      "2822/2822 [==============================] - 1s 245us/sample - loss: 0.5473 - accuracy: 0.7555 - val_loss: 0.5559 - val_accuracy: 0.7517\n",
      "Epoch 14/300\n",
      "2822/2822 [==============================] - 1s 254us/sample - loss: 0.5398 - accuracy: 0.7612 - val_loss: 0.5520 - val_accuracy: 0.7545\n",
      "Epoch 15/300\n",
      "2822/2822 [==============================] - 1s 241us/sample - loss: 0.5358 - accuracy: 0.7608 - val_loss: 0.5485 - val_accuracy: 0.7572\n",
      "Epoch 16/300\n",
      "2822/2822 [==============================] - 1s 233us/sample - loss: 0.5317 - accuracy: 0.7629 - val_loss: 0.5451 - val_accuracy: 0.7641\n",
      "Epoch 17/300\n",
      "2822/2822 [==============================] - 1s 255us/sample - loss: 0.5297 - accuracy: 0.7654 - val_loss: 0.5421 - val_accuracy: 0.7669\n",
      "Epoch 18/300\n",
      "2822/2822 [==============================] - 1s 250us/sample - loss: 0.5188 - accuracy: 0.7718 - val_loss: 0.5394 - val_accuracy: 0.7669\n",
      "Epoch 19/300\n",
      "2822/2822 [==============================] - 1s 264us/sample - loss: 0.5182 - accuracy: 0.7768 - val_loss: 0.5370 - val_accuracy: 0.7683\n",
      "Epoch 20/300\n",
      "2822/2822 [==============================] - 1s 260us/sample - loss: 0.5150 - accuracy: 0.7732 - val_loss: 0.5346 - val_accuracy: 0.7724\n",
      "Epoch 21/300\n",
      "2822/2822 [==============================] - 1s 229us/sample - loss: 0.5123 - accuracy: 0.7807 - val_loss: 0.5326 - val_accuracy: 0.7738\n",
      "Epoch 22/300\n",
      "2822/2822 [==============================] - 1s 253us/sample - loss: 0.5107 - accuracy: 0.7739 - val_loss: 0.5305 - val_accuracy: 0.7724\n",
      "Epoch 23/300\n",
      "2822/2822 [==============================] - 1s 243us/sample - loss: 0.5113 - accuracy: 0.7690 - val_loss: 0.5290 - val_accuracy: 0.7697\n",
      "Epoch 24/300\n",
      "2822/2822 [==============================] - 1s 219us/sample - loss: 0.5026 - accuracy: 0.7807 - val_loss: 0.5274 - val_accuracy: 0.7683\n",
      "Epoch 25/300\n",
      "2822/2822 [==============================] - 1s 250us/sample - loss: 0.4997 - accuracy: 0.7796 - val_loss: 0.5260 - val_accuracy: 0.7683\n",
      "Epoch 26/300\n",
      "2822/2822 [==============================] - 1s 253us/sample - loss: 0.4958 - accuracy: 0.7870 - val_loss: 0.5247 - val_accuracy: 0.7697\n",
      "Epoch 27/300\n",
      "2822/2822 [==============================] - 1s 253us/sample - loss: 0.4979 - accuracy: 0.7817 - val_loss: 0.5235 - val_accuracy: 0.7697\n",
      "Epoch 28/300\n",
      "2822/2822 [==============================] - 1s 250us/sample - loss: 0.4927 - accuracy: 0.7856 - val_loss: 0.5224 - val_accuracy: 0.7697\n",
      "Epoch 29/300\n",
      "2822/2822 [==============================] - 1s 236us/sample - loss: 0.4928 - accuracy: 0.7831 - val_loss: 0.5215 - val_accuracy: 0.7697\n",
      "Epoch 30/300\n",
      "2822/2822 [==============================] - 1s 216us/sample - loss: 0.4902 - accuracy: 0.7870 - val_loss: 0.5206 - val_accuracy: 0.7683\n",
      "Epoch 31/300\n",
      "2822/2822 [==============================] - 1s 259us/sample - loss: 0.4901 - accuracy: 0.7824 - val_loss: 0.5196 - val_accuracy: 0.7697\n",
      "Epoch 32/300\n",
      "2822/2822 [==============================] - 1s 212us/sample - loss: 0.4856 - accuracy: 0.7842 - val_loss: 0.5188 - val_accuracy: 0.7697\n",
      "Epoch 33/300\n",
      "2822/2822 [==============================] - 1s 264us/sample - loss: 0.4840 - accuracy: 0.7881 - val_loss: 0.5182 - val_accuracy: 0.7697\n",
      "Epoch 34/300\n",
      "2822/2822 [==============================] - 1s 260us/sample - loss: 0.4799 - accuracy: 0.7863 - val_loss: 0.5176 - val_accuracy: 0.7697\n",
      "Epoch 35/300\n",
      "2822/2822 [==============================] - 1s 233us/sample - loss: 0.4762 - accuracy: 0.7884 - val_loss: 0.5170 - val_accuracy: 0.7697\n",
      "Epoch 36/300\n",
      "2822/2822 [==============================] - 1s 239us/sample - loss: 0.4784 - accuracy: 0.7927 - val_loss: 0.5164 - val_accuracy: 0.7697\n",
      "Epoch 37/300\n",
      "2822/2822 [==============================] - 1s 210us/sample - loss: 0.4757 - accuracy: 0.7909 - val_loss: 0.5159 - val_accuracy: 0.7697\n",
      "Epoch 38/300\n",
      "2822/2822 [==============================] - 1s 224us/sample - loss: 0.4706 - accuracy: 0.7934 - val_loss: 0.5156 - val_accuracy: 0.7697\n",
      "Epoch 39/300\n",
      "2822/2822 [==============================] - 1s 242us/sample - loss: 0.4741 - accuracy: 0.7931 - val_loss: 0.5151 - val_accuracy: 0.7697\n",
      "Epoch 40/300\n",
      "2822/2822 [==============================] - 1s 254us/sample - loss: 0.4738 - accuracy: 0.7892 - val_loss: 0.5147 - val_accuracy: 0.7697\n",
      "Epoch 41/300\n",
      "2822/2822 [==============================] - 1s 241us/sample - loss: 0.4680 - accuracy: 0.7998 - val_loss: 0.5143 - val_accuracy: 0.7697\n",
      "Epoch 42/300\n",
      "2822/2822 [==============================] - 1s 252us/sample - loss: 0.4664 - accuracy: 0.7948 - val_loss: 0.5141 - val_accuracy: 0.7683\n",
      "Epoch 43/300\n",
      "2822/2822 [==============================] - 1s 248us/sample - loss: 0.4665 - accuracy: 0.7941 - val_loss: 0.5138 - val_accuracy: 0.7697\n",
      "Epoch 44/300\n",
      "2822/2822 [==============================] - 1s 249us/sample - loss: 0.4600 - accuracy: 0.7973 - val_loss: 0.5136 - val_accuracy: 0.7697\n",
      "Epoch 45/300\n",
      "2822/2822 [==============================] - 1s 232us/sample - loss: 0.4621 - accuracy: 0.7973 - val_loss: 0.5133 - val_accuracy: 0.7697\n",
      "Epoch 46/300\n",
      "2822/2822 [==============================] - 1s 255us/sample - loss: 0.4597 - accuracy: 0.7959 - val_loss: 0.5132 - val_accuracy: 0.7683\n",
      "Epoch 47/300\n",
      "2822/2822 [==============================] - 1s 235us/sample - loss: 0.4587 - accuracy: 0.7970 - val_loss: 0.5130 - val_accuracy: 0.7697\n",
      "Epoch 48/300\n",
      "2822/2822 [==============================] - 1s 261us/sample - loss: 0.4556 - accuracy: 0.8012 - val_loss: 0.5129 - val_accuracy: 0.7683\n",
      "Epoch 49/300\n",
      "2822/2822 [==============================] - 1s 259us/sample - loss: 0.4543 - accuracy: 0.8009 - val_loss: 0.5128 - val_accuracy: 0.7697\n",
      "Epoch 50/300\n",
      "2822/2822 [==============================] - 1s 260us/sample - loss: 0.4539 - accuracy: 0.8033 - val_loss: 0.5126 - val_accuracy: 0.7724\n",
      "Epoch 51/300\n",
      "2822/2822 [==============================] - 1s 249us/sample - loss: 0.4516 - accuracy: 0.8055 - val_loss: 0.5124 - val_accuracy: 0.7724\n",
      "Epoch 52/300\n",
      "2822/2822 [==============================] - 1s 235us/sample - loss: 0.4506 - accuracy: 0.8016 - val_loss: 0.5124 - val_accuracy: 0.7738\n",
      "Epoch 53/300\n",
      "2822/2822 [==============================] - 1s 228us/sample - loss: 0.4443 - accuracy: 0.8086 - val_loss: 0.5123 - val_accuracy: 0.7738\n",
      "Epoch 54/300\n",
      "2822/2822 [==============================] - 1s 248us/sample - loss: 0.4485 - accuracy: 0.8044 - val_loss: 0.5122 - val_accuracy: 0.7738\n",
      "Epoch 55/300\n",
      "2822/2822 [==============================] - 1s 234us/sample - loss: 0.4496 - accuracy: 0.8033 - val_loss: 0.5122 - val_accuracy: 0.7738\n",
      "Epoch 56/300\n",
      "2822/2822 [==============================] - 1s 247us/sample - loss: 0.4428 - accuracy: 0.8086 - val_loss: 0.5121 - val_accuracy: 0.7738\n",
      "Epoch 57/300\n",
      "2822/2822 [==============================] - 1s 231us/sample - loss: 0.4366 - accuracy: 0.8104 - val_loss: 0.5120 - val_accuracy: 0.7738\n",
      "Epoch 58/300\n",
      "2822/2822 [==============================] - 1s 242us/sample - loss: 0.4411 - accuracy: 0.8133 - val_loss: 0.5120 - val_accuracy: 0.7738\n",
      "Epoch 59/300\n",
      "2822/2822 [==============================] - 1s 214us/sample - loss: 0.4424 - accuracy: 0.8090 - val_loss: 0.5119 - val_accuracy: 0.7724\n",
      "Epoch 60/300\n",
      "2822/2822 [==============================] - 1s 234us/sample - loss: 0.4370 - accuracy: 0.8115 - val_loss: 0.5119 - val_accuracy: 0.7724\n",
      "Epoch 61/300\n",
      "2822/2822 [==============================] - 1s 207us/sample - loss: 0.4335 - accuracy: 0.8118 - val_loss: 0.5119 - val_accuracy: 0.7724\n",
      "Epoch 62/300\n",
      "2822/2822 [==============================] - 1s 243us/sample - loss: 0.4393 - accuracy: 0.8111 - val_loss: 0.5120 - val_accuracy: 0.7724\n",
      "Epoch 63/300\n",
      "2822/2822 [==============================] - 1s 248us/sample - loss: 0.4299 - accuracy: 0.8150 - val_loss: 0.5120 - val_accuracy: 0.7697\n",
      "Epoch 00063: early stopping\n",
      "102/102 [==============================] - 0s 182us/sample - loss: 0.2270 - accuracy: 0.9706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [5:00:24, 1040.44s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.53s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.28s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 839.3359375 steps, validate for 216.546875 steps\n",
      "Epoch 1/300\n",
      "840/839 [==============================] - 25s 30ms/step - loss: 0.5476 - accuracy: 0.7612 - val_loss: 0.5257 - val_accuracy: 0.7740\n",
      "Epoch 2/300\n",
      "840/839 [==============================] - 24s 29ms/step - loss: 0.5093 - accuracy: 0.7767 - val_loss: 0.5177 - val_accuracy: 0.7753\n",
      "Epoch 3/300\n",
      "840/839 [==============================] - 24s 29ms/step - loss: 0.4938 - accuracy: 0.7820 - val_loss: 0.5195 - val_accuracy: 0.7742\n",
      "Epoch 4/300\n",
      "840/839 [==============================] - 24s 29ms/step - loss: 0.4823 - accuracy: 0.7872 - val_loss: 0.5189 - val_accuracy: 0.7748\n",
      "Epoch 5/300\n",
      "840/839 [==============================] - 24s 29ms/step - loss: 0.4725 - accuracy: 0.7902 - val_loss: 0.5230 - val_accuracy: 0.7725\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 839.3359375 steps, validate for 216.546875 steps\n",
      "Epoch 1/300\n",
      "840/839 [==============================] - 55s 66ms/step - loss: 0.4549 - accuracy: 0.7991 - val_loss: 0.5279 - val_accuracy: 0.7685\n",
      "Epoch 2/300\n",
      "840/839 [==============================] - 54s 64ms/step - loss: 0.4278 - accuracy: 0.8126 - val_loss: 0.5444 - val_accuracy: 0.7553\n",
      "Epoch 3/300\n",
      "840/839 [==============================] - 54s 65ms/step - loss: 0.4051 - accuracy: 0.8253 - val_loss: 0.5431 - val_accuracy: 0.7596\n",
      "Epoch 4/300\n",
      "840/839 [==============================] - 54s 64ms/step - loss: 0.3838 - accuracy: 0.8366 - val_loss: 0.5466 - val_accuracy: 0.7431\n",
      "Epoch 00004: early stopping\n",
      "93/93 [==============================] - 0s 2ms/sample - loss: 0.5259 - accuracy: 0.7634\n",
      "92/92 [==============================] - 0s 256us/sample - loss: 0.6264 - accuracy: 0.6630\n",
      "90/90 [==============================] - 0s 244us/sample - loss: 0.5410 - accuracy: 0.7556\n",
      "85/85 [==============================] - 0s 240us/sample - loss: 0.5649 - accuracy: 0.7176\n",
      "84/84 [==============================] - 0s 311us/sample - loss: 0.6006 - accuracy: 0.7024\n",
      "82/82 [==============================] - 0s 273us/sample - loss: 0.6189 - accuracy: 0.6707\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.6770 - accuracy: 0.6463\n",
      "80/80 [==============================] - 0s 264us/sample - loss: 0.6174 - accuracy: 0.7000\n",
      "79/79 [==============================] - 0s 268us/sample - loss: 0.6297 - accuracy: 0.7089\n",
      "79/79 [==============================] - 0s 298us/sample - loss: 0.5984 - accuracy: 0.7215\n",
      "78/78 [==============================] - 0s 232us/sample - loss: 0.6037 - accuracy: 0.7564\n",
      "79/79 [==============================] - 0s 246us/sample - loss: 0.6480 - accuracy: 0.7342\n",
      "79/79 [==============================] - 0s 238us/sample - loss: 0.6145 - accuracy: 0.7089\n",
      "79/79 [==============================] - 0s 262us/sample - loss: 0.6780 - accuracy: 0.6709\n",
      "78/78 [==============================] - 0s 268us/sample - loss: 0.6716 - accuracy: 0.6282\n",
      "78/78 [==============================] - 0s 281us/sample - loss: 0.5635 - accuracy: 0.7179\n",
      "77/77 [==============================] - 0s 285us/sample - loss: 0.6460 - accuracy: 0.7273\n",
      "78/78 [==============================] - 0s 286us/sample - loss: 0.7044 - accuracy: 0.6795\n",
      "77/77 [==============================] - 0s 281us/sample - loss: 0.7031 - accuracy: 0.6623\n",
      "78/78 [==============================] - 0s 241us/sample - loss: 0.6867 - accuracy: 0.6154\n",
      "79/79 [==============================] - 0s 273us/sample - loss: 0.6797 - accuracy: 0.6962\n",
      "79/79 [==============================] - 0s 277us/sample - loss: 0.7452 - accuracy: 0.6456\n",
      "79/79 [==============================] - 0s 285us/sample - loss: 0.6828 - accuracy: 0.6962\n",
      "79/79 [==============================] - 0s 296us/sample - loss: 0.7764 - accuracy: 0.5823\n",
      "78/78 [==============================] - 0s 257us/sample - loss: 0.8366 - accuracy: 0.5641\n",
      "77/77 [==============================] - 0s 261us/sample - loss: 0.7423 - accuracy: 0.6234\n",
      "76/76 [==============================] - 0s 303us/sample - loss: 0.7876 - accuracy: 0.5921\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 0.8135 - accuracy: 0.6000\n",
      "76/76 [==============================] - 0s 244us/sample - loss: 0.8292 - accuracy: 0.5000\n",
      "76/76 [==============================] - 0s 266us/sample - loss: 0.7613 - accuracy: 0.6184\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.7960 - accuracy: 0.5867\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.7642 - accuracy: 0.6133\n",
      "74/74 [==============================] - 0s 312us/sample - loss: 0.8035 - accuracy: 0.5811\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2845 samples, validate on 733 samples\n",
      "Epoch 1/300\n",
      "2845/2845 [==============================] - 3s 906us/sample - loss: 0.7016 - accuracy: 0.5518 - val_loss: 0.6772 - val_accuracy: 0.6003\n",
      "Epoch 2/300\n",
      "2845/2845 [==============================] - 1s 234us/sample - loss: 0.6726 - accuracy: 0.6063 - val_loss: 0.6598 - val_accuracy: 0.6412\n",
      "Epoch 3/300\n",
      "2845/2845 [==============================] - 1s 194us/sample - loss: 0.6574 - accuracy: 0.6278 - val_loss: 0.6477 - val_accuracy: 0.6562\n",
      "Epoch 4/300\n",
      "2845/2845 [==============================] - 1s 246us/sample - loss: 0.6387 - accuracy: 0.6485 - val_loss: 0.6382 - val_accuracy: 0.6644\n",
      "Epoch 5/300\n",
      "2845/2845 [==============================] - 1s 235us/sample - loss: 0.6291 - accuracy: 0.6626 - val_loss: 0.6303 - val_accuracy: 0.6726\n",
      "Epoch 6/300\n",
      "2845/2845 [==============================] - 1s 229us/sample - loss: 0.6192 - accuracy: 0.6699 - val_loss: 0.6234 - val_accuracy: 0.6849\n",
      "Epoch 7/300\n",
      "2845/2845 [==============================] - 1s 244us/sample - loss: 0.6113 - accuracy: 0.6865 - val_loss: 0.6173 - val_accuracy: 0.6903\n",
      "Epoch 8/300\n",
      "2845/2845 [==============================] - 1s 248us/sample - loss: 0.6096 - accuracy: 0.6875 - val_loss: 0.6118 - val_accuracy: 0.6903\n",
      "Epoch 9/300\n",
      "2845/2845 [==============================] - 1s 251us/sample - loss: 0.6038 - accuracy: 0.6921 - val_loss: 0.6068 - val_accuracy: 0.6971\n",
      "Epoch 10/300\n",
      "2845/2845 [==============================] - 1s 266us/sample - loss: 0.5913 - accuracy: 0.7019 - val_loss: 0.6023 - val_accuracy: 0.7094\n",
      "Epoch 11/300\n",
      "2845/2845 [==============================] - 1s 233us/sample - loss: 0.5875 - accuracy: 0.7107 - val_loss: 0.5981 - val_accuracy: 0.7135\n",
      "Epoch 12/300\n",
      "2845/2845 [==============================] - 1s 252us/sample - loss: 0.5811 - accuracy: 0.7121 - val_loss: 0.5944 - val_accuracy: 0.7176\n",
      "Epoch 13/300\n",
      "2845/2845 [==============================] - 1s 236us/sample - loss: 0.5787 - accuracy: 0.7199 - val_loss: 0.5908 - val_accuracy: 0.7217\n",
      "Epoch 14/300\n",
      "2845/2845 [==============================] - 1s 241us/sample - loss: 0.5763 - accuracy: 0.7199 - val_loss: 0.5874 - val_accuracy: 0.7271\n",
      "Epoch 15/300\n",
      "2845/2845 [==============================] - 1s 254us/sample - loss: 0.5688 - accuracy: 0.7209 - val_loss: 0.5842 - val_accuracy: 0.7299\n",
      "Epoch 16/300\n",
      "2845/2845 [==============================] - 1s 272us/sample - loss: 0.5650 - accuracy: 0.7311 - val_loss: 0.5814 - val_accuracy: 0.7326\n",
      "Epoch 17/300\n",
      "2845/2845 [==============================] - 1s 258us/sample - loss: 0.5653 - accuracy: 0.7311 - val_loss: 0.5785 - val_accuracy: 0.7353\n",
      "Epoch 18/300\n",
      "2845/2845 [==============================] - 1s 261us/sample - loss: 0.5592 - accuracy: 0.7350 - val_loss: 0.5759 - val_accuracy: 0.7367\n",
      "Epoch 19/300\n",
      "2845/2845 [==============================] - 1s 240us/sample - loss: 0.5542 - accuracy: 0.7339 - val_loss: 0.5733 - val_accuracy: 0.7394\n",
      "Epoch 20/300\n",
      "2845/2845 [==============================] - 1s 219us/sample - loss: 0.5455 - accuracy: 0.7406 - val_loss: 0.5710 - val_accuracy: 0.7408\n",
      "Epoch 21/300\n",
      "2845/2845 [==============================] - 1s 257us/sample - loss: 0.5468 - accuracy: 0.7378 - val_loss: 0.5687 - val_accuracy: 0.7408\n",
      "Epoch 22/300\n",
      "2845/2845 [==============================] - 1s 259us/sample - loss: 0.5465 - accuracy: 0.7413 - val_loss: 0.5665 - val_accuracy: 0.7449\n",
      "Epoch 23/300\n",
      "2845/2845 [==============================] - 1s 219us/sample - loss: 0.5366 - accuracy: 0.7497 - val_loss: 0.5644 - val_accuracy: 0.7462\n",
      "Epoch 24/300\n",
      "2845/2845 [==============================] - 1s 213us/sample - loss: 0.5364 - accuracy: 0.7508 - val_loss: 0.5624 - val_accuracy: 0.7449\n",
      "Epoch 25/300\n",
      "2845/2845 [==============================] - 1s 250us/sample - loss: 0.5321 - accuracy: 0.7466 - val_loss: 0.5606 - val_accuracy: 0.7462\n",
      "Epoch 26/300\n",
      "2845/2845 [==============================] - 1s 197us/sample - loss: 0.5333 - accuracy: 0.7494 - val_loss: 0.5587 - val_accuracy: 0.7476\n",
      "Epoch 27/300\n",
      "2845/2845 [==============================] - 1s 215us/sample - loss: 0.5263 - accuracy: 0.7561 - val_loss: 0.5570 - val_accuracy: 0.7490\n",
      "Epoch 28/300\n",
      "2845/2845 [==============================] - 1s 218us/sample - loss: 0.5234 - accuracy: 0.7606 - val_loss: 0.5553 - val_accuracy: 0.7503\n",
      "Epoch 29/300\n",
      "2845/2845 [==============================] - 1s 234us/sample - loss: 0.5213 - accuracy: 0.7568 - val_loss: 0.5536 - val_accuracy: 0.7517\n",
      "Epoch 30/300\n",
      "2845/2845 [==============================] - 1s 212us/sample - loss: 0.5162 - accuracy: 0.7564 - val_loss: 0.5520 - val_accuracy: 0.7531\n",
      "Epoch 31/300\n",
      "2845/2845 [==============================] - 1s 236us/sample - loss: 0.5163 - accuracy: 0.7617 - val_loss: 0.5505 - val_accuracy: 0.7517\n",
      "Epoch 32/300\n",
      "2845/2845 [==============================] - 1s 219us/sample - loss: 0.5123 - accuracy: 0.7599 - val_loss: 0.5491 - val_accuracy: 0.7531\n",
      "Epoch 33/300\n",
      "2845/2845 [==============================] - 1s 270us/sample - loss: 0.5106 - accuracy: 0.7631 - val_loss: 0.5477 - val_accuracy: 0.7558\n",
      "Epoch 34/300\n",
      "2845/2845 [==============================] - 1s 253us/sample - loss: 0.5084 - accuracy: 0.7708 - val_loss: 0.5463 - val_accuracy: 0.7558\n",
      "Epoch 35/300\n",
      "2845/2845 [==============================] - 1s 227us/sample - loss: 0.5077 - accuracy: 0.7673 - val_loss: 0.5450 - val_accuracy: 0.7558\n",
      "Epoch 36/300\n",
      "2845/2845 [==============================] - 1s 256us/sample - loss: 0.5060 - accuracy: 0.7673 - val_loss: 0.5437 - val_accuracy: 0.7572\n",
      "Epoch 37/300\n",
      "2845/2845 [==============================] - 1s 253us/sample - loss: 0.5000 - accuracy: 0.7684 - val_loss: 0.5425 - val_accuracy: 0.7572\n",
      "Epoch 38/300\n",
      "2845/2845 [==============================] - 1s 239us/sample - loss: 0.4914 - accuracy: 0.7729 - val_loss: 0.5414 - val_accuracy: 0.7572\n",
      "Epoch 39/300\n",
      "2845/2845 [==============================] - 1s 236us/sample - loss: 0.4974 - accuracy: 0.7772 - val_loss: 0.5402 - val_accuracy: 0.7585\n",
      "Epoch 40/300\n",
      "2845/2845 [==============================] - 1s 268us/sample - loss: 0.4947 - accuracy: 0.7782 - val_loss: 0.5391 - val_accuracy: 0.7599\n",
      "Epoch 41/300\n",
      "2845/2845 [==============================] - 1s 255us/sample - loss: 0.4949 - accuracy: 0.7719 - val_loss: 0.5380 - val_accuracy: 0.7599\n",
      "Epoch 42/300\n",
      "2845/2845 [==============================] - 1s 223us/sample - loss: 0.4867 - accuracy: 0.7750 - val_loss: 0.5370 - val_accuracy: 0.7599\n",
      "Epoch 43/300\n",
      "2845/2845 [==============================] - 1s 254us/sample - loss: 0.4872 - accuracy: 0.7793 - val_loss: 0.5359 - val_accuracy: 0.7613\n",
      "Epoch 44/300\n",
      "2845/2845 [==============================] - 1s 266us/sample - loss: 0.4826 - accuracy: 0.7779 - val_loss: 0.5350 - val_accuracy: 0.7599\n",
      "Epoch 45/300\n",
      "2845/2845 [==============================] - 1s 264us/sample - loss: 0.4808 - accuracy: 0.7761 - val_loss: 0.5340 - val_accuracy: 0.7599\n",
      "Epoch 46/300\n",
      "2845/2845 [==============================] - 1s 268us/sample - loss: 0.4764 - accuracy: 0.7796 - val_loss: 0.5331 - val_accuracy: 0.7599\n",
      "Epoch 47/300\n",
      "2845/2845 [==============================] - 1s 258us/sample - loss: 0.4786 - accuracy: 0.7828 - val_loss: 0.5322 - val_accuracy: 0.7599\n",
      "Epoch 48/300\n",
      "2845/2845 [==============================] - 1s 255us/sample - loss: 0.4732 - accuracy: 0.7842 - val_loss: 0.5314 - val_accuracy: 0.7599\n",
      "Epoch 49/300\n",
      "2845/2845 [==============================] - 1s 230us/sample - loss: 0.4701 - accuracy: 0.7873 - val_loss: 0.5305 - val_accuracy: 0.7599\n",
      "Epoch 50/300\n",
      "2845/2845 [==============================] - 1s 218us/sample - loss: 0.4718 - accuracy: 0.7817 - val_loss: 0.5297 - val_accuracy: 0.7599\n",
      "Epoch 51/300\n",
      "2845/2845 [==============================] - 1s 253us/sample - loss: 0.4675 - accuracy: 0.7891 - val_loss: 0.5289 - val_accuracy: 0.7599\n",
      "Epoch 52/300\n",
      "2845/2845 [==============================] - 1s 249us/sample - loss: 0.4657 - accuracy: 0.7923 - val_loss: 0.5281 - val_accuracy: 0.7599\n",
      "Epoch 53/300\n",
      "2845/2845 [==============================] - 1s 235us/sample - loss: 0.4636 - accuracy: 0.7933 - val_loss: 0.5274 - val_accuracy: 0.7613\n",
      "Epoch 54/300\n",
      "2845/2845 [==============================] - 1s 226us/sample - loss: 0.4628 - accuracy: 0.7898 - val_loss: 0.5267 - val_accuracy: 0.7613\n",
      "Epoch 55/300\n",
      "2845/2845 [==============================] - 1s 231us/sample - loss: 0.4612 - accuracy: 0.7905 - val_loss: 0.5260 - val_accuracy: 0.7613\n",
      "Epoch 56/300\n",
      "2845/2845 [==============================] - 1s 250us/sample - loss: 0.4587 - accuracy: 0.7888 - val_loss: 0.5253 - val_accuracy: 0.7613\n",
      "Epoch 57/300\n",
      "2845/2845 [==============================] - 1s 192us/sample - loss: 0.4515 - accuracy: 0.8021 - val_loss: 0.5246 - val_accuracy: 0.7613\n",
      "Epoch 58/300\n",
      "2845/2845 [==============================] - 1s 194us/sample - loss: 0.4528 - accuracy: 0.7933 - val_loss: 0.5240 - val_accuracy: 0.7626\n",
      "Epoch 59/300\n",
      "2845/2845 [==============================] - 1s 215us/sample - loss: 0.4522 - accuracy: 0.7975 - val_loss: 0.5234 - val_accuracy: 0.7613\n",
      "Epoch 60/300\n",
      "2845/2845 [==============================] - 1s 228us/sample - loss: 0.4509 - accuracy: 0.7944 - val_loss: 0.5229 - val_accuracy: 0.7599\n",
      "Epoch 61/300\n",
      "2845/2845 [==============================] - 1s 251us/sample - loss: 0.4483 - accuracy: 0.8014 - val_loss: 0.5223 - val_accuracy: 0.7599\n",
      "Epoch 62/300\n",
      "2845/2845 [==============================] - 1s 248us/sample - loss: 0.4420 - accuracy: 0.7993 - val_loss: 0.5218 - val_accuracy: 0.7613\n",
      "Epoch 63/300\n",
      "2845/2845 [==============================] - 1s 240us/sample - loss: 0.4398 - accuracy: 0.8081 - val_loss: 0.5214 - val_accuracy: 0.7613\n",
      "Epoch 64/300\n",
      "2845/2845 [==============================] - 1s 233us/sample - loss: 0.4391 - accuracy: 0.8011 - val_loss: 0.5208 - val_accuracy: 0.7613\n",
      "Epoch 65/300\n",
      "2845/2845 [==============================] - 1s 264us/sample - loss: 0.4374 - accuracy: 0.8039 - val_loss: 0.5204 - val_accuracy: 0.7613\n",
      "Epoch 66/300\n",
      "2845/2845 [==============================] - 1s 247us/sample - loss: 0.4326 - accuracy: 0.8120 - val_loss: 0.5199 - val_accuracy: 0.7626\n",
      "Epoch 67/300\n",
      "2845/2845 [==============================] - 1s 223us/sample - loss: 0.4354 - accuracy: 0.8081 - val_loss: 0.5196 - val_accuracy: 0.7640\n",
      "Epoch 68/300\n",
      "2845/2845 [==============================] - 1s 195us/sample - loss: 0.4324 - accuracy: 0.8098 - val_loss: 0.5192 - val_accuracy: 0.7626\n",
      "Epoch 69/300\n",
      "2845/2845 [==============================] - 1s 195us/sample - loss: 0.4363 - accuracy: 0.8046 - val_loss: 0.5188 - val_accuracy: 0.7640\n",
      "Epoch 70/300\n",
      "2845/2845 [==============================] - 1s 209us/sample - loss: 0.4308 - accuracy: 0.8091 - val_loss: 0.5186 - val_accuracy: 0.7640\n",
      "Epoch 71/300\n",
      "2845/2845 [==============================] - 1s 203us/sample - loss: 0.4258 - accuracy: 0.8109 - val_loss: 0.5183 - val_accuracy: 0.7653\n",
      "Epoch 72/300\n",
      "2845/2845 [==============================] - 1s 213us/sample - loss: 0.4247 - accuracy: 0.8183 - val_loss: 0.5179 - val_accuracy: 0.7653\n",
      "Epoch 73/300\n",
      "2845/2845 [==============================] - 1s 178us/sample - loss: 0.4194 - accuracy: 0.8193 - val_loss: 0.5176 - val_accuracy: 0.7653\n",
      "Epoch 74/300\n",
      "2845/2845 [==============================] - 1s 231us/sample - loss: 0.4187 - accuracy: 0.8148 - val_loss: 0.5174 - val_accuracy: 0.7681\n",
      "Epoch 75/300\n",
      "2845/2845 [==============================] - 1s 222us/sample - loss: 0.4150 - accuracy: 0.8190 - val_loss: 0.5172 - val_accuracy: 0.7681\n",
      "Epoch 76/300\n",
      "2845/2845 [==============================] - 1s 236us/sample - loss: 0.4134 - accuracy: 0.8176 - val_loss: 0.5170 - val_accuracy: 0.7681\n",
      "Epoch 77/300\n",
      "2845/2845 [==============================] - 1s 212us/sample - loss: 0.4133 - accuracy: 0.8207 - val_loss: 0.5169 - val_accuracy: 0.7694\n",
      "Epoch 78/300\n",
      "2845/2845 [==============================] - 1s 255us/sample - loss: 0.4134 - accuracy: 0.8186 - val_loss: 0.5166 - val_accuracy: 0.7694\n",
      "Epoch 79/300\n",
      "2845/2845 [==============================] - 1s 231us/sample - loss: 0.4148 - accuracy: 0.8190 - val_loss: 0.5165 - val_accuracy: 0.7722\n",
      "Epoch 80/300\n",
      "2845/2845 [==============================] - 1s 193us/sample - loss: 0.4065 - accuracy: 0.8221 - val_loss: 0.5164 - val_accuracy: 0.7722\n",
      "Epoch 81/300\n",
      "2845/2845 [==============================] - 1s 186us/sample - loss: 0.4048 - accuracy: 0.8271 - val_loss: 0.5163 - val_accuracy: 0.7708\n",
      "Epoch 82/300\n",
      "2845/2845 [==============================] - 1s 192us/sample - loss: 0.4019 - accuracy: 0.8264 - val_loss: 0.5162 - val_accuracy: 0.7694\n",
      "Epoch 83/300\n",
      "2845/2845 [==============================] - 1s 208us/sample - loss: 0.3998 - accuracy: 0.8313 - val_loss: 0.5162 - val_accuracy: 0.7708\n",
      "Epoch 84/300\n",
      "2845/2845 [==============================] - 1s 217us/sample - loss: 0.3992 - accuracy: 0.8253 - val_loss: 0.5162 - val_accuracy: 0.7722\n",
      "Epoch 85/300\n",
      "2845/2845 [==============================] - 1s 217us/sample - loss: 0.3966 - accuracy: 0.8246 - val_loss: 0.5161 - val_accuracy: 0.7722\n",
      "Epoch 86/300\n",
      "2845/2845 [==============================] - 1s 197us/sample - loss: 0.3960 - accuracy: 0.8348 - val_loss: 0.5161 - val_accuracy: 0.7722\n",
      "Epoch 87/300\n",
      "2845/2845 [==============================] - 1s 187us/sample - loss: 0.3897 - accuracy: 0.8309 - val_loss: 0.5163 - val_accuracy: 0.7708\n",
      "Epoch 88/300\n",
      "2845/2845 [==============================] - 0s 175us/sample - loss: 0.3901 - accuracy: 0.8341 - val_loss: 0.5162 - val_accuracy: 0.7708\n",
      "Epoch 00088: early stopping\n",
      "71/71 [==============================] - 0s 162us/sample - loss: 0.5379 - accuracy: 0.6761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [5:17:51, 1042.57s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.75s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.39s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 843.4921875 steps, validate for 215.578125 steps\n",
      "Epoch 1/300\n",
      "844/843 [==============================] - 25s 30ms/step - loss: 0.5653 - accuracy: 0.7341 - val_loss: 0.5247 - val_accuracy: 0.7735\n",
      "Epoch 2/300\n",
      "844/843 [==============================] - 24s 29ms/step - loss: 0.5103 - accuracy: 0.7758 - val_loss: 0.5218 - val_accuracy: 0.7740\n",
      "Epoch 3/300\n",
      "844/843 [==============================] - 24s 29ms/step - loss: 0.4960 - accuracy: 0.7804 - val_loss: 0.5237 - val_accuracy: 0.7721\n",
      "Epoch 4/300\n",
      "844/843 [==============================] - 24s 29ms/step - loss: 0.4850 - accuracy: 0.7848 - val_loss: 0.5199 - val_accuracy: 0.7714\n",
      "Epoch 5/300\n",
      "844/843 [==============================] - 24s 28ms/step - loss: 0.4756 - accuracy: 0.7894 - val_loss: 0.5226 - val_accuracy: 0.7726\n",
      "Epoch 6/300\n",
      "844/843 [==============================] - 24s 29ms/step - loss: 0.4668 - accuracy: 0.7931 - val_loss: 0.5251 - val_accuracy: 0.7681\n",
      "Epoch 7/300\n",
      "844/843 [==============================] - 24s 29ms/step - loss: 0.4588 - accuracy: 0.7974 - val_loss: 0.5326 - val_accuracy: 0.7636\n",
      "Epoch 00007: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 843.4921875 steps, validate for 215.578125 steps\n",
      "Epoch 1/300\n",
      "844/843 [==============================] - 55s 65ms/step - loss: 0.4446 - accuracy: 0.8051 - val_loss: 0.5628 - val_accuracy: 0.7295\n",
      "Epoch 2/300\n",
      "844/843 [==============================] - 54s 64ms/step - loss: 0.4195 - accuracy: 0.8178 - val_loss: 0.5578 - val_accuracy: 0.7659\n",
      "Epoch 3/300\n",
      "844/843 [==============================] - 54s 64ms/step - loss: 0.3986 - accuracy: 0.8287 - val_loss: 0.5459 - val_accuracy: 0.7600\n",
      "Epoch 4/300\n",
      "844/843 [==============================] - 54s 64ms/step - loss: 0.3795 - accuracy: 0.8391 - val_loss: 0.5545 - val_accuracy: 0.7697\n",
      "Epoch 5/300\n",
      "844/843 [==============================] - 54s 64ms/step - loss: 0.3621 - accuracy: 0.8480 - val_loss: 0.5951 - val_accuracy: 0.7693\n",
      "Epoch 6/300\n",
      "844/843 [==============================] - 54s 64ms/step - loss: 0.3452 - accuracy: 0.8578 - val_loss: 0.5535 - val_accuracy: 0.7654\n",
      "Epoch 00006: early stopping\n",
      "78/78 [==============================] - 0s 3ms/sample - loss: 0.2208 - accuracy: 0.9744\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.2410 - accuracy: 0.9600\n",
      "73/73 [==============================] - 0s 250us/sample - loss: 0.2414 - accuracy: 0.9589\n",
      "71/71 [==============================] - 0s 291us/sample - loss: 0.2443 - accuracy: 0.9718\n",
      "71/71 [==============================] - 0s 302us/sample - loss: 0.1865 - accuracy: 0.9859\n",
      "68/68 [==============================] - 0s 253us/sample - loss: 0.2378 - accuracy: 0.9265\n",
      "69/69 [==============================] - 0s 276us/sample - loss: 0.2240 - accuracy: 1.0000\n",
      "68/68 [==============================] - 0s 253us/sample - loss: 0.2527 - accuracy: 0.9265\n",
      "66/66 [==============================] - 0s 267us/sample - loss: 0.2391 - accuracy: 0.9697\n",
      "65/65 [==============================] - 0s 281us/sample - loss: 0.2015 - accuracy: 0.9846\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.2826 - accuracy: 0.9062\n",
      "65/65 [==============================] - 0s 315us/sample - loss: 0.2305 - accuracy: 0.9692\n",
      "66/66 [==============================] - 0s 297us/sample - loss: 0.2357 - accuracy: 0.9545\n",
      "65/65 [==============================] - 0s 309us/sample - loss: 0.2556 - accuracy: 0.9538\n",
      "65/65 [==============================] - 0s 319us/sample - loss: 0.2459 - accuracy: 0.9846\n",
      "66/66 [==============================] - 0s 371us/sample - loss: 0.2680 - accuracy: 0.9394\n",
      "68/68 [==============================] - 0s 318us/sample - loss: 0.2775 - accuracy: 0.9412\n",
      "66/66 [==============================] - 0s 311us/sample - loss: 0.2759 - accuracy: 0.9242\n",
      "66/66 [==============================] - 0s 330us/sample - loss: 0.2670 - accuracy: 0.9394\n",
      "66/66 [==============================] - 0s 298us/sample - loss: 0.2713 - accuracy: 0.9242\n",
      "67/67 [==============================] - 0s 296us/sample - loss: 0.2488 - accuracy: 0.9701\n",
      "66/66 [==============================] - 0s 344us/sample - loss: 0.2502 - accuracy: 0.9242\n",
      "67/67 [==============================] - 0s 341us/sample - loss: 0.2748 - accuracy: 0.9104\n",
      "66/66 [==============================] - 0s 335us/sample - loss: 0.2785 - accuracy: 0.9545\n",
      "66/66 [==============================] - 0s 324us/sample - loss: 0.2433 - accuracy: 0.9697\n",
      "66/66 [==============================] - 0s 302us/sample - loss: 0.2373 - accuracy: 0.9545\n",
      "66/66 [==============================] - 0s 308us/sample - loss: 0.2954 - accuracy: 0.8788\n",
      "66/66 [==============================] - 0s 282us/sample - loss: 0.2450 - accuracy: 0.9394\n",
      "66/66 [==============================] - 0s 319us/sample - loss: 0.2710 - accuracy: 0.9394\n",
      "66/66 [==============================] - 0s 296us/sample - loss: 0.2588 - accuracy: 0.9697\n",
      "65/65 [==============================] - 0s 304us/sample - loss: 0.2432 - accuracy: 0.9385\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 0.2552 - accuracy: 0.9219\n",
      "65/65 [==============================] - 0s 303us/sample - loss: 0.2718 - accuracy: 0.9231\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2861 samples, validate on 727 samples\n",
      "Epoch 1/300\n",
      "2861/2861 [==============================] - 2s 873us/sample - loss: 0.7074 - accuracy: 0.5058 - val_loss: 0.6823 - val_accuracy: 0.5502\n",
      "Epoch 2/300\n",
      "2861/2861 [==============================] - 1s 240us/sample - loss: 0.6722 - accuracy: 0.5904 - val_loss: 0.6633 - val_accuracy: 0.6162\n",
      "Epoch 3/300\n",
      "2861/2861 [==============================] - 1s 180us/sample - loss: 0.6574 - accuracy: 0.6197 - val_loss: 0.6499 - val_accuracy: 0.6437\n",
      "Epoch 4/300\n",
      "2861/2861 [==============================] - 1s 207us/sample - loss: 0.6394 - accuracy: 0.6536 - val_loss: 0.6390 - val_accuracy: 0.6602\n",
      "Epoch 5/300\n",
      "2861/2861 [==============================] - 1s 192us/sample - loss: 0.6285 - accuracy: 0.6749 - val_loss: 0.6299 - val_accuracy: 0.6850\n",
      "Epoch 6/300\n",
      "2861/2861 [==============================] - 1s 259us/sample - loss: 0.6137 - accuracy: 0.7046 - val_loss: 0.6218 - val_accuracy: 0.6933\n",
      "Epoch 7/300\n",
      "2861/2861 [==============================] - 1s 252us/sample - loss: 0.6027 - accuracy: 0.7158 - val_loss: 0.6148 - val_accuracy: 0.7084\n",
      "Epoch 8/300\n",
      "2861/2861 [==============================] - 1s 221us/sample - loss: 0.5963 - accuracy: 0.7312 - val_loss: 0.6082 - val_accuracy: 0.7194\n",
      "Epoch 9/300\n",
      "2861/2861 [==============================] - 1s 238us/sample - loss: 0.5879 - accuracy: 0.7365 - val_loss: 0.6023 - val_accuracy: 0.7221\n",
      "Epoch 10/300\n",
      "2861/2861 [==============================] - 1s 224us/sample - loss: 0.5795 - accuracy: 0.7511 - val_loss: 0.5970 - val_accuracy: 0.7304\n",
      "Epoch 11/300\n",
      "2861/2861 [==============================] - 1s 215us/sample - loss: 0.5754 - accuracy: 0.7525 - val_loss: 0.5919 - val_accuracy: 0.7359\n",
      "Epoch 12/300\n",
      "2861/2861 [==============================] - 1s 259us/sample - loss: 0.5633 - accuracy: 0.7644 - val_loss: 0.5872 - val_accuracy: 0.7414\n",
      "Epoch 13/300\n",
      "2861/2861 [==============================] - 1s 241us/sample - loss: 0.5618 - accuracy: 0.7620 - val_loss: 0.5827 - val_accuracy: 0.7442\n",
      "Epoch 14/300\n",
      "2861/2861 [==============================] - 1s 245us/sample - loss: 0.5527 - accuracy: 0.7774 - val_loss: 0.5785 - val_accuracy: 0.7510\n",
      "Epoch 15/300\n",
      "2861/2861 [==============================] - 1s 209us/sample - loss: 0.5477 - accuracy: 0.7679 - val_loss: 0.5747 - val_accuracy: 0.7510\n",
      "Epoch 16/300\n",
      "2861/2861 [==============================] - 1s 216us/sample - loss: 0.5396 - accuracy: 0.7822 - val_loss: 0.5710 - val_accuracy: 0.7552\n",
      "Epoch 17/300\n",
      "2861/2861 [==============================] - 1s 219us/sample - loss: 0.5365 - accuracy: 0.7826 - val_loss: 0.5675 - val_accuracy: 0.7538\n",
      "Epoch 18/300\n",
      "2861/2861 [==============================] - 1s 242us/sample - loss: 0.5300 - accuracy: 0.7861 - val_loss: 0.5642 - val_accuracy: 0.7579\n",
      "Epoch 19/300\n",
      "2861/2861 [==============================] - 1s 238us/sample - loss: 0.5246 - accuracy: 0.7854 - val_loss: 0.5611 - val_accuracy: 0.7579\n",
      "Epoch 20/300\n",
      "2861/2861 [==============================] - 1s 251us/sample - loss: 0.5219 - accuracy: 0.7871 - val_loss: 0.5581 - val_accuracy: 0.7579\n",
      "Epoch 21/300\n",
      "2861/2861 [==============================] - 1s 257us/sample - loss: 0.5174 - accuracy: 0.7917 - val_loss: 0.5553 - val_accuracy: 0.7593\n",
      "Epoch 22/300\n",
      "2861/2861 [==============================] - 1s 220us/sample - loss: 0.5115 - accuracy: 0.7906 - val_loss: 0.5527 - val_accuracy: 0.7634\n",
      "Epoch 23/300\n",
      "2861/2861 [==============================] - 1s 245us/sample - loss: 0.5060 - accuracy: 0.7920 - val_loss: 0.5502 - val_accuracy: 0.7634\n",
      "Epoch 24/300\n",
      "2861/2861 [==============================] - 1s 252us/sample - loss: 0.5027 - accuracy: 0.7924 - val_loss: 0.5478 - val_accuracy: 0.7648\n",
      "Epoch 25/300\n",
      "2861/2861 [==============================] - 1s 229us/sample - loss: 0.4986 - accuracy: 0.7955 - val_loss: 0.5456 - val_accuracy: 0.7675\n",
      "Epoch 26/300\n",
      "2861/2861 [==============================] - 1s 228us/sample - loss: 0.4908 - accuracy: 0.7938 - val_loss: 0.5434 - val_accuracy: 0.7675\n",
      "Epoch 27/300\n",
      "2861/2861 [==============================] - 1s 223us/sample - loss: 0.4909 - accuracy: 0.8022 - val_loss: 0.5414 - val_accuracy: 0.7675\n",
      "Epoch 28/300\n",
      "2861/2861 [==============================] - 1s 265us/sample - loss: 0.4851 - accuracy: 0.7997 - val_loss: 0.5395 - val_accuracy: 0.7675\n",
      "Epoch 29/300\n",
      "2861/2861 [==============================] - 1s 256us/sample - loss: 0.4800 - accuracy: 0.8029 - val_loss: 0.5378 - val_accuracy: 0.7675\n",
      "Epoch 30/300\n",
      "2861/2861 [==============================] - 1s 250us/sample - loss: 0.4759 - accuracy: 0.8004 - val_loss: 0.5361 - val_accuracy: 0.7689\n",
      "Epoch 31/300\n",
      "2861/2861 [==============================] - 1s 216us/sample - loss: 0.4758 - accuracy: 0.8008 - val_loss: 0.5345 - val_accuracy: 0.7689\n",
      "Epoch 32/300\n",
      "2861/2861 [==============================] - 1s 216us/sample - loss: 0.4703 - accuracy: 0.8025 - val_loss: 0.5330 - val_accuracy: 0.7689\n",
      "Epoch 33/300\n",
      "2861/2861 [==============================] - 1s 206us/sample - loss: 0.4674 - accuracy: 0.8078 - val_loss: 0.5316 - val_accuracy: 0.7689\n",
      "Epoch 34/300\n",
      "2861/2861 [==============================] - 1s 233us/sample - loss: 0.4629 - accuracy: 0.8074 - val_loss: 0.5304 - val_accuracy: 0.7717\n",
      "Epoch 35/300\n",
      "2861/2861 [==============================] - 1s 238us/sample - loss: 0.4576 - accuracy: 0.8158 - val_loss: 0.5292 - val_accuracy: 0.7717\n",
      "Epoch 36/300\n",
      "2861/2861 [==============================] - 1s 209us/sample - loss: 0.4535 - accuracy: 0.8074 - val_loss: 0.5281 - val_accuracy: 0.7717\n",
      "Epoch 37/300\n",
      "2861/2861 [==============================] - 1s 218us/sample - loss: 0.4502 - accuracy: 0.8134 - val_loss: 0.5271 - val_accuracy: 0.7717\n",
      "Epoch 38/300\n",
      "2861/2861 [==============================] - 1s 242us/sample - loss: 0.4476 - accuracy: 0.8102 - val_loss: 0.5262 - val_accuracy: 0.7717\n",
      "Epoch 39/300\n",
      "2861/2861 [==============================] - 1s 257us/sample - loss: 0.4461 - accuracy: 0.8099 - val_loss: 0.5254 - val_accuracy: 0.7703\n",
      "Epoch 40/300\n",
      "2861/2861 [==============================] - 1s 224us/sample - loss: 0.4438 - accuracy: 0.8109 - val_loss: 0.5245 - val_accuracy: 0.7689\n",
      "Epoch 41/300\n",
      "2861/2861 [==============================] - 1s 242us/sample - loss: 0.4385 - accuracy: 0.8134 - val_loss: 0.5238 - val_accuracy: 0.7675\n",
      "Epoch 42/300\n",
      "2861/2861 [==============================] - 1s 241us/sample - loss: 0.4351 - accuracy: 0.8123 - val_loss: 0.5232 - val_accuracy: 0.7675\n",
      "Epoch 43/300\n",
      "2861/2861 [==============================] - 1s 229us/sample - loss: 0.4335 - accuracy: 0.8144 - val_loss: 0.5226 - val_accuracy: 0.7662\n",
      "Epoch 44/300\n",
      "2861/2861 [==============================] - 1s 229us/sample - loss: 0.4306 - accuracy: 0.8161 - val_loss: 0.5220 - val_accuracy: 0.7648\n",
      "Epoch 45/300\n",
      "2861/2861 [==============================] - 1s 249us/sample - loss: 0.4271 - accuracy: 0.8127 - val_loss: 0.5216 - val_accuracy: 0.7648\n",
      "Epoch 46/300\n",
      "2861/2861 [==============================] - 1s 244us/sample - loss: 0.4252 - accuracy: 0.8137 - val_loss: 0.5212 - val_accuracy: 0.7648\n",
      "Epoch 47/300\n",
      "2861/2861 [==============================] - 1s 243us/sample - loss: 0.4195 - accuracy: 0.8207 - val_loss: 0.5208 - val_accuracy: 0.7662\n",
      "Epoch 48/300\n",
      "2861/2861 [==============================] - 1s 241us/sample - loss: 0.4190 - accuracy: 0.8242 - val_loss: 0.5205 - val_accuracy: 0.7634\n",
      "Epoch 49/300\n",
      "2861/2861 [==============================] - 1s 258us/sample - loss: 0.4160 - accuracy: 0.8207 - val_loss: 0.5202 - val_accuracy: 0.7648\n",
      "Epoch 50/300\n",
      "2861/2861 [==============================] - 1s 253us/sample - loss: 0.4155 - accuracy: 0.8221 - val_loss: 0.5200 - val_accuracy: 0.7648\n",
      "Epoch 51/300\n",
      "2861/2861 [==============================] - 1s 220us/sample - loss: 0.4089 - accuracy: 0.8210 - val_loss: 0.5199 - val_accuracy: 0.7648\n",
      "Epoch 52/300\n",
      "2861/2861 [==============================] - 1s 236us/sample - loss: 0.4075 - accuracy: 0.8252 - val_loss: 0.5197 - val_accuracy: 0.7662\n",
      "Epoch 53/300\n",
      "2861/2861 [==============================] - 1s 222us/sample - loss: 0.4064 - accuracy: 0.8242 - val_loss: 0.5196 - val_accuracy: 0.7675\n",
      "Epoch 54/300\n",
      "2861/2861 [==============================] - 1s 274us/sample - loss: 0.3997 - accuracy: 0.8301 - val_loss: 0.5196 - val_accuracy: 0.7689\n",
      "Epoch 55/300\n",
      "2861/2861 [==============================] - 1s 256us/sample - loss: 0.3980 - accuracy: 0.8312 - val_loss: 0.5196 - val_accuracy: 0.7689\n",
      "Epoch 56/300\n",
      "2861/2861 [==============================] - 1s 252us/sample - loss: 0.3902 - accuracy: 0.8378 - val_loss: 0.5196 - val_accuracy: 0.7689\n",
      "Epoch 57/300\n",
      "2861/2861 [==============================] - 1s 246us/sample - loss: 0.3915 - accuracy: 0.8308 - val_loss: 0.5197 - val_accuracy: 0.7689\n",
      "Epoch 58/300\n",
      "2861/2861 [==============================] - 1s 232us/sample - loss: 0.3876 - accuracy: 0.8312 - val_loss: 0.5198 - val_accuracy: 0.7689\n",
      "Epoch 00058: early stopping\n",
      "61/61 [==============================] - 0s 153us/sample - loss: 0.2704 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [5:37:36, 1085.22s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.57s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.27s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 826.703125 steps, validate for 216.5078125 steps\n",
      "Epoch 1/300\n",
      "827/826 [==============================] - 25s 30ms/step - loss: 0.5577 - accuracy: 0.7402 - val_loss: 0.5285 - val_accuracy: 0.7729\n",
      "Epoch 2/300\n",
      "827/826 [==============================] - 24s 28ms/step - loss: 0.5130 - accuracy: 0.7727 - val_loss: 0.5263 - val_accuracy: 0.7712\n",
      "Epoch 3/300\n",
      "827/826 [==============================] - 24s 29ms/step - loss: 0.4993 - accuracy: 0.7776 - val_loss: 0.5266 - val_accuracy: 0.7711\n",
      "Epoch 4/300\n",
      "827/826 [==============================] - 24s 29ms/step - loss: 0.4883 - accuracy: 0.7813 - val_loss: 0.5269 - val_accuracy: 0.7713\n",
      "Epoch 5/300\n",
      "827/826 [==============================] - 24s 29ms/step - loss: 0.4785 - accuracy: 0.7861 - val_loss: 0.5299 - val_accuracy: 0.7694\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 826.703125 steps, validate for 216.5078125 steps\n",
      "Epoch 1/300\n",
      "827/826 [==============================] - 54s 66ms/step - loss: 0.4619 - accuracy: 0.7940 - val_loss: 0.5610 - val_accuracy: 0.7271\n",
      "Epoch 2/300\n",
      "827/826 [==============================] - 53s 65ms/step - loss: 0.4356 - accuracy: 0.8075 - val_loss: 0.5896 - val_accuracy: 0.7703\n",
      "Epoch 3/300\n",
      "827/826 [==============================] - 53s 64ms/step - loss: 0.4127 - accuracy: 0.8207 - val_loss: 0.5594 - val_accuracy: 0.7390\n",
      "Epoch 4/300\n",
      "827/826 [==============================] - 53s 65ms/step - loss: 0.3917 - accuracy: 0.8322 - val_loss: 0.5486 - val_accuracy: 0.7481\n",
      "Epoch 5/300\n",
      "827/826 [==============================] - 53s 64ms/step - loss: 0.3723 - accuracy: 0.8428 - val_loss: 0.5536 - val_accuracy: 0.7569\n",
      "Epoch 6/300\n",
      "827/826 [==============================] - 53s 64ms/step - loss: 0.3534 - accuracy: 0.8527 - val_loss: 0.5664 - val_accuracy: 0.7507\n",
      "Epoch 7/300\n",
      "827/826 [==============================] - 53s 64ms/step - loss: 0.3357 - accuracy: 0.8626 - val_loss: 0.5757 - val_accuracy: 0.7588\n",
      "Epoch 00007: early stopping\n",
      "144/144 [==============================] - 0s 2ms/sample - loss: 0.2062 - accuracy: 0.9722\n",
      "142/142 [==============================] - 0s 245us/sample - loss: 0.1863 - accuracy: 0.9789\n",
      "137/137 [==============================] - 0s 329us/sample - loss: 0.1711 - accuracy: 0.9854\n",
      "134/134 [==============================] - 0s 252us/sample - loss: 0.1892 - accuracy: 0.9701\n",
      "135/135 [==============================] - 0s 279us/sample - loss: 0.1948 - accuracy: 0.9778\n",
      "134/134 [==============================] - 0s 307us/sample - loss: 0.1960 - accuracy: 0.9627\n",
      "135/135 [==============================] - 0s 259us/sample - loss: 0.2118 - accuracy: 0.9630\n",
      "136/136 [==============================] - 0s 251us/sample - loss: 0.2045 - accuracy: 0.9559\n",
      "138/138 [==============================] - 0s 246us/sample - loss: 0.1999 - accuracy: 0.9710\n",
      "134/134 [==============================] - 0s 245us/sample - loss: 0.2024 - accuracy: 0.9627\n",
      "131/131 [==============================] - 0s 252us/sample - loss: 0.1946 - accuracy: 0.9695\n",
      "129/129 [==============================] - 0s 295us/sample - loss: 0.1819 - accuracy: 0.9767\n",
      "129/129 [==============================] - 0s 287us/sample - loss: 0.2075 - accuracy: 0.9612\n",
      "129/129 [==============================] - 0s 286us/sample - loss: 0.2109 - accuracy: 0.9380\n",
      "130/130 [==============================] - 0s 300us/sample - loss: 0.2023 - accuracy: 0.9769\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.2095 - accuracy: 0.9375\n",
      "127/127 [==============================] - 0s 248us/sample - loss: 0.2121 - accuracy: 0.9370\n",
      "127/127 [==============================] - 0s 251us/sample - loss: 0.1866 - accuracy: 0.9685\n",
      "127/127 [==============================] - 0s 277us/sample - loss: 0.1880 - accuracy: 0.9606\n",
      "126/126 [==============================] - 0s 254us/sample - loss: 0.1992 - accuracy: 0.9603\n",
      "125/125 [==============================] - 0s 265us/sample - loss: 0.2109 - accuracy: 0.9360\n",
      "125/125 [==============================] - 0s 241us/sample - loss: 0.1914 - accuracy: 0.9680\n",
      "124/124 [==============================] - 0s 226us/sample - loss: 0.2126 - accuracy: 0.9435\n",
      "123/123 [==============================] - 0s 246us/sample - loss: 0.2387 - accuracy: 0.9593\n",
      "122/122 [==============================] - 0s 280us/sample - loss: 0.1951 - accuracy: 0.9754\n",
      "122/122 [==============================] - 0s 242us/sample - loss: 0.2118 - accuracy: 0.9344\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.2015 - accuracy: 0.9500\n",
      "123/123 [==============================] - 0s 247us/sample - loss: 0.2149 - accuracy: 0.9675\n",
      "121/121 [==============================] - 0s 271us/sample - loss: 0.2132 - accuracy: 0.9587\n",
      "123/123 [==============================] - 0s 278us/sample - loss: 0.2261 - accuracy: 0.9350\n",
      "123/123 [==============================] - 0s 266us/sample - loss: 0.2060 - accuracy: 0.9512\n",
      "122/122 [==============================] - 0s 299us/sample - loss: 0.2330 - accuracy: 0.9180\n",
      "122/122 [==============================] - 0s 285us/sample - loss: 0.2424 - accuracy: 0.9426\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2805 samples, validate on 732 samples\n",
      "Epoch 1/300\n",
      "2805/2805 [==============================] - 2s 827us/sample - loss: 0.7247 - accuracy: 0.5041 - val_loss: 0.6969 - val_accuracy: 0.5219\n",
      "Epoch 2/300\n",
      "2805/2805 [==============================] - 1s 234us/sample - loss: 0.6843 - accuracy: 0.5640 - val_loss: 0.6736 - val_accuracy: 0.5738\n",
      "Epoch 3/300\n",
      "2805/2805 [==============================] - 1s 179us/sample - loss: 0.6546 - accuracy: 0.6111 - val_loss: 0.6573 - val_accuracy: 0.6079\n",
      "Epoch 4/300\n",
      "2805/2805 [==============================] - 1s 228us/sample - loss: 0.6327 - accuracy: 0.6517 - val_loss: 0.6442 - val_accuracy: 0.6380\n",
      "Epoch 5/300\n",
      "2805/2805 [==============================] - 1s 231us/sample - loss: 0.6166 - accuracy: 0.6841 - val_loss: 0.6335 - val_accuracy: 0.6544\n",
      "Epoch 6/300\n",
      "2805/2805 [==============================] - 1s 192us/sample - loss: 0.6042 - accuracy: 0.7048 - val_loss: 0.6243 - val_accuracy: 0.6790\n",
      "Epoch 7/300\n",
      "2805/2805 [==============================] - 1s 212us/sample - loss: 0.5929 - accuracy: 0.7127 - val_loss: 0.6159 - val_accuracy: 0.6844\n",
      "Epoch 8/300\n",
      "2805/2805 [==============================] - 1s 227us/sample - loss: 0.5780 - accuracy: 0.7340 - val_loss: 0.6085 - val_accuracy: 0.6926\n",
      "Epoch 9/300\n",
      "2805/2805 [==============================] - 1s 219us/sample - loss: 0.5699 - accuracy: 0.7412 - val_loss: 0.6020 - val_accuracy: 0.7008\n",
      "Epoch 10/300\n",
      "2805/2805 [==============================] - 1s 209us/sample - loss: 0.5569 - accuracy: 0.7494 - val_loss: 0.5960 - val_accuracy: 0.7145\n",
      "Epoch 11/300\n",
      "2805/2805 [==============================] - 1s 202us/sample - loss: 0.5540 - accuracy: 0.7611 - val_loss: 0.5904 - val_accuracy: 0.7158\n",
      "Epoch 12/300\n",
      "2805/2805 [==============================] - 1s 227us/sample - loss: 0.5412 - accuracy: 0.7701 - val_loss: 0.5853 - val_accuracy: 0.7172\n",
      "Epoch 13/300\n",
      "2805/2805 [==============================] - 1s 192us/sample - loss: 0.5318 - accuracy: 0.7854 - val_loss: 0.5804 - val_accuracy: 0.7254\n",
      "Epoch 14/300\n",
      "2805/2805 [==============================] - 1s 255us/sample - loss: 0.5287 - accuracy: 0.7800 - val_loss: 0.5760 - val_accuracy: 0.7322\n",
      "Epoch 15/300\n",
      "2805/2805 [==============================] - 1s 238us/sample - loss: 0.5165 - accuracy: 0.7893 - val_loss: 0.5719 - val_accuracy: 0.7350\n",
      "Epoch 16/300\n",
      "2805/2805 [==============================] - 1s 224us/sample - loss: 0.5109 - accuracy: 0.7925 - val_loss: 0.5682 - val_accuracy: 0.7377\n",
      "Epoch 17/300\n",
      "2805/2805 [==============================] - 1s 262us/sample - loss: 0.5082 - accuracy: 0.7968 - val_loss: 0.5647 - val_accuracy: 0.7350\n",
      "Epoch 18/300\n",
      "2805/2805 [==============================] - 1s 256us/sample - loss: 0.4968 - accuracy: 0.8086 - val_loss: 0.5615 - val_accuracy: 0.7350\n",
      "Epoch 19/300\n",
      "2805/2805 [==============================] - 1s 211us/sample - loss: 0.4953 - accuracy: 0.7996 - val_loss: 0.5585 - val_accuracy: 0.7363\n",
      "Epoch 20/300\n",
      "2805/2805 [==============================] - 1s 235us/sample - loss: 0.4857 - accuracy: 0.8004 - val_loss: 0.5557 - val_accuracy: 0.7377\n",
      "Epoch 21/300\n",
      "2805/2805 [==============================] - 1s 237us/sample - loss: 0.4819 - accuracy: 0.8046 - val_loss: 0.5531 - val_accuracy: 0.7404\n",
      "Epoch 22/300\n",
      "2805/2805 [==============================] - 1s 241us/sample - loss: 0.4773 - accuracy: 0.8078 - val_loss: 0.5508 - val_accuracy: 0.7418\n",
      "Epoch 23/300\n",
      "2805/2805 [==============================] - 1s 246us/sample - loss: 0.4703 - accuracy: 0.8086 - val_loss: 0.5487 - val_accuracy: 0.7404\n",
      "Epoch 24/300\n",
      "2805/2805 [==============================] - 1s 242us/sample - loss: 0.4671 - accuracy: 0.8093 - val_loss: 0.5467 - val_accuracy: 0.7418\n",
      "Epoch 25/300\n",
      "2805/2805 [==============================] - 1s 231us/sample - loss: 0.4597 - accuracy: 0.8196 - val_loss: 0.5449 - val_accuracy: 0.7418\n",
      "Epoch 26/300\n",
      "2805/2805 [==============================] - 1s 255us/sample - loss: 0.4531 - accuracy: 0.8232 - val_loss: 0.5432 - val_accuracy: 0.7445\n",
      "Epoch 27/300\n",
      "2805/2805 [==============================] - 1s 241us/sample - loss: 0.4521 - accuracy: 0.8168 - val_loss: 0.5417 - val_accuracy: 0.7432\n",
      "Epoch 28/300\n",
      "2805/2805 [==============================] - 1s 232us/sample - loss: 0.4463 - accuracy: 0.8200 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
      "Epoch 29/300\n",
      "2805/2805 [==============================] - 1s 257us/sample - loss: 0.4430 - accuracy: 0.8214 - val_loss: 0.5391 - val_accuracy: 0.7514\n",
      "Epoch 30/300\n",
      "2805/2805 [==============================] - 1s 246us/sample - loss: 0.4380 - accuracy: 0.8292 - val_loss: 0.5381 - val_accuracy: 0.7514\n",
      "Epoch 31/300\n",
      "2805/2805 [==============================] - 1s 235us/sample - loss: 0.4346 - accuracy: 0.8239 - val_loss: 0.5371 - val_accuracy: 0.7527\n",
      "Epoch 32/300\n",
      "2805/2805 [==============================] - 1s 247us/sample - loss: 0.4316 - accuracy: 0.8178 - val_loss: 0.5363 - val_accuracy: 0.7514\n",
      "Epoch 33/300\n",
      "2805/2805 [==============================] - 1s 220us/sample - loss: 0.4228 - accuracy: 0.8296 - val_loss: 0.5356 - val_accuracy: 0.7514\n",
      "Epoch 34/300\n",
      "2805/2805 [==============================] - 1s 217us/sample - loss: 0.4227 - accuracy: 0.8303 - val_loss: 0.5352 - val_accuracy: 0.7527\n",
      "Epoch 35/300\n",
      "2805/2805 [==============================] - 1s 220us/sample - loss: 0.4191 - accuracy: 0.8260 - val_loss: 0.5346 - val_accuracy: 0.7527\n",
      "Epoch 36/300\n",
      "2805/2805 [==============================] - 1s 227us/sample - loss: 0.4139 - accuracy: 0.8378 - val_loss: 0.5343 - val_accuracy: 0.7541\n",
      "Epoch 37/300\n",
      "2805/2805 [==============================] - 1s 243us/sample - loss: 0.4125 - accuracy: 0.8317 - val_loss: 0.5340 - val_accuracy: 0.7527\n",
      "Epoch 38/300\n",
      "2805/2805 [==============================] - 1s 256us/sample - loss: 0.4036 - accuracy: 0.8364 - val_loss: 0.5339 - val_accuracy: 0.7514\n",
      "Epoch 39/300\n",
      "2805/2805 [==============================] - 1s 237us/sample - loss: 0.4058 - accuracy: 0.8364 - val_loss: 0.5339 - val_accuracy: 0.7514\n",
      "Epoch 40/300\n",
      "2805/2805 [==============================] - 1s 219us/sample - loss: 0.4009 - accuracy: 0.8417 - val_loss: 0.5339 - val_accuracy: 0.7514\n",
      "Epoch 41/300\n",
      "2805/2805 [==============================] - 1s 211us/sample - loss: 0.3967 - accuracy: 0.8349 - val_loss: 0.5340 - val_accuracy: 0.7514\n",
      "Epoch 42/300\n",
      "2805/2805 [==============================] - 1s 202us/sample - loss: 0.3936 - accuracy: 0.8324 - val_loss: 0.5342 - val_accuracy: 0.7514\n",
      "Epoch 00042: early stopping\n",
      "112/112 [==============================] - 0s 128us/sample - loss: 0.2734 - accuracy: 0.9821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [5:57:06, 1110.75s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.57s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.27s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 834.3359375 steps, validate for 210.6640625 steps\n",
      "Epoch 1/300\n",
      "835/834 [==============================] - 25s 29ms/step - loss: 0.6482 - accuracy: 0.6477 - val_loss: 0.5385 - val_accuracy: 0.7632\n",
      "Epoch 2/300\n",
      "835/834 [==============================] - 24s 28ms/step - loss: 0.5144 - accuracy: 0.7752 - val_loss: 0.5396 - val_accuracy: 0.7615\n",
      "Epoch 3/300\n",
      "835/834 [==============================] - 24s 29ms/step - loss: 0.4976 - accuracy: 0.7809 - val_loss: 0.5413 - val_accuracy: 0.7611\n",
      "Epoch 4/300\n",
      "835/834 [==============================] - 24s 29ms/step - loss: 0.4857 - accuracy: 0.7851 - val_loss: 0.5425 - val_accuracy: 0.7606\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 834.3359375 steps, validate for 210.6640625 steps\n",
      "Epoch 1/300\n",
      "835/834 [==============================] - 55s 66ms/step - loss: 0.4675 - accuracy: 0.7943 - val_loss: 0.5433 - val_accuracy: 0.7630\n",
      "Epoch 2/300\n",
      "835/834 [==============================] - 54s 64ms/step - loss: 0.4404 - accuracy: 0.8076 - val_loss: 0.5432 - val_accuracy: 0.7683\n",
      "Epoch 3/300\n",
      "835/834 [==============================] - 54s 64ms/step - loss: 0.4203 - accuracy: 0.8184 - val_loss: 0.5684 - val_accuracy: 0.7423\n",
      "Epoch 4/300\n",
      "835/834 [==============================] - 54s 64ms/step - loss: 0.4000 - accuracy: 0.8287 - val_loss: 0.5628 - val_accuracy: 0.7594\n",
      "Epoch 5/300\n",
      "835/834 [==============================] - 54s 64ms/step - loss: 0.3816 - accuracy: 0.8383 - val_loss: 0.5661 - val_accuracy: 0.7400\n",
      "Epoch 00005: early stopping\n",
      "134/134 [==============================] - 0s 2ms/sample - loss: 0.3555 - accuracy: 0.8433\n",
      "131/131 [==============================] - 0s 290us/sample - loss: 0.3389 - accuracy: 0.8473\n",
      "125/125 [==============================] - 0s 257us/sample - loss: 0.3559 - accuracy: 0.8640\n",
      "125/125 [==============================] - 0s 250us/sample - loss: 0.4164 - accuracy: 0.8160\n",
      "126/126 [==============================] - 0s 233us/sample - loss: 0.4011 - accuracy: 0.7857\n",
      "126/126 [==============================] - 0s 256us/sample - loss: 0.3930 - accuracy: 0.8175\n",
      "126/126 [==============================] - 0s 255us/sample - loss: 0.4187 - accuracy: 0.8413\n",
      "123/123 [==============================] - 0s 234us/sample - loss: 0.3697 - accuracy: 0.8293\n",
      "124/124 [==============================] - 0s 230us/sample - loss: 0.4079 - accuracy: 0.8387\n",
      "123/123 [==============================] - 0s 263us/sample - loss: 0.3673 - accuracy: 0.8943\n",
      "124/124 [==============================] - 0s 260us/sample - loss: 0.3838 - accuracy: 0.8548\n",
      "124/124 [==============================] - 0s 245us/sample - loss: 0.3512 - accuracy: 0.9032\n",
      "123/123 [==============================] - 0s 284us/sample - loss: 0.3782 - accuracy: 0.8537\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.4571 - accuracy: 0.8083\n",
      "121/121 [==============================] - 0s 244us/sample - loss: 0.4098 - accuracy: 0.8843\n",
      "121/121 [==============================] - 0s 272us/sample - loss: 0.3743 - accuracy: 0.8347\n",
      "121/121 [==============================] - 0s 249us/sample - loss: 0.3868 - accuracy: 0.8843\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 0.3600 - accuracy: 0.8833\n",
      "121/121 [==============================] - 0s 261us/sample - loss: 0.3297 - accuracy: 0.8926\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.4232 - accuracy: 0.8417\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 0.3800 - accuracy: 0.8583\n",
      "119/119 [==============================] - 0s 248us/sample - loss: 0.3990 - accuracy: 0.8487\n",
      "119/119 [==============================] - 0s 265us/sample - loss: 0.4110 - accuracy: 0.8571\n",
      "119/119 [==============================] - 0s 339us/sample - loss: 0.4326 - accuracy: 0.8319\n",
      "119/119 [==============================] - 0s 267us/sample - loss: 0.4521 - accuracy: 0.8151\n",
      "118/118 [==============================] - 0s 289us/sample - loss: 0.4460 - accuracy: 0.7966\n",
      "117/117 [==============================] - 0s 272us/sample - loss: 0.4618 - accuracy: 0.8462\n",
      "118/118 [==============================] - 0s 298us/sample - loss: 0.4280 - accuracy: 0.8136\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.4556 - accuracy: 0.7917\n",
      "118/118 [==============================] - 0s 290us/sample - loss: 0.4421 - accuracy: 0.8051\n",
      "117/117 [==============================] - 0s 290us/sample - loss: 0.4899 - accuracy: 0.7778\n",
      "118/118 [==============================] - 0s 303us/sample - loss: 0.5477 - accuracy: 0.7542\n",
      "118/118 [==============================] - 0s 305us/sample - loss: 0.4914 - accuracy: 0.7712\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2825 samples, validate on 713 samples\n",
      "Epoch 1/300\n",
      "2825/2825 [==============================] - 3s 925us/sample - loss: 0.6505 - accuracy: 0.6333 - val_loss: 0.6272 - val_accuracy: 0.6718\n",
      "Epoch 2/300\n",
      "2825/2825 [==============================] - 1s 226us/sample - loss: 0.6211 - accuracy: 0.6789 - val_loss: 0.6108 - val_accuracy: 0.6844\n",
      "Epoch 3/300\n",
      "2825/2825 [==============================] - 1s 238us/sample - loss: 0.6012 - accuracy: 0.7065 - val_loss: 0.5996 - val_accuracy: 0.7139\n",
      "Epoch 4/300\n",
      "2825/2825 [==============================] - 1s 218us/sample - loss: 0.5904 - accuracy: 0.7165 - val_loss: 0.5904 - val_accuracy: 0.7265\n",
      "Epoch 5/300\n",
      "2825/2825 [==============================] - 1s 207us/sample - loss: 0.5760 - accuracy: 0.7370 - val_loss: 0.5832 - val_accuracy: 0.7419\n",
      "Epoch 6/300\n",
      "2825/2825 [==============================] - 1s 248us/sample - loss: 0.5708 - accuracy: 0.7402 - val_loss: 0.5771 - val_accuracy: 0.7489\n",
      "Epoch 7/300\n",
      "2825/2825 [==============================] - 1s 252us/sample - loss: 0.5604 - accuracy: 0.7558 - val_loss: 0.5717 - val_accuracy: 0.7532\n",
      "Epoch 8/300\n",
      "2825/2825 [==============================] - 1s 238us/sample - loss: 0.5501 - accuracy: 0.7604 - val_loss: 0.5669 - val_accuracy: 0.7560\n",
      "Epoch 9/300\n",
      "2825/2825 [==============================] - 1s 253us/sample - loss: 0.5451 - accuracy: 0.7575 - val_loss: 0.5627 - val_accuracy: 0.7588\n",
      "Epoch 10/300\n",
      "2825/2825 [==============================] - 1s 241us/sample - loss: 0.5403 - accuracy: 0.7650 - val_loss: 0.5588 - val_accuracy: 0.7560\n",
      "Epoch 11/300\n",
      "2825/2825 [==============================] - 1s 245us/sample - loss: 0.5313 - accuracy: 0.7653 - val_loss: 0.5554 - val_accuracy: 0.7588\n",
      "Epoch 12/300\n",
      "2825/2825 [==============================] - 1s 246us/sample - loss: 0.5267 - accuracy: 0.7696 - val_loss: 0.5522 - val_accuracy: 0.7588\n",
      "Epoch 13/300\n",
      "2825/2825 [==============================] - 1s 248us/sample - loss: 0.5238 - accuracy: 0.7717 - val_loss: 0.5493 - val_accuracy: 0.7616\n",
      "Epoch 14/300\n",
      "2825/2825 [==============================] - 1s 220us/sample - loss: 0.5160 - accuracy: 0.7805 - val_loss: 0.5467 - val_accuracy: 0.7630\n",
      "Epoch 15/300\n",
      "2825/2825 [==============================] - 1s 198us/sample - loss: 0.5135 - accuracy: 0.7791 - val_loss: 0.5444 - val_accuracy: 0.7644\n",
      "Epoch 16/300\n",
      "2825/2825 [==============================] - 1s 191us/sample - loss: 0.5063 - accuracy: 0.7834 - val_loss: 0.5423 - val_accuracy: 0.7644\n",
      "Epoch 17/300\n",
      "2825/2825 [==============================] - 1s 183us/sample - loss: 0.5048 - accuracy: 0.7809 - val_loss: 0.5404 - val_accuracy: 0.7644\n",
      "Epoch 18/300\n",
      "2825/2825 [==============================] - 1s 197us/sample - loss: 0.5010 - accuracy: 0.7834 - val_loss: 0.5386 - val_accuracy: 0.7658\n",
      "Epoch 19/300\n",
      "2825/2825 [==============================] - 1s 196us/sample - loss: 0.4964 - accuracy: 0.7788 - val_loss: 0.5369 - val_accuracy: 0.7672\n",
      "Epoch 20/300\n",
      "2825/2825 [==============================] - 1s 188us/sample - loss: 0.4957 - accuracy: 0.7919 - val_loss: 0.5355 - val_accuracy: 0.7672\n",
      "Epoch 21/300\n",
      "2825/2825 [==============================] - 1s 206us/sample - loss: 0.4839 - accuracy: 0.7922 - val_loss: 0.5342 - val_accuracy: 0.7700\n",
      "Epoch 22/300\n",
      "2825/2825 [==============================] - 1s 249us/sample - loss: 0.4859 - accuracy: 0.7876 - val_loss: 0.5329 - val_accuracy: 0.7700\n",
      "Epoch 23/300\n",
      "2825/2825 [==============================] - 1s 254us/sample - loss: 0.4825 - accuracy: 0.7890 - val_loss: 0.5319 - val_accuracy: 0.7714\n",
      "Epoch 24/300\n",
      "2825/2825 [==============================] - 1s 249us/sample - loss: 0.4793 - accuracy: 0.7869 - val_loss: 0.5307 - val_accuracy: 0.7728\n",
      "Epoch 25/300\n",
      "2825/2825 [==============================] - 1s 229us/sample - loss: 0.4722 - accuracy: 0.7929 - val_loss: 0.5298 - val_accuracy: 0.7728\n",
      "Epoch 26/300\n",
      "2825/2825 [==============================] - 1s 226us/sample - loss: 0.4726 - accuracy: 0.7912 - val_loss: 0.5290 - val_accuracy: 0.7728\n",
      "Epoch 27/300\n",
      "2825/2825 [==============================] - 1s 204us/sample - loss: 0.4676 - accuracy: 0.7958 - val_loss: 0.5282 - val_accuracy: 0.7728\n",
      "Epoch 28/300\n",
      "2825/2825 [==============================] - 1s 191us/sample - loss: 0.4671 - accuracy: 0.7926 - val_loss: 0.5275 - val_accuracy: 0.7714\n",
      "Epoch 29/300\n",
      "2825/2825 [==============================] - 1s 241us/sample - loss: 0.4583 - accuracy: 0.7958 - val_loss: 0.5269 - val_accuracy: 0.7728\n",
      "Epoch 30/300\n",
      "2825/2825 [==============================] - 1s 244us/sample - loss: 0.4597 - accuracy: 0.7979 - val_loss: 0.5264 - val_accuracy: 0.7728\n",
      "Epoch 31/300\n",
      "2825/2825 [==============================] - 1s 225us/sample - loss: 0.4565 - accuracy: 0.7989 - val_loss: 0.5259 - val_accuracy: 0.7700\n",
      "Epoch 32/300\n",
      "2825/2825 [==============================] - 1s 226us/sample - loss: 0.4542 - accuracy: 0.7940 - val_loss: 0.5256 - val_accuracy: 0.7700\n",
      "Epoch 33/300\n",
      "2825/2825 [==============================] - 1s 226us/sample - loss: 0.4496 - accuracy: 0.7926 - val_loss: 0.5252 - val_accuracy: 0.7700\n",
      "Epoch 34/300\n",
      "2825/2825 [==============================] - 1s 204us/sample - loss: 0.4464 - accuracy: 0.8000 - val_loss: 0.5249 - val_accuracy: 0.7714\n",
      "Epoch 35/300\n",
      "2825/2825 [==============================] - 1s 242us/sample - loss: 0.4446 - accuracy: 0.8035 - val_loss: 0.5247 - val_accuracy: 0.7714\n",
      "Epoch 36/300\n",
      "2825/2825 [==============================] - 1s 254us/sample - loss: 0.4430 - accuracy: 0.7996 - val_loss: 0.5245 - val_accuracy: 0.7714\n",
      "Epoch 37/300\n",
      "2825/2825 [==============================] - 1s 213us/sample - loss: 0.4389 - accuracy: 0.8025 - val_loss: 0.5243 - val_accuracy: 0.7700\n",
      "Epoch 38/300\n",
      "2825/2825 [==============================] - 1s 220us/sample - loss: 0.4360 - accuracy: 0.8053 - val_loss: 0.5242 - val_accuracy: 0.7700\n",
      "Epoch 39/300\n",
      "2825/2825 [==============================] - 1s 243us/sample - loss: 0.4335 - accuracy: 0.8050 - val_loss: 0.5241 - val_accuracy: 0.7700\n",
      "Epoch 40/300\n",
      "2825/2825 [==============================] - 1s 240us/sample - loss: 0.4329 - accuracy: 0.8053 - val_loss: 0.5240 - val_accuracy: 0.7728\n",
      "Epoch 41/300\n",
      "2825/2825 [==============================] - 1s 209us/sample - loss: 0.4310 - accuracy: 0.8078 - val_loss: 0.5241 - val_accuracy: 0.7728\n",
      "Epoch 42/300\n",
      "2825/2825 [==============================] - 1s 206us/sample - loss: 0.4292 - accuracy: 0.8064 - val_loss: 0.5241 - val_accuracy: 0.7728\n",
      "Epoch 43/300\n",
      "2825/2825 [==============================] - 1s 218us/sample - loss: 0.4235 - accuracy: 0.8064 - val_loss: 0.5242 - val_accuracy: 0.7728\n",
      "Epoch 00043: early stopping\n",
      "111/111 [==============================] - 0s 146us/sample - loss: 0.2344 - accuracy: 0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [6:14:33, 1091.45s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.52s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.30s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 831.9921875 steps, validate for 214.0546875 steps\n",
      "Epoch 1/300\n",
      "832/831 [==============================] - 25s 30ms/step - loss: 0.6091 - accuracy: 0.6860 - val_loss: 0.5359 - val_accuracy: 0.7672\n",
      "Epoch 2/300\n",
      "832/831 [==============================] - 24s 29ms/step - loss: 0.5153 - accuracy: 0.7727 - val_loss: 0.5338 - val_accuracy: 0.7700\n",
      "Epoch 3/300\n",
      "832/831 [==============================] - 24s 29ms/step - loss: 0.5001 - accuracy: 0.7785 - val_loss: 0.5317 - val_accuracy: 0.7688\n",
      "Epoch 4/300\n",
      "832/831 [==============================] - 24s 29ms/step - loss: 0.4895 - accuracy: 0.7833 - val_loss: 0.5334 - val_accuracy: 0.7666\n",
      "Epoch 5/300\n",
      "832/831 [==============================] - 24s 29ms/step - loss: 0.4803 - accuracy: 0.7866 - val_loss: 0.5352 - val_accuracy: 0.7666\n",
      "Epoch 6/300\n",
      "832/831 [==============================] - 24s 29ms/step - loss: 0.4719 - accuracy: 0.7909 - val_loss: 0.5379 - val_accuracy: 0.7660\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 831.9921875 steps, validate for 214.0546875 steps\n",
      "Epoch 1/300\n",
      "832/831 [==============================] - 55s 66ms/step - loss: 0.4550 - accuracy: 0.7991 - val_loss: 0.5573 - val_accuracy: 0.7425\n",
      "Epoch 2/300\n",
      "832/831 [==============================] - 54s 65ms/step - loss: 0.4282 - accuracy: 0.8124 - val_loss: 0.5681 - val_accuracy: 0.7552\n",
      "Epoch 3/300\n",
      "832/831 [==============================] - 54s 64ms/step - loss: 0.4052 - accuracy: 0.8250 - val_loss: 0.5469 - val_accuracy: 0.7508\n",
      "Epoch 4/300\n",
      "832/831 [==============================] - 54s 65ms/step - loss: 0.3852 - accuracy: 0.8363 - val_loss: 0.5609 - val_accuracy: 0.7484\n",
      "Epoch 5/300\n",
      "832/831 [==============================] - 54s 64ms/step - loss: 0.3656 - accuracy: 0.8470 - val_loss: 0.5665 - val_accuracy: 0.7493\n",
      "Epoch 6/300\n",
      "832/831 [==============================] - 54s 64ms/step - loss: 0.3476 - accuracy: 0.8564 - val_loss: 0.5852 - val_accuracy: 0.7325\n",
      "Epoch 00006: early stopping\n",
      "148/148 [==============================] - 0s 1ms/sample - loss: 0.3786 - accuracy: 0.8581\n",
      "138/138 [==============================] - 0s 269us/sample - loss: 0.3589 - accuracy: 0.8478\n",
      "134/134 [==============================] - 0s 231us/sample - loss: 0.3678 - accuracy: 0.8507\n",
      "133/133 [==============================] - 0s 240us/sample - loss: 0.4301 - accuracy: 0.8496\n",
      "133/133 [==============================] - 0s 281us/sample - loss: 0.3262 - accuracy: 0.8571\n",
      "130/130 [==============================] - 0s 256us/sample - loss: 0.3991 - accuracy: 0.8462\n",
      "126/126 [==============================] - 0s 253us/sample - loss: 0.3694 - accuracy: 0.8810\n",
      "126/126 [==============================] - 0s 233us/sample - loss: 0.3764 - accuracy: 0.8730\n",
      "124/124 [==============================] - 0s 234us/sample - loss: 0.3207 - accuracy: 0.8952\n",
      "121/121 [==============================] - 0s 228us/sample - loss: 0.3222 - accuracy: 0.9008\n",
      "118/118 [==============================] - 0s 266us/sample - loss: 0.3078 - accuracy: 0.8983\n",
      "117/117 [==============================] - 0s 279us/sample - loss: 0.3276 - accuracy: 0.9060\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 0.4075 - accuracy: 0.8333\n",
      "117/117 [==============================] - 0s 259us/sample - loss: 0.3326 - accuracy: 0.8889\n",
      "116/116 [==============================] - 0s 262us/sample - loss: 0.3949 - accuracy: 0.8621\n",
      "114/114 [==============================] - 0s 274us/sample - loss: 0.3547 - accuracy: 0.8947\n",
      "113/113 [==============================] - 0s 281us/sample - loss: 0.4329 - accuracy: 0.8938\n",
      "113/113 [==============================] - 0s 290us/sample - loss: 0.3964 - accuracy: 0.8407\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 0.3652 - accuracy: 0.8482\n",
      "112/112 [==============================] - 0s 285us/sample - loss: 0.3771 - accuracy: 0.8571\n",
      "113/113 [==============================] - 0s 252us/sample - loss: 0.3680 - accuracy: 0.8938\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.3784 - accuracy: 0.8661\n",
      "113/113 [==============================] - 0s 242us/sample - loss: 0.3979 - accuracy: 0.8407\n",
      "111/111 [==============================] - 0s 247us/sample - loss: 0.3760 - accuracy: 0.8829\n",
      "110/110 [==============================] - 0s 242us/sample - loss: 0.3976 - accuracy: 0.8364\n",
      "110/110 [==============================] - 0s 249us/sample - loss: 0.3872 - accuracy: 0.8455\n",
      "111/111 [==============================] - 0s 310us/sample - loss: 0.3979 - accuracy: 0.8468\n",
      "109/109 [==============================] - 0s 265us/sample - loss: 0.4001 - accuracy: 0.8257\n",
      "108/108 [==============================] - 0s 277us/sample - loss: 0.3583 - accuracy: 0.8981\n",
      "106/106 [==============================] - 0s 282us/sample - loss: 0.4433 - accuracy: 0.8396\n",
      "106/106 [==============================] - 0s 360us/sample - loss: 0.3861 - accuracy: 0.8491\n",
      "106/106 [==============================] - 0s 287us/sample - loss: 0.4142 - accuracy: 0.8208\n",
      "104/104 [==============================] - 0s 330us/sample - loss: 0.4038 - accuracy: 0.8750\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2824 samples, validate on 726 samples\n",
      "Epoch 1/300\n",
      "2824/2824 [==============================] - 2s 864us/sample - loss: 0.6269 - accuracy: 0.6657 - val_loss: 0.6180 - val_accuracy: 0.6708\n",
      "Epoch 2/300\n",
      "2824/2824 [==============================] - 1s 246us/sample - loss: 0.6032 - accuracy: 0.6944 - val_loss: 0.6045 - val_accuracy: 0.6997\n",
      "Epoch 3/300\n",
      "2824/2824 [==============================] - 1s 253us/sample - loss: 0.5839 - accuracy: 0.7157 - val_loss: 0.5959 - val_accuracy: 0.7094\n",
      "Epoch 4/300\n",
      "2824/2824 [==============================] - 1s 228us/sample - loss: 0.5752 - accuracy: 0.7266 - val_loss: 0.5890 - val_accuracy: 0.7107\n",
      "Epoch 5/300\n",
      "2824/2824 [==============================] - 1s 179us/sample - loss: 0.5623 - accuracy: 0.7454 - val_loss: 0.5832 - val_accuracy: 0.7163\n",
      "Epoch 6/300\n",
      "2824/2824 [==============================] - 0s 169us/sample - loss: 0.5531 - accuracy: 0.7493 - val_loss: 0.5785 - val_accuracy: 0.7190\n",
      "Epoch 7/300\n",
      "2824/2824 [==============================] - 1s 194us/sample - loss: 0.5430 - accuracy: 0.7617 - val_loss: 0.5743 - val_accuracy: 0.7231\n",
      "Epoch 8/300\n",
      "2824/2824 [==============================] - 1s 237us/sample - loss: 0.5355 - accuracy: 0.7705 - val_loss: 0.5706 - val_accuracy: 0.7273\n",
      "Epoch 9/300\n",
      "2824/2824 [==============================] - 1s 185us/sample - loss: 0.5313 - accuracy: 0.7688 - val_loss: 0.5675 - val_accuracy: 0.7314\n",
      "Epoch 10/300\n",
      "2824/2824 [==============================] - 1s 225us/sample - loss: 0.5255 - accuracy: 0.7705 - val_loss: 0.5646 - val_accuracy: 0.7328\n",
      "Epoch 11/300\n",
      "2824/2824 [==============================] - 1s 225us/sample - loss: 0.5141 - accuracy: 0.7865 - val_loss: 0.5621 - val_accuracy: 0.7355\n",
      "Epoch 12/300\n",
      "2824/2824 [==============================] - 1s 222us/sample - loss: 0.5116 - accuracy: 0.7882 - val_loss: 0.5598 - val_accuracy: 0.7342\n",
      "Epoch 13/300\n",
      "2824/2824 [==============================] - 1s 236us/sample - loss: 0.5065 - accuracy: 0.7797 - val_loss: 0.5576 - val_accuracy: 0.7410\n",
      "Epoch 14/300\n",
      "2824/2824 [==============================] - 1s 204us/sample - loss: 0.5064 - accuracy: 0.7879 - val_loss: 0.5557 - val_accuracy: 0.7452\n",
      "Epoch 15/300\n",
      "2824/2824 [==============================] - 1s 189us/sample - loss: 0.4980 - accuracy: 0.7950 - val_loss: 0.5538 - val_accuracy: 0.7466\n",
      "Epoch 16/300\n",
      "2824/2824 [==============================] - 1s 206us/sample - loss: 0.4908 - accuracy: 0.7946 - val_loss: 0.5522 - val_accuracy: 0.7493\n",
      "Epoch 17/300\n",
      "2824/2824 [==============================] - 1s 207us/sample - loss: 0.4874 - accuracy: 0.8017 - val_loss: 0.5507 - val_accuracy: 0.7507\n",
      "Epoch 18/300\n",
      "2824/2824 [==============================] - 1s 245us/sample - loss: 0.4844 - accuracy: 0.7985 - val_loss: 0.5492 - val_accuracy: 0.7507\n",
      "Epoch 19/300\n",
      "2824/2824 [==============================] - 1s 229us/sample - loss: 0.4787 - accuracy: 0.8013 - val_loss: 0.5480 - val_accuracy: 0.7521\n",
      "Epoch 20/300\n",
      "2824/2824 [==============================] - 1s 235us/sample - loss: 0.4753 - accuracy: 0.8049 - val_loss: 0.5469 - val_accuracy: 0.7493\n",
      "Epoch 21/300\n",
      "2824/2824 [==============================] - 1s 205us/sample - loss: 0.4693 - accuracy: 0.8056 - val_loss: 0.5458 - val_accuracy: 0.7507\n",
      "Epoch 22/300\n",
      "2824/2824 [==============================] - 1s 212us/sample - loss: 0.4675 - accuracy: 0.8031 - val_loss: 0.5448 - val_accuracy: 0.7493\n",
      "Epoch 23/300\n",
      "2824/2824 [==============================] - 1s 214us/sample - loss: 0.4635 - accuracy: 0.8081 - val_loss: 0.5440 - val_accuracy: 0.7479\n",
      "Epoch 24/300\n",
      "2824/2824 [==============================] - 1s 210us/sample - loss: 0.4570 - accuracy: 0.8155 - val_loss: 0.5432 - val_accuracy: 0.7493\n",
      "Epoch 25/300\n",
      "2824/2824 [==============================] - 1s 231us/sample - loss: 0.4544 - accuracy: 0.8130 - val_loss: 0.5425 - val_accuracy: 0.7493\n",
      "Epoch 26/300\n",
      "2824/2824 [==============================] - 1s 264us/sample - loss: 0.4533 - accuracy: 0.8166 - val_loss: 0.5418 - val_accuracy: 0.7479\n",
      "Epoch 27/300\n",
      "2824/2824 [==============================] - 1s 200us/sample - loss: 0.4479 - accuracy: 0.8169 - val_loss: 0.5412 - val_accuracy: 0.7479\n",
      "Epoch 28/300\n",
      "2824/2824 [==============================] - 1s 229us/sample - loss: 0.4438 - accuracy: 0.8159 - val_loss: 0.5408 - val_accuracy: 0.7493\n",
      "Epoch 29/300\n",
      "2824/2824 [==============================] - 1s 190us/sample - loss: 0.4376 - accuracy: 0.8198 - val_loss: 0.5403 - val_accuracy: 0.7493\n",
      "Epoch 30/300\n",
      "2824/2824 [==============================] - 1s 247us/sample - loss: 0.4357 - accuracy: 0.8279 - val_loss: 0.5400 - val_accuracy: 0.7507\n",
      "Epoch 31/300\n",
      "2824/2824 [==============================] - 1s 214us/sample - loss: 0.4290 - accuracy: 0.8247 - val_loss: 0.5397 - val_accuracy: 0.7507\n",
      "Epoch 32/300\n",
      "2824/2824 [==============================] - 1s 245us/sample - loss: 0.4286 - accuracy: 0.8251 - val_loss: 0.5395 - val_accuracy: 0.7521\n",
      "Epoch 33/300\n",
      "2824/2824 [==============================] - 1s 234us/sample - loss: 0.4243 - accuracy: 0.8283 - val_loss: 0.5393 - val_accuracy: 0.7521\n",
      "Epoch 34/300\n",
      "2824/2824 [==============================] - 1s 214us/sample - loss: 0.4218 - accuracy: 0.8307 - val_loss: 0.5392 - val_accuracy: 0.7521\n",
      "Epoch 35/300\n",
      "2824/2824 [==============================] - 1s 208us/sample - loss: 0.4164 - accuracy: 0.8332 - val_loss: 0.5392 - val_accuracy: 0.7534\n",
      "Epoch 36/300\n",
      "2824/2824 [==============================] - 1s 235us/sample - loss: 0.4155 - accuracy: 0.8300 - val_loss: 0.5392 - val_accuracy: 0.7548\n",
      "Epoch 37/300\n",
      "2824/2824 [==============================] - 1s 204us/sample - loss: 0.4113 - accuracy: 0.8343 - val_loss: 0.5392 - val_accuracy: 0.7521\n",
      "Epoch 38/300\n",
      "2824/2824 [==============================] - 1s 188us/sample - loss: 0.4080 - accuracy: 0.8357 - val_loss: 0.5393 - val_accuracy: 0.7521\n",
      "Epoch 00038: early stopping\n",
      "99/99 [==============================] - 0s 150us/sample - loss: 0.3157 - accuracy: 0.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [6:33:36, 1107.14s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.60s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.35s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 829.046875 steps, validate for 213.3046875 steps\n",
      "Epoch 1/300\n",
      "830/829 [==============================] - 25s 30ms/step - loss: 0.6357 - accuracy: 0.6622 - val_loss: 0.5366 - val_accuracy: 0.7685\n",
      "Epoch 2/300\n",
      "830/829 [==============================] - 24s 29ms/step - loss: 0.5189 - accuracy: 0.7721 - val_loss: 0.5333 - val_accuracy: 0.7687\n",
      "Epoch 3/300\n",
      "830/829 [==============================] - 24s 29ms/step - loss: 0.5027 - accuracy: 0.7772 - val_loss: 0.5280 - val_accuracy: 0.7694\n",
      "Epoch 4/300\n",
      "830/829 [==============================] - 24s 29ms/step - loss: 0.4905 - accuracy: 0.7817 - val_loss: 0.5288 - val_accuracy: 0.7676\n",
      "Epoch 5/300\n",
      "830/829 [==============================] - 24s 29ms/step - loss: 0.4797 - accuracy: 0.7865 - val_loss: 0.5326 - val_accuracy: 0.7689\n",
      "Epoch 6/300\n",
      "830/829 [==============================] - 24s 29ms/step - loss: 0.4703 - accuracy: 0.7906 - val_loss: 0.5353 - val_accuracy: 0.7673\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 829.046875 steps, validate for 213.3046875 steps\n",
      "Epoch 1/300\n",
      "830/829 [==============================] - 54s 65ms/step - loss: 0.4543 - accuracy: 0.7990 - val_loss: 0.5315 - val_accuracy: 0.7657\n",
      "Epoch 2/300\n",
      "830/829 [==============================] - 54s 65ms/step - loss: 0.4296 - accuracy: 0.8114 - val_loss: 0.5390 - val_accuracy: 0.7544\n",
      "Epoch 3/300\n",
      "830/829 [==============================] - 53s 64ms/step - loss: 0.4088 - accuracy: 0.8230 - val_loss: 0.5517 - val_accuracy: 0.7636\n",
      "Epoch 4/300\n",
      "830/829 [==============================] - 54s 64ms/step - loss: 0.3897 - accuracy: 0.8339 - val_loss: 0.5690 - val_accuracy: 0.7391\n",
      "Epoch 00004: early stopping\n",
      "152/152 [==============================] - 0s 2ms/sample - loss: 0.2690 - accuracy: 0.9145\n",
      "145/145 [==============================] - 0s 319us/sample - loss: 0.2658 - accuracy: 0.9103\n",
      "142/142 [==============================] - 0s 263us/sample - loss: 0.3025 - accuracy: 0.9014\n",
      "138/138 [==============================] - 0s 272us/sample - loss: 0.3100 - accuracy: 0.9203\n",
      "137/137 [==============================] - 0s 238us/sample - loss: 0.2792 - accuracy: 0.9343\n",
      "137/137 [==============================] - 0s 250us/sample - loss: 0.3091 - accuracy: 0.9343\n",
      "136/136 [==============================] - 0s 269us/sample - loss: 0.2965 - accuracy: 0.9632\n",
      "135/135 [==============================] - 0s 249us/sample - loss: 0.3025 - accuracy: 0.9185\n",
      "136/136 [==============================] - 0s 238us/sample - loss: 0.2808 - accuracy: 0.9412\n",
      "134/134 [==============================] - 0s 275us/sample - loss: 0.2918 - accuracy: 0.9254\n",
      "132/132 [==============================] - 0s 261us/sample - loss: 0.3074 - accuracy: 0.9167\n",
      "132/132 [==============================] - 0s 306us/sample - loss: 0.2954 - accuracy: 0.9091\n",
      "133/133 [==============================] - 0s 264us/sample - loss: 0.3017 - accuracy: 0.9173\n",
      "132/132 [==============================] - 0s 304us/sample - loss: 0.3002 - accuracy: 0.9091\n",
      "133/133 [==============================] - 0s 247us/sample - loss: 0.2768 - accuracy: 0.9248\n",
      "130/130 [==============================] - 0s 255us/sample - loss: 0.3074 - accuracy: 0.9231\n",
      "132/132 [==============================] - 0s 250us/sample - loss: 0.3078 - accuracy: 0.8712\n",
      "131/131 [==============================] - 0s 262us/sample - loss: 0.3335 - accuracy: 0.9008\n",
      "132/132 [==============================] - 0s 284us/sample - loss: 0.3468 - accuracy: 0.8864\n",
      "131/131 [==============================] - 0s 258us/sample - loss: 0.3464 - accuracy: 0.9008\n",
      "129/129 [==============================] - 0s 327us/sample - loss: 0.2876 - accuracy: 0.9302\n",
      "129/129 [==============================] - 0s 330us/sample - loss: 0.3249 - accuracy: 0.8915\n",
      "129/129 [==============================] - 0s 308us/sample - loss: 0.3469 - accuracy: 0.8760\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.3234 - accuracy: 0.9062\n",
      "129/129 [==============================] - 0s 266us/sample - loss: 0.3638 - accuracy: 0.8682\n",
      "127/127 [==============================] - 0s 231us/sample - loss: 0.3444 - accuracy: 0.8898\n",
      "127/127 [==============================] - 0s 266us/sample - loss: 0.3824 - accuracy: 0.8740\n",
      "126/126 [==============================] - 0s 276us/sample - loss: 0.3877 - accuracy: 0.8571\n",
      "124/124 [==============================] - 0s 242us/sample - loss: 0.3479 - accuracy: 0.9113\n",
      "126/126 [==============================] - 0s 251us/sample - loss: 0.3702 - accuracy: 0.9127\n",
      "125/125 [==============================] - 0s 248us/sample - loss: 0.3534 - accuracy: 0.9040\n",
      "123/123 [==============================] - 0s 268us/sample - loss: 0.3553 - accuracy: 0.8618\n",
      "125/125 [==============================] - 0s 267us/sample - loss: 0.3789 - accuracy: 0.9040\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2811 samples, validate on 719 samples\n",
      "Epoch 1/300\n",
      "2811/2811 [==============================] - 3s 961us/sample - loss: 0.6820 - accuracy: 0.5749 - val_loss: 0.6755 - val_accuracy: 0.5883\n",
      "Epoch 2/300\n",
      "2811/2811 [==============================] - 1s 237us/sample - loss: 0.6405 - accuracy: 0.6446 - val_loss: 0.6532 - val_accuracy: 0.6175\n",
      "Epoch 3/300\n",
      "2811/2811 [==============================] - 1s 243us/sample - loss: 0.6194 - accuracy: 0.6809 - val_loss: 0.6379 - val_accuracy: 0.6287\n",
      "Epoch 4/300\n",
      "2811/2811 [==============================] - 1s 277us/sample - loss: 0.6049 - accuracy: 0.6802 - val_loss: 0.6262 - val_accuracy: 0.6509\n",
      "Epoch 5/300\n",
      "2811/2811 [==============================] - 1s 248us/sample - loss: 0.5903 - accuracy: 0.7140 - val_loss: 0.6169 - val_accuracy: 0.6745\n",
      "Epoch 6/300\n",
      "2811/2811 [==============================] - 1s 218us/sample - loss: 0.5774 - accuracy: 0.7325 - val_loss: 0.6088 - val_accuracy: 0.6857\n",
      "Epoch 7/300\n",
      "2811/2811 [==============================] - 1s 224us/sample - loss: 0.5705 - accuracy: 0.7389 - val_loss: 0.6018 - val_accuracy: 0.6912\n",
      "Epoch 8/300\n",
      "2811/2811 [==============================] - 1s 213us/sample - loss: 0.5649 - accuracy: 0.7496 - val_loss: 0.5957 - val_accuracy: 0.7038\n",
      "Epoch 9/300\n",
      "2811/2811 [==============================] - 1s 248us/sample - loss: 0.5563 - accuracy: 0.7524 - val_loss: 0.5906 - val_accuracy: 0.7135\n",
      "Epoch 10/300\n",
      "2811/2811 [==============================] - 1s 269us/sample - loss: 0.5498 - accuracy: 0.7517 - val_loss: 0.5857 - val_accuracy: 0.7204\n",
      "Epoch 11/300\n",
      "2811/2811 [==============================] - 1s 243us/sample - loss: 0.5441 - accuracy: 0.7552 - val_loss: 0.5815 - val_accuracy: 0.7274\n",
      "Epoch 12/300\n",
      "2811/2811 [==============================] - 1s 250us/sample - loss: 0.5389 - accuracy: 0.7670 - val_loss: 0.5776 - val_accuracy: 0.7330\n",
      "Epoch 13/300\n",
      "2811/2811 [==============================] - 1s 251us/sample - loss: 0.5307 - accuracy: 0.7656 - val_loss: 0.5740 - val_accuracy: 0.7371\n",
      "Epoch 14/300\n",
      "2811/2811 [==============================] - 1s 236us/sample - loss: 0.5243 - accuracy: 0.7741 - val_loss: 0.5709 - val_accuracy: 0.7399\n",
      "Epoch 15/300\n",
      "2811/2811 [==============================] - 1s 247us/sample - loss: 0.5197 - accuracy: 0.7801 - val_loss: 0.5680 - val_accuracy: 0.7441\n",
      "Epoch 16/300\n",
      "2811/2811 [==============================] - 1s 240us/sample - loss: 0.5156 - accuracy: 0.7755 - val_loss: 0.5653 - val_accuracy: 0.7441\n",
      "Epoch 17/300\n",
      "2811/2811 [==============================] - 1s 255us/sample - loss: 0.5120 - accuracy: 0.7830 - val_loss: 0.5629 - val_accuracy: 0.7469\n",
      "Epoch 18/300\n",
      "2811/2811 [==============================] - 1s 221us/sample - loss: 0.5089 - accuracy: 0.7841 - val_loss: 0.5606 - val_accuracy: 0.7469\n",
      "Epoch 19/300\n",
      "2811/2811 [==============================] - 1s 261us/sample - loss: 0.5095 - accuracy: 0.7834 - val_loss: 0.5587 - val_accuracy: 0.7483\n",
      "Epoch 20/300\n",
      "2811/2811 [==============================] - 1s 224us/sample - loss: 0.5013 - accuracy: 0.7866 - val_loss: 0.5568 - val_accuracy: 0.7483\n",
      "Epoch 21/300\n",
      "2811/2811 [==============================] - 1s 230us/sample - loss: 0.4988 - accuracy: 0.7880 - val_loss: 0.5550 - val_accuracy: 0.7497\n",
      "Epoch 22/300\n",
      "2811/2811 [==============================] - 1s 211us/sample - loss: 0.4955 - accuracy: 0.7866 - val_loss: 0.5534 - val_accuracy: 0.7510\n",
      "Epoch 23/300\n",
      "2811/2811 [==============================] - 1s 232us/sample - loss: 0.4892 - accuracy: 0.7926 - val_loss: 0.5520 - val_accuracy: 0.7552\n",
      "Epoch 24/300\n",
      "2811/2811 [==============================] - 1s 255us/sample - loss: 0.4864 - accuracy: 0.7887 - val_loss: 0.5508 - val_accuracy: 0.7566\n",
      "Epoch 25/300\n",
      "2811/2811 [==============================] - 1s 276us/sample - loss: 0.4830 - accuracy: 0.7915 - val_loss: 0.5494 - val_accuracy: 0.7566\n",
      "Epoch 26/300\n",
      "2811/2811 [==============================] - 1s 228us/sample - loss: 0.4841 - accuracy: 0.7940 - val_loss: 0.5483 - val_accuracy: 0.7594\n",
      "Epoch 27/300\n",
      "2811/2811 [==============================] - 1s 192us/sample - loss: 0.4801 - accuracy: 0.7922 - val_loss: 0.5473 - val_accuracy: 0.7580\n",
      "Epoch 28/300\n",
      "2811/2811 [==============================] - 0s 174us/sample - loss: 0.4724 - accuracy: 0.8029 - val_loss: 0.5463 - val_accuracy: 0.7580\n",
      "Epoch 29/300\n",
      "2811/2811 [==============================] - 1s 204us/sample - loss: 0.4690 - accuracy: 0.8022 - val_loss: 0.5454 - val_accuracy: 0.7580\n",
      "Epoch 30/300\n",
      "2811/2811 [==============================] - 1s 200us/sample - loss: 0.4724 - accuracy: 0.7972 - val_loss: 0.5446 - val_accuracy: 0.7594\n",
      "Epoch 31/300\n",
      "2811/2811 [==============================] - 1s 190us/sample - loss: 0.4671 - accuracy: 0.8011 - val_loss: 0.5438 - val_accuracy: 0.7594\n",
      "Epoch 32/300\n",
      "2811/2811 [==============================] - 1s 192us/sample - loss: 0.4650 - accuracy: 0.7979 - val_loss: 0.5431 - val_accuracy: 0.7608\n",
      "Epoch 33/300\n",
      "2811/2811 [==============================] - 1s 203us/sample - loss: 0.4648 - accuracy: 0.8018 - val_loss: 0.5424 - val_accuracy: 0.7608\n",
      "Epoch 34/300\n",
      "2811/2811 [==============================] - 1s 206us/sample - loss: 0.4589 - accuracy: 0.8047 - val_loss: 0.5418 - val_accuracy: 0.7608\n",
      "Epoch 35/300\n",
      "2811/2811 [==============================] - 1s 258us/sample - loss: 0.4584 - accuracy: 0.8040 - val_loss: 0.5413 - val_accuracy: 0.7608\n",
      "Epoch 36/300\n",
      "2811/2811 [==============================] - 1s 215us/sample - loss: 0.4560 - accuracy: 0.8068 - val_loss: 0.5407 - val_accuracy: 0.7622\n",
      "Epoch 37/300\n",
      "2811/2811 [==============================] - 1s 235us/sample - loss: 0.4544 - accuracy: 0.8047 - val_loss: 0.5403 - val_accuracy: 0.7622\n",
      "Epoch 38/300\n",
      "2811/2811 [==============================] - 1s 213us/sample - loss: 0.4481 - accuracy: 0.8115 - val_loss: 0.5399 - val_accuracy: 0.7636\n",
      "Epoch 39/300\n",
      "2811/2811 [==============================] - 1s 194us/sample - loss: 0.4466 - accuracy: 0.8104 - val_loss: 0.5396 - val_accuracy: 0.7636\n",
      "Epoch 40/300\n",
      "2811/2811 [==============================] - 1s 215us/sample - loss: 0.4464 - accuracy: 0.8079 - val_loss: 0.5392 - val_accuracy: 0.7622\n",
      "Epoch 41/300\n",
      "2811/2811 [==============================] - 1s 210us/sample - loss: 0.4415 - accuracy: 0.8139 - val_loss: 0.5390 - val_accuracy: 0.7622\n",
      "Epoch 42/300\n",
      "2811/2811 [==============================] - 1s 218us/sample - loss: 0.4364 - accuracy: 0.8100 - val_loss: 0.5387 - val_accuracy: 0.7622\n",
      "Epoch 43/300\n",
      "2811/2811 [==============================] - 1s 235us/sample - loss: 0.4414 - accuracy: 0.8083 - val_loss: 0.5385 - val_accuracy: 0.7622\n",
      "Epoch 44/300\n",
      "2811/2811 [==============================] - 1s 252us/sample - loss: 0.4320 - accuracy: 0.8111 - val_loss: 0.5383 - val_accuracy: 0.7622\n",
      "Epoch 45/300\n",
      "2811/2811 [==============================] - 1s 197us/sample - loss: 0.4318 - accuracy: 0.8107 - val_loss: 0.5382 - val_accuracy: 0.7636\n",
      "Epoch 46/300\n",
      "2811/2811 [==============================] - 1s 194us/sample - loss: 0.4334 - accuracy: 0.8164 - val_loss: 0.5381 - val_accuracy: 0.7636\n",
      "Epoch 47/300\n",
      "2811/2811 [==============================] - 1s 235us/sample - loss: 0.4279 - accuracy: 0.8189 - val_loss: 0.5380 - val_accuracy: 0.7636\n",
      "Epoch 48/300\n",
      "2811/2811 [==============================] - 1s 210us/sample - loss: 0.4272 - accuracy: 0.8122 - val_loss: 0.5379 - val_accuracy: 0.7636\n",
      "Epoch 49/300\n",
      "2811/2811 [==============================] - 1s 191us/sample - loss: 0.4223 - accuracy: 0.8203 - val_loss: 0.5379 - val_accuracy: 0.7622\n",
      "Epoch 50/300\n",
      "2811/2811 [==============================] - 1s 217us/sample - loss: 0.4214 - accuracy: 0.8218 - val_loss: 0.5379 - val_accuracy: 0.7608\n",
      "Epoch 51/300\n",
      "2811/2811 [==============================] - 1s 235us/sample - loss: 0.4199 - accuracy: 0.8239 - val_loss: 0.5380 - val_accuracy: 0.7608\n",
      "Epoch 52/300\n",
      "2811/2811 [==============================] - 1s 214us/sample - loss: 0.4157 - accuracy: 0.8232 - val_loss: 0.5379 - val_accuracy: 0.7622\n",
      "Epoch 53/300\n",
      "2811/2811 [==============================] - 1s 226us/sample - loss: 0.4146 - accuracy: 0.8239 - val_loss: 0.5380 - val_accuracy: 0.7622\n",
      "Epoch 00053: early stopping\n",
      "119/119 [==============================] - 0s 106us/sample - loss: 0.2814 - accuracy: 0.9496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [6:51:01, 1088.35s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.56s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.26s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 825.8828125 steps, validate for 215.125 steps\n",
      "Epoch 1/300\n",
      "826/825 [==============================] - 25s 30ms/step - loss: 0.6587 - accuracy: 0.6378 - val_loss: 0.5343 - val_accuracy: 0.7719\n",
      "Epoch 2/300\n",
      "826/825 [==============================] - 24s 29ms/step - loss: 0.5148 - accuracy: 0.7734 - val_loss: 0.5352 - val_accuracy: 0.7681\n",
      "Epoch 3/300\n",
      "826/825 [==============================] - 24s 29ms/step - loss: 0.4984 - accuracy: 0.7786 - val_loss: 0.5375 - val_accuracy: 0.7663\n",
      "Epoch 4/300\n",
      "826/825 [==============================] - 24s 29ms/step - loss: 0.4870 - accuracy: 0.7833 - val_loss: 0.5372 - val_accuracy: 0.7659\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 825.8828125 steps, validate for 215.125 steps\n",
      "Epoch 1/300\n",
      "826/825 [==============================] - 54s 66ms/step - loss: 0.4683 - accuracy: 0.7924 - val_loss: 0.5472 - val_accuracy: 0.7645\n",
      "Epoch 2/300\n",
      "826/825 [==============================] - 53s 64ms/step - loss: 0.4405 - accuracy: 0.8060 - val_loss: 0.5584 - val_accuracy: 0.7535\n",
      "Epoch 3/300\n",
      "826/825 [==============================] - 53s 65ms/step - loss: 0.4173 - accuracy: 0.8183 - val_loss: 0.5674 - val_accuracy: 0.7592\n",
      "Epoch 4/300\n",
      "826/825 [==============================] - 53s 65ms/step - loss: 0.3963 - accuracy: 0.8293 - val_loss: 0.5687 - val_accuracy: 0.7477\n",
      "Epoch 00004: early stopping\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 0.3514 - accuracy: 0.8696\n",
      "154/154 [==============================] - 0s 261us/sample - loss: 0.3442 - accuracy: 0.8896\n",
      "151/151 [==============================] - 0s 238us/sample - loss: 0.3313 - accuracy: 0.8940\n",
      "146/146 [==============================] - 0s 236us/sample - loss: 0.3167 - accuracy: 0.8973\n",
      "147/147 [==============================] - 0s 211us/sample - loss: 0.2939 - accuracy: 0.9116\n",
      "145/145 [==============================] - 0s 255us/sample - loss: 0.2685 - accuracy: 0.9517\n",
      "145/145 [==============================] - 0s 241us/sample - loss: 0.2450 - accuracy: 0.9448\n",
      "144/144 [==============================] - 0s 250us/sample - loss: 0.2593 - accuracy: 0.9514\n",
      "145/145 [==============================] - 0s 237us/sample - loss: 0.2000 - accuracy: 0.9862\n",
      "143/143 [==============================] - 0s 296us/sample - loss: 0.2086 - accuracy: 0.9720\n",
      "142/142 [==============================] - 0s 242us/sample - loss: 0.2474 - accuracy: 0.9155\n",
      "140/140 [==============================] - 0s 238us/sample - loss: 0.2125 - accuracy: 0.9786\n",
      "138/138 [==============================] - 0s 232us/sample - loss: 0.2181 - accuracy: 0.9638\n",
      "138/138 [==============================] - 0s 267us/sample - loss: 0.2196 - accuracy: 0.9710\n",
      "137/137 [==============================] - 0s 267us/sample - loss: 0.2613 - accuracy: 0.9270\n",
      "136/136 [==============================] - 0s 264us/sample - loss: 0.2421 - accuracy: 0.9485\n",
      "138/138 [==============================] - 0s 268us/sample - loss: 0.2438 - accuracy: 0.9420\n",
      "138/138 [==============================] - 0s 279us/sample - loss: 0.2587 - accuracy: 0.9275\n",
      "137/137 [==============================] - 0s 274us/sample - loss: 0.2381 - accuracy: 0.9562\n",
      "136/136 [==============================] - 0s 266us/sample - loss: 0.2590 - accuracy: 0.9485\n",
      "136/136 [==============================] - 0s 267us/sample - loss: 0.2302 - accuracy: 0.9485\n",
      "136/136 [==============================] - 0s 238us/sample - loss: 0.2542 - accuracy: 0.9338\n",
      "136/136 [==============================] - 0s 236us/sample - loss: 0.2275 - accuracy: 0.9485\n",
      "135/135 [==============================] - 0s 271us/sample - loss: 0.2536 - accuracy: 0.9259\n",
      "135/135 [==============================] - 0s 279us/sample - loss: 0.2659 - accuracy: 0.9333\n",
      "134/134 [==============================] - 0s 267us/sample - loss: 0.2963 - accuracy: 0.9104\n",
      "133/133 [==============================] - 0s 271us/sample - loss: 0.3290 - accuracy: 0.8647\n",
      "125/125 [==============================] - 0s 246us/sample - loss: 0.3722 - accuracy: 0.8640\n",
      "124/124 [==============================] - 0s 272us/sample - loss: 0.2623 - accuracy: 0.9355\n",
      "122/122 [==============================] - 0s 242us/sample - loss: 0.2822 - accuracy: 0.9016\n",
      "119/119 [==============================] - 0s 254us/sample - loss: 0.3097 - accuracy: 0.9244\n",
      "117/117 [==============================] - 0s 247us/sample - loss: 0.2901 - accuracy: 0.9573\n",
      "116/116 [==============================] - 0s 242us/sample - loss: 0.3119 - accuracy: 0.9483\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2812 samples, validate on 729 samples\n",
      "Epoch 1/300\n",
      "2812/2812 [==============================] - 2s 837us/sample - loss: 0.6532 - accuracy: 0.6227 - val_loss: 0.6358 - val_accuracy: 0.6557\n",
      "Epoch 2/300\n",
      "2812/2812 [==============================] - 1s 237us/sample - loss: 0.6238 - accuracy: 0.6707 - val_loss: 0.6197 - val_accuracy: 0.6804\n",
      "Epoch 3/300\n",
      "2812/2812 [==============================] - 1s 243us/sample - loss: 0.6094 - accuracy: 0.6874 - val_loss: 0.6089 - val_accuracy: 0.6927\n",
      "Epoch 4/300\n",
      "2812/2812 [==============================] - 1s 221us/sample - loss: 0.5961 - accuracy: 0.7066 - val_loss: 0.6006 - val_accuracy: 0.7078\n",
      "Epoch 5/300\n",
      "2812/2812 [==============================] - 1s 257us/sample - loss: 0.5899 - accuracy: 0.7084 - val_loss: 0.5940 - val_accuracy: 0.7092\n",
      "Epoch 6/300\n",
      "2812/2812 [==============================] - 1s 246us/sample - loss: 0.5771 - accuracy: 0.7226 - val_loss: 0.5884 - val_accuracy: 0.7160\n",
      "Epoch 7/300\n",
      "2812/2812 [==============================] - 1s 198us/sample - loss: 0.5709 - accuracy: 0.7244 - val_loss: 0.5836 - val_accuracy: 0.7215\n",
      "Epoch 8/300\n",
      "2812/2812 [==============================] - 1s 253us/sample - loss: 0.5672 - accuracy: 0.7351 - val_loss: 0.5793 - val_accuracy: 0.7243\n",
      "Epoch 9/300\n",
      "2812/2812 [==============================] - 1s 230us/sample - loss: 0.5610 - accuracy: 0.7312 - val_loss: 0.5755 - val_accuracy: 0.7284\n",
      "Epoch 10/300\n",
      "2812/2812 [==============================] - 1s 219us/sample - loss: 0.5531 - accuracy: 0.7411 - val_loss: 0.5722 - val_accuracy: 0.7270\n",
      "Epoch 11/300\n",
      "2812/2812 [==============================] - 1s 195us/sample - loss: 0.5504 - accuracy: 0.7390 - val_loss: 0.5691 - val_accuracy: 0.7270\n",
      "Epoch 12/300\n",
      "2812/2812 [==============================] - 1s 216us/sample - loss: 0.5425 - accuracy: 0.7525 - val_loss: 0.5664 - val_accuracy: 0.7325\n",
      "Epoch 13/300\n",
      "2812/2812 [==============================] - 1s 229us/sample - loss: 0.5439 - accuracy: 0.7514 - val_loss: 0.5640 - val_accuracy: 0.7366\n",
      "Epoch 14/300\n",
      "2812/2812 [==============================] - 1s 229us/sample - loss: 0.5367 - accuracy: 0.7536 - val_loss: 0.5618 - val_accuracy: 0.7394\n",
      "Epoch 15/300\n",
      "2812/2812 [==============================] - 1s 218us/sample - loss: 0.5326 - accuracy: 0.7525 - val_loss: 0.5597 - val_accuracy: 0.7421\n",
      "Epoch 16/300\n",
      "2812/2812 [==============================] - 1s 240us/sample - loss: 0.5307 - accuracy: 0.7592 - val_loss: 0.5577 - val_accuracy: 0.7421\n",
      "Epoch 17/300\n",
      "2812/2812 [==============================] - 1s 192us/sample - loss: 0.5252 - accuracy: 0.7582 - val_loss: 0.5559 - val_accuracy: 0.7435\n",
      "Epoch 18/300\n",
      "2812/2812 [==============================] - 1s 221us/sample - loss: 0.5245 - accuracy: 0.7664 - val_loss: 0.5544 - val_accuracy: 0.7449\n",
      "Epoch 19/300\n",
      "2812/2812 [==============================] - 1s 247us/sample - loss: 0.5191 - accuracy: 0.7639 - val_loss: 0.5528 - val_accuracy: 0.7449\n",
      "Epoch 20/300\n",
      "2812/2812 [==============================] - 1s 232us/sample - loss: 0.5178 - accuracy: 0.7632 - val_loss: 0.5514 - val_accuracy: 0.7449\n",
      "Epoch 21/300\n",
      "2812/2812 [==============================] - 1s 253us/sample - loss: 0.5159 - accuracy: 0.7649 - val_loss: 0.5501 - val_accuracy: 0.7462\n",
      "Epoch 22/300\n",
      "2812/2812 [==============================] - 1s 246us/sample - loss: 0.5104 - accuracy: 0.7749 - val_loss: 0.5489 - val_accuracy: 0.7462\n",
      "Epoch 23/300\n",
      "2812/2812 [==============================] - 1s 223us/sample - loss: 0.5087 - accuracy: 0.7735 - val_loss: 0.5477 - val_accuracy: 0.7476\n",
      "Epoch 24/300\n",
      "2812/2812 [==============================] - 1s 260us/sample - loss: 0.5081 - accuracy: 0.7713 - val_loss: 0.5466 - val_accuracy: 0.7476\n",
      "Epoch 25/300\n",
      "2812/2812 [==============================] - 1s 269us/sample - loss: 0.5044 - accuracy: 0.7735 - val_loss: 0.5456 - val_accuracy: 0.7476\n",
      "Epoch 26/300\n",
      "2812/2812 [==============================] - 1s 211us/sample - loss: 0.5005 - accuracy: 0.7745 - val_loss: 0.5447 - val_accuracy: 0.7476\n",
      "Epoch 27/300\n",
      "2812/2812 [==============================] - 1s 264us/sample - loss: 0.5011 - accuracy: 0.7738 - val_loss: 0.5438 - val_accuracy: 0.7476\n",
      "Epoch 28/300\n",
      "2812/2812 [==============================] - 1s 279us/sample - loss: 0.4969 - accuracy: 0.7703 - val_loss: 0.5430 - val_accuracy: 0.7462\n",
      "Epoch 29/300\n",
      "2812/2812 [==============================] - 1s 234us/sample - loss: 0.4943 - accuracy: 0.7795 - val_loss: 0.5423 - val_accuracy: 0.7476\n",
      "Epoch 30/300\n",
      "2812/2812 [==============================] - 1s 244us/sample - loss: 0.4931 - accuracy: 0.7774 - val_loss: 0.5416 - val_accuracy: 0.7503\n",
      "Epoch 31/300\n",
      "2812/2812 [==============================] - 1s 225us/sample - loss: 0.4896 - accuracy: 0.7809 - val_loss: 0.5409 - val_accuracy: 0.7503\n",
      "Epoch 32/300\n",
      "2812/2812 [==============================] - 1s 243us/sample - loss: 0.4867 - accuracy: 0.7838 - val_loss: 0.5403 - val_accuracy: 0.7517\n",
      "Epoch 33/300\n",
      "2812/2812 [==============================] - 1s 248us/sample - loss: 0.4893 - accuracy: 0.7767 - val_loss: 0.5397 - val_accuracy: 0.7517\n",
      "Epoch 34/300\n",
      "2812/2812 [==============================] - 1s 249us/sample - loss: 0.4844 - accuracy: 0.7774 - val_loss: 0.5392 - val_accuracy: 0.7517\n",
      "Epoch 35/300\n",
      "2812/2812 [==============================] - 1s 194us/sample - loss: 0.4805 - accuracy: 0.7845 - val_loss: 0.5386 - val_accuracy: 0.7545\n",
      "Epoch 36/300\n",
      "2812/2812 [==============================] - 1s 216us/sample - loss: 0.4800 - accuracy: 0.7859 - val_loss: 0.5382 - val_accuracy: 0.7558\n",
      "Epoch 37/300\n",
      "2812/2812 [==============================] - 1s 228us/sample - loss: 0.4797 - accuracy: 0.7859 - val_loss: 0.5377 - val_accuracy: 0.7572\n",
      "Epoch 38/300\n",
      "2812/2812 [==============================] - 1s 213us/sample - loss: 0.4771 - accuracy: 0.7827 - val_loss: 0.5372 - val_accuracy: 0.7572\n",
      "Epoch 39/300\n",
      "2812/2812 [==============================] - 1s 227us/sample - loss: 0.4734 - accuracy: 0.7898 - val_loss: 0.5369 - val_accuracy: 0.7586\n",
      "Epoch 40/300\n",
      "2812/2812 [==============================] - 1s 230us/sample - loss: 0.4750 - accuracy: 0.7849 - val_loss: 0.5365 - val_accuracy: 0.7586\n",
      "Epoch 41/300\n",
      "2812/2812 [==============================] - 1s 214us/sample - loss: 0.4668 - accuracy: 0.7888 - val_loss: 0.5362 - val_accuracy: 0.7586\n",
      "Epoch 42/300\n",
      "2812/2812 [==============================] - 1s 244us/sample - loss: 0.4700 - accuracy: 0.7898 - val_loss: 0.5359 - val_accuracy: 0.7599\n",
      "Epoch 43/300\n",
      "2812/2812 [==============================] - 1s 255us/sample - loss: 0.4664 - accuracy: 0.7866 - val_loss: 0.5356 - val_accuracy: 0.7599\n",
      "Epoch 44/300\n",
      "2812/2812 [==============================] - 1s 230us/sample - loss: 0.4651 - accuracy: 0.7920 - val_loss: 0.5353 - val_accuracy: 0.7627\n",
      "Epoch 45/300\n",
      "2812/2812 [==============================] - 1s 238us/sample - loss: 0.4622 - accuracy: 0.7902 - val_loss: 0.5350 - val_accuracy: 0.7627\n",
      "Epoch 46/300\n",
      "2812/2812 [==============================] - 1s 219us/sample - loss: 0.4645 - accuracy: 0.7877 - val_loss: 0.5348 - val_accuracy: 0.7627\n",
      "Epoch 47/300\n",
      "2812/2812 [==============================] - 1s 219us/sample - loss: 0.4605 - accuracy: 0.7930 - val_loss: 0.5345 - val_accuracy: 0.7613\n",
      "Epoch 48/300\n",
      "2812/2812 [==============================] - 1s 230us/sample - loss: 0.4576 - accuracy: 0.7955 - val_loss: 0.5344 - val_accuracy: 0.7613\n",
      "Epoch 49/300\n",
      "2812/2812 [==============================] - 1s 222us/sample - loss: 0.4531 - accuracy: 0.7980 - val_loss: 0.5341 - val_accuracy: 0.7613\n",
      "Epoch 50/300\n",
      "2812/2812 [==============================] - 1s 247us/sample - loss: 0.4528 - accuracy: 0.7905 - val_loss: 0.5340 - val_accuracy: 0.7613\n",
      "Epoch 51/300\n",
      "2812/2812 [==============================] - 1s 247us/sample - loss: 0.4546 - accuracy: 0.7913 - val_loss: 0.5339 - val_accuracy: 0.7613\n",
      "Epoch 52/300\n",
      "2812/2812 [==============================] - 1s 254us/sample - loss: 0.4503 - accuracy: 0.8009 - val_loss: 0.5337 - val_accuracy: 0.7641\n",
      "Epoch 53/300\n",
      "2812/2812 [==============================] - 1s 212us/sample - loss: 0.4463 - accuracy: 0.8012 - val_loss: 0.5336 - val_accuracy: 0.7641\n",
      "Epoch 54/300\n",
      "2812/2812 [==============================] - 1s 236us/sample - loss: 0.4461 - accuracy: 0.8009 - val_loss: 0.5335 - val_accuracy: 0.7627\n",
      "Epoch 55/300\n",
      "2812/2812 [==============================] - 1s 235us/sample - loss: 0.4483 - accuracy: 0.7962 - val_loss: 0.5334 - val_accuracy: 0.7627\n",
      "Epoch 56/300\n",
      "2812/2812 [==============================] - 1s 260us/sample - loss: 0.4414 - accuracy: 0.8051 - val_loss: 0.5334 - val_accuracy: 0.7627\n",
      "Epoch 57/300\n",
      "2812/2812 [==============================] - 1s 251us/sample - loss: 0.4422 - accuracy: 0.8055 - val_loss: 0.5333 - val_accuracy: 0.7627\n",
      "Epoch 58/300\n",
      "2812/2812 [==============================] - 1s 228us/sample - loss: 0.4393 - accuracy: 0.8001 - val_loss: 0.5333 - val_accuracy: 0.7613\n",
      "Epoch 59/300\n",
      "2812/2812 [==============================] - 1s 227us/sample - loss: 0.4388 - accuracy: 0.8055 - val_loss: 0.5333 - val_accuracy: 0.7599\n",
      "Epoch 60/300\n",
      "2812/2812 [==============================] - 1s 220us/sample - loss: 0.4385 - accuracy: 0.8048 - val_loss: 0.5333 - val_accuracy: 0.7599\n",
      "Epoch 61/300\n",
      "2812/2812 [==============================] - 1s 240us/sample - loss: 0.4332 - accuracy: 0.8069 - val_loss: 0.5333 - val_accuracy: 0.7613\n",
      "Epoch 62/300\n",
      "2812/2812 [==============================] - 1s 251us/sample - loss: 0.4304 - accuracy: 0.8087 - val_loss: 0.5333 - val_accuracy: 0.7627\n",
      "Epoch 00062: early stopping\n",
      "108/108 [==============================] - 0s 125us/sample - loss: 0.2611 - accuracy: 0.9907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [7:07:42, 1062.31s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.62s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.41s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 828.078125 steps, validate for 214.0703125 steps\n",
      "Epoch 1/300\n",
      "829/828 [==============================] - 24s 30ms/step - loss: 0.5716 - accuracy: 0.7325 - val_loss: 0.5402 - val_accuracy: 0.7712\n",
      "Epoch 2/300\n",
      "829/828 [==============================] - 23s 28ms/step - loss: 0.5210 - accuracy: 0.7716 - val_loss: 0.5325 - val_accuracy: 0.7711\n",
      "Epoch 3/300\n",
      "829/828 [==============================] - 24s 29ms/step - loss: 0.5063 - accuracy: 0.7761 - val_loss: 0.5284 - val_accuracy: 0.7705\n",
      "Epoch 4/300\n",
      "829/828 [==============================] - 24s 29ms/step - loss: 0.4951 - accuracy: 0.7805 - val_loss: 0.5295 - val_accuracy: 0.7688\n",
      "Epoch 5/300\n",
      "829/828 [==============================] - 24s 29ms/step - loss: 0.4857 - accuracy: 0.7837 - val_loss: 0.5302 - val_accuracy: 0.7669\n",
      "Epoch 6/300\n",
      "829/828 [==============================] - 24s 29ms/step - loss: 0.4770 - accuracy: 0.7877 - val_loss: 0.5355 - val_accuracy: 0.7645\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 828.078125 steps, validate for 214.0703125 steps\n",
      "Epoch 1/300\n",
      "829/828 [==============================] - 55s 66ms/step - loss: 0.4612 - accuracy: 0.7947 - val_loss: 0.5399 - val_accuracy: 0.7588\n",
      "Epoch 2/300\n",
      "829/828 [==============================] - 54s 65ms/step - loss: 0.4355 - accuracy: 0.8074 - val_loss: 0.5379 - val_accuracy: 0.7588\n",
      "Epoch 3/300\n",
      "829/828 [==============================] - 54s 65ms/step - loss: 0.4138 - accuracy: 0.8188 - val_loss: 0.5309 - val_accuracy: 0.7619\n",
      "Epoch 4/300\n",
      "829/828 [==============================] - 53s 64ms/step - loss: 0.3941 - accuracy: 0.8295 - val_loss: 0.5661 - val_accuracy: 0.7453\n",
      "Epoch 5/300\n",
      "829/828 [==============================] - 53s 64ms/step - loss: 0.3758 - accuracy: 0.8403 - val_loss: 0.5715 - val_accuracy: 0.7364\n",
      "Epoch 6/300\n",
      "829/828 [==============================] - 54s 65ms/step - loss: 0.3579 - accuracy: 0.8502 - val_loss: 0.5672 - val_accuracy: 0.7579\n",
      "Epoch 00006: early stopping\n",
      "148/148 [==============================] - 0s 1ms/sample - loss: 0.2267 - accuracy: 0.9459\n",
      "147/147 [==============================] - 0s 231us/sample - loss: 0.2361 - accuracy: 0.9252\n",
      "146/146 [==============================] - 0s 288us/sample - loss: 0.2395 - accuracy: 0.9452\n",
      "144/144 [==============================] - 0s 219us/sample - loss: 0.2331 - accuracy: 0.9583\n",
      "144/144 [==============================] - 0s 230us/sample - loss: 0.2471 - accuracy: 0.9306\n",
      "140/140 [==============================] - 0s 241us/sample - loss: 0.2452 - accuracy: 0.9571\n",
      "139/139 [==============================] - 0s 223us/sample - loss: 0.2993 - accuracy: 0.9137\n",
      "138/138 [==============================] - 0s 266us/sample - loss: 0.2524 - accuracy: 0.9203\n",
      "135/135 [==============================] - 0s 250us/sample - loss: 0.2753 - accuracy: 0.9185\n",
      "135/135 [==============================] - 0s 280us/sample - loss: 0.2586 - accuracy: 0.9333\n",
      "135/135 [==============================] - 0s 283us/sample - loss: 0.2349 - accuracy: 0.9333\n",
      "132/132 [==============================] - 0s 257us/sample - loss: 0.2759 - accuracy: 0.9167\n",
      "132/132 [==============================] - 0s 325us/sample - loss: 0.2697 - accuracy: 0.9394\n",
      "131/131 [==============================] - 0s 267us/sample - loss: 0.2420 - accuracy: 0.9466\n",
      "130/130 [==============================] - 0s 280us/sample - loss: 0.2247 - accuracy: 0.9615\n",
      "131/131 [==============================] - 0s 305us/sample - loss: 0.2455 - accuracy: 0.9389\n",
      "130/130 [==============================] - 0s 283us/sample - loss: 0.2491 - accuracy: 0.9000\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 0.2425 - accuracy: 0.9688\n",
      "130/130 [==============================] - 0s 260us/sample - loss: 0.2506 - accuracy: 0.9462\n",
      "130/130 [==============================] - 0s 286us/sample - loss: 0.2347 - accuracy: 0.9462\n",
      "131/131 [==============================] - 0s 244us/sample - loss: 0.2785 - accuracy: 0.9237\n",
      "131/131 [==============================] - 0s 255us/sample - loss: 0.2592 - accuracy: 0.9466\n",
      "131/131 [==============================] - 0s 254us/sample - loss: 0.2543 - accuracy: 0.9389\n",
      "130/130 [==============================] - 0s 266us/sample - loss: 0.2442 - accuracy: 0.9154\n",
      "129/129 [==============================] - 0s 238us/sample - loss: 0.2406 - accuracy: 0.9457\n",
      "128/128 [==============================] - 0s 212us/sample - loss: 0.2504 - accuracy: 0.9141\n",
      "129/129 [==============================] - 0s 274us/sample - loss: 0.2324 - accuracy: 0.9302\n",
      "127/127 [==============================] - 0s 236us/sample - loss: 0.2397 - accuracy: 0.9370\n",
      "128/128 [==============================] - 0s 245us/sample - loss: 0.2222 - accuracy: 0.9453\n",
      "126/126 [==============================] - 0s 244us/sample - loss: 0.1893 - accuracy: 0.9683\n",
      "124/124 [==============================] - 0s 253us/sample - loss: 0.2570 - accuracy: 0.9113\n",
      "122/122 [==============================] - 0s 234us/sample - loss: 0.2794 - accuracy: 0.9426\n",
      "122/122 [==============================] - 0s 229us/sample - loss: 0.2156 - accuracy: 0.9426\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 2809 samples, validate on 724 samples\n",
      "Epoch 1/300\n",
      "2809/2809 [==============================] - 3s 913us/sample - loss: 0.7538 - accuracy: 0.4521 - val_loss: 0.6961 - val_accuracy: 0.5138\n",
      "Epoch 2/300\n",
      "2809/2809 [==============================] - 1s 252us/sample - loss: 0.7070 - accuracy: 0.5219 - val_loss: 0.6703 - val_accuracy: 0.5760\n",
      "Epoch 3/300\n",
      "2809/2809 [==============================] - 1s 244us/sample - loss: 0.6819 - accuracy: 0.5685 - val_loss: 0.6522 - val_accuracy: 0.6257\n",
      "Epoch 4/300\n",
      "2809/2809 [==============================] - 1s 246us/sample - loss: 0.6551 - accuracy: 0.6255 - val_loss: 0.6379 - val_accuracy: 0.6602\n",
      "Epoch 5/300\n",
      "2809/2809 [==============================] - 1s 261us/sample - loss: 0.6425 - accuracy: 0.6554 - val_loss: 0.6262 - val_accuracy: 0.6754\n",
      "Epoch 6/300\n",
      "2809/2809 [==============================] - 1s 260us/sample - loss: 0.6284 - accuracy: 0.6750 - val_loss: 0.6163 - val_accuracy: 0.6878\n",
      "Epoch 7/300\n",
      "2809/2809 [==============================] - 1s 256us/sample - loss: 0.6127 - accuracy: 0.7059 - val_loss: 0.6074 - val_accuracy: 0.7030\n",
      "Epoch 8/300\n",
      "2809/2809 [==============================] - 1s 244us/sample - loss: 0.6017 - accuracy: 0.7198 - val_loss: 0.6000 - val_accuracy: 0.7127\n",
      "Epoch 9/300\n",
      "2809/2809 [==============================] - 1s 221us/sample - loss: 0.5895 - accuracy: 0.7277 - val_loss: 0.5933 - val_accuracy: 0.7265\n",
      "Epoch 10/300\n",
      "2809/2809 [==============================] - 1s 212us/sample - loss: 0.5865 - accuracy: 0.7245 - val_loss: 0.5871 - val_accuracy: 0.7334\n",
      "Epoch 11/300\n",
      "2809/2809 [==============================] - 1s 231us/sample - loss: 0.5729 - accuracy: 0.7522 - val_loss: 0.5815 - val_accuracy: 0.7403\n",
      "Epoch 12/300\n",
      "2809/2809 [==============================] - 1s 220us/sample - loss: 0.5687 - accuracy: 0.7554 - val_loss: 0.5765 - val_accuracy: 0.7417\n",
      "Epoch 13/300\n",
      "2809/2809 [==============================] - 1s 200us/sample - loss: 0.5588 - accuracy: 0.7547 - val_loss: 0.5720 - val_accuracy: 0.7459\n",
      "Epoch 14/300\n",
      "2809/2809 [==============================] - 1s 232us/sample - loss: 0.5506 - accuracy: 0.7643 - val_loss: 0.5677 - val_accuracy: 0.7514\n",
      "Epoch 15/300\n",
      "2809/2809 [==============================] - 1s 206us/sample - loss: 0.5467 - accuracy: 0.7622 - val_loss: 0.5639 - val_accuracy: 0.7541\n",
      "Epoch 16/300\n",
      "2809/2809 [==============================] - 1s 245us/sample - loss: 0.5363 - accuracy: 0.7682 - val_loss: 0.5604 - val_accuracy: 0.7528\n",
      "Epoch 17/300\n",
      "2809/2809 [==============================] - 1s 273us/sample - loss: 0.5296 - accuracy: 0.7707 - val_loss: 0.5573 - val_accuracy: 0.7528\n",
      "Epoch 18/300\n",
      "2809/2809 [==============================] - 1s 257us/sample - loss: 0.5243 - accuracy: 0.7771 - val_loss: 0.5544 - val_accuracy: 0.7528\n",
      "Epoch 19/300\n",
      "2809/2809 [==============================] - 1s 247us/sample - loss: 0.5179 - accuracy: 0.7779 - val_loss: 0.5518 - val_accuracy: 0.7528\n",
      "Epoch 20/300\n",
      "2809/2809 [==============================] - 1s 265us/sample - loss: 0.5165 - accuracy: 0.7782 - val_loss: 0.5493 - val_accuracy: 0.7514\n",
      "Epoch 21/300\n",
      "2809/2809 [==============================] - 1s 241us/sample - loss: 0.5098 - accuracy: 0.7761 - val_loss: 0.5471 - val_accuracy: 0.7514\n",
      "Epoch 22/300\n",
      "2809/2809 [==============================] - 1s 267us/sample - loss: 0.4998 - accuracy: 0.7832 - val_loss: 0.5451 - val_accuracy: 0.7514\n",
      "Epoch 23/300\n",
      "2809/2809 [==============================] - 1s 254us/sample - loss: 0.5015 - accuracy: 0.7853 - val_loss: 0.5434 - val_accuracy: 0.7514\n",
      "Epoch 24/300\n",
      "2809/2809 [==============================] - 1s 246us/sample - loss: 0.4937 - accuracy: 0.7850 - val_loss: 0.5418 - val_accuracy: 0.7514\n",
      "Epoch 25/300\n",
      "2809/2809 [==============================] - 1s 229us/sample - loss: 0.4889 - accuracy: 0.7882 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
      "Epoch 26/300\n",
      "2809/2809 [==============================] - 1s 262us/sample - loss: 0.4861 - accuracy: 0.7875 - val_loss: 0.5389 - val_accuracy: 0.7514\n",
      "Epoch 27/300\n",
      "2809/2809 [==============================] - 1s 239us/sample - loss: 0.4795 - accuracy: 0.7889 - val_loss: 0.5378 - val_accuracy: 0.7514\n",
      "Epoch 28/300\n",
      "2809/2809 [==============================] - 1s 206us/sample - loss: 0.4764 - accuracy: 0.7885 - val_loss: 0.5367 - val_accuracy: 0.7541\n",
      "Epoch 29/300\n",
      "2809/2809 [==============================] - 1s 236us/sample - loss: 0.4759 - accuracy: 0.7882 - val_loss: 0.5358 - val_accuracy: 0.7555\n",
      "Epoch 30/300\n",
      "2809/2809 [==============================] - 1s 216us/sample - loss: 0.4679 - accuracy: 0.7928 - val_loss: 0.5349 - val_accuracy: 0.7555\n",
      "Epoch 31/300\n",
      "2809/2809 [==============================] - 1s 209us/sample - loss: 0.4655 - accuracy: 0.7953 - val_loss: 0.5342 - val_accuracy: 0.7555\n",
      "Epoch 32/300\n",
      "2809/2809 [==============================] - 1s 192us/sample - loss: 0.4599 - accuracy: 0.7949 - val_loss: 0.5337 - val_accuracy: 0.7555\n",
      "Epoch 33/300\n",
      "2809/2809 [==============================] - 1s 190us/sample - loss: 0.4595 - accuracy: 0.7971 - val_loss: 0.5332 - val_accuracy: 0.7555\n",
      "Epoch 34/300\n",
      "2809/2809 [==============================] - 1s 241us/sample - loss: 0.4573 - accuracy: 0.7953 - val_loss: 0.5327 - val_accuracy: 0.7555\n",
      "Epoch 35/300\n",
      "2809/2809 [==============================] - 1s 252us/sample - loss: 0.4528 - accuracy: 0.7971 - val_loss: 0.5324 - val_accuracy: 0.7569\n",
      "Epoch 36/300\n",
      "2809/2809 [==============================] - 1s 220us/sample - loss: 0.4474 - accuracy: 0.7996 - val_loss: 0.5322 - val_accuracy: 0.7569\n",
      "Epoch 37/300\n",
      "2809/2809 [==============================] - 1s 230us/sample - loss: 0.4491 - accuracy: 0.8028 - val_loss: 0.5320 - val_accuracy: 0.7569\n",
      "Epoch 38/300\n",
      "2809/2809 [==============================] - 1s 215us/sample - loss: 0.4388 - accuracy: 0.8085 - val_loss: 0.5319 - val_accuracy: 0.7583\n",
      "Epoch 39/300\n",
      "2809/2809 [==============================] - 1s 251us/sample - loss: 0.4397 - accuracy: 0.8053 - val_loss: 0.5318 - val_accuracy: 0.7569\n",
      "Epoch 40/300\n",
      "2809/2809 [==============================] - 1s 251us/sample - loss: 0.4332 - accuracy: 0.8067 - val_loss: 0.5318 - val_accuracy: 0.7555\n",
      "Epoch 41/300\n",
      "2809/2809 [==============================] - 1s 251us/sample - loss: 0.4348 - accuracy: 0.8099 - val_loss: 0.5319 - val_accuracy: 0.7569\n",
      "Epoch 42/300\n",
      "2809/2809 [==============================] - 1s 279us/sample - loss: 0.4295 - accuracy: 0.8060 - val_loss: 0.5319 - val_accuracy: 0.7569\n",
      "Epoch 00042: early stopping\n",
      "116/116 [==============================] - 0s 129us/sample - loss: 0.2237 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [7:26:50, 1072.43s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for num_ix, rand_num in enumerate(rand):\n",
    "    for index_t_well, _ in tqdm.tqdm(enumerate(tot_well)):\n",
    "\n",
    "        time_points = list(map(str, range(1,34)))\n",
    "\n",
    "        new_time = []\n",
    "        for i in time_points:\n",
    "            r = '_' + i + '.'\n",
    "            new_time.append(r)\n",
    "\n",
    "\n",
    "\n",
    "        path_test = '/home/jovyan/DATA_MASTER_PROJECT/IMG_A549_high_con/{}_cropped/'.format(a)\n",
    "\n",
    "        # NAME OF THE WELLS CORRESPONDING TO THE DRUG THAT YOU WANT IN THE TEST SET \n",
    "\n",
    "        wells_drug = [tot_well[index_t_well][0]] \n",
    "\n",
    "        test = []\n",
    "\n",
    "        for _,_, filenames in os.walk(path_test):\n",
    "\n",
    "            for filename in sorted(filenames, key = natural_keys):\n",
    "\n",
    "                for w in wells_drug:\n",
    "                    for t in new_time:\n",
    "                        if '{}'.format(w) in filename and '{}tiff'.format(t) in filename:\n",
    "                            test.append(filename)\n",
    "\n",
    "        groups_list = ['{}'.format(a), '{}'.format(b)]\n",
    "\n",
    "        fileds_of_view = ['1','2','3','4','5']\n",
    "\n",
    "        field_train, field_val = train_test_split(fileds_of_view, test_size=0.2, random_state=rand_num)\n",
    "\n",
    "\n",
    "        train = []\n",
    "\n",
    "        validation = []\n",
    "\n",
    "        group_compounds = []\n",
    "\n",
    "        for group in tqdm.tqdm(groups_list):\n",
    "\n",
    "            pa = '/home/jovyan/DATA_MASTER_PROJECT/IMG_A549_high_con/{}_cropped/'.format(group)\n",
    "\n",
    "            for _,_, filenames in os.walk(pa):\n",
    "\n",
    "                for filename in sorted(filenames, key = natural_keys):\n",
    "\n",
    "                    for t in new_time:\n",
    "\n",
    "                        if '_{}-'.format(wells_drug[0]) not in filename  and '{}tiff'.format(t) in filename:\n",
    "\n",
    "                            group_compounds.append(filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for i in group_compounds:\n",
    "\n",
    "            for f in field_train:\n",
    "                if '-{}_'.format(f) in i:\n",
    "                    train.append(i)\n",
    "\n",
    "\n",
    "            for v in field_val:\n",
    "                if '-{}_'.format(v) in i:\n",
    "                    validation.append(i)\n",
    "\n",
    "\n",
    "        x_train = loadImages(train)\n",
    "        y_train = make_labels(train)\n",
    "\n",
    "\n",
    "\n",
    "        x_val = loadImages(validation)\n",
    "        y_val = make_labels(validation)\n",
    "\n",
    "\n",
    "\n",
    "        x_train = resize(x_train)\n",
    "\n",
    "\n",
    "        x_val = resize(x_val)\n",
    "\n",
    "\n",
    "        weights = class_weight.compute_class_weight('balanced', np.unique(y_train),y_train)\n",
    "\n",
    "\n",
    "        x_train = preprocess_input(x_train)\n",
    "\n",
    "        x_val = preprocess_input(x_val)\n",
    "\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=3)\n",
    "\n",
    "        pretrained_model = VGG16(weights='imagenet',include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "        base_model = Model(inputs=pretrained_model.input, outputs=pretrained_model.get_layer('block3_pool').output)\n",
    "\n",
    "        batch_size = 128\n",
    "\n",
    "        datagen = ImageDataGenerator()\n",
    "\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "        train_gen = datagen.flow(x_train, y_train,batch_size=batch_size )\n",
    "\n",
    "        dat_val = ImageDataGenerator()\n",
    "\n",
    "        dat_val.fit(x_val)\n",
    "\n",
    "        val_gen = dat_val.flow(x_val, y_val,batch_size=batch_size)\n",
    "\n",
    "        m4 = Sequential()\n",
    "        m4.add(base_model)\n",
    "\n",
    "\n",
    "        m4.add(BatchNormalization())\n",
    "        m4.add(GlobalAveragePooling2D())\n",
    "        m4.add(Dense(64, activation='relu'))\n",
    "        m4.add(BatchNormalization())\n",
    "        m4.add(Activation('relu'))\n",
    "        m4.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "        base_model.trainable = False\n",
    "\n",
    "        opt = keras.optimizers.Adam(lr=1e-4)\n",
    "\n",
    "        m4.compile(loss= keras.losses.binary_crossentropy, optimizer=opt, metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "        epochs = 300\n",
    "\n",
    "        m4_h = m4.fit(train_gen,\n",
    "                        steps_per_epoch=(len(x_train)/batch_size),\n",
    "                        callbacks = [es],\n",
    "                        epochs=epochs,\n",
    "                        validation_data = (val_gen), \n",
    "                        validation_steps = (len(x_val)/batch_size),\n",
    "                        class_weight = weights,\n",
    "                         verbose = 1)\n",
    "\n",
    "        base_model.trainable = True\n",
    "\n",
    "        opt = keras.optimizers.Adam(lr=1e-5)\n",
    "\n",
    "        m4.compile(loss= keras.losses.binary_crossentropy, optimizer=opt, metrics = ['accuracy'])\n",
    "\n",
    "        epochs = 300\n",
    "\n",
    "        m4_h = m4.fit(train_gen,\n",
    "                        steps_per_epoch=(len(x_train)//batch_size),\n",
    "                        callbacks = [es],\n",
    "                        epochs=epochs,\n",
    "                        validation_data = val_gen, \n",
    "                        validation_steps = (len(x_val)//batch_size),\n",
    "                        class_weight = weights,\n",
    "                        verbose = 1)\n",
    "\n",
    "        l = []\n",
    "        for t in new_time:\n",
    "            for i in test:\n",
    "                if t in i:\n",
    "                    l.append((i))\n",
    "\n",
    "\n",
    "        grouped = {}\n",
    "        for elem in l:\n",
    "            key = elem.split('.tiff')[0].split('_')[5]\n",
    "            grouped.setdefault(key, []).append(elem)\n",
    "        grouped = grouped.values()\n",
    "\n",
    "        test_data = list(grouped)\n",
    "\n",
    "        r = []\n",
    "\n",
    "        for ix ,_ in enumerate(test_data):\n",
    "            r.append(time_step_acc(test_data[ix],m4))\n",
    "\n",
    "        plt.plot(time_points,r)\n",
    "        plt.savefig('/home/jovyan/IMG_CNN_FINAL/{}_accuracy.png'.format(string_well[index_t_well]))\n",
    "\n",
    "        tot_results_accuracy.append(r)\n",
    "        \n",
    "        for i, layer in enumerate(m4.layers):\n",
    "            layer._name = 'layer_' + str(i)\n",
    "\n",
    "\n",
    "\n",
    "        lstm_model = Model(inputs=m4.input, outputs=m4.get_layer('layer_4').output)\n",
    "\n",
    "        del m4\n",
    "        K.clear_session()\n",
    "        \n",
    "        data_name = [train,test,validation]\n",
    "\n",
    "        feat_name = ['train', 'test', 'validation']\n",
    "\n",
    "        for index_name, _ in enumerate(data_name):\n",
    "\n",
    "            path =  data_name[index_name]\n",
    "\n",
    "            name_well = []\n",
    "\n",
    "            for i in path:\n",
    "                name_well.append(i.split('_id')[0])\n",
    "\n",
    "            wells = list(set(name_well))\n",
    "            wells\n",
    "\n",
    "            for w in wells:\n",
    "\n",
    "                time = []\n",
    "\n",
    "\n",
    "                for filename in sorted(path, key = natural_keys):\n",
    "                    if w in filename: #PAY ATTENTION ID THE IMAGE IS A TIFF OR PNG IMAGE #########\n",
    "                        time.append(filename)\n",
    "\n",
    "                data_id = {}\n",
    "                n_id = []\n",
    "                w_n = []\n",
    "\n",
    "                for i in time:\n",
    "                    t = i.split('_id_')[1].split('time_')[0]\n",
    "                    f = i.split('_id_')[0].split('time_')[0]\n",
    "                    n_id.append(t)\n",
    "                    w_n.append(f)\n",
    "\n",
    "                id_cell = set(n_id)\n",
    "\n",
    "\n",
    "                for ix, i in enumerate(sorted(id_cell, key = natural_keys)):\n",
    "\n",
    "                    id_name = []\n",
    "                    dict_1 = {}\n",
    "\n",
    "                    for t in time:\n",
    "                        if 'id_{}'.format(i) in t:\n",
    "                            id_name.append(t)\n",
    "\n",
    "                    d = {'id':id_name}\n",
    "                    data = pd.DataFrame(d)\n",
    "\n",
    "                    dict_1[ix]=data \n",
    "                    data_id.update(dict_1) \n",
    "\n",
    "                delete = [i for i, j in data_id.items() if len(j) < len(time_points)] # 9 or the length of time span you are traning on \n",
    "                for i in delete : del data_id[i]\n",
    "\n",
    "                len_id = [i for i, j in data_id.items()]\n",
    "\n",
    "                for le in len_id:    \n",
    "\n",
    "\n",
    "                    e = pd.DataFrame(data_id[le])\n",
    "\n",
    "                    coords = e.values.tolist()\n",
    "                    id_cells = []\n",
    "                    for i in coords:\n",
    "                        for j in i:\n",
    "                            id_cells.append(j)\n",
    "\n",
    "                    x_orig = loadImages(id_cells)\n",
    "                    x_orig = resize(x_orig)\n",
    "\n",
    "                    x_orig = preprocess_input(x_orig)\n",
    "                    output = lstm_model.predict(x_orig)\n",
    "                    np.save('/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/features_{}/features_well_{}_id_{}.npy'.format(feat_name[index_name],w_n[0], le), output)\n",
    "            print('Saved_feature_{}'.format(feat_name[index_name]))\n",
    "\n",
    "\n",
    "        x_train_lstm = loadImages_LSTM(train_data, len(time_points))\n",
    "        y_train_lstm = make_labels_LSTM(y_tra_path)\n",
    "\n",
    "        x_test_lstm = loadImages_LSTM(tes_data, len(time_points))\n",
    "        y_test_lstm = make_labels_LSTM(y_tes_path)\n",
    "\n",
    "        x_val_lstm = loadImages_LSTM(val_data, len(time_points))\n",
    "        y_val_lstm = make_labels_LSTM(y_val_path)\n",
    "\n",
    "        weights_lstm = class_weight.compute_class_weight('balanced', np.unique(y_train_lstm),y_train_lstm)\n",
    "\n",
    "\n",
    "        m = Sequential()\n",
    "        m.add(LSTM(32, input_shape = (x_train_lstm.shape[1],x_train_lstm.shape[2])))\n",
    "        m.add(Dropout(0.2))\n",
    "        m.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "        opt_lstm = keras.optimizers.Adam(lr=1e-4)\n",
    "\n",
    "        m.compile(loss= keras.losses.binary_crossentropy, optimizer=opt, metrics = ['accuracy'])\n",
    "\n",
    "        epochs = 300\n",
    "\n",
    "        m_h = m.fit(x_train_lstm,y_train_lstm,\n",
    "\n",
    "                         callbacks = [es],\n",
    "\n",
    "                        epochs=epochs,\n",
    "                        validation_data = (x_val_lstm,y_val_lstm), \n",
    "\n",
    "                        class_weight = weights_lstm)\n",
    "\n",
    "\n",
    "        scores_lstm = m.evaluate(x_test_lstm, y_test_lstm)\n",
    "        results_lstm.append([scores_lstm[1]*100, string_well[index_t_well]])\n",
    "        \n",
    "        del m\n",
    "        K.clear_session()\n",
    "\n",
    "        # DELITE FILES IN FEATURE VECTOR FOLDERS\n",
    "\n",
    "        folders = glob.glob('/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/*')\n",
    "\n",
    "        for fo in folders:\n",
    "            file = glob.glob(f'{fo}/*')\n",
    "            for f in file:\n",
    "                os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(95.04924940340447, 'cycl'),\n",
       " (89.62355448742106, 'dime'),\n",
       " (95.5286275858831, 'cypr'),\n",
       " (90.8554266197513, 'lora'),\n",
       " (84.20340485042995, 'doxy'),\n",
       " (91.85233393100778, 'oloa'),\n",
       " (93.15799173682626, 'cinn'),\n",
       " (64.99575617337467, 'desl'),\n",
       " (96.24469244118893, 'chlo'),\n",
       " (90.04172538266037, 'trim'),\n",
       " (93.96070651333741, 'mian'),\n",
       " (77.97825523097106, 'fexo'),\n",
       " (89.64984651767845, 'chlo_1'),\n",
       " (89.36665684285789, 'trip'),\n",
       " (93.49249486971382, 'desi'),\n",
       " (92.89312964738018, 'levo'),\n",
       " (94.97252455865494, 'diphe_1'),\n",
       " (92.89522243268561, 'diphe_2'),\n",
       " (91.69814701032158, 'emed'),\n",
       " (95.79613967375322, 'ceti'),\n",
       " (93.46572106534784, 'trip_1'),\n",
       " (82.91941459732827, 'doxe'),\n",
       " (94.72051985336073, 'chlo_2'),\n",
       " (90.25067283649638, 'flun'),\n",
       " (92.31223060627177, 'keto')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ACCURACY SCORE AVERAGE FOR CNN\n",
    "cv_s = cv_mean_acc(tot_results_accuracy, string_well)\n",
    "cv_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.31697779472428"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_s_mean,_ = zip(*cv_s)\n",
    "\n",
    "m_cv = np.mean(list(cv_s_mean))\n",
    "m_cv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT OF MEAN ACCURACY FOR EVERY TIME POINT CNN\n",
    "\n",
    "l_drug = string_well*3\n",
    "\n",
    "acc_plot = []\n",
    "\n",
    "for i in tot_results_accuracy:\n",
    "    acc_plot.append(i)\n",
    "\n",
    "cv_plot = list(zip(acc_plot, l_drug))\n",
    "\n",
    "res_plot = sorted(cv_plot, key = lambda x: x[1])\n",
    "\n",
    "a , b = zip(*res_plot)\n",
    "    \n",
    "a = list(a)\n",
    "\n",
    "s = list(np.array_split(a, len(string_well)))\n",
    "\n",
    "cv_plot = []\n",
    "\n",
    "for ix, i in enumerate(s):\n",
    "    s1 = list(s[ix])\n",
    "    \n",
    "    cv_plot.append(np.average(s1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i in cv_plot:\n",
    "    \n",
    "    plt.plot(time_points, i)\n",
    "    plt.show\n",
    "    plt.savefig('/home/jovyan/IMG_CNN_FINAL/cv_score.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lstm = sorted(results_lstm, key=lambda x: x[1])\n",
    "r_lstm , _ = zip(*results_lstm)\n",
    "    \n",
    "r_lstm = list(r_lstm)\n",
    "\n",
    "re_lstm = list(np.array_split(r_lstm, len(string_well)))\n",
    "\n",
    "cv_lstm = []\n",
    "\n",
    "for ix, i in enumerate(re_lstm):\n",
    "    r1 = list(re_lstm[ix])\n",
    "    cv_lstm.append(np.mean(r1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(98.21428656578064, 'cycl'),\n",
       " (97.95918464660645, 'dime'),\n",
       " (96.96969588597615, 'cypr'),\n",
       " (93.27731132507324, 'lora'),\n",
       " (96.66666388511658, 'doxy'),\n",
       " (94.3396230538686, 'oloa'),\n",
       " (99.00497595469157, 'cinn'),\n",
       " (65.59139887491862, 'desl'),\n",
       " (96.1685836315155, 'chlo'),\n",
       " (95.02487579981486, 'trim'),\n",
       " (97.0588207244873, 'mian'),\n",
       " (77.46478915214539, 'fexo'),\n",
       " (94.61279511451721, 'chlo_1'),\n",
       " (97.0873773097992, 'trip'),\n",
       " (93.9890722433726, 'desi'),\n",
       " (97.72079785664876, 'levo'),\n",
       " (96.91357811292012, 'diphe_1'),\n",
       " (97.41379221280415, 'diphe_2'),\n",
       " (93.5185174147288, 'emed'),\n",
       " (96.70782089233398, 'ceti'),\n",
       " (95.99999984105428, 'trip_1'),\n",
       " (91.86991850535075, 'doxe'),\n",
       " (96.66666587193806, 'chlo_2'),\n",
       " (96.38888835906982, 'flun'),\n",
       " (96.6966986656189, 'keto')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_lstm = list(zip(cv_lstm, string_well))\n",
    "cv_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.13304527600604"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_l_mean,_ = zip(*cv_lstm)\n",
    "\n",
    "m_cv_l = np.mean(list(cv_l_mean))\n",
    "m_cv_l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE RUNNING AGAIN\n",
    "\n",
    "folders = glob.glob('/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/*')\n",
    "\n",
    "for fo in folders:\n",
    "    file = glob.glob(f'{fo}/*')\n",
    "    for f in file:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = np.mean(cv_plot, axis = 0)\n",
    "me = me.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = np.std(cv_plot, axis = 0)\n",
    "sd = sd.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.071825738502327"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_cv_l =  np.std(list(cv_l_mean))\n",
    "sd_cv_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('ytick', labelsize=18)\n",
    "ax = plt.figure(figsize=(13,8), facecolor='w').gca()\n",
    "ax.plot(me)\n",
    "ax.fill_between(time_points, me - sd, me + sd, alpha = 0.5)\n",
    "\n",
    "plt.errorbar(30.5, m_cv_l, sd_cv_l, linestyle='None', marker='^', markersize=12)\n",
    "\n",
    "plt.savefig('/home/jovyan/md_sd_score.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_stat = [i for i in cv_s_mean]\n",
    "lstm_stat = [i for i in cv_l_mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=4.000, p=0.000\n",
      "Different distribution (reject H0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "stat, p = wilcoxon(cnn_stat, lstm_stat)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
