{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D\n",
    "from tensorflow.keras.layers import MaxPooling2D, MaxPooling3D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "import tqdm\n",
    "from numpy import loadtxt\n",
    "from os import *\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(true,preds):\n",
    "    conf_matx = confusion_matrix(true, preds)\n",
    "    sns.heatmap(conf_matx, annot=True,annot_kws={\"size\": 12},fmt='g', cbar=False, cmap=plt.cm.Blues) #'viridis'\n",
    "    plt.savefig('/home/jovyan/img1.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return conf_matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(model_history, model_name):\n",
    "    fig = plt.figure(figsize=(15,5), facecolor='w')\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.plot(model_history.history['loss'])\n",
    "    ax.plot(model_history.history['val_loss'])\n",
    "    ax.set(title=model_name + ': Model loss', ylabel='Loss', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Val'], loc='upper left')\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.plot(model_history.history['accuracy'])\n",
    "    ax.plot(model_history.history['val_accuracy'])\n",
    "    ax.set(title=model_name + ': Model Accuracy; test='+ str(np.round(model_history.history['val_accuracy'][-1], 3)),\n",
    "           ylabel='Accuracy', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.savefig('/home/jovyan/curve.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(x):\n",
    "    rescaled = []\n",
    "\n",
    "    for i in x:\n",
    "\n",
    "        scale_percent = 140 # percent of original size\n",
    "        width = int(i.shape[1] / (scale_percent / 100))\n",
    "        height = int(i.shape[0] / (scale_percent / 100))\n",
    "        dim = (width, height)\n",
    "        resized = cv2.resize(i, dim, interpolation = cv2.INTER_LANCZOS4)\n",
    "        rescaled.append(resized)\n",
    "\n",
    "    x_orig = np.reshape( rescaled, (len( rescaled), resized.shape[1], resized.shape[1], 3))\n",
    "\n",
    "    return x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(path_data, path_labels):\n",
    "\n",
    "    image_list = []\n",
    "    \n",
    "\n",
    "    for filename in tqdm.tqdm(sorted(glob.glob(path_data), key=natural_keys)): \n",
    "        im=cv2.imread(filename)\n",
    "        #gray_image = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        imarray = np.array(im)\n",
    "        #imarray = imarray.astype('float32')\n",
    "        image_list.append(imarray)\n",
    "\n",
    "    x_orig = np.reshape(image_list, (len(image_list), 90, 90, 3))\n",
    "    \n",
    "    path = path_labels    \n",
    "    labels = pd.read_csv(path, usecols=[\"Type\", \"Category\"],\n",
    "                       sep=\",\" )\n",
    "    y_orig = np.array(labels['Category'])\n",
    "\n",
    "    return x_orig, y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data = '/home/jovyan/DATA_MASTER_PROJECT/Check_DIFF_T60_T_97/3_class_Cont_ADR_HRH/'\n",
    "\n",
    "train_data =  p_data + 'TRAIN/*.tiff'\n",
    "train_lab= p_data + 'train_lab.csv'\n",
    "\n",
    "validation_data = p_data + 'VALIDATION/*.tiff'\n",
    "validation_lab = p_data + 'validation_lab.csv'\n",
    "\n",
    "\n",
    "test_data= p_data + 'TEST/*.tiff'\n",
    "test_lab= p_data + 'test_lab.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73354/73354 [01:05<00:00, 1127.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((73354, 90, 90, 3), (73354,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = loadImages(train_data, train_lab)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19653/19653 [00:18<00:00, 1055.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((19653, 90, 90, 3), (19653,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val, y_val = loadImages(validation_data, validation_lab)\n",
    "x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24106/24106 [00:24<00:00, 994.55it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((24106, 90, 90, 3), (24106,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test, y_test = loadImages(test_data, test_lab)\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73354, 64, 64, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = resize(x_train)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19653, 64, 64, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = resize(x_val)\n",
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24106, 64, 64, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = resize(x_test)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 26564, 1: 36776, 2: 10014}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = VGG16(weights='imagenet',include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "base_model = Model(inputs=pretrained_model.input, outputs=pretrained_model.get_layer('block3_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = [0.9204688  0.66487202 2.44171493]\n"
     ]
    }
   ],
   "source": [
    "weights = class_weight.compute_class_weight('balanced', np.unique(y_train),y_train)\n",
    "print('weights = ' + str(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocess_input(x_train)\n",
    "\n",
    "x_val = preprocess_input(x_val)\n",
    "\n",
    "x_test = preprocess_input(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test_1 = keras.utils.to_categorical(y_test)\n",
    "y_val = keras.utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 573.078125 steps, validate for 153.5390625 steps\n",
      "Epoch 1/300\n",
      "574/573 [==============================] - 20s 35ms/step - loss: 1.1484 - accuracy: 0.3962 - val_loss: 1.0636 - val_accuracy: 0.4421\n",
      "Epoch 2/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 1.0314 - accuracy: 0.4767 - val_loss: 1.0172 - val_accuracy: 0.4783\n",
      "Epoch 3/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.9960 - accuracy: 0.4972 - val_loss: 0.9941 - val_accuracy: 0.4889\n",
      "Epoch 4/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.9745 - accuracy: 0.5060 - val_loss: 0.9813 - val_accuracy: 0.4944\n",
      "Epoch 5/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.9590 - accuracy: 0.5140 - val_loss: 0.9731 - val_accuracy: 0.4988\n",
      "Epoch 6/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.9471 - accuracy: 0.5214 - val_loss: 0.9673 - val_accuracy: 0.5001\n",
      "Epoch 7/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.9374 - accuracy: 0.5264 - val_loss: 0.9623 - val_accuracy: 0.5025\n",
      "Epoch 8/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.9292 - accuracy: 0.5322 - val_loss: 0.9578 - val_accuracy: 0.5040\n",
      "Epoch 9/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.9221 - accuracy: 0.5369 - val_loss: 0.9552 - val_accuracy: 0.5081\n",
      "Epoch 10/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.9159 - accuracy: 0.5405 - val_loss: 0.9525 - val_accuracy: 0.5087\n",
      "Epoch 11/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.9103 - accuracy: 0.5447 - val_loss: 0.9502 - val_accuracy: 0.5102\n",
      "Epoch 12/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.9052 - accuracy: 0.5485 - val_loss: 0.9478 - val_accuracy: 0.5108\n",
      "Epoch 13/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.9005 - accuracy: 0.5514 - val_loss: 0.9464 - val_accuracy: 0.5105\n",
      "Epoch 14/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8962 - accuracy: 0.5542 - val_loss: 0.9445 - val_accuracy: 0.5125\n",
      "Epoch 15/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8922 - accuracy: 0.5573 - val_loss: 0.9428 - val_accuracy: 0.5139\n",
      "Epoch 16/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8884 - accuracy: 0.5600 - val_loss: 0.9414 - val_accuracy: 0.5142\n",
      "Epoch 17/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8849 - accuracy: 0.5625 - val_loss: 0.9410 - val_accuracy: 0.5147\n",
      "Epoch 18/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8815 - accuracy: 0.5653 - val_loss: 0.9390 - val_accuracy: 0.5179\n",
      "Epoch 19/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8784 - accuracy: 0.5671 - val_loss: 0.9381 - val_accuracy: 0.5181\n",
      "Epoch 20/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8754 - accuracy: 0.5696 - val_loss: 0.9362 - val_accuracy: 0.5183\n",
      "Epoch 21/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8726 - accuracy: 0.5718 - val_loss: 0.9358 - val_accuracy: 0.5183\n",
      "Epoch 22/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8699 - accuracy: 0.5743 - val_loss: 0.9346 - val_accuracy: 0.5195\n",
      "Epoch 23/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8673 - accuracy: 0.5761 - val_loss: 0.9339 - val_accuracy: 0.5198\n",
      "Epoch 24/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8648 - accuracy: 0.5785 - val_loss: 0.9331 - val_accuracy: 0.5200\n",
      "Epoch 25/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8623 - accuracy: 0.5798 - val_loss: 0.9324 - val_accuracy: 0.5203\n",
      "Epoch 26/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8600 - accuracy: 0.5815 - val_loss: 0.9314 - val_accuracy: 0.5218\n",
      "Epoch 27/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8577 - accuracy: 0.5834 - val_loss: 0.9303 - val_accuracy: 0.5213\n",
      "Epoch 28/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8556 - accuracy: 0.5852 - val_loss: 0.9294 - val_accuracy: 0.5212\n",
      "Epoch 29/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8534 - accuracy: 0.5867 - val_loss: 0.9301 - val_accuracy: 0.5239\n",
      "Epoch 30/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8513 - accuracy: 0.5885 - val_loss: 0.9286 - val_accuracy: 0.5214\n",
      "Epoch 31/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8493 - accuracy: 0.5893 - val_loss: 0.9284 - val_accuracy: 0.5234\n",
      "Epoch 32/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8473 - accuracy: 0.5913 - val_loss: 0.9277 - val_accuracy: 0.5227\n",
      "Epoch 33/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8454 - accuracy: 0.5927 - val_loss: 0.9271 - val_accuracy: 0.5226\n",
      "Epoch 34/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8435 - accuracy: 0.5938 - val_loss: 0.9272 - val_accuracy: 0.5233\n",
      "Epoch 35/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8417 - accuracy: 0.5944 - val_loss: 0.9260 - val_accuracy: 0.5229\n",
      "Epoch 36/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8398 - accuracy: 0.5961 - val_loss: 0.9263 - val_accuracy: 0.5231\n",
      "Epoch 37/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8380 - accuracy: 0.5976 - val_loss: 0.9255 - val_accuracy: 0.5261\n",
      "Epoch 38/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8362 - accuracy: 0.5983 - val_loss: 0.9251 - val_accuracy: 0.5256\n",
      "Epoch 39/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8345 - accuracy: 0.6002 - val_loss: 0.9234 - val_accuracy: 0.5230\n",
      "Epoch 40/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8328 - accuracy: 0.6012 - val_loss: 0.9237 - val_accuracy: 0.5247\n",
      "Epoch 41/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8311 - accuracy: 0.6018 - val_loss: 0.9235 - val_accuracy: 0.5250\n",
      "Epoch 42/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8294 - accuracy: 0.6040 - val_loss: 0.9231 - val_accuracy: 0.5247\n",
      "Epoch 43/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8278 - accuracy: 0.6042 - val_loss: 0.9223 - val_accuracy: 0.5261\n",
      "Epoch 44/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8262 - accuracy: 0.6057 - val_loss: 0.9218 - val_accuracy: 0.5248\n",
      "Epoch 45/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8246 - accuracy: 0.6059 - val_loss: 0.9221 - val_accuracy: 0.5257\n",
      "Epoch 46/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8231 - accuracy: 0.6071 - val_loss: 0.9224 - val_accuracy: 0.5258\n",
      "Epoch 47/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8215 - accuracy: 0.6081 - val_loss: 0.9214 - val_accuracy: 0.5255\n",
      "Epoch 48/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8200 - accuracy: 0.6095 - val_loss: 0.9206 - val_accuracy: 0.5260\n",
      "Epoch 49/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8185 - accuracy: 0.6098 - val_loss: 0.9204 - val_accuracy: 0.5259\n",
      "Epoch 50/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8170 - accuracy: 0.6111 - val_loss: 0.9204 - val_accuracy: 0.5263\n",
      "Epoch 51/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8156 - accuracy: 0.6123 - val_loss: 0.9200 - val_accuracy: 0.5266\n",
      "Epoch 52/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8141 - accuracy: 0.6130 - val_loss: 0.9201 - val_accuracy: 0.5273\n",
      "Epoch 53/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8127 - accuracy: 0.6146 - val_loss: 0.9194 - val_accuracy: 0.5286\n",
      "Epoch 54/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8113 - accuracy: 0.6152 - val_loss: 0.9188 - val_accuracy: 0.5276\n",
      "Epoch 55/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8098 - accuracy: 0.6161 - val_loss: 0.9190 - val_accuracy: 0.5287\n",
      "Epoch 56/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8084 - accuracy: 0.6174 - val_loss: 0.9186 - val_accuracy: 0.5283\n",
      "Epoch 57/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8070 - accuracy: 0.6187 - val_loss: 0.9182 - val_accuracy: 0.5289\n",
      "Epoch 58/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8057 - accuracy: 0.6190 - val_loss: 0.9179 - val_accuracy: 0.5284\n",
      "Epoch 59/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8043 - accuracy: 0.6207 - val_loss: 0.9180 - val_accuracy: 0.5301\n",
      "Epoch 60/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.8030 - accuracy: 0.6216 - val_loss: 0.9180 - val_accuracy: 0.5297\n",
      "Epoch 61/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8017 - accuracy: 0.6218 - val_loss: 0.9172 - val_accuracy: 0.5293\n",
      "Epoch 62/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.8004 - accuracy: 0.6232 - val_loss: 0.9171 - val_accuracy: 0.5303\n",
      "Epoch 63/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.7990 - accuracy: 0.6238 - val_loss: 0.9160 - val_accuracy: 0.5315\n",
      "Epoch 64/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.7977 - accuracy: 0.6251 - val_loss: 0.9163 - val_accuracy: 0.5317\n",
      "Epoch 65/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.7964 - accuracy: 0.6261 - val_loss: 0.9159 - val_accuracy: 0.5305\n",
      "Epoch 66/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.7951 - accuracy: 0.6267 - val_loss: 0.9171 - val_accuracy: 0.5323\n",
      "Epoch 67/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.7939 - accuracy: 0.6275 - val_loss: 0.9158 - val_accuracy: 0.5327\n",
      "Epoch 68/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.7926 - accuracy: 0.6282 - val_loss: 0.9163 - val_accuracy: 0.5338\n",
      "Epoch 69/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.7914 - accuracy: 0.6290 - val_loss: 0.9157 - val_accuracy: 0.5325\n",
      "Epoch 70/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.7901 - accuracy: 0.6298 - val_loss: 0.9159 - val_accuracy: 0.5333\n",
      "Epoch 71/300\n",
      "574/573 [==============================] - 17s 30ms/step - loss: 0.7889 - accuracy: 0.6309 - val_loss: 0.9157 - val_accuracy: 0.5338\n",
      "Epoch 72/300\n",
      "574/573 [==============================] - 17s 29ms/step - loss: 0.7876 - accuracy: 0.6317 - val_loss: 0.9161 - val_accuracy: 0.5342\n",
      "Epoch 00072: early stopping\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator()\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "train_gen = datagen.flow(x_train, y_train,batch_size=batch_size )\n",
    "\n",
    "dat_val = ImageDataGenerator()\n",
    "\n",
    "dat_val.fit(x_val)\n",
    "\n",
    "val_gen = dat_val.flow(x_val, y_val,batch_size=batch_size)\n",
    "\n",
    "m4 = Sequential()\n",
    "m4.add(base_model)\n",
    "\n",
    "\n",
    "m4.add(BatchNormalization())\n",
    "m4.add(GlobalAveragePooling2D())\n",
    "m4.add(BatchNormalization())\n",
    "m4.add(Activation('relu'))\n",
    "m4.add(Dense(64, activation='relu'))\n",
    "m4.add(Dense(3,activation='softmax'))\n",
    "\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=1e-5)\n",
    "\n",
    "m4.compile(loss= keras.losses.categorical_crossentropy, optimizer=opt, metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "m4_h = m4.fit(train_gen,\n",
    "                steps_per_epoch=(len(x_train)/batch_size),\n",
    "                callbacks = [es],\n",
    "                epochs=epochs,\n",
    "                validation_data = (val_gen), \n",
    "                validation_steps = (len(x_val)/batch_size),\n",
    "                class_weight = weights,\n",
    "                 verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 573.078125 steps, validate for 153.5390625 steps\n",
      "Epoch 1/300\n",
      "574/573 [==============================] - 39s 68ms/step - loss: 0.7563 - accuracy: 0.6517 - val_loss: 0.9220 - val_accuracy: 0.5318\n",
      "Epoch 2/300\n",
      "574/573 [==============================] - 37s 65ms/step - loss: 0.7026 - accuracy: 0.6876 - val_loss: 0.8839 - val_accuracy: 0.5484\n",
      "Epoch 3/300\n",
      "574/573 [==============================] - 38s 66ms/step - loss: 0.6614 - accuracy: 0.7141 - val_loss: 0.8798 - val_accuracy: 0.5655\n",
      "Epoch 4/300\n",
      "574/573 [==============================] - 38s 66ms/step - loss: 0.6267 - accuracy: 0.7341 - val_loss: 0.9077 - val_accuracy: 0.5444\n",
      "Epoch 5/300\n",
      "574/573 [==============================] - 38s 65ms/step - loss: 0.5951 - accuracy: 0.7528 - val_loss: 0.8773 - val_accuracy: 0.5683\n",
      "Epoch 6/300\n",
      "574/573 [==============================] - 37s 65ms/step - loss: 0.5654 - accuracy: 0.7707 - val_loss: 0.8703 - val_accuracy: 0.5835\n",
      "Epoch 7/300\n",
      "574/573 [==============================] - 38s 66ms/step - loss: 0.5382 - accuracy: 0.7856 - val_loss: 0.8817 - val_accuracy: 0.5808\n",
      "Epoch 8/300\n",
      "574/573 [==============================] - 37s 65ms/step - loss: 0.5124 - accuracy: 0.8011 - val_loss: 0.8904 - val_accuracy: 0.5743\n",
      "Epoch 9/300\n",
      "574/573 [==============================] - 37s 65ms/step - loss: 0.4883 - accuracy: 0.8142 - val_loss: 0.9001 - val_accuracy: 0.5728\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=1e-5)\n",
    "\n",
    "m4.compile(loss= keras.losses.categorical_crossentropy, optimizer=opt, metrics = ['accuracy'])\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "m4_h = m4.fit(train_gen,\n",
    "                steps_per_epoch=(len(x_train)/batch_size),\n",
    "                callbacks = [es],\n",
    "                epochs=epochs,\n",
    "                validation_data = val_gen, \n",
    "                validation_steps = (len(x_val)/batch_size),\n",
    "                class_weight = weights,\n",
    "                verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(m4_h, 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = m4.evaluate(x_test, y_test_1, verbose = 0)\n",
    "print(\"\\n%s: %.2f%%\" % (m4.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = m4.predict(x_test)\n",
    "\n",
    "preds_df = pd.DataFrame(test_preds)\n",
    "predicted_labels = preds_df.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_confusion_matrix(y_test, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = '/home/jovyan/Saved_Models/'\n",
    "#m4.save(p + \"CNN_same_fields_view_Controll_HRH_ADR.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
