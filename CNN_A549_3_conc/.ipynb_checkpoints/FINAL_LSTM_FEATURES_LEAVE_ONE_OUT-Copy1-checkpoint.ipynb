{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D\n",
    "from tensorflow.keras.layers import MaxPooling2D, MaxPooling3D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "import tqdm\n",
    "from numpy import loadtxt\n",
    "from os import *\n",
    "from sklearn.utils import class_weight\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(true,preds):\n",
    "    conf_matx = confusion_matrix(true, preds)\n",
    "    sns.heatmap(conf_matx, annot=True,annot_kws={\"size\": 12},fmt='g', cbar=False, cmap=plt.cm.Blues) #'viridis'\n",
    "    #plt.savefig('/home/jovyan/conf_matrix.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return conf_matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(model_history, model_name):\n",
    "    fig = plt.figure(figsize=(15,5), facecolor='w')\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.plot(model_history.history['loss'])\n",
    "    ax.plot(model_history.history['val_loss'])\n",
    "    ax.set(title=model_name + ': Model loss', ylabel='Loss', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Val'], loc='upper left')\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.plot(model_history.history['accuracy'])\n",
    "    ax.plot(model_history.history['val_accuracy'])\n",
    "    ax.set(title=model_name + ': Model Accuracy; test='+ str(np.round(model_history.history['val_accuracy'][-1], 3)),\n",
    "           ylabel='Accuracy', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Val'], loc='upper left')\n",
    "    #plt.savefig('/home/jovyan/curve.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(x):\n",
    "    rescaled = []\n",
    "\n",
    "    for i in x:\n",
    "\n",
    "        scale_percent = 140 # percent of original size\n",
    "        width = int(i.shape[1] / (scale_percent / 100))\n",
    "        height = int(i.shape[0] / (scale_percent / 100))\n",
    "        dim = (width, height)\n",
    "        resized = cv2.resize(i, dim, interpolation = cv2.INTER_LANCZOS4)\n",
    "        rescaled.append(resized)\n",
    "\n",
    "    x_orig = np.reshape( rescaled, (len( rescaled), resized.shape[1], resized.shape[1], 3))\n",
    "\n",
    "    return x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(path_data):\n",
    "    \n",
    "    \n",
    "    \n",
    "    pa_adr = '/home/jovyan/DATA_MASTER_PROJECT/Check_DIFF_T0_T97/ADR_cropped/'\n",
    "    \n",
    "    pa_control = '/home/jovyan/DATA_MASTER_PROJECT/Check_DIFF_T0_T97/CONTROL_cropped/'\n",
    "    \n",
    "    pa_hrh = '/home/jovyan/DATA_MASTER_PROJECT/Check_DIFF_T0_T97/HRH_cropped/'\n",
    "    \n",
    "    image_list = []\n",
    "    \n",
    "    \n",
    "       \n",
    "\n",
    "\n",
    "    for filename in sorted(path_data, key=natural_keys): \n",
    "        \n",
    "        if 'adr' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_adr + filename)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "\n",
    "            image_list.append(imarray)\n",
    "            \n",
    "        if 'control' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_control + filename)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "\n",
    "            image_list.append(imarray)\n",
    "            \n",
    "        if 'hrh' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_hrh + filename)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "\n",
    "            image_list.append(imarray)\n",
    "\n",
    "\n",
    "\n",
    "    x_orig = np.reshape(image_list, (len(image_list), 90, 90, 3))\n",
    "\n",
    "    return x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_count(x):\n",
    "    name_wel = []\n",
    "    for i in sorted(x, key = natural_keys):\n",
    "        name_wel.append(i.split('_')[0])\n",
    "\n",
    "    z = sorted(list(set(name_wel)))\n",
    "    r = list(range(len(z)))\n",
    "\n",
    "    num = []\n",
    "    for iz in range(len(z)):\n",
    "        count = 0\n",
    "        for i in sorted(x, key=natural_keys):\n",
    "            if z[iz] in i:\n",
    "                count += 1\n",
    "        num.append(count)\n",
    "    return list(zip(z, r, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_label(y, indirizo):\n",
    "    labels = []\n",
    "    for ix, _ in enumerate(y):\n",
    "        \n",
    "        if y[ix][0] == 'adr':\n",
    "        \n",
    "            labels.append([[y[ix][0],0]] * y[ix][2])\n",
    "        \n",
    "        if y[ix][0] == 'hrh':\n",
    "            \n",
    "            labels.append([[y[ix][0],1]] * y[ix][2])\n",
    "            \n",
    "        if y[ix][0] == 'control':\n",
    "            \n",
    "            labels.append([[y[ix][0],1]] * y[ix][2])\n",
    "    \n",
    "    ler = [i for sub in labels for i in sub ]\n",
    "\n",
    "    df = pd.DataFrame(ler, columns = ['Type', 'Category'])\n",
    "    df = df.sort_values(by=['Type'])\n",
    "    df.to_csv(indirizo, sep=',',index=False)\n",
    "    return 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/home/jovyan/save_model_final/HRH_ADR/orp.h5'\n",
    "m4 = load_model(p)\n",
    "\n",
    "for i, layer in enumerate(m4.layers):\n",
    "    layer._name = 'layer_' + str(i)\n",
    "\n",
    "\n",
    "base_model = Model(inputs=m4.input, outputs=m4.get_layer('layer_5').output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FINAL_LSTM_LEAVE_ONE_OUT/features_train'\n",
    "os.mkdir(train_path)\n",
    "\n",
    "test_path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FINAL_LSTM_LEAVE_ONE_OUT/features_test'\n",
    "os.mkdir(test_path)\n",
    "\n",
    "val_path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FINAL_LSTM_LEAVE_ONE_OUT/features_validation'\n",
    "os.mkdir(val_path)\n",
    "\n",
    "\n",
    "\n",
    "n_well = p.split('/')[5].split('.h5')[0]\n",
    "\n",
    "full_path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FINAL_LSTM_LEAVE_ONE_OUT/{}'.format(n_well)\n",
    "os.mkdir(full_path)\n",
    "\n",
    "time_points = list(map(str, range(1,97,3)))\n",
    "\n",
    "new_time = []\n",
    "for i in time_points:\n",
    "    r = '_' + i + '.'\n",
    "    new_time.append(r)\n",
    "\n",
    "\n",
    "path_test = '/home/jovyan/DATA_MASTER_PROJECT/Check_DIFF_T0_T97/HRH_cropped/'\n",
    "\n",
    "# NAME OF THE WELLS CORRESPONDING TO THE FRUG THAT YOU WANT IN THE TEST SET \n",
    "\n",
    "wells_drug = ['D8', 'B2'] \n",
    "\n",
    "tes = []\n",
    "\n",
    "for _,_, filenames in os.walk(path_test):\n",
    "    \n",
    "    for filename in sorted(filenames, key = natural_keys):\n",
    "    \n",
    "        for w in wells_drug:\n",
    "            for t in new_time:\n",
    "                if '{}'.format(w) in filename and '{}tiff'.format(t) in filename:\n",
    "                    tes.append(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN & VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:05<00:05,  5.89s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.85s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "groups_list = ['ADR', 'HRH']#, 'CONTROL']\n",
    "\n",
    "fileds_of_view = ['1','2','3','4']\n",
    "\n",
    "field_train, field_val = train_test_split(fileds_of_view, test_size=0.2, random_state=int(np.random.randint(1,1000,1)))\n",
    "\n",
    "\n",
    "tra = []\n",
    "\n",
    "val = []\n",
    "\n",
    "group_compounds = []\n",
    "\n",
    "for group in tqdm.tqdm(groups_list):\n",
    "    \n",
    "    pa = '/home/jovyan/DATA_MASTER_PROJECT/Check_DIFF_T0_T97/{}_cropped/'.format(group)\n",
    "    \n",
    "    for _,_, filenames in os.walk(pa):\n",
    "    \n",
    "        for filename in sorted(filenames, key = natural_keys):\n",
    "\n",
    "            for t in new_time:\n",
    "\n",
    "                if '_{}-'.format(wells_drug[0]) not in filename and '_{}-'.format(wells_drug[1]) not in filename and '{}tiff'.format(t) in filename:\n",
    "\n",
    "                    group_compounds.append(filename)\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "for i in group_compounds:\n",
    "    \n",
    "    for f in field_train:\n",
    "        if '-{}_'.format(f) in i:\n",
    "            tra.append(i)\n",
    "            \n",
    "            \n",
    "    for v in field_val:\n",
    "        if '-{}_'.format(v) in i:\n",
    "            val.append(i)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM TRAIN & VALIDATIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/54 [00:01<01:21,  1.55s/it]\u001b[A\n",
      "  4%|▎         | 2/54 [00:05<01:54,  2.21s/it]\u001b[A\n",
      "  6%|▌         | 3/54 [00:08<02:13,  2.62s/it]\u001b[A\n",
      "  7%|▋         | 4/54 [00:11<02:09,  2.59s/it]\u001b[A\n",
      "  9%|▉         | 5/54 [00:13<02:00,  2.46s/it]\u001b[A\n",
      " 11%|█         | 6/54 [00:15<01:46,  2.21s/it]\u001b[A\n",
      " 13%|█▎        | 7/54 [00:18<01:52,  2.40s/it]\u001b[A\n",
      " 15%|█▍        | 8/54 [00:20<01:57,  2.56s/it]\u001b[A\n",
      " 17%|█▋        | 9/54 [00:23<01:55,  2.56s/it]\u001b[A\n",
      " 19%|█▊        | 10/54 [00:26<01:54,  2.60s/it]\u001b[A\n",
      " 20%|██        | 11/54 [00:26<01:22,  1.93s/it]\u001b[A\n",
      " 22%|██▏       | 12/54 [00:29<01:34,  2.25s/it]\u001b[A\n",
      " 24%|██▍       | 13/54 [00:32<01:41,  2.48s/it]\u001b[A\n",
      " 26%|██▌       | 14/54 [00:35<01:48,  2.71s/it]\u001b[A\n",
      " 28%|██▊       | 15/54 [00:39<01:57,  3.02s/it]\u001b[A\n",
      " 30%|██▉       | 16/54 [00:42<01:56,  3.07s/it]\u001b[A\n",
      " 31%|███▏      | 17/54 [00:46<01:56,  3.15s/it]\u001b[A\n",
      " 33%|███▎      | 18/54 [00:48<01:48,  3.01s/it]\u001b[A\n",
      " 35%|███▌      | 19/54 [00:53<02:01,  3.46s/it]\u001b[A\n",
      " 37%|███▋      | 20/54 [00:56<01:54,  3.37s/it]\u001b[A\n",
      " 39%|███▉      | 21/54 [00:59<01:51,  3.39s/it]\u001b[A\n",
      " 41%|████      | 22/54 [01:02<01:41,  3.16s/it]\u001b[A\n",
      " 43%|████▎     | 23/54 [01:04<01:29,  2.90s/it]\u001b[A\n",
      " 44%|████▍     | 24/54 [01:08<01:32,  3.10s/it]\u001b[A\n",
      " 46%|████▋     | 25/54 [01:11<01:26,  3.00s/it]\u001b[A\n",
      " 48%|████▊     | 26/54 [01:14<01:23,  3.00s/it]\u001b[A\n",
      " 50%|█████     | 27/54 [01:17<01:21,  3.03s/it]\u001b[A\n",
      " 52%|█████▏    | 28/54 [01:19<01:10,  2.72s/it]\u001b[A\n",
      " 54%|█████▎    | 29/54 [01:21<01:05,  2.62s/it]\u001b[A\n",
      " 56%|█████▌    | 30/54 [01:24<01:07,  2.81s/it]\u001b[A\n",
      " 57%|█████▋    | 31/54 [01:27<01:00,  2.64s/it]\u001b[A\n",
      " 59%|█████▉    | 32/54 [01:30<01:02,  2.85s/it]\u001b[A\n",
      " 61%|██████    | 33/54 [01:33<01:02,  2.97s/it]\u001b[A\n",
      " 63%|██████▎   | 34/54 [01:35<00:50,  2.54s/it]\u001b[A\n",
      " 65%|██████▍   | 35/54 [01:38<00:51,  2.69s/it]\u001b[A\n",
      " 67%|██████▋   | 36/54 [01:41<00:53,  2.97s/it]\u001b[A\n",
      " 69%|██████▊   | 37/54 [01:44<00:49,  2.91s/it]\u001b[A\n",
      " 70%|███████   | 38/54 [01:48<00:49,  3.07s/it]\u001b[A\n",
      " 72%|███████▏  | 39/54 [01:50<00:44,  2.96s/it]\u001b[A\n",
      " 74%|███████▍  | 40/54 [01:54<00:45,  3.25s/it]\u001b[A\n",
      " 76%|███████▌  | 41/54 [01:57<00:40,  3.08s/it]\u001b[A\n",
      " 78%|███████▊  | 42/54 [01:59<00:34,  2.88s/it]\u001b[A\n",
      " 80%|███████▉  | 43/54 [02:02<00:31,  2.90s/it]\u001b[A\n",
      " 81%|████████▏ | 44/54 [02:06<00:30,  3.09s/it]\u001b[A\n",
      " 83%|████████▎ | 45/54 [02:09<00:27,  3.03s/it]\u001b[A\n",
      " 85%|████████▌ | 46/54 [02:12<00:24,  3.07s/it]\u001b[A\n",
      " 87%|████████▋ | 47/54 [02:14<00:20,  2.89s/it]\u001b[A\n",
      " 89%|████████▉ | 48/54 [02:18<00:19,  3.17s/it]\u001b[A\n",
      " 91%|█████████ | 49/54 [02:21<00:14,  2.92s/it]\u001b[A\n",
      " 93%|█████████▎| 50/54 [02:23<00:11,  2.82s/it]\u001b[A\n",
      " 94%|█████████▍| 51/54 [02:27<00:09,  3.04s/it]\u001b[A\n",
      " 96%|█████████▋| 52/54 [02:29<00:05,  2.86s/it]\u001b[A\n",
      " 98%|█████████▊| 53/54 [02:32<00:03,  3.02s/it]\u001b[A\n",
      "100%|██████████| 54/54 [02:35<00:00,  2.89s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:03<00:25,  3.67s/it]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:05<00:19,  3.21s/it]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:07<00:14,  2.82s/it]\u001b[A\n",
      " 50%|█████     | 4/8 [00:08<00:09,  2.27s/it]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:11<00:07,  2.55s/it]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:12<00:04,  2.06s/it]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:14<00:02,  2.00s/it]\u001b[A\n",
      "100%|██████████| 8/8 [00:17<00:00,  2.17s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:02<00:45,  2.68s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:04<00:39,  2.46s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:07<00:38,  2.57s/it]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:11<00:40,  2.93s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:12<00:30,  2.32s/it]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:15<00:30,  2.56s/it]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:17<00:27,  2.52s/it]\u001b[A\n",
      " 44%|████▍     | 8/18 [00:19<00:22,  2.22s/it]\u001b[A\n",
      " 50%|█████     | 9/18 [00:21<00:19,  2.16s/it]\u001b[A\n",
      " 56%|█████▌    | 10/18 [00:23<00:17,  2.18s/it]\u001b[A\n",
      " 61%|██████    | 11/18 [00:26<00:17,  2.57s/it]\u001b[A\n",
      " 67%|██████▋   | 12/18 [00:28<00:13,  2.33s/it]\u001b[A\n",
      " 72%|███████▏  | 13/18 [00:31<00:11,  2.37s/it]\u001b[A\n",
      " 78%|███████▊  | 14/18 [00:33<00:09,  2.32s/it]\u001b[A\n",
      " 83%|████████▎ | 15/18 [00:34<00:05,  1.93s/it]\u001b[A\n",
      " 89%|████████▉ | 16/18 [00:36<00:03,  1.98s/it]\u001b[A\n",
      " 94%|█████████▍| 17/18 [00:39<00:02,  2.32s/it]\u001b[A\n",
      "100%|██████████| 18/18 [00:43<00:00,  2.42s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "data_name = [tra,tes,val]\n",
    "\n",
    "feat_name = ['train', 'test', 'validation']\n",
    "\n",
    "for index_name, _ in enumerate(data_name):\n",
    "\n",
    "    path =  data_name[index_name]\n",
    "\n",
    "    name_well = []\n",
    "\n",
    "    for i in path:\n",
    "        name_well.append(i.split('_id')[0])\n",
    "\n",
    "    wells = list(set(name_well))\n",
    "    wells\n",
    "\n",
    "    for w in tqdm.tqdm(wells):\n",
    "\n",
    "        time = []\n",
    "\n",
    "\n",
    "        for filename in sorted(path, key = natural_keys):\n",
    "            if w in filename: #PAY ATTENTION ID THE IMAGE IS A TIFF OR PNG IMAGE #########\n",
    "                time.append(filename)\n",
    "\n",
    "        data_id = {}\n",
    "        n_id = []\n",
    "        w_n = []\n",
    "\n",
    "        for i in time:\n",
    "            t = i.split('_id_')[1].split('time_')[0]\n",
    "            f = i.split('_id_')[0].split('time_')[0]\n",
    "            n_id.append(t)\n",
    "            w_n.append(f)\n",
    "\n",
    "        id_cell = set(n_id)\n",
    "\n",
    "\n",
    "        for ix, i in enumerate(sorted(id_cell, key = natural_keys)):\n",
    "\n",
    "            id_name = []\n",
    "            dict_1 = {}\n",
    "\n",
    "            for t in time:\n",
    "                if 'id_{}'.format(i) in t:\n",
    "                    id_name.append(t)\n",
    "\n",
    "            d = {'id':id_name}\n",
    "            data = pd.DataFrame(d)\n",
    "\n",
    "            dict_1[ix]=data \n",
    "            data_id.update(dict_1) \n",
    "\n",
    "        delete = [i for i, j in data_id.items() if len(j) < 32] # 9 or the length of time span you are traning on \n",
    "        for i in delete : del data_id[i]\n",
    "\n",
    "        len_id = [i for i, j in data_id.items()]\n",
    "\n",
    "        for le in len_id:    \n",
    "\n",
    "\n",
    "            e = pd.DataFrame(data_id[le])\n",
    "\n",
    "            coords = e.values.tolist()\n",
    "            id_cells = []\n",
    "            for i in coords:\n",
    "                for j in i:\n",
    "                    id_cells.append(j)\n",
    "\n",
    "            x_orig = loadImages(id_cells)\n",
    "            x_orig = resize(x_orig)\n",
    "\n",
    "            x_orig = preprocess_input(x_orig)\n",
    "            output = base_model.predict(x_orig)\n",
    "            np.save('/home/jovyan/DATA_MASTER_PROJECT/LSTM/FINAL_LSTM_LEAVE_ONE_OUT/features_{}/features_well_{}_id_{}.npy'.format(feat_name[index_name],w_n[0], le), output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "controll = ['B3', 'D5','D6','F10']\n",
    "adr = ['C6','F11', 'D11', 'G4', 'F2', 'G10', 'G5', 'B10', 'G3', 'B8']\n",
    "hrh = ['E4', 'G6', 'G8', 'D10', 'E7', 'B7', 'E10', 'B11', 'D8', 'B2']\n",
    "\n",
    "n_data = ['validation', 'train', 'test']\n",
    "\n",
    "indi = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FINAL_LSTM_LEAVE_ONE_OUT/'\n",
    "\n",
    "for ix_name, _ in enumerate(n_data):\n",
    "\n",
    "    directory = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FINAL_LSTM_LEAVE_ONE_OUT/features_{}/'.format(n_data[ix_name])\n",
    "\n",
    "    for i in os.listdir(directory):\n",
    "        for c in controll:\n",
    "            if c in i:\n",
    "                os.rename(directory + i, directory + 'control_' + i)\n",
    "\n",
    "\n",
    "        for a in adr:\n",
    "            if a in i:\n",
    "                os.rename(directory + i, directory + 'adr_' + i)\n",
    "\n",
    "        for h in hrh:\n",
    "            if h in i:\n",
    "                os.rename(directory + i, directory + 'hrh_' + i)\n",
    "\n",
    "    feat = []\n",
    "    for dire, dir_name, filnames in os.walk(directory):\n",
    "        for f_name in filnames:\n",
    "            feat.append(f_name)\n",
    "\n",
    "    tr = return_count(feat)\n",
    "    creat_label(tr, indi + '/' + 'lstm_{}.csv'.format(n_data[ix_name]))\n",
    "\n",
    "tot_path = [train_path, test_path, val_path]\n",
    "\n",
    "for i in tot_path:\n",
    "    shutil.move(i, full_path)\n",
    "    \n",
    "csv_f = ['lstm_train.csv', 'lstm_validation.csv', 'lstm_test.csv']\n",
    "\n",
    "for i in csv_f:\n",
    "    shutil.move(indi+i, full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
