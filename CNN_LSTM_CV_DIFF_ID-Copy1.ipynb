{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten, LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "import tqdm\n",
    "from numpy import loadtxt\n",
    "from os import *\n",
    "from sklearn.utils import class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(true,preds):\n",
    "    conf_matx = confusion_matrix(true, preds)\n",
    "    sns.heatmap(conf_matx, annot=True,annot_kws={\"size\": 12},fmt='g', cbar=False, cmap=plt.cm.Blues) #'viridis'\n",
    "    #plt.savefig('/home/jovyan/conf_matrix.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return conf_matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(model_history, model_name):\n",
    "    fig = plt.figure(figsize=(15,5), facecolor='w')\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.plot(model_history.history['loss'])\n",
    "    ax.plot(model_history.history['val_loss'])\n",
    "    ax.set(title=model_name + ': Model loss', ylabel='Loss', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Val'], loc='upper left')\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.plot(model_history.history['accuracy'])\n",
    "    ax.plot(model_history.history['val_accuracy'])\n",
    "    ax.set(title=model_name + ': Model Accuracy; test='+ str(np.round(model_history.history['val_accuracy'][-1], 3)),\n",
    "           ylabel='Accuracy', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Val'], loc='upper left')\n",
    "    #plt.savefig('/home/jovyan/curve.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(x):\n",
    "    rescaled = []\n",
    "\n",
    "    for i in x:\n",
    "\n",
    "        scale_percent = 140 # percent of original size\n",
    "        width = int(i.shape[1] / (scale_percent / 100))\n",
    "        height = int(i.shape[0] / (scale_percent / 100))\n",
    "        dim = (width, height)\n",
    "        resized = cv2.resize(i, dim, interpolation = cv2.INTER_LANCZOS4)\n",
    "        rescaled.append(resized)\n",
    "\n",
    "    x_orig = np.reshape( rescaled, (len( rescaled), resized.shape[1], resized.shape[1], 3))\n",
    "\n",
    "    return x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(path_data):\n",
    "    \n",
    "    p = '/home/jovyan/DATA_MASTER_PROJECT/Check_DIFF_T0_T97/'\n",
    "    \n",
    "    \n",
    "    \n",
    "    pa_adr = p + 'ADR_cropped/'\n",
    "    \n",
    "    pa_control = p + 'CONTROL_cropped/'\n",
    "    \n",
    "    pa_hrh = p + 'HRH_cropped/'\n",
    "    \n",
    "    image_list = []\n",
    "    \n",
    "    \n",
    "       \n",
    "\n",
    "\n",
    "    for filename in sorted(path_data, key=natural_keys): \n",
    "        \n",
    "        if 'adr' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_adr + filename)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "            \n",
    "\n",
    "            image_list.append(imarray)\n",
    "            \n",
    "        if 'control' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_control + filename)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "            \n",
    "\n",
    "            image_list.append(imarray)\n",
    "            \n",
    "        if 'hrh' in filename:\n",
    "            \n",
    "            im=cv2.imread(pa_hrh + filename)\n",
    "\n",
    "            imarray = np.array(im)\n",
    "            \n",
    "\n",
    "            image_list.append(imarray)\n",
    "\n",
    "\n",
    "\n",
    "    x_orig = np.reshape(image_list, (len(image_list), 90, 90, 3))\n",
    "\n",
    "    return x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_count(x):\n",
    "    name_wel = []\n",
    "    for i in sorted(x, key = natural_keys):\n",
    "        name_wel.append(i.split('_')[0])\n",
    "\n",
    "    z = sorted(list(set(name_wel)))\n",
    "    r = list(range(len(z)))\n",
    "\n",
    "    num = []\n",
    "    for iz in range(len(z)):\n",
    "        count = 0\n",
    "        for i in sorted(x, key=natural_keys):\n",
    "            if z[iz] in i:\n",
    "                count += 1\n",
    "        num.append(count)\n",
    "    return list(zip(z, r, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages_LSTM(path_data):\n",
    "    \n",
    "\n",
    "    feat_list = []\n",
    "\n",
    "\n",
    "    for filename in sorted(glob.glob(path_data), key=natural_keys): \n",
    "        feat_list.append(np.load(filename))\n",
    "\n",
    "    x_orig = np.reshape(feat_list, (len(feat_list),32, 64))\n",
    "\n",
    "    return x_orig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(data_set):\n",
    "    fe = return_count(data_set)\n",
    "    leb = creat_label(fe)\n",
    "    y = np.array(list(leb))\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels_LSTM(data_set):\n",
    "    fe = return_count_LSTM(data_set)\n",
    "    leb = creat_label(fe)\n",
    "    y = np.array(list(leb))\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_count_LSTM(x):\n",
    "    name_wel = []\n",
    "    for _,_,i in os.walk(x):\n",
    "        for f in i:\n",
    "            name_wel.append(f.split('_')[2])\n",
    "\n",
    "    z = sorted(list(set(name_wel)), key=natural_keys)\n",
    "    r = list(range(len(z)))\n",
    "\n",
    "    num = []\n",
    "    for iz in range(len(z)):\n",
    "        count = 0\n",
    "        for i in sorted(name_wel, key=natural_keys):\n",
    "            if z[iz] in i:\n",
    "                count += 1\n",
    "        num.append(count)\n",
    "    return list(zip(z, r, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_label(y):\n",
    "    labels = []\n",
    "    for ix, _ in enumerate(y):\n",
    "        \n",
    "        if y[ix][0] == 'adr':\n",
    "        \n",
    "            labels.append([[y[ix][0],0]] * y[ix][2])\n",
    "        \n",
    "        if y[ix][0] == 'hrh':\n",
    "            \n",
    "            labels.append([[y[ix][0],1]] * y[ix][2])\n",
    "        \n",
    "        if y[ix][0] == 'control':\n",
    "            \n",
    "            labels.append([[y[ix][0],1]] * y[ix][2])\n",
    "    \n",
    "    ler = [i for sub in labels for i in sub ]\n",
    "    \n",
    "    _, lab= zip(*ler)\n",
    "\n",
    "    \n",
    "    return lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_step_acc(tes_data, x):\n",
    "\n",
    "    results = []            \n",
    "\n",
    "    x_test = loadImages(tes_data)\n",
    "    y_test = make_labels(tes_data)\n",
    "    x_test = resize(x_test)\n",
    "    x_test = preprocess_input(x_test)\n",
    "\n",
    "    scores = x.evaluate(x_test, y_test, verbose = 1)\n",
    "    results.append(scores[1]*100)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_mean_acc(result_cv, string_well):\n",
    "    \n",
    "    l_drug = string_well*3\n",
    "\n",
    "    acc_mean_cv = []\n",
    "\n",
    "    for i in result_cv:\n",
    "        acc_mean_cv.append(np.mean(i))\n",
    "        \n",
    "    cv_drug = list(zip(acc_mean_cv, l_drug))\n",
    "    \n",
    "    res = sorted(cv_drug, key = lambda x: x[1])\n",
    "    a , b = zip(*res)\n",
    "    \n",
    "    a = list(a)\n",
    "    \n",
    "    s = list(np.array_split(a, 5))\n",
    "    \n",
    "    cv_score_acc = []\n",
    "    \n",
    "    for ix, i in enumerate(s):\n",
    "        s1 = list(s[ix])\n",
    "        \n",
    "        cv_score_acc.append(np.mean(s1))\n",
    "        \n",
    "    return list(zip(cv_score_acc, string_well))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA FOR LSTM PART\n",
    "\n",
    "p_feat = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/'\n",
    "train_data = p_feat + 'features_train/*.npy'\n",
    "val_data = p_feat + 'features_validation/*.npy'\n",
    "tes_data= p_feat + 'features_test/*.npy'\n",
    "\n",
    "y_tra_path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/features_train/'\n",
    "y_tes_path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/features_test/'\n",
    "y_val_path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/features_validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = ['C6', 'F11']\n",
    "leb = ['D11', 'G4']\n",
    "mep = ['F2', 'G10']\n",
    "met = ['G5', 'B10']\n",
    "oxy = ['G3', 'B8']\n",
    "\n",
    "cyc = ['E4', 'G6']\n",
    "dox = ['G8', 'D10']\n",
    "olo = ['E7', 'B7']\n",
    "ket = ['E10', 'B11']\n",
    "orp = ['D8', 'B2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_results_accuracy = []\n",
    "\n",
    "results_lstm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_well_adr = [mid, leb, mep, met, oxy]\n",
    "tot_well_hrh = [cyc, dox, olo, ket, orp]\n",
    "\n",
    "string_well_adr = ['mid', 'leb', 'mep', 'met', 'oxy']\n",
    "string_well_hrh = ['cyc', 'dox', 'olo', 'ket', 'orp']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_well = []\n",
    "string_well = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'ADR' # FOR TEST SET\n",
    "b = 'HRH' # FOR REST\n",
    "\n",
    "if a == 'HRH':\n",
    "    tot_well = tot_well_hrh\n",
    "    string_well = string_well_hrh\n",
    "    \n",
    "if a == 'ADR':\n",
    "    tot_well = tot_well_adr\n",
    "    string_well = string_well_adr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = list(np.random.randint(1,1000,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:05<00:05,  5.42s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.88s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "10it [00:00, 81.41it/s]\u001b[A\n",
      "15it [00:00, 66.93it/s]\u001b[A\n",
      "19it [00:00, 54.40it/s]\u001b[A\n",
      "23it [00:00, 45.00it/s]\u001b[A\n",
      "27it [00:00, 41.60it/s]\u001b[A\n",
      "32it [00:00, 43.33it/s]\u001b[A\n",
      "38it [00:00, 44.30it/s]\u001b[A\n",
      "43it [00:00, 44.71it/s]\u001b[A\n",
      "48it [00:01, 39.83it/s]\u001b[A\n",
      "52it [00:01, 39.43it/s]\u001b[A\n",
      "57it [00:01, 40.69it/s]\u001b[A\n",
      "62it [00:01, 35.17it/s]\u001b[A\n",
      "66it [00:01, 35.13it/s]\u001b[A\n",
      "72it [00:01, 42.18it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 72/72 [00:00<00:00, 2366.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 500.203125 steps, validate for 127.4921875 steps\n",
      "Epoch 1/300\n",
      "501/500 [==============================] - 17s 35ms/step - loss: 0.6688 - accuracy: 0.5904 - val_loss: 0.6630 - val_accuracy: 0.5984\n",
      "Epoch 2/300\n",
      "501/500 [==============================] - 14s 27ms/step - loss: 0.6254 - accuracy: 0.6377 - val_loss: 0.6522 - val_accuracy: 0.6128\n",
      "Epoch 3/300\n",
      "501/500 [==============================] - 14s 27ms/step - loss: 0.6101 - accuracy: 0.6553 - val_loss: 0.6428 - val_accuracy: 0.6243\n",
      "Epoch 4/300\n",
      "501/500 [==============================] - 14s 27ms/step - loss: 0.5986 - accuracy: 0.6688 - val_loss: 0.6369 - val_accuracy: 0.6353\n",
      "Epoch 5/300\n",
      "501/500 [==============================] - 14s 27ms/step - loss: 0.5887 - accuracy: 0.6790 - val_loss: 0.6325 - val_accuracy: 0.6369\n",
      "Epoch 6/300\n",
      "501/500 [==============================] - 14s 27ms/step - loss: 0.5801 - accuracy: 0.6863 - val_loss: 0.6308 - val_accuracy: 0.6379\n",
      "Epoch 7/300\n",
      "501/500 [==============================] - 14s 27ms/step - loss: 0.5723 - accuracy: 0.6939 - val_loss: 0.6305 - val_accuracy: 0.6413\n",
      "Epoch 8/300\n",
      "501/500 [==============================] - 14s 28ms/step - loss: 0.5652 - accuracy: 0.7005 - val_loss: 0.6295 - val_accuracy: 0.6431\n",
      "Epoch 9/300\n",
      "501/500 [==============================] - 14s 28ms/step - loss: 0.5586 - accuracy: 0.7061 - val_loss: 0.6275 - val_accuracy: 0.6435\n",
      "Epoch 10/300\n",
      "501/500 [==============================] - 14s 28ms/step - loss: 0.5523 - accuracy: 0.7114 - val_loss: 0.6264 - val_accuracy: 0.6434\n",
      "Epoch 11/300\n",
      "501/500 [==============================] - 14s 28ms/step - loss: 0.5463 - accuracy: 0.7161 - val_loss: 0.6281 - val_accuracy: 0.6426\n",
      "Epoch 12/300\n",
      "501/500 [==============================] - 14s 27ms/step - loss: 0.5405 - accuracy: 0.7207 - val_loss: 0.6264 - val_accuracy: 0.6493\n",
      "Epoch 13/300\n",
      "501/500 [==============================] - 14s 27ms/step - loss: 0.5350 - accuracy: 0.7258 - val_loss: 0.6315 - val_accuracy: 0.6462\n",
      "Epoch 14/300\n",
      "501/500 [==============================] - 14s 27ms/step - loss: 0.5298 - accuracy: 0.7296 - val_loss: 0.6286 - val_accuracy: 0.6448\n",
      "Epoch 15/300\n",
      "501/500 [==============================] - 14s 27ms/step - loss: 0.5248 - accuracy: 0.7335 - val_loss: 0.6325 - val_accuracy: 0.6472\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 500.203125 steps, validate for 127.4921875 steps\n",
      "Epoch 1/300\n",
      "501/500 [==============================] - 34s 68ms/step - loss: 0.5164 - accuracy: 0.7403 - val_loss: 0.6428 - val_accuracy: 0.6427\n",
      "Epoch 2/300\n",
      "501/500 [==============================] - 32s 64ms/step - loss: 0.4963 - accuracy: 0.7571 - val_loss: 0.6435 - val_accuracy: 0.6397\n",
      "Epoch 3/300\n",
      "501/500 [==============================] - 32s 64ms/step - loss: 0.4809 - accuracy: 0.7668 - val_loss: 0.6283 - val_accuracy: 0.6569\n",
      "Epoch 4/300\n",
      "501/500 [==============================] - 32s 64ms/step - loss: 0.4670 - accuracy: 0.7798 - val_loss: 0.6603 - val_accuracy: 0.6335\n",
      "Epoch 5/300\n",
      "501/500 [==============================] - 32s 64ms/step - loss: 0.4542 - accuracy: 0.7889 - val_loss: 0.6282 - val_accuracy: 0.6657\n",
      "Epoch 6/300\n",
      "501/500 [==============================] - 32s 64ms/step - loss: 0.4422 - accuracy: 0.7980 - val_loss: 0.6332 - val_accuracy: 0.6600\n",
      "Epoch 7/300\n",
      "501/500 [==============================] - 32s 64ms/step - loss: 0.4312 - accuracy: 0.8055 - val_loss: 0.6338 - val_accuracy: 0.6598\n",
      "Epoch 8/300\n",
      "501/500 [==============================] - 32s 64ms/step - loss: 0.4206 - accuracy: 0.8131 - val_loss: 0.6383 - val_accuracy: 0.6699\n",
      "Epoch 00008: early stopping\n",
      "421/421 [==============================] - 0s 1ms/sample - loss: 1.4121 - accuracy: 0.2898\n",
      "397/397 [==============================] - 0s 402us/sample - loss: 1.3519 - accuracy: 0.2846\n",
      "389/389 [==============================] - 0s 198us/sample - loss: 1.3880 - accuracy: 0.2931\n",
      "381/381 [==============================] - 0s 461us/sample - loss: 1.4324 - accuracy: 0.3307\n",
      "375/375 [==============================] - 0s 460us/sample - loss: 1.3985 - accuracy: 0.3173\n",
      "369/369 [==============================] - 0s 454us/sample - loss: 1.4362 - accuracy: 0.3333\n",
      "366/366 [==============================] - 0s 436us/sample - loss: 1.4565 - accuracy: 0.3033\n",
      "357/357 [==============================] - 0s 205us/sample - loss: 1.5302 - accuracy: 0.3193\n",
      "355/355 [==============================] - 0s 419us/sample - loss: 1.5263 - accuracy: 0.2901\n",
      "347/347 [==============================] - 0s 491us/sample - loss: 1.3792 - accuracy: 0.3199\n",
      "343/343 [==============================] - 0s 204us/sample - loss: 1.4369 - accuracy: 0.3207\n",
      "339/339 [==============================] - 0s 497us/sample - loss: 1.4661 - accuracy: 0.2832\n",
      "335/335 [==============================] - 0s 450us/sample - loss: 1.4792 - accuracy: 0.3284\n",
      "338/338 [==============================] - 0s 465us/sample - loss: 1.4474 - accuracy: 0.3254\n",
      "330/330 [==============================] - 0s 420us/sample - loss: 1.4154 - accuracy: 0.3636\n",
      "330/330 [==============================] - 0s 211us/sample - loss: 1.4024 - accuracy: 0.3576\n",
      "332/332 [==============================] - 0s 439us/sample - loss: 1.4014 - accuracy: 0.3645\n",
      "327/327 [==============================] - 0s 432us/sample - loss: 1.4732 - accuracy: 0.3303\n",
      "324/324 [==============================] - 0s 419us/sample - loss: 1.3840 - accuracy: 0.3519\n",
      "322/322 [==============================] - 0s 392us/sample - loss: 1.4560 - accuracy: 0.3354\n",
      "321/321 [==============================] - 0s 409us/sample - loss: 1.4961 - accuracy: 0.2928\n",
      "320/320 [==============================] - 0s 759us/sample - loss: 1.4795 - accuracy: 0.2937\n",
      "313/313 [==============================] - 0s 516us/sample - loss: 1.5435 - accuracy: 0.2971\n",
      "315/315 [==============================] - 0s 197us/sample - loss: 1.5129 - accuracy: 0.2984\n",
      "309/309 [==============================] - 0s 525us/sample - loss: 1.5081 - accuracy: 0.2945\n",
      "308/308 [==============================] - 0s 490us/sample - loss: 1.5458 - accuracy: 0.3052\n",
      "306/306 [==============================] - 0s 223us/sample - loss: 1.5937 - accuracy: 0.2680\n",
      "301/301 [==============================] - 0s 206us/sample - loss: 1.4869 - accuracy: 0.3322\n",
      "300/300 [==============================] - 0s 206us/sample - loss: 1.4967 - accuracy: 0.3033\n",
      "301/301 [==============================] - 0s 196us/sample - loss: 1.5101 - accuracy: 0.2990\n",
      "296/296 [==============================] - 0s 413us/sample - loss: 1.5285 - accuracy: 0.2804\n",
      "297/297 [==============================] - 0s 435us/sample - loss: 1.4317 - accuracy: 0.3199\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 1566 samples, validate on 402 samples\n",
      "Epoch 1/300\n",
      "1566/1566 [==============================] - 2s 1ms/sample - loss: 0.7291 - accuracy: 0.4821 - val_loss: 0.7220 - val_accuracy: 0.4701\n",
      "Epoch 2/300\n",
      "1566/1566 [==============================] - 0s 175us/sample - loss: 0.7116 - accuracy: 0.5006 - val_loss: 0.7143 - val_accuracy: 0.4975\n",
      "Epoch 3/300\n",
      "1566/1566 [==============================] - 0s 173us/sample - loss: 0.7061 - accuracy: 0.5096 - val_loss: 0.7087 - val_accuracy: 0.5025\n",
      "Epoch 4/300\n",
      "1566/1566 [==============================] - 0s 170us/sample - loss: 0.6968 - accuracy: 0.5313 - val_loss: 0.7041 - val_accuracy: 0.5100\n",
      "Epoch 5/300\n",
      "1566/1566 [==============================] - 0s 159us/sample - loss: 0.6879 - accuracy: 0.5549 - val_loss: 0.7000 - val_accuracy: 0.5249\n",
      "Epoch 6/300\n",
      "1566/1566 [==============================] - 0s 162us/sample - loss: 0.6875 - accuracy: 0.5517 - val_loss: 0.6966 - val_accuracy: 0.5373\n",
      "Epoch 7/300\n",
      "1566/1566 [==============================] - 0s 160us/sample - loss: 0.6787 - accuracy: 0.5632 - val_loss: 0.6934 - val_accuracy: 0.5498\n",
      "Epoch 8/300\n",
      "1566/1566 [==============================] - 0s 159us/sample - loss: 0.6728 - accuracy: 0.5830 - val_loss: 0.6906 - val_accuracy: 0.5597\n",
      "Epoch 9/300\n",
      "1566/1566 [==============================] - 0s 170us/sample - loss: 0.6736 - accuracy: 0.5824 - val_loss: 0.6880 - val_accuracy: 0.5597\n",
      "Epoch 10/300\n",
      "1566/1566 [==============================] - 0s 160us/sample - loss: 0.6716 - accuracy: 0.5805 - val_loss: 0.6855 - val_accuracy: 0.5597\n",
      "Epoch 11/300\n",
      "1566/1566 [==============================] - 0s 169us/sample - loss: 0.6638 - accuracy: 0.5964 - val_loss: 0.6832 - val_accuracy: 0.5622\n",
      "Epoch 12/300\n",
      "1566/1566 [==============================] - 0s 175us/sample - loss: 0.6576 - accuracy: 0.6111 - val_loss: 0.6811 - val_accuracy: 0.5721\n",
      "Epoch 13/300\n",
      "1566/1566 [==============================] - 0s 179us/sample - loss: 0.6556 - accuracy: 0.6137 - val_loss: 0.6790 - val_accuracy: 0.5771\n",
      "Epoch 14/300\n",
      "1566/1566 [==============================] - 0s 177us/sample - loss: 0.6553 - accuracy: 0.6015 - val_loss: 0.6770 - val_accuracy: 0.5796\n",
      "Epoch 15/300\n",
      "1566/1566 [==============================] - 0s 170us/sample - loss: 0.6488 - accuracy: 0.6162 - val_loss: 0.6752 - val_accuracy: 0.5846\n",
      "Epoch 16/300\n",
      "1566/1566 [==============================] - 0s 159us/sample - loss: 0.6452 - accuracy: 0.6328 - val_loss: 0.6734 - val_accuracy: 0.5896\n",
      "Epoch 17/300\n",
      "1566/1566 [==============================] - 0s 166us/sample - loss: 0.6445 - accuracy: 0.6315 - val_loss: 0.6717 - val_accuracy: 0.5896\n",
      "Epoch 18/300\n",
      "1566/1566 [==============================] - 0s 160us/sample - loss: 0.6435 - accuracy: 0.6335 - val_loss: 0.6700 - val_accuracy: 0.5920\n",
      "Epoch 19/300\n",
      "1566/1566 [==============================] - 0s 171us/sample - loss: 0.6375 - accuracy: 0.6443 - val_loss: 0.6685 - val_accuracy: 0.5995\n",
      "Epoch 20/300\n",
      "1566/1566 [==============================] - 0s 161us/sample - loss: 0.6351 - accuracy: 0.6488 - val_loss: 0.6669 - val_accuracy: 0.6020\n",
      "Epoch 21/300\n",
      "1566/1566 [==============================] - 0s 169us/sample - loss: 0.6335 - accuracy: 0.6309 - val_loss: 0.6655 - val_accuracy: 0.5995\n",
      "Epoch 22/300\n",
      "1566/1566 [==============================] - 0s 161us/sample - loss: 0.6317 - accuracy: 0.6488 - val_loss: 0.6640 - val_accuracy: 0.6070\n",
      "Epoch 23/300\n",
      "1566/1566 [==============================] - 0s 159us/sample - loss: 0.6277 - accuracy: 0.6603 - val_loss: 0.6626 - val_accuracy: 0.6070\n",
      "Epoch 24/300\n",
      "1566/1566 [==============================] - 0s 168us/sample - loss: 0.6247 - accuracy: 0.6679 - val_loss: 0.6613 - val_accuracy: 0.6119\n",
      "Epoch 25/300\n",
      "1566/1566 [==============================] - 0s 178us/sample - loss: 0.6224 - accuracy: 0.6737 - val_loss: 0.6599 - val_accuracy: 0.6169\n",
      "Epoch 26/300\n",
      "1566/1566 [==============================] - 0s 176us/sample - loss: 0.6196 - accuracy: 0.6667 - val_loss: 0.6586 - val_accuracy: 0.6169\n",
      "Epoch 27/300\n",
      "1566/1566 [==============================] - 0s 177us/sample - loss: 0.6197 - accuracy: 0.6897 - val_loss: 0.6574 - val_accuracy: 0.6169\n",
      "Epoch 28/300\n",
      "1566/1566 [==============================] - 0s 164us/sample - loss: 0.6170 - accuracy: 0.6903 - val_loss: 0.6561 - val_accuracy: 0.6169\n",
      "Epoch 29/300\n",
      "1566/1566 [==============================] - 0s 171us/sample - loss: 0.6155 - accuracy: 0.6801 - val_loss: 0.6549 - val_accuracy: 0.6194\n",
      "Epoch 30/300\n",
      "1566/1566 [==============================] - 0s 161us/sample - loss: 0.6094 - accuracy: 0.6877 - val_loss: 0.6538 - val_accuracy: 0.6219\n",
      "Epoch 31/300\n",
      "1566/1566 [==============================] - 0s 170us/sample - loss: 0.6086 - accuracy: 0.7024 - val_loss: 0.6527 - val_accuracy: 0.6219\n",
      "Epoch 32/300\n",
      "1566/1566 [==============================] - 0s 161us/sample - loss: 0.6030 - accuracy: 0.7031 - val_loss: 0.6516 - val_accuracy: 0.6269\n",
      "Epoch 33/300\n",
      "1566/1566 [==============================] - 0s 158us/sample - loss: 0.6021 - accuracy: 0.6865 - val_loss: 0.6505 - val_accuracy: 0.6244\n",
      "Epoch 34/300\n",
      "1566/1566 [==============================] - 0s 158us/sample - loss: 0.6089 - accuracy: 0.6980 - val_loss: 0.6493 - val_accuracy: 0.6294\n",
      "Epoch 35/300\n",
      "1566/1566 [==============================] - 0s 166us/sample - loss: 0.5993 - accuracy: 0.7120 - val_loss: 0.6483 - val_accuracy: 0.6294\n",
      "Epoch 36/300\n",
      "1566/1566 [==============================] - 0s 160us/sample - loss: 0.5975 - accuracy: 0.7254 - val_loss: 0.6472 - val_accuracy: 0.6294\n",
      "Epoch 37/300\n",
      "1566/1566 [==============================] - 0s 157us/sample - loss: 0.5951 - accuracy: 0.7203 - val_loss: 0.6462 - val_accuracy: 0.6294\n",
      "Epoch 38/300\n",
      "1566/1566 [==============================] - 0s 158us/sample - loss: 0.5920 - accuracy: 0.7190 - val_loss: 0.6452 - val_accuracy: 0.6294\n",
      "Epoch 39/300\n",
      "1566/1566 [==============================] - 0s 154us/sample - loss: 0.5867 - accuracy: 0.7273 - val_loss: 0.6442 - val_accuracy: 0.6318\n",
      "Epoch 40/300\n",
      "1566/1566 [==============================] - 0s 162us/sample - loss: 0.5913 - accuracy: 0.7165 - val_loss: 0.6432 - val_accuracy: 0.6318\n",
      "Epoch 41/300\n",
      "1566/1566 [==============================] - 0s 161us/sample - loss: 0.5891 - accuracy: 0.7184 - val_loss: 0.6423 - val_accuracy: 0.6269\n",
      "Epoch 42/300\n",
      "1566/1566 [==============================] - 0s 155us/sample - loss: 0.5861 - accuracy: 0.7216 - val_loss: 0.6414 - val_accuracy: 0.6294\n",
      "Epoch 43/300\n",
      "1566/1566 [==============================] - 0s 168us/sample - loss: 0.5854 - accuracy: 0.7165 - val_loss: 0.6404 - val_accuracy: 0.6318\n",
      "Epoch 44/300\n",
      "1566/1566 [==============================] - 0s 177us/sample - loss: 0.5852 - accuracy: 0.7158 - val_loss: 0.6395 - val_accuracy: 0.6343\n",
      "Epoch 45/300\n",
      "1566/1566 [==============================] - 0s 174us/sample - loss: 0.5782 - accuracy: 0.7292 - val_loss: 0.6387 - val_accuracy: 0.6368\n",
      "Epoch 46/300\n",
      "1566/1566 [==============================] - 0s 164us/sample - loss: 0.5791 - accuracy: 0.7235 - val_loss: 0.6378 - val_accuracy: 0.6368\n",
      "Epoch 47/300\n",
      "1566/1566 [==============================] - 0s 175us/sample - loss: 0.5770 - accuracy: 0.7126 - val_loss: 0.6370 - val_accuracy: 0.6418\n",
      "Epoch 48/300\n",
      "1566/1566 [==============================] - 0s 177us/sample - loss: 0.5709 - accuracy: 0.7337 - val_loss: 0.6362 - val_accuracy: 0.6418\n",
      "Epoch 49/300\n",
      "1566/1566 [==============================] - 0s 179us/sample - loss: 0.5671 - accuracy: 0.7465 - val_loss: 0.6353 - val_accuracy: 0.6443\n",
      "Epoch 50/300\n",
      "1566/1566 [==============================] - 0s 162us/sample - loss: 0.5668 - accuracy: 0.7324 - val_loss: 0.6345 - val_accuracy: 0.6493\n",
      "Epoch 51/300\n",
      "1566/1566 [==============================] - 0s 168us/sample - loss: 0.5716 - accuracy: 0.7363 - val_loss: 0.6337 - val_accuracy: 0.6517\n",
      "Epoch 52/300\n",
      "1566/1566 [==============================] - 0s 163us/sample - loss: 0.5622 - accuracy: 0.7458 - val_loss: 0.6329 - val_accuracy: 0.6493\n",
      "Epoch 53/300\n",
      "1566/1566 [==============================] - 0s 158us/sample - loss: 0.5655 - accuracy: 0.7458 - val_loss: 0.6321 - val_accuracy: 0.6542\n",
      "Epoch 54/300\n",
      "1566/1566 [==============================] - 0s 157us/sample - loss: 0.5649 - accuracy: 0.7318 - val_loss: 0.6313 - val_accuracy: 0.6517\n",
      "Epoch 55/300\n",
      "1566/1566 [==============================] - 0s 161us/sample - loss: 0.5572 - accuracy: 0.7446 - val_loss: 0.6306 - val_accuracy: 0.6517\n",
      "Epoch 56/300\n",
      "1566/1566 [==============================] - 0s 166us/sample - loss: 0.5618 - accuracy: 0.7382 - val_loss: 0.6298 - val_accuracy: 0.6517\n",
      "Epoch 57/300\n",
      "1566/1566 [==============================] - 0s 157us/sample - loss: 0.5543 - accuracy: 0.7510 - val_loss: 0.6292 - val_accuracy: 0.6592\n",
      "Epoch 58/300\n",
      "1566/1566 [==============================] - 0s 196us/sample - loss: 0.5552 - accuracy: 0.7535 - val_loss: 0.6284 - val_accuracy: 0.6617\n",
      "Epoch 59/300\n",
      "1566/1566 [==============================] - 0s 161us/sample - loss: 0.5513 - accuracy: 0.7567 - val_loss: 0.6277 - val_accuracy: 0.6617\n",
      "Epoch 60/300\n",
      "1566/1566 [==============================] - 0s 164us/sample - loss: 0.5517 - accuracy: 0.7446 - val_loss: 0.6270 - val_accuracy: 0.6617\n",
      "Epoch 61/300\n",
      "1566/1566 [==============================] - 0s 164us/sample - loss: 0.5467 - accuracy: 0.7503 - val_loss: 0.6264 - val_accuracy: 0.6592\n",
      "Epoch 62/300\n",
      "1566/1566 [==============================] - 0s 177us/sample - loss: 0.5446 - accuracy: 0.7682 - val_loss: 0.6257 - val_accuracy: 0.6592\n",
      "Epoch 63/300\n",
      "1566/1566 [==============================] - 0s 196us/sample - loss: 0.5502 - accuracy: 0.7484 - val_loss: 0.6251 - val_accuracy: 0.6592\n",
      "Epoch 64/300\n",
      "1566/1566 [==============================] - 0s 174us/sample - loss: 0.5427 - accuracy: 0.7669 - val_loss: 0.6244 - val_accuracy: 0.6592\n",
      "Epoch 65/300\n",
      "1566/1566 [==============================] - 0s 176us/sample - loss: 0.5451 - accuracy: 0.7522 - val_loss: 0.6237 - val_accuracy: 0.6592\n",
      "Epoch 66/300\n",
      "1566/1566 [==============================] - 0s 178us/sample - loss: 0.5405 - accuracy: 0.7554 - val_loss: 0.6231 - val_accuracy: 0.6592\n",
      "Epoch 67/300\n",
      "1566/1566 [==============================] - 0s 174us/sample - loss: 0.5341 - accuracy: 0.7708 - val_loss: 0.6225 - val_accuracy: 0.6592\n",
      "Epoch 68/300\n",
      "1566/1566 [==============================] - 0s 160us/sample - loss: 0.5404 - accuracy: 0.7561 - val_loss: 0.6219 - val_accuracy: 0.6592\n",
      "Epoch 69/300\n",
      "1566/1566 [==============================] - 0s 185us/sample - loss: 0.5336 - accuracy: 0.7739 - val_loss: 0.6213 - val_accuracy: 0.6592\n",
      "Epoch 70/300\n",
      "1566/1566 [==============================] - 0s 168us/sample - loss: 0.5334 - accuracy: 0.7618 - val_loss: 0.6207 - val_accuracy: 0.6592\n",
      "Epoch 71/300\n",
      "1566/1566 [==============================] - 0s 159us/sample - loss: 0.5294 - accuracy: 0.7733 - val_loss: 0.6201 - val_accuracy: 0.6592\n",
      "Epoch 72/300\n",
      "1566/1566 [==============================] - 0s 169us/sample - loss: 0.5292 - accuracy: 0.7676 - val_loss: 0.6195 - val_accuracy: 0.6592\n",
      "Epoch 73/300\n",
      "1566/1566 [==============================] - 0s 166us/sample - loss: 0.5217 - accuracy: 0.7784 - val_loss: 0.6190 - val_accuracy: 0.6592\n",
      "Epoch 74/300\n",
      "1566/1566 [==============================] - 0s 169us/sample - loss: 0.5214 - accuracy: 0.7829 - val_loss: 0.6185 - val_accuracy: 0.6617\n",
      "Epoch 75/300\n",
      "1566/1566 [==============================] - 0s 161us/sample - loss: 0.5177 - accuracy: 0.7771 - val_loss: 0.6179 - val_accuracy: 0.6642\n",
      "Epoch 76/300\n",
      "1566/1566 [==============================] - 0s 160us/sample - loss: 0.5261 - accuracy: 0.7701 - val_loss: 0.6174 - val_accuracy: 0.6642\n",
      "Epoch 77/300\n",
      "1566/1566 [==============================] - 0s 166us/sample - loss: 0.5221 - accuracy: 0.7708 - val_loss: 0.6168 - val_accuracy: 0.6642\n",
      "Epoch 78/300\n",
      "1566/1566 [==============================] - 0s 159us/sample - loss: 0.5177 - accuracy: 0.7791 - val_loss: 0.6164 - val_accuracy: 0.6642\n",
      "Epoch 79/300\n",
      "1566/1566 [==============================] - 0s 164us/sample - loss: 0.5094 - accuracy: 0.7765 - val_loss: 0.6159 - val_accuracy: 0.6642\n",
      "Epoch 80/300\n",
      "1566/1566 [==============================] - 0s 170us/sample - loss: 0.5158 - accuracy: 0.7803 - val_loss: 0.6153 - val_accuracy: 0.6667\n",
      "Epoch 81/300\n",
      "1566/1566 [==============================] - 0s 159us/sample - loss: 0.5124 - accuracy: 0.7816 - val_loss: 0.6149 - val_accuracy: 0.6667\n",
      "Epoch 82/300\n",
      "1566/1566 [==============================] - 0s 160us/sample - loss: 0.5089 - accuracy: 0.7822 - val_loss: 0.6144 - val_accuracy: 0.6667\n",
      "Epoch 83/300\n",
      "1566/1566 [==============================] - 0s 163us/sample - loss: 0.5107 - accuracy: 0.7803 - val_loss: 0.6140 - val_accuracy: 0.6667\n",
      "Epoch 84/300\n",
      "1566/1566 [==============================] - 0s 178us/sample - loss: 0.5088 - accuracy: 0.7720 - val_loss: 0.6136 - val_accuracy: 0.6667\n",
      "Epoch 85/300\n",
      "1566/1566 [==============================] - 0s 176us/sample - loss: 0.5038 - accuracy: 0.7861 - val_loss: 0.6131 - val_accuracy: 0.6642\n",
      "Epoch 86/300\n",
      "1566/1566 [==============================] - 0s 168us/sample - loss: 0.4994 - accuracy: 0.7893 - val_loss: 0.6127 - val_accuracy: 0.6667\n",
      "Epoch 87/300\n",
      "1566/1566 [==============================] - 0s 177us/sample - loss: 0.5029 - accuracy: 0.7893 - val_loss: 0.6123 - val_accuracy: 0.6667\n",
      "Epoch 88/300\n",
      "1566/1566 [==============================] - 0s 176us/sample - loss: 0.4998 - accuracy: 0.7893 - val_loss: 0.6119 - val_accuracy: 0.6642\n",
      "Epoch 89/300\n",
      "1566/1566 [==============================] - 0s 180us/sample - loss: 0.4945 - accuracy: 0.7893 - val_loss: 0.6115 - val_accuracy: 0.6642\n",
      "Epoch 90/300\n",
      "1566/1566 [==============================] - 0s 177us/sample - loss: 0.4946 - accuracy: 0.8091 - val_loss: 0.6111 - val_accuracy: 0.6667\n",
      "Epoch 91/300\n",
      "1566/1566 [==============================] - 0s 172us/sample - loss: 0.4931 - accuracy: 0.7912 - val_loss: 0.6108 - val_accuracy: 0.6617\n",
      "Epoch 92/300\n",
      "1566/1566 [==============================] - 0s 175us/sample - loss: 0.4895 - accuracy: 0.8014 - val_loss: 0.6104 - val_accuracy: 0.6642\n",
      "Epoch 93/300\n",
      "1566/1566 [==============================] - 0s 171us/sample - loss: 0.4905 - accuracy: 0.7995 - val_loss: 0.6101 - val_accuracy: 0.6692\n",
      "Epoch 94/300\n",
      "1566/1566 [==============================] - 0s 176us/sample - loss: 0.4817 - accuracy: 0.8027 - val_loss: 0.6097 - val_accuracy: 0.6692\n",
      "Epoch 95/300\n",
      "1566/1566 [==============================] - 0s 176us/sample - loss: 0.4873 - accuracy: 0.7976 - val_loss: 0.6094 - val_accuracy: 0.6667\n",
      "Epoch 96/300\n",
      "1566/1566 [==============================] - 0s 160us/sample - loss: 0.4840 - accuracy: 0.8059 - val_loss: 0.6091 - val_accuracy: 0.6667\n",
      "Epoch 97/300\n",
      "1566/1566 [==============================] - 0s 158us/sample - loss: 0.4836 - accuracy: 0.7931 - val_loss: 0.6088 - val_accuracy: 0.6642\n",
      "Epoch 98/300\n",
      "1566/1566 [==============================] - 0s 159us/sample - loss: 0.4842 - accuracy: 0.7963 - val_loss: 0.6084 - val_accuracy: 0.6667\n",
      "Epoch 99/300\n",
      "1566/1566 [==============================] - 0s 157us/sample - loss: 0.4780 - accuracy: 0.8110 - val_loss: 0.6082 - val_accuracy: 0.6667\n",
      "Epoch 100/300\n",
      "1566/1566 [==============================] - 0s 157us/sample - loss: 0.4712 - accuracy: 0.8084 - val_loss: 0.6078 - val_accuracy: 0.6667\n",
      "Epoch 101/300\n",
      "1566/1566 [==============================] - 0s 163us/sample - loss: 0.4764 - accuracy: 0.8014 - val_loss: 0.6076 - val_accuracy: 0.6667\n",
      "Epoch 102/300\n",
      "1566/1566 [==============================] - 0s 164us/sample - loss: 0.4719 - accuracy: 0.8103 - val_loss: 0.6073 - val_accuracy: 0.6667\n",
      "Epoch 103/300\n",
      "1566/1566 [==============================] - 0s 166us/sample - loss: 0.4731 - accuracy: 0.8110 - val_loss: 0.6071 - val_accuracy: 0.6667\n",
      "Epoch 104/300\n",
      "1566/1566 [==============================] - 0s 157us/sample - loss: 0.4677 - accuracy: 0.8103 - val_loss: 0.6069 - val_accuracy: 0.6667\n",
      "Epoch 105/300\n",
      "1566/1566 [==============================] - 0s 167us/sample - loss: 0.4692 - accuracy: 0.8001 - val_loss: 0.6066 - val_accuracy: 0.6642\n",
      "Epoch 106/300\n",
      "1566/1566 [==============================] - 0s 173us/sample - loss: 0.4660 - accuracy: 0.8116 - val_loss: 0.6065 - val_accuracy: 0.6642\n",
      "Epoch 107/300\n",
      "1566/1566 [==============================] - 0s 169us/sample - loss: 0.4618 - accuracy: 0.8116 - val_loss: 0.6063 - val_accuracy: 0.6642\n",
      "Epoch 108/300\n",
      "1566/1566 [==============================] - 0s 166us/sample - loss: 0.4609 - accuracy: 0.8148 - val_loss: 0.6061 - val_accuracy: 0.6642\n",
      "Epoch 109/300\n",
      "1566/1566 [==============================] - 0s 174us/sample - loss: 0.4584 - accuracy: 0.8231 - val_loss: 0.6058 - val_accuracy: 0.6667\n",
      "Epoch 110/300\n",
      "1566/1566 [==============================] - 0s 173us/sample - loss: 0.4569 - accuracy: 0.8161 - val_loss: 0.6057 - val_accuracy: 0.6667\n",
      "Epoch 111/300\n",
      "1566/1566 [==============================] - 0s 177us/sample - loss: 0.4550 - accuracy: 0.8199 - val_loss: 0.6055 - val_accuracy: 0.6667\n",
      "Epoch 112/300\n",
      "1566/1566 [==============================] - 0s 170us/sample - loss: 0.4518 - accuracy: 0.8084 - val_loss: 0.6054 - val_accuracy: 0.6667\n",
      "Epoch 113/300\n",
      "1566/1566 [==============================] - 0s 172us/sample - loss: 0.4536 - accuracy: 0.8199 - val_loss: 0.6053 - val_accuracy: 0.6667\n",
      "Epoch 114/300\n",
      "1566/1566 [==============================] - 0s 161us/sample - loss: 0.4453 - accuracy: 0.8174 - val_loss: 0.6051 - val_accuracy: 0.6642\n",
      "Epoch 115/300\n",
      "1566/1566 [==============================] - 0s 157us/sample - loss: 0.4419 - accuracy: 0.8263 - val_loss: 0.6050 - val_accuracy: 0.6667\n",
      "Epoch 116/300\n",
      "1566/1566 [==============================] - 0s 162us/sample - loss: 0.4462 - accuracy: 0.8199 - val_loss: 0.6049 - val_accuracy: 0.6667\n",
      "Epoch 117/300\n",
      "1566/1566 [==============================] - 0s 171us/sample - loss: 0.4453 - accuracy: 0.8301 - val_loss: 0.6048 - val_accuracy: 0.6667\n",
      "Epoch 118/300\n",
      "1566/1566 [==============================] - 0s 169us/sample - loss: 0.4389 - accuracy: 0.8289 - val_loss: 0.6047 - val_accuracy: 0.6642\n",
      "Epoch 119/300\n",
      "1566/1566 [==============================] - 0s 168us/sample - loss: 0.4379 - accuracy: 0.8238 - val_loss: 0.6047 - val_accuracy: 0.6642\n",
      "Epoch 120/300\n",
      "1566/1566 [==============================] - 0s 170us/sample - loss: 0.4329 - accuracy: 0.8276 - val_loss: 0.6047 - val_accuracy: 0.6642\n",
      "Epoch 121/300\n",
      "1566/1566 [==============================] - 0s 162us/sample - loss: 0.4310 - accuracy: 0.8295 - val_loss: 0.6046 - val_accuracy: 0.6617\n",
      "Epoch 122/300\n",
      "1566/1566 [==============================] - 0s 157us/sample - loss: 0.4332 - accuracy: 0.8238 - val_loss: 0.6046 - val_accuracy: 0.6642\n",
      "Epoch 123/300\n",
      "1566/1566 [==============================] - 0s 180us/sample - loss: 0.4279 - accuracy: 0.8282 - val_loss: 0.6047 - val_accuracy: 0.6692\n",
      "Epoch 124/300\n",
      "1566/1566 [==============================] - 0s 166us/sample - loss: 0.4291 - accuracy: 0.8372 - val_loss: 0.6046 - val_accuracy: 0.6716\n",
      "Epoch 00124: early stopping\n",
      "271/271 [==============================] - 0s 84us/sample - loss: 1.2165 - accuracy: 0.2768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [13:30, 810.78s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:05<00:05,  5.58s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.06s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "8it [00:00, 72.59it/s]\u001b[A\n",
      "11it [00:00, 47.89it/s]\u001b[A\n",
      "15it [00:00, 44.93it/s]\u001b[A\n",
      "18it [00:00, 38.76it/s]\u001b[A\n",
      "23it [00:00, 40.95it/s]\u001b[A\n",
      "27it [00:00, 34.62it/s]\u001b[A\n",
      "32it [00:00, 35.88it/s]\u001b[A\n",
      "38it [00:00, 38.42it/s]\u001b[A\n",
      "43it [00:01, 40.98it/s]\u001b[A\n",
      "48it [00:01, 38.23it/s]\u001b[A\n",
      "52it [00:01, 37.93it/s]\u001b[A\n",
      "57it [00:01, 39.21it/s]\u001b[A\n",
      "61it [00:01, 32.76it/s]\u001b[A\n",
      "66it [00:01, 33.63it/s]\u001b[A\n",
      "72it [00:01, 38.85it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 72/72 [00:00<00:00, 2276.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 515.390625 steps, validate for 133.8671875 steps\n",
      "Epoch 1/300\n",
      "516/515 [==============================] - 15s 29ms/step - loss: 0.6884 - accuracy: 0.5729 - val_loss: 0.6851 - val_accuracy: 0.5768\n",
      "Epoch 2/300\n",
      "516/515 [==============================] - 14s 27ms/step - loss: 0.6457 - accuracy: 0.6216 - val_loss: 0.6680 - val_accuracy: 0.5996\n",
      "Epoch 3/300\n",
      "516/515 [==============================] - 14s 27ms/step - loss: 0.6284 - accuracy: 0.6424 - val_loss: 0.6552 - val_accuracy: 0.6194\n",
      "Epoch 4/300\n",
      "516/515 [==============================] - 14s 27ms/step - loss: 0.6160 - accuracy: 0.6553 - val_loss: 0.6507 - val_accuracy: 0.6216\n",
      "Epoch 5/300\n",
      "516/515 [==============================] - 14s 27ms/step - loss: 0.6060 - accuracy: 0.6649 - val_loss: 0.6506 - val_accuracy: 0.6224\n",
      "Epoch 6/300\n",
      "516/515 [==============================] - 14s 27ms/step - loss: 0.5975 - accuracy: 0.6745 - val_loss: 0.6462 - val_accuracy: 0.6310\n",
      "Epoch 7/300\n",
      "516/515 [==============================] - 14s 27ms/step - loss: 0.5899 - accuracy: 0.6813 - val_loss: 0.6462 - val_accuracy: 0.6293\n",
      "Epoch 8/300\n",
      "516/515 [==============================] - 14s 27ms/step - loss: 0.5833 - accuracy: 0.6875 - val_loss: 0.6447 - val_accuracy: 0.6345\n",
      "Epoch 9/300\n",
      "516/515 [==============================] - 14s 27ms/step - loss: 0.5772 - accuracy: 0.6930 - val_loss: 0.6437 - val_accuracy: 0.6358\n",
      "Epoch 10/300\n",
      "516/515 [==============================] - 14s 27ms/step - loss: 0.5717 - accuracy: 0.6981 - val_loss: 0.6436 - val_accuracy: 0.6377\n",
      "Epoch 11/300\n",
      "516/515 [==============================] - 14s 27ms/step - loss: 0.5662 - accuracy: 0.7025 - val_loss: 0.6425 - val_accuracy: 0.6398\n",
      "Epoch 12/300\n",
      "516/515 [==============================] - 14s 27ms/step - loss: 0.5613 - accuracy: 0.7064 - val_loss: 0.6486 - val_accuracy: 0.6362\n",
      "Epoch 13/300\n",
      "516/515 [==============================] - 14s 27ms/step - loss: 0.5566 - accuracy: 0.7099 - val_loss: 0.6438 - val_accuracy: 0.6391\n",
      "Epoch 14/300\n",
      "516/515 [==============================] - 14s 27ms/step - loss: 0.5520 - accuracy: 0.7134 - val_loss: 0.6473 - val_accuracy: 0.6369\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 515.390625 steps, validate for 133.8671875 steps\n",
      "Epoch 1/300\n",
      "516/515 [==============================] - 33s 65ms/step - loss: 0.5442 - accuracy: 0.7214 - val_loss: 0.6688 - val_accuracy: 0.6267\n",
      "Epoch 2/300\n",
      "516/515 [==============================] - 32s 63ms/step - loss: 0.5248 - accuracy: 0.7366 - val_loss: 0.6596 - val_accuracy: 0.6368\n",
      "Epoch 3/300\n",
      "516/515 [==============================] - 32s 62ms/step - loss: 0.5094 - accuracy: 0.7501 - val_loss: 0.6576 - val_accuracy: 0.6337\n",
      "Epoch 4/300\n",
      "516/515 [==============================] - 32s 63ms/step - loss: 0.4956 - accuracy: 0.7615 - val_loss: 0.6483 - val_accuracy: 0.6410\n",
      "Epoch 5/300\n",
      "516/515 [==============================] - 32s 62ms/step - loss: 0.4833 - accuracy: 0.7720 - val_loss: 0.6414 - val_accuracy: 0.6486\n",
      "Epoch 6/300\n",
      "516/515 [==============================] - 32s 62ms/step - loss: 0.4708 - accuracy: 0.7808 - val_loss: 0.6695 - val_accuracy: 0.6364\n",
      "Epoch 7/300\n",
      "516/515 [==============================] - 32s 62ms/step - loss: 0.4596 - accuracy: 0.7892 - val_loss: 0.6904 - val_accuracy: 0.6322\n",
      "Epoch 8/300\n",
      "516/515 [==============================] - 32s 62ms/step - loss: 0.4489 - accuracy: 0.7965 - val_loss: 0.6487 - val_accuracy: 0.6546\n",
      "Epoch 00008: early stopping\n",
      "312/312 [==============================] - 0s 1ms/sample - loss: 1.0557 - accuracy: 0.3365\n",
      "296/296 [==============================] - 0s 196us/sample - loss: 1.0915 - accuracy: 0.3480\n",
      "290/290 [==============================] - 0s 221us/sample - loss: 1.1091 - accuracy: 0.3000\n",
      "285/285 [==============================] - 0s 194us/sample - loss: 1.1869 - accuracy: 0.3053\n",
      "279/279 [==============================] - 0s 209us/sample - loss: 1.2480 - accuracy: 0.2760\n",
      "272/272 [==============================] - 0s 483us/sample - loss: 1.2812 - accuracy: 0.2904\n",
      "270/270 [==============================] - 0s 203us/sample - loss: 1.3091 - accuracy: 0.2741\n",
      "269/269 [==============================] - 0s 198us/sample - loss: 1.3312 - accuracy: 0.2677\n",
      "263/263 [==============================] - 0s 199us/sample - loss: 1.2703 - accuracy: 0.2776\n",
      "262/262 [==============================] - 0s 455us/sample - loss: 1.2860 - accuracy: 0.2939\n",
      "261/261 [==============================] - 0s 191us/sample - loss: 1.3814 - accuracy: 0.2299\n",
      "254/254 [==============================] - 0s 603us/sample - loss: 1.3051 - accuracy: 0.2835\n",
      "252/252 [==============================] - 0s 595us/sample - loss: 1.3845 - accuracy: 0.2421\n",
      "249/249 [==============================] - 0s 201us/sample - loss: 1.3510 - accuracy: 0.2731\n",
      "251/251 [==============================] - 0s 194us/sample - loss: 1.3080 - accuracy: 0.2869\n",
      "247/247 [==============================] - 0s 196us/sample - loss: 1.3541 - accuracy: 0.2996\n",
      "246/246 [==============================] - 0s 598us/sample - loss: 1.3119 - accuracy: 0.2967\n",
      "243/243 [==============================] - 0s 197us/sample - loss: 1.3078 - accuracy: 0.2922\n",
      "242/242 [==============================] - 0s 207us/sample - loss: 1.2675 - accuracy: 0.2851\n",
      "236/236 [==============================] - 0s 219us/sample - loss: 1.2247 - accuracy: 0.3093\n",
      "234/234 [==============================] - 0s 213us/sample - loss: 1.1679 - accuracy: 0.3034\n",
      "230/230 [==============================] - 0s 213us/sample - loss: 1.1776 - accuracy: 0.3348\n",
      "231/231 [==============================] - 0s 205us/sample - loss: 1.2470 - accuracy: 0.3550\n",
      "228/228 [==============================] - 0s 219us/sample - loss: 1.1535 - accuracy: 0.3289\n",
      "227/227 [==============================] - 0s 198us/sample - loss: 1.1753 - accuracy: 0.3568\n",
      "227/227 [==============================] - 0s 241us/sample - loss: 1.2190 - accuracy: 0.3524\n",
      "221/221 [==============================] - 0s 212us/sample - loss: 1.1981 - accuracy: 0.3484\n",
      "226/226 [==============================] - 0s 220us/sample - loss: 1.2200 - accuracy: 0.3186\n",
      "230/230 [==============================] - 0s 226us/sample - loss: 1.1747 - accuracy: 0.3522\n",
      "226/226 [==============================] - 0s 256us/sample - loss: 1.2074 - accuracy: 0.3142\n",
      "223/223 [==============================] - 0s 716us/sample - loss: 1.2817 - accuracy: 0.2915\n",
      "222/222 [==============================] - 0s 204us/sample - loss: 1.2795 - accuracy: 0.3018\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 1617 samples, validate on 425 samples\n",
      "Epoch 1/300\n",
      "1617/1617 [==============================] - 2s 1ms/sample - loss: 0.7333 - accuracy: 0.5090 - val_loss: 0.6902 - val_accuracy: 0.5624\n",
      "Epoch 2/300\n",
      "1617/1617 [==============================] - 0s 183us/sample - loss: 0.7090 - accuracy: 0.5325 - val_loss: 0.6813 - val_accuracy: 0.5624\n",
      "Epoch 3/300\n",
      "1617/1617 [==============================] - 0s 170us/sample - loss: 0.6949 - accuracy: 0.5430 - val_loss: 0.6752 - val_accuracy: 0.5718\n",
      "Epoch 4/300\n",
      "1617/1617 [==============================] - 0s 161us/sample - loss: 0.6906 - accuracy: 0.5622 - val_loss: 0.6702 - val_accuracy: 0.5788\n",
      "Epoch 5/300\n",
      "1617/1617 [==============================] - 0s 157us/sample - loss: 0.6872 - accuracy: 0.5560 - val_loss: 0.6660 - val_accuracy: 0.5953\n",
      "Epoch 6/300\n",
      "1617/1617 [==============================] - 0s 160us/sample - loss: 0.6702 - accuracy: 0.5832 - val_loss: 0.6625 - val_accuracy: 0.6000\n",
      "Epoch 7/300\n",
      "1617/1617 [==============================] - 0s 162us/sample - loss: 0.6632 - accuracy: 0.6024 - val_loss: 0.6593 - val_accuracy: 0.6024\n",
      "Epoch 8/300\n",
      "1617/1617 [==============================] - 0s 174us/sample - loss: 0.6619 - accuracy: 0.5857 - val_loss: 0.6564 - val_accuracy: 0.6071\n",
      "Epoch 9/300\n",
      "1617/1617 [==============================] - 0s 170us/sample - loss: 0.6564 - accuracy: 0.6067 - val_loss: 0.6536 - val_accuracy: 0.6188\n",
      "Epoch 10/300\n",
      "1617/1617 [==============================] - 0s 160us/sample - loss: 0.6535 - accuracy: 0.6030 - val_loss: 0.6512 - val_accuracy: 0.6235\n",
      "Epoch 11/300\n",
      "1617/1617 [==============================] - 0s 166us/sample - loss: 0.6509 - accuracy: 0.6141 - val_loss: 0.6488 - val_accuracy: 0.6329\n",
      "Epoch 12/300\n",
      "1617/1617 [==============================] - 0s 164us/sample - loss: 0.6365 - accuracy: 0.6382 - val_loss: 0.6466 - val_accuracy: 0.6353\n",
      "Epoch 13/300\n",
      "1617/1617 [==============================] - 0s 164us/sample - loss: 0.6385 - accuracy: 0.6289 - val_loss: 0.6445 - val_accuracy: 0.6376\n",
      "Epoch 14/300\n",
      "1617/1617 [==============================] - 0s 170us/sample - loss: 0.6332 - accuracy: 0.6382 - val_loss: 0.6425 - val_accuracy: 0.6424\n",
      "Epoch 15/300\n",
      "1617/1617 [==============================] - 0s 177us/sample - loss: 0.6260 - accuracy: 0.6512 - val_loss: 0.6406 - val_accuracy: 0.6424\n",
      "Epoch 16/300\n",
      "1617/1617 [==============================] - 0s 180us/sample - loss: 0.6286 - accuracy: 0.6524 - val_loss: 0.6388 - val_accuracy: 0.6541\n",
      "Epoch 17/300\n",
      "1617/1617 [==============================] - 0s 157us/sample - loss: 0.6194 - accuracy: 0.6642 - val_loss: 0.6371 - val_accuracy: 0.6565\n",
      "Epoch 18/300\n",
      "1617/1617 [==============================] - 0s 171us/sample - loss: 0.6219 - accuracy: 0.6531 - val_loss: 0.6354 - val_accuracy: 0.6518\n",
      "Epoch 19/300\n",
      "1617/1617 [==============================] - 0s 188us/sample - loss: 0.6200 - accuracy: 0.6481 - val_loss: 0.6336 - val_accuracy: 0.6518\n",
      "Epoch 20/300\n",
      "1617/1617 [==============================] - 0s 163us/sample - loss: 0.6147 - accuracy: 0.6636 - val_loss: 0.6321 - val_accuracy: 0.6494\n",
      "Epoch 21/300\n",
      "1617/1617 [==============================] - 0s 158us/sample - loss: 0.6077 - accuracy: 0.6642 - val_loss: 0.6306 - val_accuracy: 0.6518\n",
      "Epoch 22/300\n",
      "1617/1617 [==============================] - 0s 171us/sample - loss: 0.6117 - accuracy: 0.6698 - val_loss: 0.6291 - val_accuracy: 0.6518\n",
      "Epoch 23/300\n",
      "1617/1617 [==============================] - 0s 175us/sample - loss: 0.6027 - accuracy: 0.6784 - val_loss: 0.6277 - val_accuracy: 0.6541\n",
      "Epoch 24/300\n",
      "1617/1617 [==============================] - 0s 171us/sample - loss: 0.5988 - accuracy: 0.6858 - val_loss: 0.6263 - val_accuracy: 0.6588\n",
      "Epoch 25/300\n",
      "1617/1617 [==============================] - 0s 172us/sample - loss: 0.6000 - accuracy: 0.6834 - val_loss: 0.6249 - val_accuracy: 0.6588\n",
      "Epoch 26/300\n",
      "1617/1617 [==============================] - 0s 159us/sample - loss: 0.5959 - accuracy: 0.6834 - val_loss: 0.6236 - val_accuracy: 0.6612\n",
      "Epoch 27/300\n",
      "1617/1617 [==============================] - 0s 165us/sample - loss: 0.5948 - accuracy: 0.7056 - val_loss: 0.6223 - val_accuracy: 0.6635\n",
      "Epoch 28/300\n",
      "1617/1617 [==============================] - 0s 162us/sample - loss: 0.5854 - accuracy: 0.7007 - val_loss: 0.6211 - val_accuracy: 0.6635\n",
      "Epoch 29/300\n",
      "1617/1617 [==============================] - 0s 170us/sample - loss: 0.5862 - accuracy: 0.7075 - val_loss: 0.6199 - val_accuracy: 0.6635\n",
      "Epoch 30/300\n",
      "1617/1617 [==============================] - 0s 174us/sample - loss: 0.5878 - accuracy: 0.7050 - val_loss: 0.6187 - val_accuracy: 0.6612\n",
      "Epoch 31/300\n",
      "1617/1617 [==============================] - 0s 168us/sample - loss: 0.5809 - accuracy: 0.7069 - val_loss: 0.6176 - val_accuracy: 0.6635\n",
      "Epoch 32/300\n",
      "1617/1617 [==============================] - 0s 168us/sample - loss: 0.5791 - accuracy: 0.7192 - val_loss: 0.6164 - val_accuracy: 0.6659\n",
      "Epoch 33/300\n",
      "1617/1617 [==============================] - 0s 178us/sample - loss: 0.5740 - accuracy: 0.7168 - val_loss: 0.6153 - val_accuracy: 0.6659\n",
      "Epoch 34/300\n",
      "1617/1617 [==============================] - 0s 159us/sample - loss: 0.5645 - accuracy: 0.7211 - val_loss: 0.6142 - val_accuracy: 0.6635\n",
      "Epoch 35/300\n",
      "1617/1617 [==============================] - 0s 158us/sample - loss: 0.5730 - accuracy: 0.7260 - val_loss: 0.6132 - val_accuracy: 0.6659\n",
      "Epoch 36/300\n",
      "1617/1617 [==============================] - 0s 158us/sample - loss: 0.5723 - accuracy: 0.7192 - val_loss: 0.6122 - val_accuracy: 0.6635\n",
      "Epoch 37/300\n",
      "1617/1617 [==============================] - 0s 173us/sample - loss: 0.5669 - accuracy: 0.7186 - val_loss: 0.6112 - val_accuracy: 0.6682\n",
      "Epoch 38/300\n",
      "1617/1617 [==============================] - 0s 159us/sample - loss: 0.5617 - accuracy: 0.7285 - val_loss: 0.6101 - val_accuracy: 0.6706\n",
      "Epoch 39/300\n",
      "1617/1617 [==============================] - 0s 155us/sample - loss: 0.5589 - accuracy: 0.7273 - val_loss: 0.6092 - val_accuracy: 0.6682\n",
      "Epoch 40/300\n",
      "1617/1617 [==============================] - 0s 169us/sample - loss: 0.5570 - accuracy: 0.7409 - val_loss: 0.6082 - val_accuracy: 0.6682\n",
      "Epoch 41/300\n",
      "1617/1617 [==============================] - 0s 175us/sample - loss: 0.5518 - accuracy: 0.7341 - val_loss: 0.6073 - val_accuracy: 0.6706\n",
      "Epoch 42/300\n",
      "1617/1617 [==============================] - 0s 165us/sample - loss: 0.5483 - accuracy: 0.7427 - val_loss: 0.6064 - val_accuracy: 0.6706\n",
      "Epoch 43/300\n",
      "1617/1617 [==============================] - 0s 164us/sample - loss: 0.5520 - accuracy: 0.7335 - val_loss: 0.6054 - val_accuracy: 0.6682\n",
      "Epoch 44/300\n",
      "1617/1617 [==============================] - 0s 164us/sample - loss: 0.5508 - accuracy: 0.7440 - val_loss: 0.6046 - val_accuracy: 0.6659\n",
      "Epoch 45/300\n",
      "1617/1617 [==============================] - 0s 163us/sample - loss: 0.5462 - accuracy: 0.7434 - val_loss: 0.6037 - val_accuracy: 0.6682\n",
      "Epoch 46/300\n",
      "1617/1617 [==============================] - 0s 163us/sample - loss: 0.5410 - accuracy: 0.7297 - val_loss: 0.6028 - val_accuracy: 0.6682\n",
      "Epoch 47/300\n",
      "1617/1617 [==============================] - 0s 172us/sample - loss: 0.5365 - accuracy: 0.7489 - val_loss: 0.6021 - val_accuracy: 0.6682\n",
      "Epoch 48/300\n",
      "1617/1617 [==============================] - 0s 167us/sample - loss: 0.5348 - accuracy: 0.7631 - val_loss: 0.6012 - val_accuracy: 0.6635\n",
      "Epoch 49/300\n",
      "1617/1617 [==============================] - 0s 163us/sample - loss: 0.5373 - accuracy: 0.7452 - val_loss: 0.6004 - val_accuracy: 0.6659\n",
      "Epoch 50/300\n",
      "1617/1617 [==============================] - 0s 171us/sample - loss: 0.5322 - accuracy: 0.7619 - val_loss: 0.5997 - val_accuracy: 0.6682\n",
      "Epoch 51/300\n",
      "1617/1617 [==============================] - 0s 172us/sample - loss: 0.5294 - accuracy: 0.7545 - val_loss: 0.5988 - val_accuracy: 0.6682\n",
      "Epoch 52/300\n",
      "1617/1617 [==============================] - 0s 160us/sample - loss: 0.5273 - accuracy: 0.7502 - val_loss: 0.5981 - val_accuracy: 0.6706\n",
      "Epoch 53/300\n",
      "1617/1617 [==============================] - 0s 160us/sample - loss: 0.5239 - accuracy: 0.7563 - val_loss: 0.5974 - val_accuracy: 0.6706\n",
      "Epoch 54/300\n",
      "1617/1617 [==============================] - 0s 166us/sample - loss: 0.5252 - accuracy: 0.7545 - val_loss: 0.5967 - val_accuracy: 0.6729\n",
      "Epoch 55/300\n",
      "1617/1617 [==============================] - 0s 168us/sample - loss: 0.5157 - accuracy: 0.7786 - val_loss: 0.5960 - val_accuracy: 0.6753\n",
      "Epoch 56/300\n",
      "1617/1617 [==============================] - 0s 166us/sample - loss: 0.5142 - accuracy: 0.7631 - val_loss: 0.5953 - val_accuracy: 0.6753\n",
      "Epoch 57/300\n",
      "1617/1617 [==============================] - 0s 158us/sample - loss: 0.5157 - accuracy: 0.7675 - val_loss: 0.5946 - val_accuracy: 0.6682\n",
      "Epoch 58/300\n",
      "1617/1617 [==============================] - 0s 166us/sample - loss: 0.5095 - accuracy: 0.7767 - val_loss: 0.5939 - val_accuracy: 0.6682\n",
      "Epoch 59/300\n",
      "1617/1617 [==============================] - 0s 176us/sample - loss: 0.5085 - accuracy: 0.7786 - val_loss: 0.5933 - val_accuracy: 0.6682\n",
      "Epoch 60/300\n",
      "1617/1617 [==============================] - 0s 166us/sample - loss: 0.5065 - accuracy: 0.7774 - val_loss: 0.5927 - val_accuracy: 0.6706\n",
      "Epoch 61/300\n",
      "1617/1617 [==============================] - 0s 169us/sample - loss: 0.5088 - accuracy: 0.7755 - val_loss: 0.5921 - val_accuracy: 0.6753\n",
      "Epoch 62/300\n",
      "1617/1617 [==============================] - 0s 166us/sample - loss: 0.4994 - accuracy: 0.7761 - val_loss: 0.5915 - val_accuracy: 0.6753\n",
      "Epoch 63/300\n",
      "1617/1617 [==============================] - 0s 165us/sample - loss: 0.5019 - accuracy: 0.7755 - val_loss: 0.5909 - val_accuracy: 0.6753\n",
      "Epoch 64/300\n",
      "1617/1617 [==============================] - 0s 180us/sample - loss: 0.5021 - accuracy: 0.7848 - val_loss: 0.5903 - val_accuracy: 0.6753\n",
      "Epoch 65/300\n",
      "1617/1617 [==============================] - 0s 166us/sample - loss: 0.4978 - accuracy: 0.7835 - val_loss: 0.5897 - val_accuracy: 0.6776\n",
      "Epoch 66/300\n",
      "1617/1617 [==============================] - 0s 176us/sample - loss: 0.4957 - accuracy: 0.7879 - val_loss: 0.5892 - val_accuracy: 0.6800\n",
      "Epoch 67/300\n",
      "1617/1617 [==============================] - 0s 168us/sample - loss: 0.4982 - accuracy: 0.7798 - val_loss: 0.5886 - val_accuracy: 0.6800\n",
      "Epoch 68/300\n",
      "1617/1617 [==============================] - 0s 160us/sample - loss: 0.4907 - accuracy: 0.7842 - val_loss: 0.5881 - val_accuracy: 0.6800\n",
      "Epoch 69/300\n",
      "1617/1617 [==============================] - 0s 155us/sample - loss: 0.4861 - accuracy: 0.7866 - val_loss: 0.5876 - val_accuracy: 0.6847\n",
      "Epoch 70/300\n",
      "1617/1617 [==============================] - 0s 156us/sample - loss: 0.4841 - accuracy: 0.7829 - val_loss: 0.5870 - val_accuracy: 0.6847\n",
      "Epoch 71/300\n",
      "1617/1617 [==============================] - 0s 162us/sample - loss: 0.4818 - accuracy: 0.7934 - val_loss: 0.5865 - val_accuracy: 0.6847\n",
      "Epoch 72/300\n",
      "1617/1617 [==============================] - 0s 165us/sample - loss: 0.4809 - accuracy: 0.7959 - val_loss: 0.5860 - val_accuracy: 0.6871\n",
      "Epoch 73/300\n",
      "1617/1617 [==============================] - 0s 176us/sample - loss: 0.4792 - accuracy: 0.8040 - val_loss: 0.5855 - val_accuracy: 0.6894\n",
      "Epoch 74/300\n",
      "1617/1617 [==============================] - 0s 178us/sample - loss: 0.4771 - accuracy: 0.7959 - val_loss: 0.5851 - val_accuracy: 0.6847\n",
      "Epoch 75/300\n",
      "1617/1617 [==============================] - 0s 166us/sample - loss: 0.4732 - accuracy: 0.7990 - val_loss: 0.5847 - val_accuracy: 0.6918\n",
      "Epoch 76/300\n",
      "1617/1617 [==============================] - 0s 170us/sample - loss: 0.4725 - accuracy: 0.8040 - val_loss: 0.5842 - val_accuracy: 0.6941\n",
      "Epoch 77/300\n",
      "1617/1617 [==============================] - 0s 165us/sample - loss: 0.4672 - accuracy: 0.8027 - val_loss: 0.5838 - val_accuracy: 0.6918\n",
      "Epoch 78/300\n",
      "1617/1617 [==============================] - 0s 169us/sample - loss: 0.4662 - accuracy: 0.8015 - val_loss: 0.5834 - val_accuracy: 0.6965\n",
      "Epoch 79/300\n",
      "1617/1617 [==============================] - 0s 161us/sample - loss: 0.4681 - accuracy: 0.8002 - val_loss: 0.5831 - val_accuracy: 0.7012\n",
      "Epoch 80/300\n",
      "1617/1617 [==============================] - 0s 164us/sample - loss: 0.4645 - accuracy: 0.8015 - val_loss: 0.5827 - val_accuracy: 0.6988\n",
      "Epoch 81/300\n",
      "1617/1617 [==============================] - 0s 165us/sample - loss: 0.4623 - accuracy: 0.8015 - val_loss: 0.5823 - val_accuracy: 0.7012\n",
      "Epoch 82/300\n",
      "1617/1617 [==============================] - 0s 155us/sample - loss: 0.4570 - accuracy: 0.8083 - val_loss: 0.5820 - val_accuracy: 0.6988\n",
      "Epoch 83/300\n",
      "1617/1617 [==============================] - 0s 168us/sample - loss: 0.4551 - accuracy: 0.8021 - val_loss: 0.5816 - val_accuracy: 0.7012\n",
      "Epoch 84/300\n",
      "1617/1617 [==============================] - 0s 162us/sample - loss: 0.4531 - accuracy: 0.8064 - val_loss: 0.5813 - val_accuracy: 0.7035\n",
      "Epoch 85/300\n",
      "1617/1617 [==============================] - 0s 168us/sample - loss: 0.4514 - accuracy: 0.8083 - val_loss: 0.5810 - val_accuracy: 0.7035\n",
      "Epoch 86/300\n",
      "1617/1617 [==============================] - 0s 163us/sample - loss: 0.4507 - accuracy: 0.7953 - val_loss: 0.5806 - val_accuracy: 0.7059\n",
      "Epoch 87/300\n",
      "1617/1617 [==============================] - 0s 165us/sample - loss: 0.4479 - accuracy: 0.8157 - val_loss: 0.5803 - val_accuracy: 0.7059\n",
      "Epoch 88/300\n",
      "1617/1617 [==============================] - 0s 172us/sample - loss: 0.4487 - accuracy: 0.8071 - val_loss: 0.5801 - val_accuracy: 0.7082\n",
      "Epoch 89/300\n",
      "1617/1617 [==============================] - 0s 172us/sample - loss: 0.4415 - accuracy: 0.8281 - val_loss: 0.5798 - val_accuracy: 0.7059\n",
      "Epoch 90/300\n",
      "1617/1617 [==============================] - 0s 159us/sample - loss: 0.4395 - accuracy: 0.8145 - val_loss: 0.5796 - val_accuracy: 0.7059\n",
      "Epoch 91/300\n",
      "1617/1617 [==============================] - 0s 165us/sample - loss: 0.4380 - accuracy: 0.8126 - val_loss: 0.5794 - val_accuracy: 0.7059\n",
      "Epoch 92/300\n",
      "1617/1617 [==============================] - 0s 167us/sample - loss: 0.4376 - accuracy: 0.8169 - val_loss: 0.5791 - val_accuracy: 0.7035\n",
      "Epoch 93/300\n",
      "1617/1617 [==============================] - 0s 160us/sample - loss: 0.4363 - accuracy: 0.8120 - val_loss: 0.5789 - val_accuracy: 0.7035\n",
      "Epoch 94/300\n",
      "1617/1617 [==============================] - 0s 166us/sample - loss: 0.4345 - accuracy: 0.8293 - val_loss: 0.5787 - val_accuracy: 0.7035\n",
      "Epoch 95/300\n",
      "1617/1617 [==============================] - 0s 165us/sample - loss: 0.4374 - accuracy: 0.8176 - val_loss: 0.5785 - val_accuracy: 0.7035\n",
      "Epoch 96/300\n",
      "1617/1617 [==============================] - 0s 191us/sample - loss: 0.4269 - accuracy: 0.8231 - val_loss: 0.5784 - val_accuracy: 0.7059\n",
      "Epoch 97/300\n",
      "1617/1617 [==============================] - 0s 171us/sample - loss: 0.4313 - accuracy: 0.8194 - val_loss: 0.5783 - val_accuracy: 0.7035\n",
      "Epoch 98/300\n",
      "1617/1617 [==============================] - 0s 178us/sample - loss: 0.4227 - accuracy: 0.8256 - val_loss: 0.5782 - val_accuracy: 0.7059\n",
      "Epoch 99/300\n",
      "1617/1617 [==============================] - 0s 165us/sample - loss: 0.4219 - accuracy: 0.8293 - val_loss: 0.5781 - val_accuracy: 0.7059\n",
      "Epoch 100/300\n",
      "1617/1617 [==============================] - 0s 169us/sample - loss: 0.4195 - accuracy: 0.8176 - val_loss: 0.5780 - val_accuracy: 0.7059\n",
      "Epoch 101/300\n",
      "1617/1617 [==============================] - 0s 167us/sample - loss: 0.4187 - accuracy: 0.8207 - val_loss: 0.5780 - val_accuracy: 0.7059\n",
      "Epoch 102/300\n",
      "1617/1617 [==============================] - 0s 167us/sample - loss: 0.4145 - accuracy: 0.8275 - val_loss: 0.5779 - val_accuracy: 0.7059\n",
      "Epoch 103/300\n",
      "1617/1617 [==============================] - 0s 155us/sample - loss: 0.4121 - accuracy: 0.8398 - val_loss: 0.5778 - val_accuracy: 0.7059\n",
      "Epoch 104/300\n",
      "1617/1617 [==============================] - 0s 155us/sample - loss: 0.4082 - accuracy: 0.8380 - val_loss: 0.5779 - val_accuracy: 0.7035\n",
      "Epoch 105/300\n",
      "1617/1617 [==============================] - 0s 165us/sample - loss: 0.4166 - accuracy: 0.8163 - val_loss: 0.5779 - val_accuracy: 0.7059\n",
      "Epoch 106/300\n",
      "1617/1617 [==============================] - 0s 159us/sample - loss: 0.4115 - accuracy: 0.8231 - val_loss: 0.5778 - val_accuracy: 0.7106\n",
      "Epoch 107/300\n",
      "1617/1617 [==============================] - 0s 166us/sample - loss: 0.4072 - accuracy: 0.8324 - val_loss: 0.5778 - val_accuracy: 0.7129\n",
      "Epoch 108/300\n",
      "1617/1617 [==============================] - 0s 164us/sample - loss: 0.4030 - accuracy: 0.8287 - val_loss: 0.5779 - val_accuracy: 0.7129\n",
      "Epoch 109/300\n",
      "1617/1617 [==============================] - 0s 164us/sample - loss: 0.4019 - accuracy: 0.8318 - val_loss: 0.5779 - val_accuracy: 0.7129\n",
      "Epoch 00109: early stopping\n",
      "197/197 [==============================] - 0s 88us/sample - loss: 1.3002 - accuracy: 0.2284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [26:44, 805.80s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:05<00:05,  5.69s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.13s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "9it [00:00, 71.95it/s]\u001b[A\n",
      "12it [00:00, 48.54it/s]\u001b[A\n",
      "18it [00:00, 49.89it/s]\u001b[A\n",
      "22it [00:00, 44.87it/s]\u001b[A\n",
      "26it [00:00, 35.60it/s]\u001b[A\n",
      "30it [00:00, 36.68it/s]\u001b[A\n",
      "35it [00:00, 38.89it/s]\u001b[A\n",
      "41it [00:00, 40.22it/s]\u001b[A\n",
      "45it [00:01, 37.75it/s]\u001b[A\n",
      "50it [00:01, 37.42it/s]\u001b[A\n",
      "55it [00:01, 37.31it/s]\u001b[A\n",
      "59it [00:01, 35.92it/s]\u001b[A\n",
      "63it [00:01, 34.14it/s]\u001b[A\n",
      "72it [00:01, 39.59it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 72/72 [00:00<00:00, 2006.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 510.46875 steps, validate for 129.9296875 steps\n",
      "Epoch 1/300\n",
      "511/510 [==============================] - 15s 29ms/step - loss: 0.6987 - accuracy: 0.5682 - val_loss: 0.6781 - val_accuracy: 0.5772\n",
      "Epoch 2/300\n",
      "511/510 [==============================] - 14s 27ms/step - loss: 0.6585 - accuracy: 0.6047 - val_loss: 0.6698 - val_accuracy: 0.5877\n",
      "Epoch 3/300\n",
      "511/510 [==============================] - 13s 26ms/step - loss: 0.6444 - accuracy: 0.6229 - val_loss: 0.6660 - val_accuracy: 0.5950\n",
      "Epoch 4/300\n",
      "511/510 [==============================] - 14s 27ms/step - loss: 0.6337 - accuracy: 0.6373 - val_loss: 0.6626 - val_accuracy: 0.6004\n",
      "Epoch 5/300\n",
      "511/510 [==============================] - 14s 27ms/step - loss: 0.6246 - accuracy: 0.6464 - val_loss: 0.6606 - val_accuracy: 0.6026\n",
      "Epoch 6/300\n",
      "511/510 [==============================] - 14s 27ms/step - loss: 0.6167 - accuracy: 0.6549 - val_loss: 0.6599 - val_accuracy: 0.6061\n",
      "Epoch 7/300\n",
      "511/510 [==============================] - 14s 27ms/step - loss: 0.6093 - accuracy: 0.6630 - val_loss: 0.6615 - val_accuracy: 0.6060\n",
      "Epoch 8/300\n",
      "511/510 [==============================] - 14s 27ms/step - loss: 0.6028 - accuracy: 0.6702 - val_loss: 0.6619 - val_accuracy: 0.6054\n",
      "Epoch 9/300\n",
      "511/510 [==============================] - 14s 27ms/step - loss: 0.5969 - accuracy: 0.6743 - val_loss: 0.6633 - val_accuracy: 0.6074\n",
      "Epoch 00009: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 510.46875 steps, validate for 129.9296875 steps\n",
      "Epoch 1/300\n",
      "511/510 [==============================] - 33s 65ms/step - loss: 0.5869 - accuracy: 0.6838 - val_loss: 0.6638 - val_accuracy: 0.6009\n",
      "Epoch 2/300\n",
      "511/510 [==============================] - 32s 62ms/step - loss: 0.5674 - accuracy: 0.7042 - val_loss: 0.6961 - val_accuracy: 0.5817\n",
      "Epoch 3/300\n",
      "511/510 [==============================] - 32s 62ms/step - loss: 0.5520 - accuracy: 0.7197 - val_loss: 0.6766 - val_accuracy: 0.6009\n",
      "Epoch 4/300\n",
      "511/510 [==============================] - 32s 62ms/step - loss: 0.5381 - accuracy: 0.7319 - val_loss: 0.6639 - val_accuracy: 0.6120\n",
      "Epoch 00004: early stopping\n",
      "364/364 [==============================] - 0s 867us/sample - loss: 0.9879 - accuracy: 0.3077\n",
      "349/349 [==============================] - 0s 189us/sample - loss: 0.9195 - accuracy: 0.3467\n",
      "342/342 [==============================] - 0s 212us/sample - loss: 0.8226 - accuracy: 0.4269\n",
      "334/334 [==============================] - 0s 193us/sample - loss: 0.8521 - accuracy: 0.4162\n",
      "327/327 [==============================] - 0s 194us/sample - loss: 0.8291 - accuracy: 0.4618\n",
      "323/323 [==============================] - 0s 216us/sample - loss: 0.8022 - accuracy: 0.4675\n",
      "314/314 [==============================] - 0s 387us/sample - loss: 0.8229 - accuracy: 0.4395\n",
      "307/307 [==============================] - 0s 228us/sample - loss: 0.7781 - accuracy: 0.4788\n",
      "301/301 [==============================] - 0s 229us/sample - loss: 0.7637 - accuracy: 0.5116\n",
      "296/296 [==============================] - 0s 212us/sample - loss: 0.7915 - accuracy: 0.4899\n",
      "290/290 [==============================] - 0s 203us/sample - loss: 0.7654 - accuracy: 0.5241\n",
      "288/288 [==============================] - 0s 1ms/sample - loss: 0.7593 - accuracy: 0.4965\n",
      "286/286 [==============================] - 0s 215us/sample - loss: 0.7651 - accuracy: 0.5210\n",
      "286/286 [==============================] - 0s 211us/sample - loss: 0.7531 - accuracy: 0.5280\n",
      "280/280 [==============================] - 0s 199us/sample - loss: 0.7769 - accuracy: 0.5286\n",
      "280/280 [==============================] - 0s 217us/sample - loss: 0.7925 - accuracy: 0.4893\n",
      "276/276 [==============================] - 0s 206us/sample - loss: 0.7812 - accuracy: 0.5036\n",
      "274/274 [==============================] - 0s 215us/sample - loss: 0.7911 - accuracy: 0.5073\n",
      "272/272 [==============================] - 0s 216us/sample - loss: 0.7611 - accuracy: 0.5551\n",
      "271/271 [==============================] - 0s 218us/sample - loss: 0.7612 - accuracy: 0.4945\n",
      "266/266 [==============================] - 0s 218us/sample - loss: 0.8091 - accuracy: 0.4436\n",
      "264/264 [==============================] - 0s 242us/sample - loss: 0.7874 - accuracy: 0.5114\n",
      "263/263 [==============================] - 0s 249us/sample - loss: 0.7630 - accuracy: 0.4867\n",
      "260/260 [==============================] - 0s 207us/sample - loss: 0.7496 - accuracy: 0.5385\n",
      "258/258 [==============================] - 0s 247us/sample - loss: 0.7262 - accuracy: 0.5388\n",
      "258/258 [==============================] - 0s 200us/sample - loss: 0.7751 - accuracy: 0.5271\n",
      "258/258 [==============================] - 0s 211us/sample - loss: 0.7691 - accuracy: 0.5078\n",
      "254/254 [==============================] - 0s 227us/sample - loss: 0.8072 - accuracy: 0.4685\n",
      "252/252 [==============================] - 0s 201us/sample - loss: 0.7859 - accuracy: 0.5238\n",
      "249/249 [==============================] - 0s 212us/sample - loss: 0.7852 - accuracy: 0.4900\n",
      "250/250 [==============================] - 0s 204us/sample - loss: 0.8019 - accuracy: 0.4720\n",
      "246/246 [==============================] - 0s 282us/sample - loss: 0.8163 - accuracy: 0.4634\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 1606 samples, validate on 410 samples\n",
      "Epoch 1/300\n",
      "1606/1606 [==============================] - 2s 1ms/sample - loss: 0.7121 - accuracy: 0.5081 - val_loss: 0.7150 - val_accuracy: 0.4854\n",
      "Epoch 2/300\n",
      "1606/1606 [==============================] - 0s 168us/sample - loss: 0.7002 - accuracy: 0.5448 - val_loss: 0.7107 - val_accuracy: 0.5000\n",
      "Epoch 3/300\n",
      "1606/1606 [==============================] - 0s 167us/sample - loss: 0.6959 - accuracy: 0.5436 - val_loss: 0.7073 - val_accuracy: 0.5024\n",
      "Epoch 4/300\n",
      "1606/1606 [==============================] - 0s 209us/sample - loss: 0.6974 - accuracy: 0.5268 - val_loss: 0.7052 - val_accuracy: 0.5024\n",
      "Epoch 5/300\n",
      "1606/1606 [==============================] - 0s 164us/sample - loss: 0.6875 - accuracy: 0.5542 - val_loss: 0.7030 - val_accuracy: 0.5098\n",
      "Epoch 6/300\n",
      "1606/1606 [==============================] - 0s 172us/sample - loss: 0.6896 - accuracy: 0.5604 - val_loss: 0.7012 - val_accuracy: 0.5073\n",
      "Epoch 7/300\n",
      "1606/1606 [==============================] - 0s 170us/sample - loss: 0.6803 - accuracy: 0.5747 - val_loss: 0.6997 - val_accuracy: 0.5049\n",
      "Epoch 8/300\n",
      "1606/1606 [==============================] - 0s 182us/sample - loss: 0.6818 - accuracy: 0.5598 - val_loss: 0.6982 - val_accuracy: 0.5098\n",
      "Epoch 9/300\n",
      "1606/1606 [==============================] - 0s 167us/sample - loss: 0.6814 - accuracy: 0.5654 - val_loss: 0.6970 - val_accuracy: 0.5171\n",
      "Epoch 10/300\n",
      "1606/1606 [==============================] - 0s 185us/sample - loss: 0.6741 - accuracy: 0.5866 - val_loss: 0.6958 - val_accuracy: 0.5122\n",
      "Epoch 11/300\n",
      "1606/1606 [==============================] - 0s 197us/sample - loss: 0.6717 - accuracy: 0.5722 - val_loss: 0.6947 - val_accuracy: 0.5195\n",
      "Epoch 12/300\n",
      "1606/1606 [==============================] - 0s 177us/sample - loss: 0.6714 - accuracy: 0.5828 - val_loss: 0.6936 - val_accuracy: 0.5244\n",
      "Epoch 13/300\n",
      "1606/1606 [==============================] - 0s 182us/sample - loss: 0.6701 - accuracy: 0.5847 - val_loss: 0.6927 - val_accuracy: 0.5244\n",
      "Epoch 14/300\n",
      "1606/1606 [==============================] - 0s 185us/sample - loss: 0.6717 - accuracy: 0.5791 - val_loss: 0.6918 - val_accuracy: 0.5317\n",
      "Epoch 15/300\n",
      "1606/1606 [==============================] - 0s 186us/sample - loss: 0.6665 - accuracy: 0.5897 - val_loss: 0.6909 - val_accuracy: 0.5390\n",
      "Epoch 16/300\n",
      "1606/1606 [==============================] - 0s 174us/sample - loss: 0.6656 - accuracy: 0.5928 - val_loss: 0.6901 - val_accuracy: 0.5415\n",
      "Epoch 17/300\n",
      "1606/1606 [==============================] - 0s 170us/sample - loss: 0.6649 - accuracy: 0.5828 - val_loss: 0.6894 - val_accuracy: 0.5463\n",
      "Epoch 18/300\n",
      "1606/1606 [==============================] - 0s 181us/sample - loss: 0.6630 - accuracy: 0.5971 - val_loss: 0.6885 - val_accuracy: 0.5488\n",
      "Epoch 19/300\n",
      "1606/1606 [==============================] - 0s 174us/sample - loss: 0.6647 - accuracy: 0.5922 - val_loss: 0.6878 - val_accuracy: 0.5537\n",
      "Epoch 20/300\n",
      "1606/1606 [==============================] - 0s 161us/sample - loss: 0.6610 - accuracy: 0.6083 - val_loss: 0.6870 - val_accuracy: 0.5512\n",
      "Epoch 21/300\n",
      "1606/1606 [==============================] - 0s 166us/sample - loss: 0.6652 - accuracy: 0.5934 - val_loss: 0.6864 - val_accuracy: 0.5537\n",
      "Epoch 22/300\n",
      "1606/1606 [==============================] - 0s 176us/sample - loss: 0.6604 - accuracy: 0.5965 - val_loss: 0.6858 - val_accuracy: 0.5561\n",
      "Epoch 23/300\n",
      "1606/1606 [==============================] - 0s 179us/sample - loss: 0.6540 - accuracy: 0.6146 - val_loss: 0.6852 - val_accuracy: 0.5561\n",
      "Epoch 24/300\n",
      "1606/1606 [==============================] - 0s 167us/sample - loss: 0.6582 - accuracy: 0.6021 - val_loss: 0.6846 - val_accuracy: 0.5610\n",
      "Epoch 25/300\n",
      "1606/1606 [==============================] - 0s 165us/sample - loss: 0.6557 - accuracy: 0.6034 - val_loss: 0.6839 - val_accuracy: 0.5610\n",
      "Epoch 26/300\n",
      "1606/1606 [==============================] - 0s 171us/sample - loss: 0.6559 - accuracy: 0.6009 - val_loss: 0.6834 - val_accuracy: 0.5610\n",
      "Epoch 27/300\n",
      "1606/1606 [==============================] - 0s 164us/sample - loss: 0.6518 - accuracy: 0.6202 - val_loss: 0.6827 - val_accuracy: 0.5659\n",
      "Epoch 28/300\n",
      "1606/1606 [==============================] - 0s 158us/sample - loss: 0.6504 - accuracy: 0.6152 - val_loss: 0.6823 - val_accuracy: 0.5683\n",
      "Epoch 29/300\n",
      "1606/1606 [==============================] - 0s 163us/sample - loss: 0.6482 - accuracy: 0.6196 - val_loss: 0.6817 - val_accuracy: 0.5707\n",
      "Epoch 30/300\n",
      "1606/1606 [==============================] - 0s 164us/sample - loss: 0.6512 - accuracy: 0.6196 - val_loss: 0.6812 - val_accuracy: 0.5756\n",
      "Epoch 31/300\n",
      "1606/1606 [==============================] - 0s 176us/sample - loss: 0.6458 - accuracy: 0.6258 - val_loss: 0.6806 - val_accuracy: 0.5780\n",
      "Epoch 32/300\n",
      "1606/1606 [==============================] - 0s 169us/sample - loss: 0.6438 - accuracy: 0.6308 - val_loss: 0.6801 - val_accuracy: 0.5780\n",
      "Epoch 33/300\n",
      "1606/1606 [==============================] - 0s 172us/sample - loss: 0.6449 - accuracy: 0.6245 - val_loss: 0.6796 - val_accuracy: 0.5780\n",
      "Epoch 34/300\n",
      "1606/1606 [==============================] - 0s 166us/sample - loss: 0.6467 - accuracy: 0.6214 - val_loss: 0.6791 - val_accuracy: 0.5756\n",
      "Epoch 35/300\n",
      "1606/1606 [==============================] - 0s 157us/sample - loss: 0.6417 - accuracy: 0.6308 - val_loss: 0.6785 - val_accuracy: 0.5756\n",
      "Epoch 36/300\n",
      "1606/1606 [==============================] - 0s 161us/sample - loss: 0.6423 - accuracy: 0.6183 - val_loss: 0.6780 - val_accuracy: 0.5780\n",
      "Epoch 37/300\n",
      "1606/1606 [==============================] - 0s 180us/sample - loss: 0.6399 - accuracy: 0.6233 - val_loss: 0.6775 - val_accuracy: 0.5756\n",
      "Epoch 38/300\n",
      "1606/1606 [==============================] - 0s 186us/sample - loss: 0.6429 - accuracy: 0.6276 - val_loss: 0.6770 - val_accuracy: 0.5756\n",
      "Epoch 39/300\n",
      "1606/1606 [==============================] - 0s 174us/sample - loss: 0.6354 - accuracy: 0.6314 - val_loss: 0.6766 - val_accuracy: 0.5780\n",
      "Epoch 40/300\n",
      "1606/1606 [==============================] - 0s 168us/sample - loss: 0.6371 - accuracy: 0.6301 - val_loss: 0.6761 - val_accuracy: 0.5756\n",
      "Epoch 41/300\n",
      "1606/1606 [==============================] - 0s 167us/sample - loss: 0.6329 - accuracy: 0.6426 - val_loss: 0.6756 - val_accuracy: 0.5756\n",
      "Epoch 42/300\n",
      "1606/1606 [==============================] - 0s 161us/sample - loss: 0.6370 - accuracy: 0.6333 - val_loss: 0.6752 - val_accuracy: 0.5756\n",
      "Epoch 43/300\n",
      "1606/1606 [==============================] - 0s 161us/sample - loss: 0.6319 - accuracy: 0.6382 - val_loss: 0.6747 - val_accuracy: 0.5756\n",
      "Epoch 44/300\n",
      "1606/1606 [==============================] - 0s 163us/sample - loss: 0.6287 - accuracy: 0.6501 - val_loss: 0.6742 - val_accuracy: 0.5756\n",
      "Epoch 45/300\n",
      "1606/1606 [==============================] - 0s 161us/sample - loss: 0.6284 - accuracy: 0.6550 - val_loss: 0.6738 - val_accuracy: 0.5780\n",
      "Epoch 46/300\n",
      "1606/1606 [==============================] - 0s 162us/sample - loss: 0.6324 - accuracy: 0.6376 - val_loss: 0.6733 - val_accuracy: 0.5780\n",
      "Epoch 47/300\n",
      "1606/1606 [==============================] - 0s 159us/sample - loss: 0.6295 - accuracy: 0.6445 - val_loss: 0.6729 - val_accuracy: 0.5780\n",
      "Epoch 48/300\n",
      "1606/1606 [==============================] - 0s 187us/sample - loss: 0.6249 - accuracy: 0.6532 - val_loss: 0.6724 - val_accuracy: 0.5829\n",
      "Epoch 49/300\n",
      "1606/1606 [==============================] - 0s 170us/sample - loss: 0.6297 - accuracy: 0.6463 - val_loss: 0.6720 - val_accuracy: 0.5829\n",
      "Epoch 50/300\n",
      "1606/1606 [==============================] - 0s 170us/sample - loss: 0.6247 - accuracy: 0.6494 - val_loss: 0.6716 - val_accuracy: 0.5854\n",
      "Epoch 51/300\n",
      "1606/1606 [==============================] - 0s 183us/sample - loss: 0.6243 - accuracy: 0.6526 - val_loss: 0.6712 - val_accuracy: 0.5854\n",
      "Epoch 52/300\n",
      "1606/1606 [==============================] - 0s 185us/sample - loss: 0.6306 - accuracy: 0.6550 - val_loss: 0.6708 - val_accuracy: 0.5854\n",
      "Epoch 53/300\n",
      "1606/1606 [==============================] - 0s 172us/sample - loss: 0.6227 - accuracy: 0.6575 - val_loss: 0.6704 - val_accuracy: 0.5829\n",
      "Epoch 54/300\n",
      "1606/1606 [==============================] - 0s 159us/sample - loss: 0.6236 - accuracy: 0.6538 - val_loss: 0.6700 - val_accuracy: 0.5829\n",
      "Epoch 55/300\n",
      "1606/1606 [==============================] - 0s 163us/sample - loss: 0.6171 - accuracy: 0.6600 - val_loss: 0.6695 - val_accuracy: 0.5780\n",
      "Epoch 56/300\n",
      "1606/1606 [==============================] - 0s 167us/sample - loss: 0.6228 - accuracy: 0.6600 - val_loss: 0.6691 - val_accuracy: 0.5829\n",
      "Epoch 57/300\n",
      "1606/1606 [==============================] - 0s 164us/sample - loss: 0.6184 - accuracy: 0.6663 - val_loss: 0.6688 - val_accuracy: 0.5829\n",
      "Epoch 58/300\n",
      "1606/1606 [==============================] - 0s 189us/sample - loss: 0.6198 - accuracy: 0.6631 - val_loss: 0.6684 - val_accuracy: 0.5878\n",
      "Epoch 59/300\n",
      "1606/1606 [==============================] - 0s 176us/sample - loss: 0.6180 - accuracy: 0.6656 - val_loss: 0.6681 - val_accuracy: 0.5878\n",
      "Epoch 60/300\n",
      "1606/1606 [==============================] - 0s 187us/sample - loss: 0.6148 - accuracy: 0.6569 - val_loss: 0.6677 - val_accuracy: 0.5927\n",
      "Epoch 61/300\n",
      "1606/1606 [==============================] - 0s 171us/sample - loss: 0.6103 - accuracy: 0.6706 - val_loss: 0.6674 - val_accuracy: 0.5976\n",
      "Epoch 62/300\n",
      "1606/1606 [==============================] - 0s 175us/sample - loss: 0.6105 - accuracy: 0.6719 - val_loss: 0.6670 - val_accuracy: 0.5951\n",
      "Epoch 63/300\n",
      "1606/1606 [==============================] - 0s 173us/sample - loss: 0.6119 - accuracy: 0.6681 - val_loss: 0.6666 - val_accuracy: 0.5951\n",
      "Epoch 64/300\n",
      "1606/1606 [==============================] - 0s 176us/sample - loss: 0.6088 - accuracy: 0.6768 - val_loss: 0.6663 - val_accuracy: 0.5927\n",
      "Epoch 65/300\n",
      "1606/1606 [==============================] - 0s 177us/sample - loss: 0.6107 - accuracy: 0.6737 - val_loss: 0.6659 - val_accuracy: 0.5902\n",
      "Epoch 66/300\n",
      "1606/1606 [==============================] - 0s 175us/sample - loss: 0.6042 - accuracy: 0.6806 - val_loss: 0.6655 - val_accuracy: 0.5951\n",
      "Epoch 67/300\n",
      "1606/1606 [==============================] - 0s 164us/sample - loss: 0.6015 - accuracy: 0.6800 - val_loss: 0.6652 - val_accuracy: 0.5927\n",
      "Epoch 68/300\n",
      "1606/1606 [==============================] - 0s 157us/sample - loss: 0.6034 - accuracy: 0.6800 - val_loss: 0.6648 - val_accuracy: 0.5951\n",
      "Epoch 69/300\n",
      "1606/1606 [==============================] - 0s 156us/sample - loss: 0.6024 - accuracy: 0.6806 - val_loss: 0.6645 - val_accuracy: 0.5951\n",
      "Epoch 70/300\n",
      "1606/1606 [==============================] - 0s 171us/sample - loss: 0.6016 - accuracy: 0.6849 - val_loss: 0.6642 - val_accuracy: 0.5951\n",
      "Epoch 71/300\n",
      "1606/1606 [==============================] - 0s 163us/sample - loss: 0.6050 - accuracy: 0.6743 - val_loss: 0.6638 - val_accuracy: 0.6000\n",
      "Epoch 72/300\n",
      "1606/1606 [==============================] - 0s 161us/sample - loss: 0.6013 - accuracy: 0.6824 - val_loss: 0.6636 - val_accuracy: 0.6024\n",
      "Epoch 73/300\n",
      "1606/1606 [==============================] - 0s 171us/sample - loss: 0.5973 - accuracy: 0.6918 - val_loss: 0.6633 - val_accuracy: 0.6024\n",
      "Epoch 74/300\n",
      "1606/1606 [==============================] - 0s 163us/sample - loss: 0.5974 - accuracy: 0.6918 - val_loss: 0.6629 - val_accuracy: 0.6049\n",
      "Epoch 75/300\n",
      "1606/1606 [==============================] - 0s 172us/sample - loss: 0.5982 - accuracy: 0.6955 - val_loss: 0.6626 - val_accuracy: 0.6049\n",
      "Epoch 76/300\n",
      "1606/1606 [==============================] - 0s 186us/sample - loss: 0.5970 - accuracy: 0.6880 - val_loss: 0.6623 - val_accuracy: 0.6049\n",
      "Epoch 77/300\n",
      "1606/1606 [==============================] - 0s 168us/sample - loss: 0.5970 - accuracy: 0.6762 - val_loss: 0.6620 - val_accuracy: 0.6049\n",
      "Epoch 78/300\n",
      "1606/1606 [==============================] - 0s 177us/sample - loss: 0.5971 - accuracy: 0.6955 - val_loss: 0.6617 - val_accuracy: 0.6024\n",
      "Epoch 79/300\n",
      "1606/1606 [==============================] - 0s 172us/sample - loss: 0.5926 - accuracy: 0.6980 - val_loss: 0.6614 - val_accuracy: 0.6049\n",
      "Epoch 80/300\n",
      "1606/1606 [==============================] - 0s 175us/sample - loss: 0.5937 - accuracy: 0.6893 - val_loss: 0.6610 - val_accuracy: 0.6049\n",
      "Epoch 81/300\n",
      "1606/1606 [==============================] - 0s 163us/sample - loss: 0.5880 - accuracy: 0.6930 - val_loss: 0.6607 - val_accuracy: 0.6049\n",
      "Epoch 82/300\n",
      "1606/1606 [==============================] - 0s 166us/sample - loss: 0.5896 - accuracy: 0.6961 - val_loss: 0.6604 - val_accuracy: 0.6024\n",
      "Epoch 83/300\n",
      "1606/1606 [==============================] - 0s 156us/sample - loss: 0.5907 - accuracy: 0.6930 - val_loss: 0.6601 - val_accuracy: 0.6024\n",
      "Epoch 84/300\n",
      "1606/1606 [==============================] - 0s 164us/sample - loss: 0.5936 - accuracy: 0.6880 - val_loss: 0.6598 - val_accuracy: 0.6000\n",
      "Epoch 85/300\n",
      "1606/1606 [==============================] - 0s 163us/sample - loss: 0.5903 - accuracy: 0.6936 - val_loss: 0.6595 - val_accuracy: 0.6000\n",
      "Epoch 86/300\n",
      "1606/1606 [==============================] - 0s 160us/sample - loss: 0.5812 - accuracy: 0.7061 - val_loss: 0.6592 - val_accuracy: 0.6024\n",
      "Epoch 87/300\n",
      "1606/1606 [==============================] - 0s 158us/sample - loss: 0.5808 - accuracy: 0.7067 - val_loss: 0.6589 - val_accuracy: 0.6024\n",
      "Epoch 88/300\n",
      "1606/1606 [==============================] - 0s 158us/sample - loss: 0.5781 - accuracy: 0.7123 - val_loss: 0.6586 - val_accuracy: 0.6024\n",
      "Epoch 89/300\n",
      "1606/1606 [==============================] - 0s 168us/sample - loss: 0.5846 - accuracy: 0.6924 - val_loss: 0.6583 - val_accuracy: 0.6049\n",
      "Epoch 90/300\n",
      "1606/1606 [==============================] - 0s 167us/sample - loss: 0.5769 - accuracy: 0.7186 - val_loss: 0.6580 - val_accuracy: 0.6049\n",
      "Epoch 91/300\n",
      "1606/1606 [==============================] - 0s 177us/sample - loss: 0.5817 - accuracy: 0.7036 - val_loss: 0.6577 - val_accuracy: 0.6049\n",
      "Epoch 92/300\n",
      "1606/1606 [==============================] - 0s 179us/sample - loss: 0.5784 - accuracy: 0.7080 - val_loss: 0.6575 - val_accuracy: 0.6049\n",
      "Epoch 93/300\n",
      "1606/1606 [==============================] - 0s 166us/sample - loss: 0.5812 - accuracy: 0.7092 - val_loss: 0.6571 - val_accuracy: 0.6049\n",
      "Epoch 94/300\n",
      "1606/1606 [==============================] - 0s 177us/sample - loss: 0.5739 - accuracy: 0.7111 - val_loss: 0.6569 - val_accuracy: 0.6049\n",
      "Epoch 95/300\n",
      "1606/1606 [==============================] - 0s 170us/sample - loss: 0.5706 - accuracy: 0.7167 - val_loss: 0.6566 - val_accuracy: 0.6049\n",
      "Epoch 96/300\n",
      "1606/1606 [==============================] - 0s 172us/sample - loss: 0.5724 - accuracy: 0.7117 - val_loss: 0.6564 - val_accuracy: 0.6049\n",
      "Epoch 97/300\n",
      "1606/1606 [==============================] - 0s 159us/sample - loss: 0.5727 - accuracy: 0.7148 - val_loss: 0.6561 - val_accuracy: 0.6000\n",
      "Epoch 98/300\n",
      "1606/1606 [==============================] - 0s 160us/sample - loss: 0.5718 - accuracy: 0.7148 - val_loss: 0.6558 - val_accuracy: 0.6000\n",
      "Epoch 99/300\n",
      "1606/1606 [==============================] - 0s 157us/sample - loss: 0.5692 - accuracy: 0.7148 - val_loss: 0.6556 - val_accuracy: 0.6000\n",
      "Epoch 100/300\n",
      "1606/1606 [==============================] - 0s 160us/sample - loss: 0.5716 - accuracy: 0.7105 - val_loss: 0.6554 - val_accuracy: 0.5976\n",
      "Epoch 101/300\n",
      "1606/1606 [==============================] - 0s 160us/sample - loss: 0.5648 - accuracy: 0.7254 - val_loss: 0.6551 - val_accuracy: 0.6000\n",
      "Epoch 102/300\n",
      "1606/1606 [==============================] - 0s 172us/sample - loss: 0.5705 - accuracy: 0.7179 - val_loss: 0.6549 - val_accuracy: 0.6000\n",
      "Epoch 103/300\n",
      "1606/1606 [==============================] - 0s 183us/sample - loss: 0.5658 - accuracy: 0.7248 - val_loss: 0.6546 - val_accuracy: 0.6000\n",
      "Epoch 104/300\n",
      "1606/1606 [==============================] - 0s 189us/sample - loss: 0.5592 - accuracy: 0.7329 - val_loss: 0.6545 - val_accuracy: 0.6000\n",
      "Epoch 105/300\n",
      "1606/1606 [==============================] - 0s 175us/sample - loss: 0.5666 - accuracy: 0.7130 - val_loss: 0.6542 - val_accuracy: 0.6000\n",
      "Epoch 106/300\n",
      "1606/1606 [==============================] - 0s 176us/sample - loss: 0.5534 - accuracy: 0.7379 - val_loss: 0.6541 - val_accuracy: 0.6024\n",
      "Epoch 107/300\n",
      "1606/1606 [==============================] - 0s 175us/sample - loss: 0.5603 - accuracy: 0.7242 - val_loss: 0.6539 - val_accuracy: 0.6024\n",
      "Epoch 108/300\n",
      "1606/1606 [==============================] - 0s 166us/sample - loss: 0.5581 - accuracy: 0.7242 - val_loss: 0.6536 - val_accuracy: 0.6073\n",
      "Epoch 109/300\n",
      "1606/1606 [==============================] - 0s 164us/sample - loss: 0.5544 - accuracy: 0.7316 - val_loss: 0.6533 - val_accuracy: 0.6098\n",
      "Epoch 110/300\n",
      "1606/1606 [==============================] - 0s 161us/sample - loss: 0.5496 - accuracy: 0.7503 - val_loss: 0.6532 - val_accuracy: 0.6098\n",
      "Epoch 111/300\n",
      "1606/1606 [==============================] - 0s 173us/sample - loss: 0.5555 - accuracy: 0.7403 - val_loss: 0.6530 - val_accuracy: 0.6073\n",
      "Epoch 112/300\n",
      "1606/1606 [==============================] - 0s 165us/sample - loss: 0.5508 - accuracy: 0.7385 - val_loss: 0.6529 - val_accuracy: 0.6098\n",
      "Epoch 113/300\n",
      "1606/1606 [==============================] - 0s 168us/sample - loss: 0.5507 - accuracy: 0.7435 - val_loss: 0.6527 - val_accuracy: 0.6073\n",
      "Epoch 114/300\n",
      "1606/1606 [==============================] - 0s 166us/sample - loss: 0.5533 - accuracy: 0.7403 - val_loss: 0.6525 - val_accuracy: 0.6049\n",
      "Epoch 115/300\n",
      "1606/1606 [==============================] - 0s 181us/sample - loss: 0.5528 - accuracy: 0.7366 - val_loss: 0.6523 - val_accuracy: 0.6024\n",
      "Epoch 116/300\n",
      "1606/1606 [==============================] - 0s 181us/sample - loss: 0.5458 - accuracy: 0.7410 - val_loss: 0.6521 - val_accuracy: 0.6000\n",
      "Epoch 117/300\n",
      "1606/1606 [==============================] - 0s 177us/sample - loss: 0.5498 - accuracy: 0.7323 - val_loss: 0.6519 - val_accuracy: 0.6024\n",
      "Epoch 118/300\n",
      "1606/1606 [==============================] - 0s 184us/sample - loss: 0.5457 - accuracy: 0.7441 - val_loss: 0.6517 - val_accuracy: 0.6024\n",
      "Epoch 119/300\n",
      "1606/1606 [==============================] - 0s 173us/sample - loss: 0.5438 - accuracy: 0.7329 - val_loss: 0.6515 - val_accuracy: 0.6024\n",
      "Epoch 120/300\n",
      "1606/1606 [==============================] - 0s 178us/sample - loss: 0.5440 - accuracy: 0.7453 - val_loss: 0.6513 - val_accuracy: 0.6024\n",
      "Epoch 121/300\n",
      "1606/1606 [==============================] - 0s 178us/sample - loss: 0.5399 - accuracy: 0.7528 - val_loss: 0.6512 - val_accuracy: 0.6024\n",
      "Epoch 122/300\n",
      "1606/1606 [==============================] - 0s 164us/sample - loss: 0.5364 - accuracy: 0.7597 - val_loss: 0.6509 - val_accuracy: 0.6024\n",
      "Epoch 123/300\n",
      "1606/1606 [==============================] - 0s 167us/sample - loss: 0.5404 - accuracy: 0.7484 - val_loss: 0.6507 - val_accuracy: 0.6024\n",
      "Epoch 124/300\n",
      "1606/1606 [==============================] - 0s 167us/sample - loss: 0.5383 - accuracy: 0.7528 - val_loss: 0.6506 - val_accuracy: 0.6073\n",
      "Epoch 125/300\n",
      "1606/1606 [==============================] - 0s 177us/sample - loss: 0.5431 - accuracy: 0.7491 - val_loss: 0.6504 - val_accuracy: 0.6073\n",
      "Epoch 126/300\n",
      "1606/1606 [==============================] - 0s 179us/sample - loss: 0.5304 - accuracy: 0.7522 - val_loss: 0.6502 - val_accuracy: 0.6049\n",
      "Epoch 127/300\n",
      "1606/1606 [==============================] - 0s 192us/sample - loss: 0.5311 - accuracy: 0.7534 - val_loss: 0.6500 - val_accuracy: 0.6073\n",
      "Epoch 128/300\n",
      "1606/1606 [==============================] - 0s 183us/sample - loss: 0.5347 - accuracy: 0.7422 - val_loss: 0.6499 - val_accuracy: 0.6073\n",
      "Epoch 129/300\n",
      "1606/1606 [==============================] - 0s 173us/sample - loss: 0.5306 - accuracy: 0.7516 - val_loss: 0.6498 - val_accuracy: 0.6073\n",
      "Epoch 130/300\n",
      "1606/1606 [==============================] - 0s 167us/sample - loss: 0.5280 - accuracy: 0.7559 - val_loss: 0.6496 - val_accuracy: 0.6098\n",
      "Epoch 131/300\n",
      "1606/1606 [==============================] - 0s 190us/sample - loss: 0.5246 - accuracy: 0.7634 - val_loss: 0.6495 - val_accuracy: 0.6098\n",
      "Epoch 132/300\n",
      "1606/1606 [==============================] - 0s 178us/sample - loss: 0.5269 - accuracy: 0.7590 - val_loss: 0.6494 - val_accuracy: 0.6098\n",
      "Epoch 133/300\n",
      "1606/1606 [==============================] - 0s 169us/sample - loss: 0.5269 - accuracy: 0.7534 - val_loss: 0.6493 - val_accuracy: 0.6122\n",
      "Epoch 134/300\n",
      "1606/1606 [==============================] - 0s 163us/sample - loss: 0.5256 - accuracy: 0.7590 - val_loss: 0.6491 - val_accuracy: 0.6146\n",
      "Epoch 135/300\n",
      "1606/1606 [==============================] - 0s 172us/sample - loss: 0.5239 - accuracy: 0.7621 - val_loss: 0.6491 - val_accuracy: 0.6146\n",
      "Epoch 136/300\n",
      "1606/1606 [==============================] - 0s 177us/sample - loss: 0.5249 - accuracy: 0.7696 - val_loss: 0.6490 - val_accuracy: 0.6146\n",
      "Epoch 137/300\n",
      "1606/1606 [==============================] - 0s 178us/sample - loss: 0.5186 - accuracy: 0.7746 - val_loss: 0.6489 - val_accuracy: 0.6122\n",
      "Epoch 138/300\n",
      "1606/1606 [==============================] - 0s 178us/sample - loss: 0.5227 - accuracy: 0.7715 - val_loss: 0.6489 - val_accuracy: 0.6122\n",
      "Epoch 139/300\n",
      "1606/1606 [==============================] - 0s 179us/sample - loss: 0.5210 - accuracy: 0.7553 - val_loss: 0.6489 - val_accuracy: 0.6098\n",
      "Epoch 140/300\n",
      "1606/1606 [==============================] - 0s 181us/sample - loss: 0.5126 - accuracy: 0.7709 - val_loss: 0.6487 - val_accuracy: 0.6098\n",
      "Epoch 141/300\n",
      "1606/1606 [==============================] - 0s 163us/sample - loss: 0.5126 - accuracy: 0.7659 - val_loss: 0.6486 - val_accuracy: 0.6122\n",
      "Epoch 142/300\n",
      "1606/1606 [==============================] - 0s 163us/sample - loss: 0.5148 - accuracy: 0.7646 - val_loss: 0.6486 - val_accuracy: 0.6122\n",
      "Epoch 143/300\n",
      "1606/1606 [==============================] - 0s 162us/sample - loss: 0.5135 - accuracy: 0.7578 - val_loss: 0.6485 - val_accuracy: 0.6146\n",
      "Epoch 144/300\n",
      "1606/1606 [==============================] - 0s 159us/sample - loss: 0.5142 - accuracy: 0.7790 - val_loss: 0.6485 - val_accuracy: 0.6171\n",
      "Epoch 145/300\n",
      "1606/1606 [==============================] - 0s 159us/sample - loss: 0.5098 - accuracy: 0.7821 - val_loss: 0.6484 - val_accuracy: 0.6195\n",
      "Epoch 146/300\n",
      "1606/1606 [==============================] - 0s 159us/sample - loss: 0.5090 - accuracy: 0.7653 - val_loss: 0.6484 - val_accuracy: 0.6195\n",
      "Epoch 147/300\n",
      "1606/1606 [==============================] - 0s 161us/sample - loss: 0.5115 - accuracy: 0.7758 - val_loss: 0.6482 - val_accuracy: 0.6195\n",
      "Epoch 148/300\n",
      "1606/1606 [==============================] - 0s 166us/sample - loss: 0.5094 - accuracy: 0.7758 - val_loss: 0.6482 - val_accuracy: 0.6171\n",
      "Epoch 149/300\n",
      "1606/1606 [==============================] - 0s 164us/sample - loss: 0.5049 - accuracy: 0.7777 - val_loss: 0.6481 - val_accuracy: 0.6171\n",
      "Epoch 150/300\n",
      "1606/1606 [==============================] - 0s 164us/sample - loss: 0.5039 - accuracy: 0.7740 - val_loss: 0.6480 - val_accuracy: 0.6220\n",
      "Epoch 151/300\n",
      "1606/1606 [==============================] - 0s 162us/sample - loss: 0.4994 - accuracy: 0.7696 - val_loss: 0.6480 - val_accuracy: 0.6244\n",
      "Epoch 152/300\n",
      "1606/1606 [==============================] - 0s 158us/sample - loss: 0.4993 - accuracy: 0.7864 - val_loss: 0.6479 - val_accuracy: 0.6244\n",
      "Epoch 153/300\n",
      "1606/1606 [==============================] - 0s 160us/sample - loss: 0.5062 - accuracy: 0.7709 - val_loss: 0.6479 - val_accuracy: 0.6244\n",
      "Epoch 154/300\n",
      "1606/1606 [==============================] - 0s 171us/sample - loss: 0.5076 - accuracy: 0.7727 - val_loss: 0.6479 - val_accuracy: 0.6244\n",
      "Epoch 155/300\n",
      "1606/1606 [==============================] - 0s 169us/sample - loss: 0.4950 - accuracy: 0.7839 - val_loss: 0.6479 - val_accuracy: 0.6244\n",
      "Epoch 156/300\n",
      "1606/1606 [==============================] - 0s 174us/sample - loss: 0.4951 - accuracy: 0.7902 - val_loss: 0.6479 - val_accuracy: 0.6244\n",
      "Epoch 157/300\n",
      "1606/1606 [==============================] - 0s 176us/sample - loss: 0.4997 - accuracy: 0.7715 - val_loss: 0.6478 - val_accuracy: 0.6244\n",
      "Epoch 158/300\n",
      "1606/1606 [==============================] - 0s 194us/sample - loss: 0.4947 - accuracy: 0.7821 - val_loss: 0.6479 - val_accuracy: 0.6220\n",
      "Epoch 159/300\n",
      "1606/1606 [==============================] - 0s 189us/sample - loss: 0.4945 - accuracy: 0.7858 - val_loss: 0.6480 - val_accuracy: 0.6244\n",
      "Epoch 160/300\n",
      "1606/1606 [==============================] - 0s 173us/sample - loss: 0.4913 - accuracy: 0.7870 - val_loss: 0.6479 - val_accuracy: 0.6244\n",
      "Epoch 00160: early stopping\n",
      "223/223 [==============================] - 0s 80us/sample - loss: 0.6525 - accuracy: 0.6457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [37:00, 748.73s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:05<00:05,  5.93s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.38s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "6it [00:00, 49.51it/s]\u001b[A\n",
      "12it [00:00, 50.73it/s]\u001b[A\n",
      "16it [00:00, 43.65it/s]\u001b[A\n",
      "19it [00:00, 37.14it/s]\u001b[A\n",
      "24it [00:00, 39.58it/s]\u001b[A\n",
      "28it [00:00, 34.45it/s]\u001b[A\n",
      "32it [00:00, 35.24it/s]\u001b[A\n",
      "37it [00:00, 38.40it/s]\u001b[A\n",
      "41it [00:01, 36.32it/s]\u001b[A\n",
      "45it [00:01, 35.20it/s]\u001b[A\n",
      "49it [00:01, 36.36it/s]\u001b[A\n",
      "53it [00:01, 35.12it/s]\u001b[A\n",
      "58it [00:01, 35.84it/s]\u001b[A\n",
      "62it [00:01, 34.15it/s]\u001b[A\n",
      "66it [00:01, 35.04it/s]\u001b[A\n",
      "72it [00:01, 37.97it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 72/72 [00:00<00:00, 2320.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 517.8203125 steps, validate for 133.21875 steps\n",
      "Epoch 1/300\n",
      "518/517 [==============================] - 15s 29ms/step - loss: 0.6925 - accuracy: 0.5749 - val_loss: 0.6630 - val_accuracy: 0.5964\n",
      "Epoch 2/300\n",
      "518/517 [==============================] - 14s 27ms/step - loss: 0.6368 - accuracy: 0.6265 - val_loss: 0.6477 - val_accuracy: 0.6172\n",
      "Epoch 3/300\n",
      "518/517 [==============================] - 14s 27ms/step - loss: 0.6218 - accuracy: 0.6455 - val_loss: 0.6412 - val_accuracy: 0.6241\n",
      "Epoch 4/300\n",
      "518/517 [==============================] - 14s 27ms/step - loss: 0.6107 - accuracy: 0.6577 - val_loss: 0.6350 - val_accuracy: 0.6338\n",
      "Epoch 5/300\n",
      "518/517 [==============================] - 14s 27ms/step - loss: 0.6014 - accuracy: 0.6680 - val_loss: 0.6294 - val_accuracy: 0.6396\n",
      "Epoch 6/300\n",
      "518/517 [==============================] - 14s 27ms/step - loss: 0.5931 - accuracy: 0.6748 - val_loss: 0.6290 - val_accuracy: 0.6417\n",
      "Epoch 7/300\n",
      "518/517 [==============================] - 14s 27ms/step - loss: 0.5860 - accuracy: 0.6825 - val_loss: 0.6308 - val_accuracy: 0.6378\n",
      "Epoch 8/300\n",
      "518/517 [==============================] - 14s 27ms/step - loss: 0.5795 - accuracy: 0.6883 - val_loss: 0.6279 - val_accuracy: 0.6412\n",
      "Epoch 9/300\n",
      "518/517 [==============================] - 14s 27ms/step - loss: 0.5735 - accuracy: 0.6938 - val_loss: 0.6279 - val_accuracy: 0.6423\n",
      "Epoch 10/300\n",
      "518/517 [==============================] - 14s 27ms/step - loss: 0.5680 - accuracy: 0.6999 - val_loss: 0.6292 - val_accuracy: 0.6466\n",
      "Epoch 11/300\n",
      "518/517 [==============================] - 14s 27ms/step - loss: 0.5627 - accuracy: 0.7056 - val_loss: 0.6294 - val_accuracy: 0.6446\n",
      "Epoch 12/300\n",
      "518/517 [==============================] - 14s 27ms/step - loss: 0.5577 - accuracy: 0.7094 - val_loss: 0.6306 - val_accuracy: 0.6454\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 517.8203125 steps, validate for 133.21875 steps\n",
      "Epoch 1/300\n",
      "518/517 [==============================] - 34s 66ms/step - loss: 0.5492 - accuracy: 0.7168 - val_loss: 0.6485 - val_accuracy: 0.6213\n",
      "Epoch 2/300\n",
      "518/517 [==============================] - 33s 63ms/step - loss: 0.5296 - accuracy: 0.7336 - val_loss: 0.6334 - val_accuracy: 0.6437\n",
      "Epoch 3/300\n",
      "518/517 [==============================] - 32s 63ms/step - loss: 0.5133 - accuracy: 0.7475 - val_loss: 0.6335 - val_accuracy: 0.6453\n",
      "Epoch 4/300\n",
      "518/517 [==============================] - 33s 63ms/step - loss: 0.4990 - accuracy: 0.7602 - val_loss: 0.6409 - val_accuracy: 0.6464\n",
      "Epoch 5/300\n",
      "518/517 [==============================] - 32s 62ms/step - loss: 0.4858 - accuracy: 0.7709 - val_loss: 0.6328 - val_accuracy: 0.6567\n",
      "Epoch 6/300\n",
      "518/517 [==============================] - 32s 63ms/step - loss: 0.4741 - accuracy: 0.7793 - val_loss: 0.6277 - val_accuracy: 0.6605\n",
      "Epoch 7/300\n",
      "518/517 [==============================] - 33s 63ms/step - loss: 0.4616 - accuracy: 0.7886 - val_loss: 0.6617 - val_accuracy: 0.6319\n",
      "Epoch 8/300\n",
      "518/517 [==============================] - 33s 63ms/step - loss: 0.4496 - accuracy: 0.7965 - val_loss: 0.6481 - val_accuracy: 0.6598\n",
      "Epoch 9/300\n",
      "518/517 [==============================] - 33s 63ms/step - loss: 0.4387 - accuracy: 0.8047 - val_loss: 0.6120 - val_accuracy: 0.6699\n",
      "Epoch 10/300\n",
      "518/517 [==============================] - 33s 63ms/step - loss: 0.4273 - accuracy: 0.8120 - val_loss: 0.6455 - val_accuracy: 0.6609\n",
      "Epoch 11/300\n",
      "518/517 [==============================] - 33s 63ms/step - loss: 0.4163 - accuracy: 0.8200 - val_loss: 0.6506 - val_accuracy: 0.6527\n",
      "Epoch 12/300\n",
      "518/517 [==============================] - 32s 63ms/step - loss: 0.4060 - accuracy: 0.8269 - val_loss: 0.6468 - val_accuracy: 0.6593\n",
      "Epoch 00012: early stopping\n",
      "306/306 [==============================] - 0s 929us/sample - loss: 1.7580 - accuracy: 0.2908\n",
      "287/287 [==============================] - 0s 194us/sample - loss: 1.5097 - accuracy: 0.3171\n",
      "283/283 [==============================] - 0s 198us/sample - loss: 1.4358 - accuracy: 0.3640\n",
      "281/281 [==============================] - 0s 213us/sample - loss: 1.5503 - accuracy: 0.2954\n",
      "273/273 [==============================] - 0s 210us/sample - loss: 1.5286 - accuracy: 0.3187\n",
      "266/266 [==============================] - 0s 224us/sample - loss: 1.5831 - accuracy: 0.3008\n",
      "265/265 [==============================] - 0s 212us/sample - loss: 1.6171 - accuracy: 0.3132\n",
      "262/262 [==============================] - 0s 222us/sample - loss: 1.6005 - accuracy: 0.3053\n",
      "254/254 [==============================] - 0s 238us/sample - loss: 1.5300 - accuracy: 0.3150\n",
      "248/248 [==============================] - 0s 244us/sample - loss: 1.5707 - accuracy: 0.3669\n",
      "245/245 [==============================] - 0s 225us/sample - loss: 1.5201 - accuracy: 0.3306\n",
      "247/247 [==============================] - 0s 231us/sample - loss: 1.5960 - accuracy: 0.3077\n",
      "243/243 [==============================] - 0s 255us/sample - loss: 1.6436 - accuracy: 0.3539\n",
      "243/243 [==============================] - 0s 243us/sample - loss: 1.4570 - accuracy: 0.3704\n",
      "242/242 [==============================] - 0s 244us/sample - loss: 1.4903 - accuracy: 0.3678\n",
      "243/243 [==============================] - 0s 261us/sample - loss: 1.5167 - accuracy: 0.3539\n",
      "237/237 [==============================] - 0s 270us/sample - loss: 1.6004 - accuracy: 0.2869\n",
      "240/240 [==============================] - 0s 220us/sample - loss: 1.4390 - accuracy: 0.3458\n",
      "235/235 [==============================] - 0s 589us/sample - loss: 1.5810 - accuracy: 0.3149\n",
      "232/232 [==============================] - 0s 213us/sample - loss: 1.5222 - accuracy: 0.3103\n",
      "232/232 [==============================] - 0s 219us/sample - loss: 1.5693 - accuracy: 0.3362\n",
      "227/227 [==============================] - 0s 213us/sample - loss: 1.5365 - accuracy: 0.3480\n",
      "224/224 [==============================] - 0s 1ms/sample - loss: 1.5737 - accuracy: 0.3304\n",
      "223/223 [==============================] - 0s 212us/sample - loss: 1.6330 - accuracy: 0.3453\n",
      "223/223 [==============================] - 0s 255us/sample - loss: 1.4822 - accuracy: 0.3498\n",
      "219/219 [==============================] - 0s 217us/sample - loss: 1.4161 - accuracy: 0.3562\n",
      "220/220 [==============================] - 0s 217us/sample - loss: 1.4368 - accuracy: 0.3727\n",
      "215/215 [==============================] - 0s 205us/sample - loss: 1.4707 - accuracy: 0.3767\n",
      "216/216 [==============================] - 0s 209us/sample - loss: 1.5530 - accuracy: 0.3426\n",
      "216/216 [==============================] - 0s 220us/sample - loss: 1.5101 - accuracy: 0.3519\n",
      "215/215 [==============================] - 0s 228us/sample - loss: 1.5838 - accuracy: 0.3070\n",
      "214/214 [==============================] - 0s 207us/sample - loss: 1.5356 - accuracy: 0.3318\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 1621 samples, validate on 421 samples\n",
      "Epoch 1/300\n",
      "1621/1621 [==============================] - 2s 1ms/sample - loss: 0.6822 - accuracy: 0.5645 - val_loss: 0.6946 - val_accuracy: 0.5273\n",
      "Epoch 2/300\n",
      "1621/1621 [==============================] - 0s 214us/sample - loss: 0.6639 - accuracy: 0.6002 - val_loss: 0.6847 - val_accuracy: 0.5416\n",
      "Epoch 3/300\n",
      "1621/1621 [==============================] - 0s 184us/sample - loss: 0.6494 - accuracy: 0.6169 - val_loss: 0.6776 - val_accuracy: 0.5653\n",
      "Epoch 4/300\n",
      "1621/1621 [==============================] - 0s 191us/sample - loss: 0.6370 - accuracy: 0.6403 - val_loss: 0.6717 - val_accuracy: 0.5653\n",
      "Epoch 5/300\n",
      "1621/1621 [==============================] - 0s 172us/sample - loss: 0.6312 - accuracy: 0.6490 - val_loss: 0.6667 - val_accuracy: 0.5724\n",
      "Epoch 6/300\n",
      "1621/1621 [==============================] - 0s 180us/sample - loss: 0.6271 - accuracy: 0.6539 - val_loss: 0.6623 - val_accuracy: 0.5772\n",
      "Epoch 7/300\n",
      "1621/1621 [==============================] - 0s 175us/sample - loss: 0.6172 - accuracy: 0.6823 - val_loss: 0.6583 - val_accuracy: 0.5891\n",
      "Epoch 8/300\n",
      "1621/1621 [==============================] - 0s 172us/sample - loss: 0.6149 - accuracy: 0.6743 - val_loss: 0.6547 - val_accuracy: 0.6010\n",
      "Epoch 9/300\n",
      "1621/1621 [==============================] - 0s 177us/sample - loss: 0.6045 - accuracy: 0.6866 - val_loss: 0.6513 - val_accuracy: 0.6128\n",
      "Epoch 10/300\n",
      "1621/1621 [==============================] - 0s 173us/sample - loss: 0.5978 - accuracy: 0.7002 - val_loss: 0.6480 - val_accuracy: 0.6152\n",
      "Epoch 11/300\n",
      "1621/1621 [==============================] - 0s 172us/sample - loss: 0.5995 - accuracy: 0.6903 - val_loss: 0.6451 - val_accuracy: 0.6200\n",
      "Epoch 12/300\n",
      "1621/1621 [==============================] - 0s 169us/sample - loss: 0.5947 - accuracy: 0.7008 - val_loss: 0.6423 - val_accuracy: 0.6247\n",
      "Epoch 13/300\n",
      "1621/1621 [==============================] - 0s 175us/sample - loss: 0.5891 - accuracy: 0.7076 - val_loss: 0.6397 - val_accuracy: 0.6247\n",
      "Epoch 14/300\n",
      "1621/1621 [==============================] - 0s 164us/sample - loss: 0.5826 - accuracy: 0.7150 - val_loss: 0.6372 - val_accuracy: 0.6223\n",
      "Epoch 15/300\n",
      "1621/1621 [==============================] - 0s 159us/sample - loss: 0.5788 - accuracy: 0.7304 - val_loss: 0.6348 - val_accuracy: 0.6295\n",
      "Epoch 16/300\n",
      "1621/1621 [==============================] - 0s 167us/sample - loss: 0.5788 - accuracy: 0.7218 - val_loss: 0.6325 - val_accuracy: 0.6342\n",
      "Epoch 17/300\n",
      "1621/1621 [==============================] - 0s 168us/sample - loss: 0.5730 - accuracy: 0.7310 - val_loss: 0.6302 - val_accuracy: 0.6366\n",
      "Epoch 18/300\n",
      "1621/1621 [==============================] - 0s 185us/sample - loss: 0.5706 - accuracy: 0.7273 - val_loss: 0.6282 - val_accuracy: 0.6366\n",
      "Epoch 19/300\n",
      "1621/1621 [==============================] - 0s 166us/sample - loss: 0.5660 - accuracy: 0.7329 - val_loss: 0.6260 - val_accuracy: 0.6413\n",
      "Epoch 20/300\n",
      "1621/1621 [==============================] - 0s 179us/sample - loss: 0.5612 - accuracy: 0.7323 - val_loss: 0.6241 - val_accuracy: 0.6390\n",
      "Epoch 21/300\n",
      "1621/1621 [==============================] - 0s 172us/sample - loss: 0.5570 - accuracy: 0.7539 - val_loss: 0.6221 - val_accuracy: 0.6413\n",
      "Epoch 22/300\n",
      "1621/1621 [==============================] - 0s 168us/sample - loss: 0.5567 - accuracy: 0.7514 - val_loss: 0.6202 - val_accuracy: 0.6485\n",
      "Epoch 23/300\n",
      "1621/1621 [==============================] - 0s 180us/sample - loss: 0.5500 - accuracy: 0.7563 - val_loss: 0.6183 - val_accuracy: 0.6532\n",
      "Epoch 24/300\n",
      "1621/1621 [==============================] - 0s 159us/sample - loss: 0.5436 - accuracy: 0.7650 - val_loss: 0.6165 - val_accuracy: 0.6603\n",
      "Epoch 25/300\n",
      "1621/1621 [==============================] - 0s 165us/sample - loss: 0.5459 - accuracy: 0.7569 - val_loss: 0.6149 - val_accuracy: 0.6627\n",
      "Epoch 26/300\n",
      "1621/1621 [==============================] - 0s 162us/sample - loss: 0.5409 - accuracy: 0.7705 - val_loss: 0.6132 - val_accuracy: 0.6722\n",
      "Epoch 27/300\n",
      "1621/1621 [==============================] - 0s 177us/sample - loss: 0.5388 - accuracy: 0.7717 - val_loss: 0.6115 - val_accuracy: 0.6746\n",
      "Epoch 28/300\n",
      "1621/1621 [==============================] - 0s 185us/sample - loss: 0.5357 - accuracy: 0.7699 - val_loss: 0.6099 - val_accuracy: 0.6770\n",
      "Epoch 29/300\n",
      "1621/1621 [==============================] - 0s 166us/sample - loss: 0.5280 - accuracy: 0.7804 - val_loss: 0.6083 - val_accuracy: 0.6793\n",
      "Epoch 30/300\n",
      "1621/1621 [==============================] - 0s 179us/sample - loss: 0.5301 - accuracy: 0.7668 - val_loss: 0.6067 - val_accuracy: 0.6746\n",
      "Epoch 31/300\n",
      "1621/1621 [==============================] - 0s 175us/sample - loss: 0.5250 - accuracy: 0.7822 - val_loss: 0.6053 - val_accuracy: 0.6793\n",
      "Epoch 32/300\n",
      "1621/1621 [==============================] - 0s 180us/sample - loss: 0.5186 - accuracy: 0.7859 - val_loss: 0.6038 - val_accuracy: 0.6793\n",
      "Epoch 33/300\n",
      "1621/1621 [==============================] - 0s 176us/sample - loss: 0.5131 - accuracy: 0.7933 - val_loss: 0.6023 - val_accuracy: 0.6817\n",
      "Epoch 34/300\n",
      "1621/1621 [==============================] - 0s 192us/sample - loss: 0.5124 - accuracy: 0.7909 - val_loss: 0.6010 - val_accuracy: 0.6841\n",
      "Epoch 35/300\n",
      "1621/1621 [==============================] - 0s 178us/sample - loss: 0.5114 - accuracy: 0.7829 - val_loss: 0.5996 - val_accuracy: 0.6817\n",
      "Epoch 36/300\n",
      "1621/1621 [==============================] - 0s 189us/sample - loss: 0.5092 - accuracy: 0.7970 - val_loss: 0.5982 - val_accuracy: 0.6841\n",
      "Epoch 37/300\n",
      "1621/1621 [==============================] - 0s 186us/sample - loss: 0.5036 - accuracy: 0.8106 - val_loss: 0.5969 - val_accuracy: 0.6865\n",
      "Epoch 38/300\n",
      "1621/1621 [==============================] - 0s 163us/sample - loss: 0.5008 - accuracy: 0.8014 - val_loss: 0.5956 - val_accuracy: 0.6912\n",
      "Epoch 39/300\n",
      "1621/1621 [==============================] - 0s 172us/sample - loss: 0.5033 - accuracy: 0.7890 - val_loss: 0.5943 - val_accuracy: 0.6912\n",
      "Epoch 40/300\n",
      "1621/1621 [==============================] - 0s 168us/sample - loss: 0.4953 - accuracy: 0.7989 - val_loss: 0.5931 - val_accuracy: 0.6936\n",
      "Epoch 41/300\n",
      "1621/1621 [==============================] - 0s 161us/sample - loss: 0.4919 - accuracy: 0.8020 - val_loss: 0.5919 - val_accuracy: 0.6960\n",
      "Epoch 42/300\n",
      "1621/1621 [==============================] - 0s 171us/sample - loss: 0.4883 - accuracy: 0.8038 - val_loss: 0.5906 - val_accuracy: 0.6936\n",
      "Epoch 43/300\n",
      "1621/1621 [==============================] - 0s 175us/sample - loss: 0.4837 - accuracy: 0.8149 - val_loss: 0.5894 - val_accuracy: 0.6960\n",
      "Epoch 44/300\n",
      "1621/1621 [==============================] - 0s 197us/sample - loss: 0.4848 - accuracy: 0.8051 - val_loss: 0.5883 - val_accuracy: 0.6983\n",
      "Epoch 45/300\n",
      "1621/1621 [==============================] - 0s 198us/sample - loss: 0.4829 - accuracy: 0.8026 - val_loss: 0.5871 - val_accuracy: 0.6983\n",
      "Epoch 46/300\n",
      "1621/1621 [==============================] - 0s 183us/sample - loss: 0.4764 - accuracy: 0.8155 - val_loss: 0.5861 - val_accuracy: 0.6983\n",
      "Epoch 47/300\n",
      "1621/1621 [==============================] - 0s 168us/sample - loss: 0.4752 - accuracy: 0.8236 - val_loss: 0.5850 - val_accuracy: 0.7007\n",
      "Epoch 48/300\n",
      "1621/1621 [==============================] - 0s 164us/sample - loss: 0.4715 - accuracy: 0.8199 - val_loss: 0.5840 - val_accuracy: 0.7007\n",
      "Epoch 49/300\n",
      "1621/1621 [==============================] - 0s 164us/sample - loss: 0.4664 - accuracy: 0.8267 - val_loss: 0.5829 - val_accuracy: 0.7007\n",
      "Epoch 50/300\n",
      "1621/1621 [==============================] - 0s 161us/sample - loss: 0.4656 - accuracy: 0.8211 - val_loss: 0.5819 - val_accuracy: 0.7007\n",
      "Epoch 51/300\n",
      "1621/1621 [==============================] - 0s 172us/sample - loss: 0.4612 - accuracy: 0.8242 - val_loss: 0.5810 - val_accuracy: 0.7007\n",
      "Epoch 52/300\n",
      "1621/1621 [==============================] - 0s 174us/sample - loss: 0.4593 - accuracy: 0.8242 - val_loss: 0.5800 - val_accuracy: 0.6960\n",
      "Epoch 53/300\n",
      "1621/1621 [==============================] - 0s 174us/sample - loss: 0.4565 - accuracy: 0.8192 - val_loss: 0.5790 - val_accuracy: 0.6960\n",
      "Epoch 54/300\n",
      "1621/1621 [==============================] - 0s 170us/sample - loss: 0.4527 - accuracy: 0.8254 - val_loss: 0.5781 - val_accuracy: 0.6983\n",
      "Epoch 55/300\n",
      "1621/1621 [==============================] - 0s 194us/sample - loss: 0.4476 - accuracy: 0.8322 - val_loss: 0.5773 - val_accuracy: 0.7031\n",
      "Epoch 56/300\n",
      "1621/1621 [==============================] - 0s 186us/sample - loss: 0.4504 - accuracy: 0.8310 - val_loss: 0.5764 - val_accuracy: 0.7055\n",
      "Epoch 57/300\n",
      "1621/1621 [==============================] - 0s 176us/sample - loss: 0.4431 - accuracy: 0.8279 - val_loss: 0.5755 - val_accuracy: 0.7031\n",
      "Epoch 58/300\n",
      "1621/1621 [==============================] - 0s 186us/sample - loss: 0.4368 - accuracy: 0.8297 - val_loss: 0.5748 - val_accuracy: 0.7055\n",
      "Epoch 59/300\n",
      "1621/1621 [==============================] - 0s 193us/sample - loss: 0.4332 - accuracy: 0.8402 - val_loss: 0.5740 - val_accuracy: 0.7055\n",
      "Epoch 60/300\n",
      "1621/1621 [==============================] - 0s 183us/sample - loss: 0.4358 - accuracy: 0.8378 - val_loss: 0.5732 - val_accuracy: 0.7126\n",
      "Epoch 61/300\n",
      "1621/1621 [==============================] - 0s 166us/sample - loss: 0.4277 - accuracy: 0.8482 - val_loss: 0.5725 - val_accuracy: 0.7126\n",
      "Epoch 62/300\n",
      "1621/1621 [==============================] - 0s 173us/sample - loss: 0.4258 - accuracy: 0.8439 - val_loss: 0.5718 - val_accuracy: 0.7150\n",
      "Epoch 63/300\n",
      "1621/1621 [==============================] - 0s 174us/sample - loss: 0.4233 - accuracy: 0.8384 - val_loss: 0.5710 - val_accuracy: 0.7173\n",
      "Epoch 64/300\n",
      "1621/1621 [==============================] - 0s 175us/sample - loss: 0.4215 - accuracy: 0.8464 - val_loss: 0.5703 - val_accuracy: 0.7197\n",
      "Epoch 65/300\n",
      "1621/1621 [==============================] - 0s 178us/sample - loss: 0.4205 - accuracy: 0.8402 - val_loss: 0.5697 - val_accuracy: 0.7245\n",
      "Epoch 66/300\n",
      "1621/1621 [==============================] - 0s 170us/sample - loss: 0.4169 - accuracy: 0.8482 - val_loss: 0.5690 - val_accuracy: 0.7245\n",
      "Epoch 67/300\n",
      "1621/1621 [==============================] - 0s 185us/sample - loss: 0.4141 - accuracy: 0.8470 - val_loss: 0.5683 - val_accuracy: 0.7268\n",
      "Epoch 68/300\n",
      "1621/1621 [==============================] - 0s 182us/sample - loss: 0.4081 - accuracy: 0.8513 - val_loss: 0.5677 - val_accuracy: 0.7292\n",
      "Epoch 69/300\n",
      "1621/1621 [==============================] - 0s 163us/sample - loss: 0.4059 - accuracy: 0.8501 - val_loss: 0.5671 - val_accuracy: 0.7268\n",
      "Epoch 70/300\n",
      "1621/1621 [==============================] - 0s 162us/sample - loss: 0.4067 - accuracy: 0.8476 - val_loss: 0.5666 - val_accuracy: 0.7292\n",
      "Epoch 71/300\n",
      "1621/1621 [==============================] - 0s 175us/sample - loss: 0.4034 - accuracy: 0.8470 - val_loss: 0.5660 - val_accuracy: 0.7316\n",
      "Epoch 72/300\n",
      "1621/1621 [==============================] - 0s 169us/sample - loss: 0.3961 - accuracy: 0.8612 - val_loss: 0.5655 - val_accuracy: 0.7340\n",
      "Epoch 73/300\n",
      "1621/1621 [==============================] - 0s 159us/sample - loss: 0.3929 - accuracy: 0.8550 - val_loss: 0.5650 - val_accuracy: 0.7316\n",
      "Epoch 74/300\n",
      "1621/1621 [==============================] - 0s 175us/sample - loss: 0.3933 - accuracy: 0.8556 - val_loss: 0.5645 - val_accuracy: 0.7292\n",
      "Epoch 75/300\n",
      "1621/1621 [==============================] - 0s 167us/sample - loss: 0.3895 - accuracy: 0.8624 - val_loss: 0.5639 - val_accuracy: 0.7292\n",
      "Epoch 76/300\n",
      "1621/1621 [==============================] - 0s 180us/sample - loss: 0.3831 - accuracy: 0.8618 - val_loss: 0.5634 - val_accuracy: 0.7316\n",
      "Epoch 77/300\n",
      "1621/1621 [==============================] - 0s 186us/sample - loss: 0.3846 - accuracy: 0.8587 - val_loss: 0.5630 - val_accuracy: 0.7363\n",
      "Epoch 78/300\n",
      "1621/1621 [==============================] - 0s 179us/sample - loss: 0.3798 - accuracy: 0.8655 - val_loss: 0.5626 - val_accuracy: 0.7363\n",
      "Epoch 79/300\n",
      "1621/1621 [==============================] - 0s 200us/sample - loss: 0.3713 - accuracy: 0.8723 - val_loss: 0.5623 - val_accuracy: 0.7363\n",
      "Epoch 80/300\n",
      "1621/1621 [==============================] - 0s 192us/sample - loss: 0.3711 - accuracy: 0.8680 - val_loss: 0.5618 - val_accuracy: 0.7387\n",
      "Epoch 81/300\n",
      "1621/1621 [==============================] - 0s 180us/sample - loss: 0.3677 - accuracy: 0.8612 - val_loss: 0.5615 - val_accuracy: 0.7387\n",
      "Epoch 82/300\n",
      "1621/1621 [==============================] - 0s 175us/sample - loss: 0.3677 - accuracy: 0.8674 - val_loss: 0.5612 - val_accuracy: 0.7387\n",
      "Epoch 83/300\n",
      "1621/1621 [==============================] - 0s 175us/sample - loss: 0.3671 - accuracy: 0.8686 - val_loss: 0.5608 - val_accuracy: 0.7387\n",
      "Epoch 84/300\n",
      "1621/1621 [==============================] - 0s 174us/sample - loss: 0.3576 - accuracy: 0.8742 - val_loss: 0.5605 - val_accuracy: 0.7363\n",
      "Epoch 85/300\n",
      "1621/1621 [==============================] - 0s 169us/sample - loss: 0.3578 - accuracy: 0.8723 - val_loss: 0.5602 - val_accuracy: 0.7363\n",
      "Epoch 86/300\n",
      "1621/1621 [==============================] - 0s 169us/sample - loss: 0.3529 - accuracy: 0.8754 - val_loss: 0.5600 - val_accuracy: 0.7387\n",
      "Epoch 87/300\n",
      "1621/1621 [==============================] - 0s 182us/sample - loss: 0.3492 - accuracy: 0.8754 - val_loss: 0.5597 - val_accuracy: 0.7387\n",
      "Epoch 88/300\n",
      "1621/1621 [==============================] - 0s 193us/sample - loss: 0.3498 - accuracy: 0.8840 - val_loss: 0.5594 - val_accuracy: 0.7387\n",
      "Epoch 89/300\n",
      "1621/1621 [==============================] - 0s 183us/sample - loss: 0.3430 - accuracy: 0.8840 - val_loss: 0.5590 - val_accuracy: 0.7411\n",
      "Epoch 90/300\n",
      "1621/1621 [==============================] - 0s 184us/sample - loss: 0.3409 - accuracy: 0.8791 - val_loss: 0.5587 - val_accuracy: 0.7387\n",
      "Epoch 91/300\n",
      "1621/1621 [==============================] - 0s 179us/sample - loss: 0.3317 - accuracy: 0.8896 - val_loss: 0.5586 - val_accuracy: 0.7387\n",
      "Epoch 92/300\n",
      "1621/1621 [==============================] - 0s 181us/sample - loss: 0.3364 - accuracy: 0.8772 - val_loss: 0.5583 - val_accuracy: 0.7387\n",
      "Epoch 93/300\n",
      "1621/1621 [==============================] - 0s 185us/sample - loss: 0.3304 - accuracy: 0.8840 - val_loss: 0.5582 - val_accuracy: 0.7411\n",
      "Epoch 94/300\n",
      "1621/1621 [==============================] - 0s 185us/sample - loss: 0.3293 - accuracy: 0.8840 - val_loss: 0.5582 - val_accuracy: 0.7411\n",
      "Epoch 95/300\n",
      "1621/1621 [==============================] - 0s 185us/sample - loss: 0.3286 - accuracy: 0.8902 - val_loss: 0.5578 - val_accuracy: 0.7387\n",
      "Epoch 96/300\n",
      "1621/1621 [==============================] - 0s 192us/sample - loss: 0.3236 - accuracy: 0.8883 - val_loss: 0.5578 - val_accuracy: 0.7411\n",
      "Epoch 97/300\n",
      "1621/1621 [==============================] - 0s 189us/sample - loss: 0.3178 - accuracy: 0.8865 - val_loss: 0.5579 - val_accuracy: 0.7411\n",
      "Epoch 98/300\n",
      "1621/1621 [==============================] - 0s 181us/sample - loss: 0.3160 - accuracy: 0.8908 - val_loss: 0.5578 - val_accuracy: 0.7411\n",
      "Epoch 99/300\n",
      "1621/1621 [==============================] - 0s 181us/sample - loss: 0.3147 - accuracy: 0.8890 - val_loss: 0.5577 - val_accuracy: 0.7435\n",
      "Epoch 100/300\n",
      "1621/1621 [==============================] - 0s 174us/sample - loss: 0.3098 - accuracy: 0.8933 - val_loss: 0.5576 - val_accuracy: 0.7435\n",
      "Epoch 101/300\n",
      "1621/1621 [==============================] - 0s 181us/sample - loss: 0.3058 - accuracy: 0.8951 - val_loss: 0.5575 - val_accuracy: 0.7435\n",
      "Epoch 102/300\n",
      "1621/1621 [==============================] - 0s 178us/sample - loss: 0.3059 - accuracy: 0.8890 - val_loss: 0.5574 - val_accuracy: 0.7435\n",
      "Epoch 103/300\n",
      "1621/1621 [==============================] - 0s 195us/sample - loss: 0.3003 - accuracy: 0.8976 - val_loss: 0.5575 - val_accuracy: 0.7458\n",
      "Epoch 104/300\n",
      "1621/1621 [==============================] - 0s 190us/sample - loss: 0.2977 - accuracy: 0.8994 - val_loss: 0.5577 - val_accuracy: 0.7458\n",
      "Epoch 105/300\n",
      "1621/1621 [==============================] - 0s 190us/sample - loss: 0.2922 - accuracy: 0.9062 - val_loss: 0.5577 - val_accuracy: 0.7458\n",
      "Epoch 00105: early stopping\n",
      "197/197 [==============================] - 0s 164us/sample - loss: 1.3919 - accuracy: 0.3452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [52:13, 798.04s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:06<00:06,  6.09s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.86s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "5it [00:00, 45.28it/s]\u001b[A\n",
      "8it [00:00, 36.29it/s]\u001b[A\n",
      "14it [00:00, 39.87it/s]\u001b[A\n",
      "17it [00:00, 33.09it/s]\u001b[A\n",
      "21it [00:00, 33.70it/s]\u001b[A\n",
      "25it [00:00, 33.61it/s]\u001b[A\n",
      "30it [00:00, 34.45it/s]\u001b[A\n",
      "35it [00:00, 36.96it/s]\u001b[A\n",
      "41it [00:01, 38.59it/s]\u001b[A\n",
      "45it [00:01, 36.22it/s]\u001b[A\n",
      "50it [00:01, 36.18it/s]\u001b[A\n",
      "55it [00:01, 36.74it/s]\u001b[A\n",
      "59it [00:01, 35.95it/s]\u001b[A\n",
      "63it [00:01, 34.59it/s]\u001b[A\n",
      "72it [00:01, 36.84it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 72/72 [00:00<00:00, 2063.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 511.0078125 steps, validate for 131.84375 steps\n",
      "Epoch 1/300\n",
      "512/511 [==============================] - 15s 30ms/step - loss: 0.7146 - accuracy: 0.5504 - val_loss: 0.6707 - val_accuracy: 0.5914\n",
      "Epoch 2/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.6526 - accuracy: 0.6132 - val_loss: 0.6591 - val_accuracy: 0.6070\n",
      "Epoch 3/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.6360 - accuracy: 0.6342 - val_loss: 0.6517 - val_accuracy: 0.6183\n",
      "Epoch 4/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.6240 - accuracy: 0.6474 - val_loss: 0.6477 - val_accuracy: 0.6213\n",
      "Epoch 5/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.6142 - accuracy: 0.6577 - val_loss: 0.6461 - val_accuracy: 0.6289\n",
      "Epoch 6/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.6059 - accuracy: 0.6657 - val_loss: 0.6460 - val_accuracy: 0.6287\n",
      "Epoch 7/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.5983 - accuracy: 0.6745 - val_loss: 0.6448 - val_accuracy: 0.6311\n",
      "Epoch 8/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.5916 - accuracy: 0.6816 - val_loss: 0.6443 - val_accuracy: 0.6351\n",
      "Epoch 9/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.5849 - accuracy: 0.6873 - val_loss: 0.6475 - val_accuracy: 0.6324\n",
      "Epoch 10/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.5788 - accuracy: 0.6926 - val_loss: 0.6465 - val_accuracy: 0.6347\n",
      "Epoch 11/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.5728 - accuracy: 0.6996 - val_loss: 0.6451 - val_accuracy: 0.6385\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 511.0078125 steps, validate for 131.84375 steps\n",
      "Epoch 1/300\n",
      "512/511 [==============================] - 34s 66ms/step - loss: 0.5624 - accuracy: 0.7091 - val_loss: 0.6484 - val_accuracy: 0.6465\n",
      "Epoch 2/300\n",
      "512/511 [==============================] - 32s 62ms/step - loss: 0.5420 - accuracy: 0.7264 - val_loss: 0.6618 - val_accuracy: 0.6310\n",
      "Epoch 3/300\n",
      "512/511 [==============================] - 32s 62ms/step - loss: 0.5265 - accuracy: 0.7401 - val_loss: 0.6410 - val_accuracy: 0.6478\n",
      "Epoch 4/300\n",
      "512/511 [==============================] - 32s 63ms/step - loss: 0.5126 - accuracy: 0.7515 - val_loss: 0.6789 - val_accuracy: 0.6292\n",
      "Epoch 5/300\n",
      "512/511 [==============================] - 32s 63ms/step - loss: 0.4997 - accuracy: 0.7602 - val_loss: 0.6480 - val_accuracy: 0.6432\n",
      "Epoch 6/300\n",
      "512/511 [==============================] - 32s 62ms/step - loss: 0.4876 - accuracy: 0.7709 - val_loss: 0.6496 - val_accuracy: 0.6396\n",
      "Epoch 00006: early stopping\n",
      "360/360 [==============================] - 0s 704us/sample - loss: 1.2035 - accuracy: 0.2028\n",
      "335/335 [==============================] - 0s 209us/sample - loss: 1.1738 - accuracy: 0.2418\n",
      "327/327 [==============================] - 0s 206us/sample - loss: 1.1367 - accuracy: 0.2416\n",
      "320/320 [==============================] - 0s 827us/sample - loss: 1.1762 - accuracy: 0.2188\n",
      "312/312 [==============================] - 0s 193us/sample - loss: 1.1526 - accuracy: 0.2308\n",
      "307/307 [==============================] - 0s 233us/sample - loss: 1.1523 - accuracy: 0.2182\n",
      "304/304 [==============================] - 0s 232us/sample - loss: 1.1542 - accuracy: 0.2303\n",
      "297/297 [==============================] - 0s 265us/sample - loss: 1.1461 - accuracy: 0.2121\n",
      "297/297 [==============================] - 0s 223us/sample - loss: 1.1512 - accuracy: 0.2323\n",
      "291/291 [==============================] - 0s 219us/sample - loss: 1.1335 - accuracy: 0.2577\n",
      "284/284 [==============================] - 0s 218us/sample - loss: 1.1586 - accuracy: 0.2148\n",
      "283/283 [==============================] - 0s 218us/sample - loss: 1.1893 - accuracy: 0.2403\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 1.1970 - accuracy: 0.2340\n",
      "277/277 [==============================] - 0s 210us/sample - loss: 1.1036 - accuracy: 0.2310\n",
      "279/279 [==============================] - 0s 209us/sample - loss: 1.1840 - accuracy: 0.2401\n",
      "270/270 [==============================] - 0s 237us/sample - loss: 1.1386 - accuracy: 0.2444\n",
      "265/265 [==============================] - 0s 235us/sample - loss: 1.1084 - accuracy: 0.2792\n",
      "266/266 [==============================] - 0s 282us/sample - loss: 1.1332 - accuracy: 0.3045\n",
      "266/266 [==============================] - 0s 252us/sample - loss: 1.1202 - accuracy: 0.2820\n",
      "264/264 [==============================] - 0s 220us/sample - loss: 1.1689 - accuracy: 0.2652\n",
      "258/258 [==============================] - 0s 283us/sample - loss: 1.2034 - accuracy: 0.2791\n",
      "255/255 [==============================] - 0s 242us/sample - loss: 1.1371 - accuracy: 0.2941\n",
      "255/255 [==============================] - 0s 241us/sample - loss: 1.1263 - accuracy: 0.3020\n",
      "254/254 [==============================] - 0s 248us/sample - loss: 1.1426 - accuracy: 0.2874\n",
      "246/246 [==============================] - 0s 223us/sample - loss: 1.1307 - accuracy: 0.2886\n",
      "242/242 [==============================] - 0s 218us/sample - loss: 1.1118 - accuracy: 0.3223\n",
      "242/242 [==============================] - 0s 232us/sample - loss: 1.1389 - accuracy: 0.2645\n",
      "240/240 [==============================] - 0s 232us/sample - loss: 1.1305 - accuracy: 0.2833\n",
      "238/238 [==============================] - 0s 253us/sample - loss: 1.1214 - accuracy: 0.2647\n",
      "239/239 [==============================] - 0s 242us/sample - loss: 1.2431 - accuracy: 0.2218\n",
      "235/235 [==============================] - 0s 230us/sample - loss: 1.1968 - accuracy: 0.2596\n",
      "234/234 [==============================] - 0s 230us/sample - loss: 1.1900 - accuracy: 0.2222\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 1604 samples, validate on 420 samples\n",
      "Epoch 1/300\n",
      "1604/1604 [==============================] - 2s 1ms/sample - loss: 0.7458 - accuracy: 0.4582 - val_loss: 0.7390 - val_accuracy: 0.4952\n",
      "Epoch 2/300\n",
      "1604/1604 [==============================] - 0s 191us/sample - loss: 0.7336 - accuracy: 0.4857 - val_loss: 0.7306 - val_accuracy: 0.5024\n",
      "Epoch 3/300\n",
      "1604/1604 [==============================] - 0s 171us/sample - loss: 0.7215 - accuracy: 0.5050 - val_loss: 0.7246 - val_accuracy: 0.5119\n",
      "Epoch 4/300\n",
      "1604/1604 [==============================] - 0s 185us/sample - loss: 0.7159 - accuracy: 0.5069 - val_loss: 0.7197 - val_accuracy: 0.5310\n",
      "Epoch 5/300\n",
      "1604/1604 [==============================] - 0s 180us/sample - loss: 0.7093 - accuracy: 0.5200 - val_loss: 0.7156 - val_accuracy: 0.5286\n",
      "Epoch 6/300\n",
      "1604/1604 [==============================] - 0s 193us/sample - loss: 0.7057 - accuracy: 0.5262 - val_loss: 0.7118 - val_accuracy: 0.5381\n",
      "Epoch 7/300\n",
      "1604/1604 [==============================] - 0s 169us/sample - loss: 0.6985 - accuracy: 0.5443 - val_loss: 0.7084 - val_accuracy: 0.5381\n",
      "Epoch 8/300\n",
      "1604/1604 [==============================] - 0s 164us/sample - loss: 0.6949 - accuracy: 0.5567 - val_loss: 0.7054 - val_accuracy: 0.5381\n",
      "Epoch 9/300\n",
      "1604/1604 [==============================] - 0s 169us/sample - loss: 0.6906 - accuracy: 0.5536 - val_loss: 0.7027 - val_accuracy: 0.5381\n",
      "Epoch 10/300\n",
      "1604/1604 [==============================] - 0s 171us/sample - loss: 0.6871 - accuracy: 0.5648 - val_loss: 0.7000 - val_accuracy: 0.5357\n",
      "Epoch 11/300\n",
      "1604/1604 [==============================] - 0s 171us/sample - loss: 0.6881 - accuracy: 0.5592 - val_loss: 0.6980 - val_accuracy: 0.5405\n",
      "Epoch 12/300\n",
      "1604/1604 [==============================] - 0s 180us/sample - loss: 0.6819 - accuracy: 0.5860 - val_loss: 0.6957 - val_accuracy: 0.5476\n",
      "Epoch 13/300\n",
      "1604/1604 [==============================] - 0s 187us/sample - loss: 0.6735 - accuracy: 0.5892 - val_loss: 0.6935 - val_accuracy: 0.5595\n",
      "Epoch 14/300\n",
      "1604/1604 [==============================] - 0s 172us/sample - loss: 0.6727 - accuracy: 0.5941 - val_loss: 0.6915 - val_accuracy: 0.5714\n",
      "Epoch 15/300\n",
      "1604/1604 [==============================] - 0s 167us/sample - loss: 0.6751 - accuracy: 0.5892 - val_loss: 0.6896 - val_accuracy: 0.5714\n",
      "Epoch 16/300\n",
      "1604/1604 [==============================] - 0s 170us/sample - loss: 0.6629 - accuracy: 0.6234 - val_loss: 0.6877 - val_accuracy: 0.5738\n",
      "Epoch 17/300\n",
      "1604/1604 [==============================] - 0s 162us/sample - loss: 0.6667 - accuracy: 0.5985 - val_loss: 0.6860 - val_accuracy: 0.5762\n",
      "Epoch 18/300\n",
      "1604/1604 [==============================] - 0s 177us/sample - loss: 0.6638 - accuracy: 0.6110 - val_loss: 0.6844 - val_accuracy: 0.5857\n",
      "Epoch 19/300\n",
      "1604/1604 [==============================] - 0s 186us/sample - loss: 0.6607 - accuracy: 0.6160 - val_loss: 0.6827 - val_accuracy: 0.5881\n",
      "Epoch 20/300\n",
      "1604/1604 [==============================] - 0s 188us/sample - loss: 0.6626 - accuracy: 0.6172 - val_loss: 0.6811 - val_accuracy: 0.5857\n",
      "Epoch 21/300\n",
      "1604/1604 [==============================] - 0s 197us/sample - loss: 0.6532 - accuracy: 0.6347 - val_loss: 0.6796 - val_accuracy: 0.5929\n",
      "Epoch 22/300\n",
      "1604/1604 [==============================] - 0s 191us/sample - loss: 0.6514 - accuracy: 0.6315 - val_loss: 0.6782 - val_accuracy: 0.6024\n",
      "Epoch 23/300\n",
      "1604/1604 [==============================] - 0s 175us/sample - loss: 0.6510 - accuracy: 0.6328 - val_loss: 0.6768 - val_accuracy: 0.6024\n",
      "Epoch 24/300\n",
      "1604/1604 [==============================] - 0s 181us/sample - loss: 0.6501 - accuracy: 0.6253 - val_loss: 0.6754 - val_accuracy: 0.6024\n",
      "Epoch 25/300\n",
      "1604/1604 [==============================] - 0s 177us/sample - loss: 0.6444 - accuracy: 0.6428 - val_loss: 0.6741 - val_accuracy: 0.6071\n",
      "Epoch 26/300\n",
      "1604/1604 [==============================] - 0s 181us/sample - loss: 0.6408 - accuracy: 0.6552 - val_loss: 0.6729 - val_accuracy: 0.6119\n",
      "Epoch 27/300\n",
      "1604/1604 [==============================] - 0s 181us/sample - loss: 0.6422 - accuracy: 0.6559 - val_loss: 0.6716 - val_accuracy: 0.6095\n",
      "Epoch 28/300\n",
      "1604/1604 [==============================] - 0s 190us/sample - loss: 0.6446 - accuracy: 0.6478 - val_loss: 0.6704 - val_accuracy: 0.6119\n",
      "Epoch 29/300\n",
      "1604/1604 [==============================] - 0s 180us/sample - loss: 0.6400 - accuracy: 0.6540 - val_loss: 0.6691 - val_accuracy: 0.6190\n",
      "Epoch 30/300\n",
      "1604/1604 [==============================] - 0s 191us/sample - loss: 0.6362 - accuracy: 0.6534 - val_loss: 0.6679 - val_accuracy: 0.6262\n",
      "Epoch 31/300\n",
      "1604/1604 [==============================] - 0s 176us/sample - loss: 0.6321 - accuracy: 0.6658 - val_loss: 0.6668 - val_accuracy: 0.6286\n",
      "Epoch 32/300\n",
      "1604/1604 [==============================] - 0s 169us/sample - loss: 0.6377 - accuracy: 0.6509 - val_loss: 0.6656 - val_accuracy: 0.6238\n",
      "Epoch 33/300\n",
      "1604/1604 [==============================] - 0s 178us/sample - loss: 0.6335 - accuracy: 0.6708 - val_loss: 0.6645 - val_accuracy: 0.6190\n",
      "Epoch 34/300\n",
      "1604/1604 [==============================] - 0s 191us/sample - loss: 0.6256 - accuracy: 0.6708 - val_loss: 0.6634 - val_accuracy: 0.6143\n",
      "Epoch 35/300\n",
      "1604/1604 [==============================] - 0s 184us/sample - loss: 0.6264 - accuracy: 0.6633 - val_loss: 0.6623 - val_accuracy: 0.6143\n",
      "Epoch 36/300\n",
      "1604/1604 [==============================] - 0s 184us/sample - loss: 0.6210 - accuracy: 0.6758 - val_loss: 0.6612 - val_accuracy: 0.6143\n",
      "Epoch 37/300\n",
      "1604/1604 [==============================] - 0s 181us/sample - loss: 0.6256 - accuracy: 0.6752 - val_loss: 0.6602 - val_accuracy: 0.6143\n",
      "Epoch 38/300\n",
      "1604/1604 [==============================] - 0s 179us/sample - loss: 0.6257 - accuracy: 0.6633 - val_loss: 0.6592 - val_accuracy: 0.6143\n",
      "Epoch 39/300\n",
      "1604/1604 [==============================] - 0s 186us/sample - loss: 0.6225 - accuracy: 0.6833 - val_loss: 0.6582 - val_accuracy: 0.6143\n",
      "Epoch 40/300\n",
      "1604/1604 [==============================] - 0s 184us/sample - loss: 0.6166 - accuracy: 0.6764 - val_loss: 0.6572 - val_accuracy: 0.6143\n",
      "Epoch 41/300\n",
      "1604/1604 [==============================] - 0s 174us/sample - loss: 0.6166 - accuracy: 0.6895 - val_loss: 0.6562 - val_accuracy: 0.6167\n",
      "Epoch 42/300\n",
      "1604/1604 [==============================] - 0s 168us/sample - loss: 0.6197 - accuracy: 0.6839 - val_loss: 0.6552 - val_accuracy: 0.6167\n",
      "Epoch 43/300\n",
      "1604/1604 [==============================] - 0s 177us/sample - loss: 0.6128 - accuracy: 0.6989 - val_loss: 0.6542 - val_accuracy: 0.6143\n",
      "Epoch 44/300\n",
      "1604/1604 [==============================] - 0s 178us/sample - loss: 0.6077 - accuracy: 0.6951 - val_loss: 0.6533 - val_accuracy: 0.6190\n",
      "Epoch 45/300\n",
      "1604/1604 [==============================] - 0s 179us/sample - loss: 0.6108 - accuracy: 0.6939 - val_loss: 0.6523 - val_accuracy: 0.6190\n",
      "Epoch 46/300\n",
      "1604/1604 [==============================] - 0s 186us/sample - loss: 0.6088 - accuracy: 0.6858 - val_loss: 0.6514 - val_accuracy: 0.6190\n",
      "Epoch 47/300\n",
      "1604/1604 [==============================] - 0s 183us/sample - loss: 0.6080 - accuracy: 0.6808 - val_loss: 0.6504 - val_accuracy: 0.6238\n",
      "Epoch 48/300\n",
      "1604/1604 [==============================] - 0s 190us/sample - loss: 0.6052 - accuracy: 0.6914 - val_loss: 0.6496 - val_accuracy: 0.6238\n",
      "Epoch 49/300\n",
      "1604/1604 [==============================] - 0s 192us/sample - loss: 0.6042 - accuracy: 0.7020 - val_loss: 0.6487 - val_accuracy: 0.6238\n",
      "Epoch 50/300\n",
      "1604/1604 [==============================] - 0s 192us/sample - loss: 0.6001 - accuracy: 0.7032 - val_loss: 0.6479 - val_accuracy: 0.6238\n",
      "Epoch 51/300\n",
      "1604/1604 [==============================] - 0s 186us/sample - loss: 0.6000 - accuracy: 0.7014 - val_loss: 0.6470 - val_accuracy: 0.6262\n",
      "Epoch 52/300\n",
      "1604/1604 [==============================] - 0s 190us/sample - loss: 0.5943 - accuracy: 0.7007 - val_loss: 0.6462 - val_accuracy: 0.6310\n",
      "Epoch 53/300\n",
      "1604/1604 [==============================] - 0s 180us/sample - loss: 0.5943 - accuracy: 0.7082 - val_loss: 0.6454 - val_accuracy: 0.6310\n",
      "Epoch 54/300\n",
      "1604/1604 [==============================] - 0s 194us/sample - loss: 0.5901 - accuracy: 0.7182 - val_loss: 0.6445 - val_accuracy: 0.6310\n",
      "Epoch 55/300\n",
      "1604/1604 [==============================] - 0s 164us/sample - loss: 0.5917 - accuracy: 0.7089 - val_loss: 0.6437 - val_accuracy: 0.6310\n",
      "Epoch 56/300\n",
      "1604/1604 [==============================] - 0s 174us/sample - loss: 0.5908 - accuracy: 0.7113 - val_loss: 0.6428 - val_accuracy: 0.6310\n",
      "Epoch 57/300\n",
      "1604/1604 [==============================] - 0s 173us/sample - loss: 0.5897 - accuracy: 0.7032 - val_loss: 0.6421 - val_accuracy: 0.6286\n",
      "Epoch 58/300\n",
      "1604/1604 [==============================] - 0s 181us/sample - loss: 0.5859 - accuracy: 0.7126 - val_loss: 0.6413 - val_accuracy: 0.6262\n",
      "Epoch 59/300\n",
      "1604/1604 [==============================] - 0s 168us/sample - loss: 0.5836 - accuracy: 0.7207 - val_loss: 0.6404 - val_accuracy: 0.6310\n",
      "Epoch 60/300\n",
      "1604/1604 [==============================] - 0s 166us/sample - loss: 0.5815 - accuracy: 0.7163 - val_loss: 0.6397 - val_accuracy: 0.6310\n",
      "Epoch 61/300\n",
      "1604/1604 [==============================] - 0s 174us/sample - loss: 0.5815 - accuracy: 0.7219 - val_loss: 0.6389 - val_accuracy: 0.6310\n",
      "Epoch 62/300\n",
      "1604/1604 [==============================] - 0s 168us/sample - loss: 0.5825 - accuracy: 0.7195 - val_loss: 0.6382 - val_accuracy: 0.6310\n",
      "Epoch 63/300\n",
      "1604/1604 [==============================] - 0s 176us/sample - loss: 0.5742 - accuracy: 0.7182 - val_loss: 0.6374 - val_accuracy: 0.6333\n",
      "Epoch 64/300\n",
      "1604/1604 [==============================] - 0s 181us/sample - loss: 0.5739 - accuracy: 0.7344 - val_loss: 0.6366 - val_accuracy: 0.6357\n",
      "Epoch 65/300\n",
      "1604/1604 [==============================] - 0s 184us/sample - loss: 0.5719 - accuracy: 0.7419 - val_loss: 0.6359 - val_accuracy: 0.6357\n",
      "Epoch 66/300\n",
      "1604/1604 [==============================] - 0s 189us/sample - loss: 0.5739 - accuracy: 0.7269 - val_loss: 0.6351 - val_accuracy: 0.6357\n",
      "Epoch 67/300\n",
      "1604/1604 [==============================] - 0s 201us/sample - loss: 0.5709 - accuracy: 0.7219 - val_loss: 0.6343 - val_accuracy: 0.6357\n",
      "Epoch 68/300\n",
      "1604/1604 [==============================] - 0s 176us/sample - loss: 0.5675 - accuracy: 0.7375 - val_loss: 0.6336 - val_accuracy: 0.6357\n",
      "Epoch 69/300\n",
      "1604/1604 [==============================] - 0s 175us/sample - loss: 0.5701 - accuracy: 0.7251 - val_loss: 0.6329 - val_accuracy: 0.6357\n",
      "Epoch 70/300\n",
      "1604/1604 [==============================] - 0s 191us/sample - loss: 0.5646 - accuracy: 0.7357 - val_loss: 0.6322 - val_accuracy: 0.6357\n",
      "Epoch 71/300\n",
      "1604/1604 [==============================] - 0s 199us/sample - loss: 0.5639 - accuracy: 0.7413 - val_loss: 0.6315 - val_accuracy: 0.6381\n",
      "Epoch 72/300\n",
      "1604/1604 [==============================] - 0s 192us/sample - loss: 0.5631 - accuracy: 0.7332 - val_loss: 0.6309 - val_accuracy: 0.6357\n",
      "Epoch 73/300\n",
      "1604/1604 [==============================] - 0s 186us/sample - loss: 0.5621 - accuracy: 0.7438 - val_loss: 0.6302 - val_accuracy: 0.6357\n",
      "Epoch 74/300\n",
      "1604/1604 [==============================] - 0s 189us/sample - loss: 0.5582 - accuracy: 0.7338 - val_loss: 0.6295 - val_accuracy: 0.6381\n",
      "Epoch 75/300\n",
      "1604/1604 [==============================] - 0s 187us/sample - loss: 0.5528 - accuracy: 0.7506 - val_loss: 0.6289 - val_accuracy: 0.6405\n",
      "Epoch 76/300\n",
      "1604/1604 [==============================] - 0s 196us/sample - loss: 0.5529 - accuracy: 0.7494 - val_loss: 0.6282 - val_accuracy: 0.6405\n",
      "Epoch 77/300\n",
      "1604/1604 [==============================] - 0s 193us/sample - loss: 0.5522 - accuracy: 0.7425 - val_loss: 0.6275 - val_accuracy: 0.6429\n",
      "Epoch 78/300\n",
      "1604/1604 [==============================] - 0s 178us/sample - loss: 0.5522 - accuracy: 0.7369 - val_loss: 0.6269 - val_accuracy: 0.6452\n",
      "Epoch 79/300\n",
      "1604/1604 [==============================] - 0s 184us/sample - loss: 0.5506 - accuracy: 0.7388 - val_loss: 0.6262 - val_accuracy: 0.6452\n",
      "Epoch 80/300\n",
      "1604/1604 [==============================] - 0s 174us/sample - loss: 0.5497 - accuracy: 0.7413 - val_loss: 0.6256 - val_accuracy: 0.6429\n",
      "Epoch 81/300\n",
      "1604/1604 [==============================] - 0s 176us/sample - loss: 0.5495 - accuracy: 0.7456 - val_loss: 0.6250 - val_accuracy: 0.6452\n",
      "Epoch 82/300\n",
      "1604/1604 [==============================] - 0s 174us/sample - loss: 0.5399 - accuracy: 0.7481 - val_loss: 0.6244 - val_accuracy: 0.6452\n",
      "Epoch 83/300\n",
      "1604/1604 [==============================] - 0s 173us/sample - loss: 0.5418 - accuracy: 0.7469 - val_loss: 0.6238 - val_accuracy: 0.6429\n",
      "Epoch 84/300\n",
      "1604/1604 [==============================] - 0s 179us/sample - loss: 0.5384 - accuracy: 0.7556 - val_loss: 0.6232 - val_accuracy: 0.6429\n",
      "Epoch 85/300\n",
      "1604/1604 [==============================] - 0s 168us/sample - loss: 0.5408 - accuracy: 0.7512 - val_loss: 0.6226 - val_accuracy: 0.6429\n",
      "Epoch 86/300\n",
      "1604/1604 [==============================] - 0s 174us/sample - loss: 0.5358 - accuracy: 0.7562 - val_loss: 0.6220 - val_accuracy: 0.6452\n",
      "Epoch 87/300\n",
      "1604/1604 [==============================] - 0s 167us/sample - loss: 0.5346 - accuracy: 0.7512 - val_loss: 0.6215 - val_accuracy: 0.6452\n",
      "Epoch 88/300\n",
      "1604/1604 [==============================] - 0s 176us/sample - loss: 0.5332 - accuracy: 0.7537 - val_loss: 0.6209 - val_accuracy: 0.6452\n",
      "Epoch 89/300\n",
      "1604/1604 [==============================] - 0s 191us/sample - loss: 0.5299 - accuracy: 0.7525 - val_loss: 0.6204 - val_accuracy: 0.6476\n",
      "Epoch 90/300\n",
      "1604/1604 [==============================] - 0s 168us/sample - loss: 0.5268 - accuracy: 0.7537 - val_loss: 0.6199 - val_accuracy: 0.6452\n",
      "Epoch 91/300\n",
      "1604/1604 [==============================] - 0s 172us/sample - loss: 0.5269 - accuracy: 0.7650 - val_loss: 0.6194 - val_accuracy: 0.6452\n",
      "Epoch 92/300\n",
      "1604/1604 [==============================] - 0s 185us/sample - loss: 0.5195 - accuracy: 0.7706 - val_loss: 0.6188 - val_accuracy: 0.6476\n",
      "Epoch 93/300\n",
      "1604/1604 [==============================] - 0s 177us/sample - loss: 0.5211 - accuracy: 0.7675 - val_loss: 0.6183 - val_accuracy: 0.6452\n",
      "Epoch 94/300\n",
      "1604/1604 [==============================] - 0s 171us/sample - loss: 0.5212 - accuracy: 0.7631 - val_loss: 0.6178 - val_accuracy: 0.6476\n",
      "Epoch 95/300\n",
      "1604/1604 [==============================] - 0s 175us/sample - loss: 0.5201 - accuracy: 0.7643 - val_loss: 0.6173 - val_accuracy: 0.6524\n",
      "Epoch 96/300\n",
      "1604/1604 [==============================] - 0s 176us/sample - loss: 0.5136 - accuracy: 0.7675 - val_loss: 0.6169 - val_accuracy: 0.6548\n",
      "Epoch 97/300\n",
      "1604/1604 [==============================] - 0s 174us/sample - loss: 0.5112 - accuracy: 0.7731 - val_loss: 0.6163 - val_accuracy: 0.6548\n",
      "Epoch 98/300\n",
      "1604/1604 [==============================] - 0s 172us/sample - loss: 0.5084 - accuracy: 0.7749 - val_loss: 0.6159 - val_accuracy: 0.6595\n",
      "Epoch 99/300\n",
      "1604/1604 [==============================] - 0s 190us/sample - loss: 0.5064 - accuracy: 0.7743 - val_loss: 0.6155 - val_accuracy: 0.6595\n",
      "Epoch 100/300\n",
      "1604/1604 [==============================] - 0s 170us/sample - loss: 0.5050 - accuracy: 0.7762 - val_loss: 0.6150 - val_accuracy: 0.6619\n",
      "Epoch 101/300\n",
      "1604/1604 [==============================] - 0s 184us/sample - loss: 0.5105 - accuracy: 0.7724 - val_loss: 0.6146 - val_accuracy: 0.6643\n",
      "Epoch 102/300\n",
      "1604/1604 [==============================] - 0s 187us/sample - loss: 0.5031 - accuracy: 0.7843 - val_loss: 0.6141 - val_accuracy: 0.6643\n",
      "Epoch 103/300\n",
      "1604/1604 [==============================] - 0s 176us/sample - loss: 0.5051 - accuracy: 0.7762 - val_loss: 0.6137 - val_accuracy: 0.6667\n",
      "Epoch 104/300\n",
      "1604/1604 [==============================] - 0s 180us/sample - loss: 0.4993 - accuracy: 0.7737 - val_loss: 0.6132 - val_accuracy: 0.6690\n",
      "Epoch 105/300\n",
      "1604/1604 [==============================] - 0s 188us/sample - loss: 0.4962 - accuracy: 0.7799 - val_loss: 0.6129 - val_accuracy: 0.6690\n",
      "Epoch 106/300\n",
      "1604/1604 [==============================] - 0s 191us/sample - loss: 0.4941 - accuracy: 0.7849 - val_loss: 0.6125 - val_accuracy: 0.6690\n",
      "Epoch 107/300\n",
      "1604/1604 [==============================] - 0s 193us/sample - loss: 0.4936 - accuracy: 0.7787 - val_loss: 0.6122 - val_accuracy: 0.6690\n",
      "Epoch 108/300\n",
      "1604/1604 [==============================] - 0s 176us/sample - loss: 0.4894 - accuracy: 0.7862 - val_loss: 0.6119 - val_accuracy: 0.6714\n",
      "Epoch 109/300\n",
      "1604/1604 [==============================] - 0s 182us/sample - loss: 0.4864 - accuracy: 0.7930 - val_loss: 0.6116 - val_accuracy: 0.6738\n",
      "Epoch 110/300\n",
      "1604/1604 [==============================] - 0s 173us/sample - loss: 0.4857 - accuracy: 0.7930 - val_loss: 0.6113 - val_accuracy: 0.6738\n",
      "Epoch 111/300\n",
      "1604/1604 [==============================] - 0s 195us/sample - loss: 0.4831 - accuracy: 0.7830 - val_loss: 0.6110 - val_accuracy: 0.6786\n",
      "Epoch 112/300\n",
      "1604/1604 [==============================] - 0s 181us/sample - loss: 0.4816 - accuracy: 0.7905 - val_loss: 0.6107 - val_accuracy: 0.6810\n",
      "Epoch 113/300\n",
      "1604/1604 [==============================] - 0s 174us/sample - loss: 0.4843 - accuracy: 0.7893 - val_loss: 0.6105 - val_accuracy: 0.6881\n",
      "Epoch 114/300\n",
      "1604/1604 [==============================] - 0s 186us/sample - loss: 0.4786 - accuracy: 0.7924 - val_loss: 0.6102 - val_accuracy: 0.6905\n",
      "Epoch 115/300\n",
      "1604/1604 [==============================] - 0s 177us/sample - loss: 0.4699 - accuracy: 0.8049 - val_loss: 0.6099 - val_accuracy: 0.6905\n",
      "Epoch 116/300\n",
      "1604/1604 [==============================] - 0s 186us/sample - loss: 0.4715 - accuracy: 0.7918 - val_loss: 0.6098 - val_accuracy: 0.6905\n",
      "Epoch 117/300\n",
      "1604/1604 [==============================] - 0s 170us/sample - loss: 0.4701 - accuracy: 0.8030 - val_loss: 0.6096 - val_accuracy: 0.6929\n",
      "Epoch 118/300\n",
      "1604/1604 [==============================] - 0s 194us/sample - loss: 0.4677 - accuracy: 0.8005 - val_loss: 0.6093 - val_accuracy: 0.6905\n",
      "Epoch 119/300\n",
      "1604/1604 [==============================] - 0s 210us/sample - loss: 0.4648 - accuracy: 0.8067 - val_loss: 0.6092 - val_accuracy: 0.6857\n",
      "Epoch 120/300\n",
      "1604/1604 [==============================] - 0s 183us/sample - loss: 0.4630 - accuracy: 0.8061 - val_loss: 0.6089 - val_accuracy: 0.6857\n",
      "Epoch 121/300\n",
      "1604/1604 [==============================] - 0s 194us/sample - loss: 0.4668 - accuracy: 0.7899 - val_loss: 0.6087 - val_accuracy: 0.6857\n",
      "Epoch 122/300\n",
      "1604/1604 [==============================] - 0s 207us/sample - loss: 0.4567 - accuracy: 0.8067 - val_loss: 0.6086 - val_accuracy: 0.6881\n",
      "Epoch 123/300\n",
      "1604/1604 [==============================] - 0s 185us/sample - loss: 0.4576 - accuracy: 0.8105 - val_loss: 0.6084 - val_accuracy: 0.6881\n",
      "Epoch 124/300\n",
      "1604/1604 [==============================] - 0s 164us/sample - loss: 0.4523 - accuracy: 0.8074 - val_loss: 0.6084 - val_accuracy: 0.6881\n",
      "Epoch 125/300\n",
      "1604/1604 [==============================] - 0s 177us/sample - loss: 0.4497 - accuracy: 0.8148 - val_loss: 0.6084 - val_accuracy: 0.6881\n",
      "Epoch 126/300\n",
      "1604/1604 [==============================] - 0s 187us/sample - loss: 0.4488 - accuracy: 0.8173 - val_loss: 0.6084 - val_accuracy: 0.6905\n",
      "Epoch 127/300\n",
      "1604/1604 [==============================] - 0s 173us/sample - loss: 0.4445 - accuracy: 0.8161 - val_loss: 0.6084 - val_accuracy: 0.6905\n",
      "Epoch 128/300\n",
      "1604/1604 [==============================] - 0s 178us/sample - loss: 0.4460 - accuracy: 0.8142 - val_loss: 0.6084 - val_accuracy: 0.6905\n",
      "Epoch 129/300\n",
      "1604/1604 [==============================] - 0s 176us/sample - loss: 0.4439 - accuracy: 0.8142 - val_loss: 0.6085 - val_accuracy: 0.6905\n",
      "Epoch 00129: early stopping\n",
      "215/215 [==============================] - 0s 90us/sample - loss: 0.9440 - accuracy: 0.4233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [1:04:01, 768.33s/it]\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:05<00:05,  5.75s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.28s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "8it [00:00, 77.95it/s]\u001b[A\n",
      "14it [00:00, 67.99it/s]\u001b[A\n",
      "18it [00:00, 47.04it/s]\u001b[A\n",
      "23it [00:00, 41.31it/s]\u001b[A\n",
      "27it [00:00, 38.28it/s]\u001b[A\n",
      "32it [00:00, 40.00it/s]\u001b[A\n",
      "38it [00:00, 41.41it/s]\u001b[A\n",
      "42it [00:00, 39.63it/s]\u001b[A\n",
      "46it [00:01, 38.72it/s]\u001b[A\n",
      "50it [00:01, 37.48it/s]\u001b[A\n",
      "55it [00:01, 36.81it/s]\u001b[A\n",
      "59it [00:01, 34.85it/s]\u001b[A\n",
      "63it [00:01, 32.70it/s]\u001b[A\n",
      "72it [00:01, 38.77it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 72/72 [00:00<00:00, 1758.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 496.640625 steps, validate for 131.0546875 steps\n",
      "Epoch 1/300\n",
      "497/496 [==============================] - 15s 29ms/step - loss: 0.6637 - accuracy: 0.6006 - val_loss: 0.6516 - val_accuracy: 0.6224\n",
      "Epoch 2/300\n",
      "497/496 [==============================] - 13s 27ms/step - loss: 0.6196 - accuracy: 0.6448 - val_loss: 0.6444 - val_accuracy: 0.6302\n",
      "Epoch 3/300\n",
      "497/496 [==============================] - 13s 27ms/step - loss: 0.6031 - accuracy: 0.6628 - val_loss: 0.6396 - val_accuracy: 0.6365\n",
      "Epoch 4/300\n",
      "497/496 [==============================] - 14s 28ms/step - loss: 0.5915 - accuracy: 0.6754 - val_loss: 0.6390 - val_accuracy: 0.6377\n",
      "Epoch 5/300\n",
      "497/496 [==============================] - 13s 27ms/step - loss: 0.5823 - accuracy: 0.6851 - val_loss: 0.6342 - val_accuracy: 0.6448\n",
      "Epoch 6/300\n",
      "497/496 [==============================] - 14s 27ms/step - loss: 0.5742 - accuracy: 0.6908 - val_loss: 0.6375 - val_accuracy: 0.6451\n",
      "Epoch 7/300\n",
      "497/496 [==============================] - 13s 27ms/step - loss: 0.5671 - accuracy: 0.6979 - val_loss: 0.6340 - val_accuracy: 0.6508\n",
      "Epoch 8/300\n",
      "497/496 [==============================] - 14s 27ms/step - loss: 0.5603 - accuracy: 0.7046 - val_loss: 0.6350 - val_accuracy: 0.6508\n",
      "Epoch 9/300\n",
      "497/496 [==============================] - 13s 27ms/step - loss: 0.5536 - accuracy: 0.7089 - val_loss: 0.6321 - val_accuracy: 0.6534\n",
      "Epoch 10/300\n",
      "497/496 [==============================] - 14s 27ms/step - loss: 0.5477 - accuracy: 0.7137 - val_loss: 0.6355 - val_accuracy: 0.6537\n",
      "Epoch 11/300\n",
      "497/496 [==============================] - 13s 27ms/step - loss: 0.5420 - accuracy: 0.7186 - val_loss: 0.6372 - val_accuracy: 0.6535\n",
      "Epoch 12/300\n",
      "497/496 [==============================] - 14s 27ms/step - loss: 0.5364 - accuracy: 0.7240 - val_loss: 0.6348 - val_accuracy: 0.6560\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 496.640625 steps, validate for 131.0546875 steps\n",
      "Epoch 1/300\n",
      "497/496 [==============================] - 33s 66ms/step - loss: 0.5263 - accuracy: 0.7316 - val_loss: 0.6375 - val_accuracy: 0.6580\n",
      "Epoch 2/300\n",
      "497/496 [==============================] - 31s 63ms/step - loss: 0.5052 - accuracy: 0.7502 - val_loss: 0.6313 - val_accuracy: 0.6606\n",
      "Epoch 3/300\n",
      "497/496 [==============================] - 31s 63ms/step - loss: 0.4893 - accuracy: 0.7624 - val_loss: 0.6686 - val_accuracy: 0.6357\n",
      "Epoch 4/300\n",
      "497/496 [==============================] - 31s 63ms/step - loss: 0.4752 - accuracy: 0.7740 - val_loss: 0.6453 - val_accuracy: 0.6594\n",
      "Epoch 5/300\n",
      "497/496 [==============================] - 31s 63ms/step - loss: 0.4622 - accuracy: 0.7840 - val_loss: 0.6260 - val_accuracy: 0.6694\n",
      "Epoch 6/300\n",
      "497/496 [==============================] - 31s 63ms/step - loss: 0.4489 - accuracy: 0.7928 - val_loss: 0.6274 - val_accuracy: 0.6668\n",
      "Epoch 7/300\n",
      "497/496 [==============================] - 31s 63ms/step - loss: 0.4368 - accuracy: 0.8033 - val_loss: 0.6585 - val_accuracy: 0.6525\n",
      "Epoch 8/300\n",
      "497/496 [==============================] - 31s 63ms/step - loss: 0.4245 - accuracy: 0.8124 - val_loss: 0.6562 - val_accuracy: 0.6580\n",
      "Epoch 00008: early stopping\n",
      "421/421 [==============================] - 0s 647us/sample - loss: 2.0100 - accuracy: 0.1544\n",
      "397/397 [==============================] - 0s 189us/sample - loss: 1.7954 - accuracy: 0.1965\n",
      "389/389 [==============================] - 0s 226us/sample - loss: 1.8713 - accuracy: 0.1979\n",
      "381/381 [==============================] - 0s 198us/sample - loss: 2.0203 - accuracy: 0.2126\n",
      "375/375 [==============================] - 0s 192us/sample - loss: 1.9374 - accuracy: 0.2080\n",
      "369/369 [==============================] - 0s 209us/sample - loss: 2.0635 - accuracy: 0.1897\n",
      "366/366 [==============================] - 0s 232us/sample - loss: 2.0459 - accuracy: 0.2131\n",
      "357/357 [==============================] - 0s 223us/sample - loss: 2.1547 - accuracy: 0.1905\n",
      "355/355 [==============================] - 0s 219us/sample - loss: 2.1428 - accuracy: 0.2056\n",
      "347/347 [==============================] - 0s 233us/sample - loss: 2.1199 - accuracy: 0.2017\n",
      "343/343 [==============================] - 0s 224us/sample - loss: 2.2066 - accuracy: 0.2012\n",
      "339/339 [==============================] - 0s 216us/sample - loss: 2.1551 - accuracy: 0.1770\n",
      "335/335 [==============================] - 0s 222us/sample - loss: 2.1393 - accuracy: 0.1881\n",
      "338/338 [==============================] - 0s 217us/sample - loss: 2.1617 - accuracy: 0.2012\n",
      "330/330 [==============================] - 0s 220us/sample - loss: 2.1271 - accuracy: 0.2061\n",
      "330/330 [==============================] - 0s 253us/sample - loss: 2.0988 - accuracy: 0.2212\n",
      "332/332 [==============================] - 0s 207us/sample - loss: 2.2497 - accuracy: 0.2139\n",
      "327/327 [==============================] - 0s 232us/sample - loss: 2.1766 - accuracy: 0.2110\n",
      "324/324 [==============================] - 0s 224us/sample - loss: 2.1388 - accuracy: 0.2500\n",
      "322/322 [==============================] - 0s 261us/sample - loss: 2.2360 - accuracy: 0.2267\n",
      "321/321 [==============================] - 0s 240us/sample - loss: 2.2547 - accuracy: 0.2181\n",
      "320/320 [==============================] - 0s 855us/sample - loss: 2.2761 - accuracy: 0.1750\n",
      "313/313 [==============================] - 0s 205us/sample - loss: 2.4185 - accuracy: 0.2077\n",
      "315/315 [==============================] - 0s 224us/sample - loss: 2.2337 - accuracy: 0.1968\n",
      "309/309 [==============================] - 0s 230us/sample - loss: 2.3139 - accuracy: 0.1942\n",
      "308/308 [==============================] - 0s 244us/sample - loss: 2.3314 - accuracy: 0.1818\n",
      "306/306 [==============================] - 0s 215us/sample - loss: 2.4142 - accuracy: 0.1797\n",
      "301/301 [==============================] - 0s 227us/sample - loss: 2.3008 - accuracy: 0.2093\n",
      "300/300 [==============================] - 0s 223us/sample - loss: 2.2401 - accuracy: 0.1933\n",
      "301/301 [==============================] - 0s 237us/sample - loss: 2.2172 - accuracy: 0.1960\n",
      "296/296 [==============================] - 0s 232us/sample - loss: 2.3243 - accuracy: 0.1858\n",
      "297/297 [==============================] - 0s 240us/sample - loss: 2.2616 - accuracy: 0.2054\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 1552 samples, validate on 416 samples\n",
      "Epoch 1/300\n",
      "1552/1552 [==============================] - 2s 1ms/sample - loss: 0.7602 - accuracy: 0.4523 - val_loss: 0.7345 - val_accuracy: 0.4712\n",
      "Epoch 2/300\n",
      "1552/1552 [==============================] - 0s 194us/sample - loss: 0.7410 - accuracy: 0.4787 - val_loss: 0.7242 - val_accuracy: 0.4928\n",
      "Epoch 3/300\n",
      "1552/1552 [==============================] - 0s 183us/sample - loss: 0.7332 - accuracy: 0.4820 - val_loss: 0.7167 - val_accuracy: 0.5072\n",
      "Epoch 4/300\n",
      "1552/1552 [==============================] - 0s 176us/sample - loss: 0.7217 - accuracy: 0.5097 - val_loss: 0.7106 - val_accuracy: 0.5192\n",
      "Epoch 5/300\n",
      "1552/1552 [==============================] - 0s 163us/sample - loss: 0.7118 - accuracy: 0.5290 - val_loss: 0.7055 - val_accuracy: 0.5264\n",
      "Epoch 6/300\n",
      "1552/1552 [==============================] - 0s 187us/sample - loss: 0.7012 - accuracy: 0.5341 - val_loss: 0.7011 - val_accuracy: 0.5409\n",
      "Epoch 7/300\n",
      "1552/1552 [==============================] - 0s 164us/sample - loss: 0.7010 - accuracy: 0.5432 - val_loss: 0.6971 - val_accuracy: 0.5361\n",
      "Epoch 8/300\n",
      "1552/1552 [==============================] - 0s 164us/sample - loss: 0.6989 - accuracy: 0.5425 - val_loss: 0.6935 - val_accuracy: 0.5433\n",
      "Epoch 9/300\n",
      "1552/1552 [==============================] - 0s 179us/sample - loss: 0.6869 - accuracy: 0.5619 - val_loss: 0.6901 - val_accuracy: 0.5457\n",
      "Epoch 10/300\n",
      "1552/1552 [==============================] - 0s 184us/sample - loss: 0.6895 - accuracy: 0.5554 - val_loss: 0.6871 - val_accuracy: 0.5553\n",
      "Epoch 11/300\n",
      "1552/1552 [==============================] - 0s 196us/sample - loss: 0.6803 - accuracy: 0.5702 - val_loss: 0.6840 - val_accuracy: 0.5673\n",
      "Epoch 12/300\n",
      "1552/1552 [==============================] - 0s 197us/sample - loss: 0.6760 - accuracy: 0.5741 - val_loss: 0.6814 - val_accuracy: 0.5697\n",
      "Epoch 13/300\n",
      "1552/1552 [==============================] - 0s 176us/sample - loss: 0.6769 - accuracy: 0.5735 - val_loss: 0.6789 - val_accuracy: 0.5745\n",
      "Epoch 14/300\n",
      "1552/1552 [==============================] - 0s 165us/sample - loss: 0.6719 - accuracy: 0.5863 - val_loss: 0.6764 - val_accuracy: 0.5841\n",
      "Epoch 15/300\n",
      "1552/1552 [==============================] - 0s 175us/sample - loss: 0.6682 - accuracy: 0.5805 - val_loss: 0.6740 - val_accuracy: 0.5865\n",
      "Epoch 16/300\n",
      "1552/1552 [==============================] - 0s 177us/sample - loss: 0.6605 - accuracy: 0.5902 - val_loss: 0.6717 - val_accuracy: 0.5841\n",
      "Epoch 17/300\n",
      "1552/1552 [==============================] - 0s 178us/sample - loss: 0.6609 - accuracy: 0.6044 - val_loss: 0.6695 - val_accuracy: 0.5865\n",
      "Epoch 18/300\n",
      "1552/1552 [==============================] - 0s 175us/sample - loss: 0.6580 - accuracy: 0.6070 - val_loss: 0.6674 - val_accuracy: 0.5938\n",
      "Epoch 19/300\n",
      "1552/1552 [==============================] - 0s 164us/sample - loss: 0.6517 - accuracy: 0.6018 - val_loss: 0.6654 - val_accuracy: 0.5913\n",
      "Epoch 20/300\n",
      "1552/1552 [==============================] - 0s 165us/sample - loss: 0.6486 - accuracy: 0.6128 - val_loss: 0.6635 - val_accuracy: 0.5962\n",
      "Epoch 21/300\n",
      "1552/1552 [==============================] - 0s 172us/sample - loss: 0.6409 - accuracy: 0.6263 - val_loss: 0.6615 - val_accuracy: 0.5962\n",
      "Epoch 22/300\n",
      "1552/1552 [==============================] - 0s 182us/sample - loss: 0.6424 - accuracy: 0.6276 - val_loss: 0.6596 - val_accuracy: 0.5962\n",
      "Epoch 23/300\n",
      "1552/1552 [==============================] - 0s 175us/sample - loss: 0.6402 - accuracy: 0.6256 - val_loss: 0.6578 - val_accuracy: 0.5938\n",
      "Epoch 24/300\n",
      "1552/1552 [==============================] - 0s 172us/sample - loss: 0.6436 - accuracy: 0.6082 - val_loss: 0.6560 - val_accuracy: 0.6058\n",
      "Epoch 25/300\n",
      "1552/1552 [==============================] - 0s 185us/sample - loss: 0.6334 - accuracy: 0.6392 - val_loss: 0.6543 - val_accuracy: 0.6130\n",
      "Epoch 26/300\n",
      "1552/1552 [==============================] - 0s 183us/sample - loss: 0.6337 - accuracy: 0.6250 - val_loss: 0.6526 - val_accuracy: 0.6154\n",
      "Epoch 27/300\n",
      "1552/1552 [==============================] - 0s 187us/sample - loss: 0.6293 - accuracy: 0.6424 - val_loss: 0.6509 - val_accuracy: 0.6226\n",
      "Epoch 28/300\n",
      "1552/1552 [==============================] - 0s 181us/sample - loss: 0.6259 - accuracy: 0.6482 - val_loss: 0.6492 - val_accuracy: 0.6226\n",
      "Epoch 29/300\n",
      "1552/1552 [==============================] - 0s 183us/sample - loss: 0.6196 - accuracy: 0.6379 - val_loss: 0.6477 - val_accuracy: 0.6250\n",
      "Epoch 30/300\n",
      "1552/1552 [==============================] - 0s 177us/sample - loss: 0.6186 - accuracy: 0.6553 - val_loss: 0.6461 - val_accuracy: 0.6346\n",
      "Epoch 31/300\n",
      "1552/1552 [==============================] - 0s 170us/sample - loss: 0.6208 - accuracy: 0.6572 - val_loss: 0.6446 - val_accuracy: 0.6370\n",
      "Epoch 32/300\n",
      "1552/1552 [==============================] - 0s 170us/sample - loss: 0.6138 - accuracy: 0.6740 - val_loss: 0.6430 - val_accuracy: 0.6418\n",
      "Epoch 33/300\n",
      "1552/1552 [==============================] - 0s 164us/sample - loss: 0.6136 - accuracy: 0.6534 - val_loss: 0.6415 - val_accuracy: 0.6442\n",
      "Epoch 34/300\n",
      "1552/1552 [==============================] - 0s 169us/sample - loss: 0.6079 - accuracy: 0.6765 - val_loss: 0.6400 - val_accuracy: 0.6442\n",
      "Epoch 35/300\n",
      "1552/1552 [==============================] - 0s 168us/sample - loss: 0.6111 - accuracy: 0.6753 - val_loss: 0.6386 - val_accuracy: 0.6466\n",
      "Epoch 36/300\n",
      "1552/1552 [==============================] - 0s 172us/sample - loss: 0.6057 - accuracy: 0.6804 - val_loss: 0.6371 - val_accuracy: 0.6490\n",
      "Epoch 37/300\n",
      "1552/1552 [==============================] - 0s 176us/sample - loss: 0.6027 - accuracy: 0.6753 - val_loss: 0.6357 - val_accuracy: 0.6514\n",
      "Epoch 38/300\n",
      "1552/1552 [==============================] - 0s 220us/sample - loss: 0.6025 - accuracy: 0.6830 - val_loss: 0.6343 - val_accuracy: 0.6514\n",
      "Epoch 39/300\n",
      "1552/1552 [==============================] - 0s 185us/sample - loss: 0.5980 - accuracy: 0.6804 - val_loss: 0.6330 - val_accuracy: 0.6514\n",
      "Epoch 40/300\n",
      "1552/1552 [==============================] - 0s 185us/sample - loss: 0.5972 - accuracy: 0.6778 - val_loss: 0.6316 - val_accuracy: 0.6490\n",
      "Epoch 41/300\n",
      "1552/1552 [==============================] - 0s 190us/sample - loss: 0.5907 - accuracy: 0.6939 - val_loss: 0.6303 - val_accuracy: 0.6490\n",
      "Epoch 42/300\n",
      "1552/1552 [==============================] - 0s 195us/sample - loss: 0.5917 - accuracy: 0.6933 - val_loss: 0.6289 - val_accuracy: 0.6514\n",
      "Epoch 43/300\n",
      "1552/1552 [==============================] - 0s 165us/sample - loss: 0.5901 - accuracy: 0.6907 - val_loss: 0.6276 - val_accuracy: 0.6490\n",
      "Epoch 44/300\n",
      "1552/1552 [==============================] - 0s 169us/sample - loss: 0.5866 - accuracy: 0.6901 - val_loss: 0.6263 - val_accuracy: 0.6490\n",
      "Epoch 45/300\n",
      "1552/1552 [==============================] - 0s 192us/sample - loss: 0.5834 - accuracy: 0.7043 - val_loss: 0.6250 - val_accuracy: 0.6514\n",
      "Epoch 46/300\n",
      "1552/1552 [==============================] - 0s 197us/sample - loss: 0.5841 - accuracy: 0.7088 - val_loss: 0.6237 - val_accuracy: 0.6514\n",
      "Epoch 47/300\n",
      "1552/1552 [==============================] - 0s 175us/sample - loss: 0.5817 - accuracy: 0.7023 - val_loss: 0.6225 - val_accuracy: 0.6538\n",
      "Epoch 48/300\n",
      "1552/1552 [==============================] - 0s 166us/sample - loss: 0.5773 - accuracy: 0.6972 - val_loss: 0.6212 - val_accuracy: 0.6562\n",
      "Epoch 49/300\n",
      "1552/1552 [==============================] - 0s 169us/sample - loss: 0.5697 - accuracy: 0.7178 - val_loss: 0.6199 - val_accuracy: 0.6562\n",
      "Epoch 50/300\n",
      "1552/1552 [==============================] - 0s 170us/sample - loss: 0.5736 - accuracy: 0.7120 - val_loss: 0.6187 - val_accuracy: 0.6611\n",
      "Epoch 51/300\n",
      "1552/1552 [==============================] - 0s 171us/sample - loss: 0.5716 - accuracy: 0.7107 - val_loss: 0.6175 - val_accuracy: 0.6635\n",
      "Epoch 52/300\n",
      "1552/1552 [==============================] - 0s 177us/sample - loss: 0.5662 - accuracy: 0.7210 - val_loss: 0.6163 - val_accuracy: 0.6635\n",
      "Epoch 53/300\n",
      "1552/1552 [==============================] - 0s 174us/sample - loss: 0.5677 - accuracy: 0.7223 - val_loss: 0.6151 - val_accuracy: 0.6683\n",
      "Epoch 54/300\n",
      "1552/1552 [==============================] - 0s 173us/sample - loss: 0.5660 - accuracy: 0.7262 - val_loss: 0.6139 - val_accuracy: 0.6683\n",
      "Epoch 55/300\n",
      "1552/1552 [==============================] - 0s 165us/sample - loss: 0.5628 - accuracy: 0.7204 - val_loss: 0.6127 - val_accuracy: 0.6683\n",
      "Epoch 56/300\n",
      "1552/1552 [==============================] - 0s 177us/sample - loss: 0.5629 - accuracy: 0.7223 - val_loss: 0.6116 - val_accuracy: 0.6707\n",
      "Epoch 57/300\n",
      "1552/1552 [==============================] - 0s 172us/sample - loss: 0.5552 - accuracy: 0.7378 - val_loss: 0.6104 - val_accuracy: 0.6731\n",
      "Epoch 58/300\n",
      "1552/1552 [==============================] - 0s 176us/sample - loss: 0.5562 - accuracy: 0.7339 - val_loss: 0.6093 - val_accuracy: 0.6707\n",
      "Epoch 59/300\n",
      "1552/1552 [==============================] - 0s 192us/sample - loss: 0.5527 - accuracy: 0.7320 - val_loss: 0.6081 - val_accuracy: 0.6731\n",
      "Epoch 60/300\n",
      "1552/1552 [==============================] - 0s 182us/sample - loss: 0.5512 - accuracy: 0.7313 - val_loss: 0.6070 - val_accuracy: 0.6707\n",
      "Epoch 61/300\n",
      "1552/1552 [==============================] - 0s 179us/sample - loss: 0.5442 - accuracy: 0.7513 - val_loss: 0.6059 - val_accuracy: 0.6779\n",
      "Epoch 62/300\n",
      "1552/1552 [==============================] - 0s 172us/sample - loss: 0.5464 - accuracy: 0.7468 - val_loss: 0.6047 - val_accuracy: 0.6779\n",
      "Epoch 63/300\n",
      "1552/1552 [==============================] - 0s 206us/sample - loss: 0.5441 - accuracy: 0.7416 - val_loss: 0.6036 - val_accuracy: 0.6803\n",
      "Epoch 64/300\n",
      "1552/1552 [==============================] - 0s 191us/sample - loss: 0.5394 - accuracy: 0.7494 - val_loss: 0.6025 - val_accuracy: 0.6779\n",
      "Epoch 65/300\n",
      "1552/1552 [==============================] - 0s 182us/sample - loss: 0.5428 - accuracy: 0.7552 - val_loss: 0.6014 - val_accuracy: 0.6803\n",
      "Epoch 66/300\n",
      "1552/1552 [==============================] - 0s 193us/sample - loss: 0.5379 - accuracy: 0.7494 - val_loss: 0.6003 - val_accuracy: 0.6803\n",
      "Epoch 67/300\n",
      "1552/1552 [==============================] - 0s 167us/sample - loss: 0.5299 - accuracy: 0.7526 - val_loss: 0.5992 - val_accuracy: 0.6779\n",
      "Epoch 68/300\n",
      "1552/1552 [==============================] - 0s 175us/sample - loss: 0.5328 - accuracy: 0.7577 - val_loss: 0.5982 - val_accuracy: 0.6803\n",
      "Epoch 69/300\n",
      "1552/1552 [==============================] - 0s 183us/sample - loss: 0.5273 - accuracy: 0.7590 - val_loss: 0.5971 - val_accuracy: 0.6803\n",
      "Epoch 70/300\n",
      "1552/1552 [==============================] - 0s 181us/sample - loss: 0.5297 - accuracy: 0.7590 - val_loss: 0.5961 - val_accuracy: 0.6803\n",
      "Epoch 71/300\n",
      "1552/1552 [==============================] - 0s 169us/sample - loss: 0.5247 - accuracy: 0.7687 - val_loss: 0.5950 - val_accuracy: 0.6803\n",
      "Epoch 72/300\n",
      "1552/1552 [==============================] - 0s 168us/sample - loss: 0.5263 - accuracy: 0.7584 - val_loss: 0.5940 - val_accuracy: 0.6851\n",
      "Epoch 73/300\n",
      "1552/1552 [==============================] - 0s 181us/sample - loss: 0.5201 - accuracy: 0.7764 - val_loss: 0.5930 - val_accuracy: 0.6851\n",
      "Epoch 74/300\n",
      "1552/1552 [==============================] - 0s 182us/sample - loss: 0.5180 - accuracy: 0.7603 - val_loss: 0.5919 - val_accuracy: 0.6851\n",
      "Epoch 75/300\n",
      "1552/1552 [==============================] - 0s 179us/sample - loss: 0.5169 - accuracy: 0.7726 - val_loss: 0.5909 - val_accuracy: 0.6851\n",
      "Epoch 76/300\n",
      "1552/1552 [==============================] - 0s 189us/sample - loss: 0.5120 - accuracy: 0.7784 - val_loss: 0.5899 - val_accuracy: 0.6875\n",
      "Epoch 77/300\n",
      "1552/1552 [==============================] - 0s 177us/sample - loss: 0.5117 - accuracy: 0.7822 - val_loss: 0.5889 - val_accuracy: 0.6899\n",
      "Epoch 78/300\n",
      "1552/1552 [==============================] - 0s 177us/sample - loss: 0.5144 - accuracy: 0.7674 - val_loss: 0.5880 - val_accuracy: 0.6899\n",
      "Epoch 79/300\n",
      "1552/1552 [==============================] - 0s 178us/sample - loss: 0.5061 - accuracy: 0.7854 - val_loss: 0.5870 - val_accuracy: 0.6899\n",
      "Epoch 80/300\n",
      "1552/1552 [==============================] - 0s 169us/sample - loss: 0.5066 - accuracy: 0.7861 - val_loss: 0.5860 - val_accuracy: 0.6923\n",
      "Epoch 81/300\n",
      "1552/1552 [==============================] - 0s 168us/sample - loss: 0.4989 - accuracy: 0.7854 - val_loss: 0.5850 - val_accuracy: 0.6923\n",
      "Epoch 82/300\n",
      "1552/1552 [==============================] - 0s 166us/sample - loss: 0.4968 - accuracy: 0.7835 - val_loss: 0.5841 - val_accuracy: 0.6947\n",
      "Epoch 83/300\n",
      "1552/1552 [==============================] - 0s 173us/sample - loss: 0.4959 - accuracy: 0.7874 - val_loss: 0.5832 - val_accuracy: 0.6947\n",
      "Epoch 84/300\n",
      "1552/1552 [==============================] - 0s 180us/sample - loss: 0.4920 - accuracy: 0.7912 - val_loss: 0.5823 - val_accuracy: 0.6923\n",
      "Epoch 85/300\n",
      "1552/1552 [==============================] - 0s 173us/sample - loss: 0.4966 - accuracy: 0.7796 - val_loss: 0.5814 - val_accuracy: 0.6923\n",
      "Epoch 86/300\n",
      "1552/1552 [==============================] - 0s 168us/sample - loss: 0.4910 - accuracy: 0.7893 - val_loss: 0.5804 - val_accuracy: 0.6947\n",
      "Epoch 87/300\n",
      "1552/1552 [==============================] - 0s 164us/sample - loss: 0.4909 - accuracy: 0.7841 - val_loss: 0.5796 - val_accuracy: 0.6947\n",
      "Epoch 88/300\n",
      "1552/1552 [==============================] - 0s 168us/sample - loss: 0.4843 - accuracy: 0.7964 - val_loss: 0.5787 - val_accuracy: 0.6899\n",
      "Epoch 89/300\n",
      "1552/1552 [==============================] - 0s 171us/sample - loss: 0.4851 - accuracy: 0.8061 - val_loss: 0.5777 - val_accuracy: 0.6923\n",
      "Epoch 90/300\n",
      "1552/1552 [==============================] - 0s 187us/sample - loss: 0.4741 - accuracy: 0.8048 - val_loss: 0.5769 - val_accuracy: 0.6995\n",
      "Epoch 91/300\n",
      "1552/1552 [==============================] - 0s 179us/sample - loss: 0.4806 - accuracy: 0.7996 - val_loss: 0.5760 - val_accuracy: 0.7043\n",
      "Epoch 92/300\n",
      "1552/1552 [==============================] - 0s 176us/sample - loss: 0.4738 - accuracy: 0.8041 - val_loss: 0.5751 - val_accuracy: 0.7043\n",
      "Epoch 93/300\n",
      "1552/1552 [==============================] - 0s 185us/sample - loss: 0.4757 - accuracy: 0.7977 - val_loss: 0.5742 - val_accuracy: 0.6995\n",
      "Epoch 94/300\n",
      "1552/1552 [==============================] - 0s 163us/sample - loss: 0.4731 - accuracy: 0.7990 - val_loss: 0.5734 - val_accuracy: 0.7019\n",
      "Epoch 95/300\n",
      "1552/1552 [==============================] - 0s 189us/sample - loss: 0.4700 - accuracy: 0.8106 - val_loss: 0.5726 - val_accuracy: 0.7043\n",
      "Epoch 96/300\n",
      "1552/1552 [==============================] - 0s 197us/sample - loss: 0.4699 - accuracy: 0.8073 - val_loss: 0.5718 - val_accuracy: 0.7091\n",
      "Epoch 97/300\n",
      "1552/1552 [==============================] - 0s 171us/sample - loss: 0.4673 - accuracy: 0.8080 - val_loss: 0.5710 - val_accuracy: 0.7163\n",
      "Epoch 98/300\n",
      "1552/1552 [==============================] - 0s 170us/sample - loss: 0.4610 - accuracy: 0.8157 - val_loss: 0.5702 - val_accuracy: 0.7188\n",
      "Epoch 99/300\n",
      "1552/1552 [==============================] - 0s 182us/sample - loss: 0.4610 - accuracy: 0.8028 - val_loss: 0.5694 - val_accuracy: 0.7188\n",
      "Epoch 100/300\n",
      "1552/1552 [==============================] - 0s 175us/sample - loss: 0.4591 - accuracy: 0.8131 - val_loss: 0.5686 - val_accuracy: 0.7212\n",
      "Epoch 101/300\n",
      "1552/1552 [==============================] - 0s 167us/sample - loss: 0.4534 - accuracy: 0.8157 - val_loss: 0.5679 - val_accuracy: 0.7236\n",
      "Epoch 102/300\n",
      "1552/1552 [==============================] - 0s 172us/sample - loss: 0.4532 - accuracy: 0.8138 - val_loss: 0.5671 - val_accuracy: 0.7212\n",
      "Epoch 103/300\n",
      "1552/1552 [==============================] - 0s 173us/sample - loss: 0.4505 - accuracy: 0.8222 - val_loss: 0.5664 - val_accuracy: 0.7236\n",
      "Epoch 104/300\n",
      "1552/1552 [==============================] - 0s 167us/sample - loss: 0.4498 - accuracy: 0.8177 - val_loss: 0.5656 - val_accuracy: 0.7284\n",
      "Epoch 105/300\n",
      "1552/1552 [==============================] - 0s 167us/sample - loss: 0.4422 - accuracy: 0.8260 - val_loss: 0.5648 - val_accuracy: 0.7284\n",
      "Epoch 106/300\n",
      "1552/1552 [==============================] - 0s 181us/sample - loss: 0.4431 - accuracy: 0.8189 - val_loss: 0.5642 - val_accuracy: 0.7308\n",
      "Epoch 107/300\n",
      "1552/1552 [==============================] - 0s 171us/sample - loss: 0.4407 - accuracy: 0.8228 - val_loss: 0.5635 - val_accuracy: 0.7332\n",
      "Epoch 108/300\n",
      "1552/1552 [==============================] - 0s 177us/sample - loss: 0.4368 - accuracy: 0.8260 - val_loss: 0.5628 - val_accuracy: 0.7332\n",
      "Epoch 109/300\n",
      "1552/1552 [==============================] - 0s 165us/sample - loss: 0.4334 - accuracy: 0.8370 - val_loss: 0.5622 - val_accuracy: 0.7332\n",
      "Epoch 110/300\n",
      "1552/1552 [==============================] - 0s 185us/sample - loss: 0.4307 - accuracy: 0.8351 - val_loss: 0.5615 - val_accuracy: 0.7308\n",
      "Epoch 111/300\n",
      "1552/1552 [==============================] - 0s 172us/sample - loss: 0.4300 - accuracy: 0.8286 - val_loss: 0.5609 - val_accuracy: 0.7332\n",
      "Epoch 112/300\n",
      "1552/1552 [==============================] - 0s 178us/sample - loss: 0.4304 - accuracy: 0.8305 - val_loss: 0.5603 - val_accuracy: 0.7332\n",
      "Epoch 113/300\n",
      "1552/1552 [==============================] - 0s 176us/sample - loss: 0.4265 - accuracy: 0.8273 - val_loss: 0.5597 - val_accuracy: 0.7308\n",
      "Epoch 114/300\n",
      "1552/1552 [==============================] - 0s 172us/sample - loss: 0.4184 - accuracy: 0.8370 - val_loss: 0.5590 - val_accuracy: 0.7308\n",
      "Epoch 115/300\n",
      "1552/1552 [==============================] - 0s 198us/sample - loss: 0.4255 - accuracy: 0.8260 - val_loss: 0.5585 - val_accuracy: 0.7332\n",
      "Epoch 116/300\n",
      "1552/1552 [==============================] - 0s 173us/sample - loss: 0.4203 - accuracy: 0.8434 - val_loss: 0.5580 - val_accuracy: 0.7332\n",
      "Epoch 117/300\n",
      "1552/1552 [==============================] - 0s 169us/sample - loss: 0.4172 - accuracy: 0.8460 - val_loss: 0.5574 - val_accuracy: 0.7308\n",
      "Epoch 118/300\n",
      "1552/1552 [==============================] - 0s 210us/sample - loss: 0.4114 - accuracy: 0.8428 - val_loss: 0.5569 - val_accuracy: 0.7356\n",
      "Epoch 119/300\n",
      "1552/1552 [==============================] - 0s 166us/sample - loss: 0.4104 - accuracy: 0.8428 - val_loss: 0.5564 - val_accuracy: 0.7356\n",
      "Epoch 120/300\n",
      "1552/1552 [==============================] - 0s 195us/sample - loss: 0.4088 - accuracy: 0.8421 - val_loss: 0.5559 - val_accuracy: 0.7356\n",
      "Epoch 121/300\n",
      "1552/1552 [==============================] - 0s 167us/sample - loss: 0.4018 - accuracy: 0.8466 - val_loss: 0.5554 - val_accuracy: 0.7356\n",
      "Epoch 122/300\n",
      "1552/1552 [==============================] - 0s 187us/sample - loss: 0.4047 - accuracy: 0.8383 - val_loss: 0.5549 - val_accuracy: 0.7332\n",
      "Epoch 123/300\n",
      "1552/1552 [==============================] - 0s 176us/sample - loss: 0.4040 - accuracy: 0.8537 - val_loss: 0.5545 - val_accuracy: 0.7356\n",
      "Epoch 124/300\n",
      "1552/1552 [==============================] - 0s 240us/sample - loss: 0.3995 - accuracy: 0.8447 - val_loss: 0.5541 - val_accuracy: 0.7404\n",
      "Epoch 125/300\n",
      "1552/1552 [==============================] - 0s 201us/sample - loss: 0.3970 - accuracy: 0.8479 - val_loss: 0.5537 - val_accuracy: 0.7404\n",
      "Epoch 126/300\n",
      "1552/1552 [==============================] - 0s 190us/sample - loss: 0.3962 - accuracy: 0.8486 - val_loss: 0.5533 - val_accuracy: 0.7404\n",
      "Epoch 127/300\n",
      "1552/1552 [==============================] - 0s 177us/sample - loss: 0.3899 - accuracy: 0.8531 - val_loss: 0.5528 - val_accuracy: 0.7428\n",
      "Epoch 128/300\n",
      "1552/1552 [==============================] - 0s 165us/sample - loss: 0.3920 - accuracy: 0.8512 - val_loss: 0.5525 - val_accuracy: 0.7428\n",
      "Epoch 129/300\n",
      "1552/1552 [==============================] - 0s 165us/sample - loss: 0.3876 - accuracy: 0.8473 - val_loss: 0.5522 - val_accuracy: 0.7428\n",
      "Epoch 130/300\n",
      "1552/1552 [==============================] - 0s 167us/sample - loss: 0.3788 - accuracy: 0.8595 - val_loss: 0.5519 - val_accuracy: 0.7428\n",
      "Epoch 131/300\n",
      "1552/1552 [==============================] - 0s 183us/sample - loss: 0.3828 - accuracy: 0.8505 - val_loss: 0.5516 - val_accuracy: 0.7404\n",
      "Epoch 132/300\n",
      "1552/1552 [==============================] - 0s 167us/sample - loss: 0.3788 - accuracy: 0.8595 - val_loss: 0.5512 - val_accuracy: 0.7380\n",
      "Epoch 133/300\n",
      "1552/1552 [==============================] - 0s 179us/sample - loss: 0.3773 - accuracy: 0.8608 - val_loss: 0.5509 - val_accuracy: 0.7356\n",
      "Epoch 134/300\n",
      "1552/1552 [==============================] - 0s 172us/sample - loss: 0.3750 - accuracy: 0.8640 - val_loss: 0.5506 - val_accuracy: 0.7380\n",
      "Epoch 135/300\n",
      "1552/1552 [==============================] - 0s 169us/sample - loss: 0.3676 - accuracy: 0.8640 - val_loss: 0.5504 - val_accuracy: 0.7380\n",
      "Epoch 136/300\n",
      "1552/1552 [==============================] - 0s 174us/sample - loss: 0.3719 - accuracy: 0.8557 - val_loss: 0.5502 - val_accuracy: 0.7380\n",
      "Epoch 137/300\n",
      "1552/1552 [==============================] - 0s 175us/sample - loss: 0.3681 - accuracy: 0.8628 - val_loss: 0.5500 - val_accuracy: 0.7356\n",
      "Epoch 138/300\n",
      "1552/1552 [==============================] - 0s 194us/sample - loss: 0.3670 - accuracy: 0.8653 - val_loss: 0.5498 - val_accuracy: 0.7356\n",
      "Epoch 139/300\n",
      "1552/1552 [==============================] - 0s 162us/sample - loss: 0.3589 - accuracy: 0.8673 - val_loss: 0.5496 - val_accuracy: 0.7356\n",
      "Epoch 140/300\n",
      "1552/1552 [==============================] - 0s 169us/sample - loss: 0.3595 - accuracy: 0.8666 - val_loss: 0.5495 - val_accuracy: 0.7380\n",
      "Epoch 141/300\n",
      "1552/1552 [==============================] - 0s 171us/sample - loss: 0.3605 - accuracy: 0.8647 - val_loss: 0.5494 - val_accuracy: 0.7380\n",
      "Epoch 142/300\n",
      "1552/1552 [==============================] - 0s 176us/sample - loss: 0.3603 - accuracy: 0.8673 - val_loss: 0.5493 - val_accuracy: 0.7404\n",
      "Epoch 143/300\n",
      "1552/1552 [==============================] - 0s 165us/sample - loss: 0.3550 - accuracy: 0.8744 - val_loss: 0.5493 - val_accuracy: 0.7428\n",
      "Epoch 144/300\n",
      "1552/1552 [==============================] - 0s 169us/sample - loss: 0.3535 - accuracy: 0.8705 - val_loss: 0.5493 - val_accuracy: 0.7404\n",
      "Epoch 145/300\n",
      "1552/1552 [==============================] - 0s 166us/sample - loss: 0.3482 - accuracy: 0.8763 - val_loss: 0.5493 - val_accuracy: 0.7428\n",
      "Epoch 146/300\n",
      "1552/1552 [==============================] - 0s 169us/sample - loss: 0.3446 - accuracy: 0.8750 - val_loss: 0.5493 - val_accuracy: 0.7428\n",
      "Epoch 147/300\n",
      "1552/1552 [==============================] - 0s 178us/sample - loss: 0.3443 - accuracy: 0.8756 - val_loss: 0.5493 - val_accuracy: 0.7428\n",
      "Epoch 00147: early stopping\n",
      "271/271 [==============================] - 0s 1ms/sample - loss: 1.6124 - accuracy: 0.2657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [12:57, 777.45s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:05<00:05,  5.81s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.19s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "8it [00:00, 77.32it/s]\u001b[A\n",
      "11it [00:00, 50.71it/s]\u001b[A\n",
      "14it [00:00, 40.87it/s]\u001b[A\n",
      "17it [00:00, 35.64it/s]\u001b[A\n",
      "22it [00:00, 37.41it/s]\u001b[A\n",
      "27it [00:00, 37.57it/s]\u001b[A\n",
      "32it [00:00, 38.11it/s]\u001b[A\n",
      "37it [00:00, 39.90it/s]\u001b[A\n",
      "41it [00:01, 39.46it/s]\u001b[A\n",
      "45it [00:01, 38.60it/s]\u001b[A\n",
      "49it [00:01, 37.23it/s]\u001b[A\n",
      "53it [00:01, 35.31it/s]\u001b[A\n",
      "58it [00:01, 35.07it/s]\u001b[A\n",
      "62it [00:01, 32.39it/s]\u001b[A\n",
      "66it [00:01, 33.86it/s]\u001b[A\n",
      "72it [00:01, 38.01it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 72/72 [00:00<00:00, 1930.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 512.3515625 steps, validate for 136.90625 steps\n",
      "Epoch 1/300\n",
      "513/512 [==============================] - 15s 30ms/step - loss: 0.6909 - accuracy: 0.5753 - val_loss: 0.6741 - val_accuracy: 0.5895\n",
      "Epoch 2/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.6485 - accuracy: 0.6188 - val_loss: 0.6600 - val_accuracy: 0.6113\n",
      "Epoch 3/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.6313 - accuracy: 0.6400 - val_loss: 0.6540 - val_accuracy: 0.6213\n",
      "Epoch 4/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.6189 - accuracy: 0.6531 - val_loss: 0.6474 - val_accuracy: 0.6261\n",
      "Epoch 5/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.6089 - accuracy: 0.6644 - val_loss: 0.6453 - val_accuracy: 0.6297\n",
      "Epoch 6/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.6002 - accuracy: 0.6726 - val_loss: 0.6449 - val_accuracy: 0.6326\n",
      "Epoch 7/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.5923 - accuracy: 0.6810 - val_loss: 0.6451 - val_accuracy: 0.6286\n",
      "Epoch 8/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.5849 - accuracy: 0.6873 - val_loss: 0.6429 - val_accuracy: 0.6331\n",
      "Epoch 9/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.5782 - accuracy: 0.6940 - val_loss: 0.6442 - val_accuracy: 0.6349\n",
      "Epoch 10/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.5719 - accuracy: 0.6997 - val_loss: 0.6462 - val_accuracy: 0.6349\n",
      "Epoch 11/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.5658 - accuracy: 0.7045 - val_loss: 0.6465 - val_accuracy: 0.6356\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 512.3515625 steps, validate for 136.90625 steps\n",
      "Epoch 1/300\n",
      "513/512 [==============================] - 34s 66ms/step - loss: 0.5552 - accuracy: 0.7120 - val_loss: 0.6501 - val_accuracy: 0.6373\n",
      "Epoch 2/300\n",
      "513/512 [==============================] - 32s 63ms/step - loss: 0.5342 - accuracy: 0.7310 - val_loss: 0.6358 - val_accuracy: 0.6470\n",
      "Epoch 3/300\n",
      "513/512 [==============================] - 32s 63ms/step - loss: 0.5176 - accuracy: 0.7455 - val_loss: 0.6724 - val_accuracy: 0.6289\n",
      "Epoch 4/300\n",
      "513/512 [==============================] - 32s 63ms/step - loss: 0.5034 - accuracy: 0.7566 - val_loss: 0.6718 - val_accuracy: 0.6361\n",
      "Epoch 5/300\n",
      "513/512 [==============================] - 32s 63ms/step - loss: 0.4904 - accuracy: 0.7665 - val_loss: 0.6789 - val_accuracy: 0.6262\n",
      "Epoch 00005: early stopping\n",
      "312/312 [==============================] - 0s 871us/sample - loss: 0.7603 - accuracy: 0.5481\n",
      "296/296 [==============================] - 0s 207us/sample - loss: 0.8557 - accuracy: 0.4459\n",
      "290/290 [==============================] - 0s 230us/sample - loss: 0.8426 - accuracy: 0.4207\n",
      "285/285 [==============================] - 0s 253us/sample - loss: 0.8572 - accuracy: 0.4772\n",
      "279/279 [==============================] - 0s 219us/sample - loss: 0.8316 - accuracy: 0.4695\n",
      "272/272 [==============================] - 0s 201us/sample - loss: 0.8390 - accuracy: 0.5184\n",
      "270/270 [==============================] - 0s 222us/sample - loss: 0.8346 - accuracy: 0.5111\n",
      "269/269 [==============================] - 0s 250us/sample - loss: 0.8664 - accuracy: 0.4870\n",
      "263/263 [==============================] - 0s 229us/sample - loss: 0.8624 - accuracy: 0.4753\n",
      "262/262 [==============================] - 0s 226us/sample - loss: 0.8679 - accuracy: 0.4695\n",
      "261/261 [==============================] - 0s 221us/sample - loss: 0.8758 - accuracy: 0.4636\n",
      "254/254 [==============================] - 0s 224us/sample - loss: 0.8583 - accuracy: 0.5079\n",
      "252/252 [==============================] - 0s 229us/sample - loss: 0.8714 - accuracy: 0.5040\n",
      "249/249 [==============================] - 0s 221us/sample - loss: 0.8960 - accuracy: 0.4779\n",
      "251/251 [==============================] - 0s 209us/sample - loss: 0.8445 - accuracy: 0.5219\n",
      "247/247 [==============================] - 0s 227us/sample - loss: 0.8604 - accuracy: 0.4818\n",
      "246/246 [==============================] - 0s 232us/sample - loss: 0.8099 - accuracy: 0.4837\n",
      "243/243 [==============================] - 0s 261us/sample - loss: 0.8376 - accuracy: 0.4650\n",
      "242/242 [==============================] - 0s 213us/sample - loss: 0.8043 - accuracy: 0.4835\n",
      "236/236 [==============================] - 0s 216us/sample - loss: 0.7671 - accuracy: 0.5678\n",
      "234/234 [==============================] - 0s 216us/sample - loss: 0.7191 - accuracy: 0.5769\n",
      "230/230 [==============================] - 0s 219us/sample - loss: 0.7172 - accuracy: 0.6217\n",
      "231/231 [==============================] - 0s 239us/sample - loss: 0.7472 - accuracy: 0.5628\n",
      "228/228 [==============================] - 0s 243us/sample - loss: 0.7226 - accuracy: 0.5833\n",
      "227/227 [==============================] - 0s 250us/sample - loss: 0.7905 - accuracy: 0.5242\n",
      "227/227 [==============================] - 0s 275us/sample - loss: 0.7816 - accuracy: 0.5507\n",
      "221/221 [==============================] - 0s 244us/sample - loss: 0.7739 - accuracy: 0.5430\n",
      "226/226 [==============================] - 0s 220us/sample - loss: 0.8272 - accuracy: 0.5044\n",
      "230/230 [==============================] - 0s 219us/sample - loss: 0.6888 - accuracy: 0.6261\n",
      "226/226 [==============================] - 0s 233us/sample - loss: 0.7866 - accuracy: 0.5531\n",
      "223/223 [==============================] - 0s 217us/sample - loss: 0.8078 - accuracy: 0.5336\n",
      "222/222 [==============================] - 0s 216us/sample - loss: 0.8375 - accuracy: 0.4775\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 1603 samples, validate on 439 samples\n",
      "Epoch 1/300\n",
      "1603/1603 [==============================] - 2s 1ms/sample - loss: 0.6941 - accuracy: 0.5459 - val_loss: 0.7120 - val_accuracy: 0.5148\n",
      "Epoch 2/300\n",
      "1603/1603 [==============================] - 0s 175us/sample - loss: 0.6843 - accuracy: 0.5546 - val_loss: 0.7077 - val_accuracy: 0.5239\n",
      "Epoch 3/300\n",
      "1603/1603 [==============================] - 0s 168us/sample - loss: 0.6832 - accuracy: 0.5565 - val_loss: 0.7042 - val_accuracy: 0.5285\n",
      "Epoch 4/300\n",
      "1603/1603 [==============================] - 0s 184us/sample - loss: 0.6761 - accuracy: 0.5752 - val_loss: 0.7012 - val_accuracy: 0.5308\n",
      "Epoch 5/300\n",
      "1603/1603 [==============================] - 0s 183us/sample - loss: 0.6691 - accuracy: 0.5808 - val_loss: 0.6988 - val_accuracy: 0.5353\n",
      "Epoch 6/300\n",
      "1603/1603 [==============================] - 0s 183us/sample - loss: 0.6707 - accuracy: 0.5696 - val_loss: 0.6967 - val_accuracy: 0.5421\n",
      "Epoch 7/300\n",
      "1603/1603 [==============================] - 0s 180us/sample - loss: 0.6607 - accuracy: 0.5970 - val_loss: 0.6948 - val_accuracy: 0.5353\n",
      "Epoch 8/300\n",
      "1603/1603 [==============================] - 0s 185us/sample - loss: 0.6655 - accuracy: 0.5951 - val_loss: 0.6929 - val_accuracy: 0.5399\n",
      "Epoch 9/300\n",
      "1603/1603 [==============================] - 0s 184us/sample - loss: 0.6539 - accuracy: 0.6120 - val_loss: 0.6911 - val_accuracy: 0.5467\n",
      "Epoch 10/300\n",
      "1603/1603 [==============================] - 0s 170us/sample - loss: 0.6557 - accuracy: 0.5983 - val_loss: 0.6894 - val_accuracy: 0.5490\n",
      "Epoch 11/300\n",
      "1603/1603 [==============================] - 0s 193us/sample - loss: 0.6496 - accuracy: 0.6120 - val_loss: 0.6879 - val_accuracy: 0.5535\n",
      "Epoch 12/300\n",
      "1603/1603 [==============================] - 0s 182us/sample - loss: 0.6528 - accuracy: 0.6132 - val_loss: 0.6864 - val_accuracy: 0.5581\n",
      "Epoch 13/300\n",
      "1603/1603 [==============================] - 0s 177us/sample - loss: 0.6482 - accuracy: 0.6101 - val_loss: 0.6850 - val_accuracy: 0.5581\n",
      "Epoch 14/300\n",
      "1603/1603 [==============================] - 0s 181us/sample - loss: 0.6432 - accuracy: 0.6226 - val_loss: 0.6836 - val_accuracy: 0.5626\n",
      "Epoch 15/300\n",
      "1603/1603 [==============================] - 0s 166us/sample - loss: 0.6427 - accuracy: 0.6195 - val_loss: 0.6824 - val_accuracy: 0.5672\n",
      "Epoch 16/300\n",
      "1603/1603 [==============================] - 0s 162us/sample - loss: 0.6394 - accuracy: 0.6344 - val_loss: 0.6811 - val_accuracy: 0.5672\n",
      "Epoch 17/300\n",
      "1603/1603 [==============================] - 0s 164us/sample - loss: 0.6401 - accuracy: 0.6338 - val_loss: 0.6798 - val_accuracy: 0.5695\n",
      "Epoch 18/300\n",
      "1603/1603 [==============================] - 0s 179us/sample - loss: 0.6408 - accuracy: 0.6226 - val_loss: 0.6785 - val_accuracy: 0.5718\n",
      "Epoch 19/300\n",
      "1603/1603 [==============================] - 0s 157us/sample - loss: 0.6364 - accuracy: 0.6319 - val_loss: 0.6773 - val_accuracy: 0.5763\n",
      "Epoch 20/300\n",
      "1603/1603 [==============================] - 0s 162us/sample - loss: 0.6361 - accuracy: 0.6400 - val_loss: 0.6761 - val_accuracy: 0.5809\n",
      "Epoch 21/300\n",
      "1603/1603 [==============================] - 0s 175us/sample - loss: 0.6317 - accuracy: 0.6457 - val_loss: 0.6750 - val_accuracy: 0.5831\n",
      "Epoch 22/300\n",
      "1603/1603 [==============================] - 0s 162us/sample - loss: 0.6288 - accuracy: 0.6706 - val_loss: 0.6739 - val_accuracy: 0.5831\n",
      "Epoch 23/300\n",
      "1603/1603 [==============================] - 0s 168us/sample - loss: 0.6238 - accuracy: 0.6619 - val_loss: 0.6728 - val_accuracy: 0.5831\n",
      "Epoch 24/300\n",
      "1603/1603 [==============================] - 0s 176us/sample - loss: 0.6213 - accuracy: 0.6650 - val_loss: 0.6717 - val_accuracy: 0.5831\n",
      "Epoch 25/300\n",
      "1603/1603 [==============================] - 0s 163us/sample - loss: 0.6253 - accuracy: 0.6500 - val_loss: 0.6707 - val_accuracy: 0.5900\n",
      "Epoch 26/300\n",
      "1603/1603 [==============================] - 0s 165us/sample - loss: 0.6190 - accuracy: 0.6719 - val_loss: 0.6696 - val_accuracy: 0.5923\n",
      "Epoch 27/300\n",
      "1603/1603 [==============================] - 0s 174us/sample - loss: 0.6182 - accuracy: 0.6631 - val_loss: 0.6686 - val_accuracy: 0.5945\n",
      "Epoch 28/300\n",
      "1603/1603 [==============================] - 0s 175us/sample - loss: 0.6159 - accuracy: 0.6694 - val_loss: 0.6677 - val_accuracy: 0.5945\n",
      "Epoch 29/300\n",
      "1603/1603 [==============================] - 0s 174us/sample - loss: 0.6156 - accuracy: 0.6700 - val_loss: 0.6668 - val_accuracy: 0.5968\n",
      "Epoch 30/300\n",
      "1603/1603 [==============================] - 0s 185us/sample - loss: 0.6133 - accuracy: 0.6756 - val_loss: 0.6658 - val_accuracy: 0.5968\n",
      "Epoch 31/300\n",
      "1603/1603 [==============================] - 0s 182us/sample - loss: 0.6126 - accuracy: 0.6787 - val_loss: 0.6649 - val_accuracy: 0.6014\n",
      "Epoch 32/300\n",
      "1603/1603 [==============================] - 0s 170us/sample - loss: 0.6126 - accuracy: 0.6663 - val_loss: 0.6640 - val_accuracy: 0.6036\n",
      "Epoch 33/300\n",
      "1603/1603 [==============================] - 0s 166us/sample - loss: 0.6076 - accuracy: 0.6862 - val_loss: 0.6631 - val_accuracy: 0.6059\n",
      "Epoch 34/300\n",
      "1603/1603 [==============================] - 0s 190us/sample - loss: 0.6054 - accuracy: 0.6812 - val_loss: 0.6621 - val_accuracy: 0.6036\n",
      "Epoch 35/300\n",
      "1603/1603 [==============================] - 0s 191us/sample - loss: 0.6026 - accuracy: 0.6843 - val_loss: 0.6613 - val_accuracy: 0.6036\n",
      "Epoch 36/300\n",
      "1603/1603 [==============================] - 0s 175us/sample - loss: 0.6037 - accuracy: 0.6956 - val_loss: 0.6604 - val_accuracy: 0.6059\n",
      "Epoch 37/300\n",
      "1603/1603 [==============================] - 0s 173us/sample - loss: 0.6019 - accuracy: 0.6837 - val_loss: 0.6595 - val_accuracy: 0.6082\n",
      "Epoch 38/300\n",
      "1603/1603 [==============================] - 0s 165us/sample - loss: 0.5983 - accuracy: 0.6900 - val_loss: 0.6585 - val_accuracy: 0.6128\n",
      "Epoch 39/300\n",
      "1603/1603 [==============================] - 0s 169us/sample - loss: 0.5977 - accuracy: 0.6843 - val_loss: 0.6577 - val_accuracy: 0.6150\n",
      "Epoch 40/300\n",
      "1603/1603 [==============================] - 0s 167us/sample - loss: 0.5971 - accuracy: 0.6981 - val_loss: 0.6569 - val_accuracy: 0.6150\n",
      "Epoch 41/300\n",
      "1603/1603 [==============================] - 0s 162us/sample - loss: 0.5938 - accuracy: 0.6912 - val_loss: 0.6561 - val_accuracy: 0.6173\n",
      "Epoch 42/300\n",
      "1603/1603 [==============================] - 0s 175us/sample - loss: 0.5905 - accuracy: 0.7087 - val_loss: 0.6552 - val_accuracy: 0.6150\n",
      "Epoch 43/300\n",
      "1603/1603 [==============================] - 0s 173us/sample - loss: 0.5925 - accuracy: 0.6987 - val_loss: 0.6543 - val_accuracy: 0.6150\n",
      "Epoch 44/300\n",
      "1603/1603 [==============================] - 0s 169us/sample - loss: 0.5882 - accuracy: 0.7049 - val_loss: 0.6535 - val_accuracy: 0.6196\n",
      "Epoch 45/300\n",
      "1603/1603 [==============================] - 0s 170us/sample - loss: 0.5859 - accuracy: 0.7068 - val_loss: 0.6527 - val_accuracy: 0.6219\n",
      "Epoch 46/300\n",
      "1603/1603 [==============================] - 0s 171us/sample - loss: 0.5874 - accuracy: 0.7130 - val_loss: 0.6519 - val_accuracy: 0.6264\n",
      "Epoch 47/300\n",
      "1603/1603 [==============================] - 0s 174us/sample - loss: 0.5876 - accuracy: 0.7049 - val_loss: 0.6511 - val_accuracy: 0.6264\n",
      "Epoch 48/300\n",
      "1603/1603 [==============================] - 0s 173us/sample - loss: 0.5823 - accuracy: 0.7093 - val_loss: 0.6504 - val_accuracy: 0.6241\n",
      "Epoch 49/300\n",
      "1603/1603 [==============================] - 0s 166us/sample - loss: 0.5831 - accuracy: 0.7143 - val_loss: 0.6496 - val_accuracy: 0.6287\n",
      "Epoch 50/300\n",
      "1603/1603 [==============================] - 0s 171us/sample - loss: 0.5820 - accuracy: 0.7224 - val_loss: 0.6488 - val_accuracy: 0.6287\n",
      "Epoch 51/300\n",
      "1603/1603 [==============================] - 0s 174us/sample - loss: 0.5759 - accuracy: 0.7236 - val_loss: 0.6480 - val_accuracy: 0.6310\n",
      "Epoch 52/300\n",
      "1603/1603 [==============================] - 0s 174us/sample - loss: 0.5792 - accuracy: 0.7162 - val_loss: 0.6472 - val_accuracy: 0.6333\n",
      "Epoch 53/300\n",
      "1603/1603 [==============================] - 0s 170us/sample - loss: 0.5768 - accuracy: 0.7324 - val_loss: 0.6464 - val_accuracy: 0.6333\n",
      "Epoch 54/300\n",
      "1603/1603 [==============================] - 0s 173us/sample - loss: 0.5751 - accuracy: 0.7162 - val_loss: 0.6457 - val_accuracy: 0.6333\n",
      "Epoch 55/300\n",
      "1603/1603 [==============================] - 0s 174us/sample - loss: 0.5753 - accuracy: 0.7162 - val_loss: 0.6450 - val_accuracy: 0.6310\n",
      "Epoch 56/300\n",
      "1603/1603 [==============================] - 0s 201us/sample - loss: 0.5696 - accuracy: 0.7224 - val_loss: 0.6442 - val_accuracy: 0.6287\n",
      "Epoch 57/300\n",
      "1603/1603 [==============================] - 0s 183us/sample - loss: 0.5741 - accuracy: 0.7187 - val_loss: 0.6435 - val_accuracy: 0.6310\n",
      "Epoch 58/300\n",
      "1603/1603 [==============================] - 0s 181us/sample - loss: 0.5676 - accuracy: 0.7324 - val_loss: 0.6428 - val_accuracy: 0.6310\n",
      "Epoch 59/300\n",
      "1603/1603 [==============================] - 0s 195us/sample - loss: 0.5638 - accuracy: 0.7274 - val_loss: 0.6421 - val_accuracy: 0.6333\n",
      "Epoch 60/300\n",
      "1603/1603 [==============================] - 0s 182us/sample - loss: 0.5646 - accuracy: 0.7324 - val_loss: 0.6414 - val_accuracy: 0.6333\n",
      "Epoch 61/300\n",
      "1603/1603 [==============================] - 0s 180us/sample - loss: 0.5618 - accuracy: 0.7374 - val_loss: 0.6406 - val_accuracy: 0.6333\n",
      "Epoch 62/300\n",
      "1603/1603 [==============================] - 0s 185us/sample - loss: 0.5643 - accuracy: 0.7330 - val_loss: 0.6400 - val_accuracy: 0.6355\n",
      "Epoch 63/300\n",
      "1603/1603 [==============================] - 0s 179us/sample - loss: 0.5598 - accuracy: 0.7424 - val_loss: 0.6392 - val_accuracy: 0.6355\n",
      "Epoch 64/300\n",
      "1603/1603 [==============================] - 0s 181us/sample - loss: 0.5616 - accuracy: 0.7249 - val_loss: 0.6385 - val_accuracy: 0.6355\n",
      "Epoch 65/300\n",
      "1603/1603 [==============================] - 0s 195us/sample - loss: 0.5584 - accuracy: 0.7305 - val_loss: 0.6379 - val_accuracy: 0.6355\n",
      "Epoch 66/300\n",
      "1603/1603 [==============================] - 0s 183us/sample - loss: 0.5564 - accuracy: 0.7386 - val_loss: 0.6372 - val_accuracy: 0.6355\n",
      "Epoch 67/300\n",
      "1603/1603 [==============================] - 0s 179us/sample - loss: 0.5512 - accuracy: 0.7449 - val_loss: 0.6365 - val_accuracy: 0.6355\n",
      "Epoch 68/300\n",
      "1603/1603 [==============================] - 0s 165us/sample - loss: 0.5481 - accuracy: 0.7461 - val_loss: 0.6359 - val_accuracy: 0.6378\n",
      "Epoch 69/300\n",
      "1603/1603 [==============================] - 0s 160us/sample - loss: 0.5540 - accuracy: 0.7286 - val_loss: 0.6352 - val_accuracy: 0.6378\n",
      "Epoch 70/300\n",
      "1603/1603 [==============================] - 0s 177us/sample - loss: 0.5496 - accuracy: 0.7467 - val_loss: 0.6346 - val_accuracy: 0.6401\n",
      "Epoch 71/300\n",
      "1603/1603 [==============================] - 0s 177us/sample - loss: 0.5484 - accuracy: 0.7467 - val_loss: 0.6339 - val_accuracy: 0.6401\n",
      "Epoch 72/300\n",
      "1603/1603 [==============================] - 0s 166us/sample - loss: 0.5440 - accuracy: 0.7455 - val_loss: 0.6333 - val_accuracy: 0.6424\n",
      "Epoch 73/300\n",
      "1603/1603 [==============================] - 0s 165us/sample - loss: 0.5442 - accuracy: 0.7498 - val_loss: 0.6327 - val_accuracy: 0.6469\n",
      "Epoch 74/300\n",
      "1603/1603 [==============================] - 0s 166us/sample - loss: 0.5403 - accuracy: 0.7473 - val_loss: 0.6321 - val_accuracy: 0.6492\n",
      "Epoch 75/300\n",
      "1603/1603 [==============================] - 0s 182us/sample - loss: 0.5367 - accuracy: 0.7523 - val_loss: 0.6315 - val_accuracy: 0.6492\n",
      "Epoch 76/300\n",
      "1603/1603 [==============================] - 0s 189us/sample - loss: 0.5355 - accuracy: 0.7573 - val_loss: 0.6309 - val_accuracy: 0.6469\n",
      "Epoch 77/300\n",
      "1603/1603 [==============================] - 0s 168us/sample - loss: 0.5396 - accuracy: 0.7517 - val_loss: 0.6303 - val_accuracy: 0.6469\n",
      "Epoch 78/300\n",
      "1603/1603 [==============================] - 0s 170us/sample - loss: 0.5319 - accuracy: 0.7567 - val_loss: 0.6296 - val_accuracy: 0.6469\n",
      "Epoch 79/300\n",
      "1603/1603 [==============================] - 0s 179us/sample - loss: 0.5337 - accuracy: 0.7548 - val_loss: 0.6291 - val_accuracy: 0.6469\n",
      "Epoch 80/300\n",
      "1603/1603 [==============================] - 0s 178us/sample - loss: 0.5355 - accuracy: 0.7561 - val_loss: 0.6285 - val_accuracy: 0.6469\n",
      "Epoch 81/300\n",
      "1603/1603 [==============================] - 0s 177us/sample - loss: 0.5302 - accuracy: 0.7604 - val_loss: 0.6279 - val_accuracy: 0.6492\n",
      "Epoch 82/300\n",
      "1603/1603 [==============================] - 0s 170us/sample - loss: 0.5313 - accuracy: 0.7642 - val_loss: 0.6274 - val_accuracy: 0.6492\n",
      "Epoch 83/300\n",
      "1603/1603 [==============================] - 0s 165us/sample - loss: 0.5292 - accuracy: 0.7511 - val_loss: 0.6268 - val_accuracy: 0.6492\n",
      "Epoch 84/300\n",
      "1603/1603 [==============================] - 0s 171us/sample - loss: 0.5309 - accuracy: 0.7486 - val_loss: 0.6263 - val_accuracy: 0.6515\n",
      "Epoch 85/300\n",
      "1603/1603 [==============================] - 0s 193us/sample - loss: 0.5252 - accuracy: 0.7604 - val_loss: 0.6257 - val_accuracy: 0.6515\n",
      "Epoch 86/300\n",
      "1603/1603 [==============================] - 0s 178us/sample - loss: 0.5238 - accuracy: 0.7642 - val_loss: 0.6251 - val_accuracy: 0.6515\n",
      "Epoch 87/300\n",
      "1603/1603 [==============================] - 0s 175us/sample - loss: 0.5242 - accuracy: 0.7673 - val_loss: 0.6246 - val_accuracy: 0.6515\n",
      "Epoch 88/300\n",
      "1603/1603 [==============================] - 0s 173us/sample - loss: 0.5218 - accuracy: 0.7580 - val_loss: 0.6241 - val_accuracy: 0.6469\n",
      "Epoch 89/300\n",
      "1603/1603 [==============================] - 0s 170us/sample - loss: 0.5192 - accuracy: 0.7530 - val_loss: 0.6236 - val_accuracy: 0.6469\n",
      "Epoch 90/300\n",
      "1603/1603 [==============================] - 0s 188us/sample - loss: 0.5176 - accuracy: 0.7679 - val_loss: 0.6231 - val_accuracy: 0.6492\n",
      "Epoch 91/300\n",
      "1603/1603 [==============================] - 0s 186us/sample - loss: 0.5162 - accuracy: 0.7654 - val_loss: 0.6226 - val_accuracy: 0.6515\n",
      "Epoch 92/300\n",
      "1603/1603 [==============================] - 0s 178us/sample - loss: 0.5150 - accuracy: 0.7760 - val_loss: 0.6221 - val_accuracy: 0.6469\n",
      "Epoch 93/300\n",
      "1603/1603 [==============================] - 0s 177us/sample - loss: 0.5117 - accuracy: 0.7698 - val_loss: 0.6216 - val_accuracy: 0.6469\n",
      "Epoch 94/300\n",
      "1603/1603 [==============================] - 0s 190us/sample - loss: 0.5113 - accuracy: 0.7717 - val_loss: 0.6211 - val_accuracy: 0.6469\n",
      "Epoch 95/300\n",
      "1603/1603 [==============================] - 0s 183us/sample - loss: 0.5075 - accuracy: 0.7817 - val_loss: 0.6206 - val_accuracy: 0.6469\n",
      "Epoch 96/300\n",
      "1603/1603 [==============================] - 0s 179us/sample - loss: 0.5057 - accuracy: 0.7723 - val_loss: 0.6202 - val_accuracy: 0.6469\n",
      "Epoch 97/300\n",
      "1603/1603 [==============================] - 0s 175us/sample - loss: 0.4995 - accuracy: 0.7717 - val_loss: 0.6197 - val_accuracy: 0.6515\n",
      "Epoch 98/300\n",
      "1603/1603 [==============================] - 0s 177us/sample - loss: 0.5031 - accuracy: 0.7848 - val_loss: 0.6193 - val_accuracy: 0.6515\n",
      "Epoch 99/300\n",
      "1603/1603 [==============================] - 0s 169us/sample - loss: 0.4992 - accuracy: 0.7773 - val_loss: 0.6187 - val_accuracy: 0.6515\n",
      "Epoch 100/300\n",
      "1603/1603 [==============================] - 0s 181us/sample - loss: 0.4996 - accuracy: 0.7867 - val_loss: 0.6182 - val_accuracy: 0.6515\n",
      "Epoch 101/300\n",
      "1603/1603 [==============================] - 0s 162us/sample - loss: 0.4966 - accuracy: 0.7804 - val_loss: 0.6179 - val_accuracy: 0.6515\n",
      "Epoch 102/300\n",
      "1603/1603 [==============================] - 0s 174us/sample - loss: 0.4931 - accuracy: 0.7817 - val_loss: 0.6175 - val_accuracy: 0.6515\n",
      "Epoch 103/300\n",
      "1603/1603 [==============================] - 0s 160us/sample - loss: 0.4959 - accuracy: 0.7785 - val_loss: 0.6171 - val_accuracy: 0.6538\n",
      "Epoch 104/300\n",
      "1603/1603 [==============================] - 0s 180us/sample - loss: 0.4969 - accuracy: 0.7823 - val_loss: 0.6167 - val_accuracy: 0.6538\n",
      "Epoch 105/300\n",
      "1603/1603 [==============================] - 0s 179us/sample - loss: 0.4897 - accuracy: 0.7910 - val_loss: 0.6163 - val_accuracy: 0.6538\n",
      "Epoch 106/300\n",
      "1603/1603 [==============================] - 0s 168us/sample - loss: 0.4904 - accuracy: 0.7941 - val_loss: 0.6159 - val_accuracy: 0.6515\n",
      "Epoch 107/300\n",
      "1603/1603 [==============================] - 0s 175us/sample - loss: 0.4869 - accuracy: 0.7823 - val_loss: 0.6156 - val_accuracy: 0.6492\n",
      "Epoch 108/300\n",
      "1603/1603 [==============================] - 0s 171us/sample - loss: 0.4889 - accuracy: 0.7785 - val_loss: 0.6152 - val_accuracy: 0.6515\n",
      "Epoch 109/300\n",
      "1603/1603 [==============================] - 0s 177us/sample - loss: 0.4841 - accuracy: 0.7948 - val_loss: 0.6148 - val_accuracy: 0.6515\n",
      "Epoch 110/300\n",
      "1603/1603 [==============================] - 0s 167us/sample - loss: 0.4814 - accuracy: 0.7985 - val_loss: 0.6145 - val_accuracy: 0.6538\n",
      "Epoch 111/300\n",
      "1603/1603 [==============================] - 0s 179us/sample - loss: 0.4794 - accuracy: 0.7848 - val_loss: 0.6142 - val_accuracy: 0.6538\n",
      "Epoch 112/300\n",
      "1603/1603 [==============================] - 0s 187us/sample - loss: 0.4794 - accuracy: 0.7916 - val_loss: 0.6139 - val_accuracy: 0.6538\n",
      "Epoch 113/300\n",
      "1603/1603 [==============================] - 0s 173us/sample - loss: 0.4734 - accuracy: 0.8060 - val_loss: 0.6136 - val_accuracy: 0.6515\n",
      "Epoch 114/300\n",
      "1603/1603 [==============================] - 0s 188us/sample - loss: 0.4821 - accuracy: 0.7823 - val_loss: 0.6134 - val_accuracy: 0.6515\n",
      "Epoch 115/300\n",
      "1603/1603 [==============================] - 0s 175us/sample - loss: 0.4739 - accuracy: 0.7985 - val_loss: 0.6132 - val_accuracy: 0.6515\n",
      "Epoch 116/300\n",
      "1603/1603 [==============================] - 0s 181us/sample - loss: 0.4773 - accuracy: 0.8022 - val_loss: 0.6129 - val_accuracy: 0.6515\n",
      "Epoch 117/300\n",
      "1603/1603 [==============================] - 0s 176us/sample - loss: 0.4714 - accuracy: 0.7935 - val_loss: 0.6127 - val_accuracy: 0.6515\n",
      "Epoch 118/300\n",
      "1603/1603 [==============================] - 0s 189us/sample - loss: 0.4709 - accuracy: 0.8060 - val_loss: 0.6124 - val_accuracy: 0.6538\n",
      "Epoch 119/300\n",
      "1603/1603 [==============================] - 0s 190us/sample - loss: 0.4663 - accuracy: 0.8029 - val_loss: 0.6122 - val_accuracy: 0.6538\n",
      "Epoch 120/300\n",
      "1603/1603 [==============================] - 0s 185us/sample - loss: 0.4647 - accuracy: 0.7954 - val_loss: 0.6120 - val_accuracy: 0.6583\n",
      "Epoch 121/300\n",
      "1603/1603 [==============================] - 0s 193us/sample - loss: 0.4605 - accuracy: 0.8066 - val_loss: 0.6118 - val_accuracy: 0.6606\n",
      "Epoch 122/300\n",
      "1603/1603 [==============================] - 0s 193us/sample - loss: 0.4621 - accuracy: 0.7991 - val_loss: 0.6116 - val_accuracy: 0.6560\n",
      "Epoch 123/300\n",
      "1603/1603 [==============================] - 0s 206us/sample - loss: 0.4607 - accuracy: 0.8066 - val_loss: 0.6114 - val_accuracy: 0.6583\n",
      "Epoch 124/300\n",
      "1603/1603 [==============================] - 0s 196us/sample - loss: 0.4544 - accuracy: 0.8110 - val_loss: 0.6113 - val_accuracy: 0.6583\n",
      "Epoch 125/300\n",
      "1603/1603 [==============================] - 0s 194us/sample - loss: 0.4553 - accuracy: 0.8135 - val_loss: 0.6112 - val_accuracy: 0.6606\n",
      "Epoch 126/300\n",
      "1603/1603 [==============================] - 0s 183us/sample - loss: 0.4535 - accuracy: 0.8041 - val_loss: 0.6112 - val_accuracy: 0.6583\n",
      "Epoch 127/300\n",
      "1603/1603 [==============================] - 0s 183us/sample - loss: 0.4553 - accuracy: 0.8072 - val_loss: 0.6111 - val_accuracy: 0.6560\n",
      "Epoch 128/300\n",
      "1603/1603 [==============================] - 0s 175us/sample - loss: 0.4506 - accuracy: 0.8072 - val_loss: 0.6112 - val_accuracy: 0.6560\n",
      "Epoch 129/300\n",
      "1603/1603 [==============================] - 0s 178us/sample - loss: 0.4476 - accuracy: 0.8122 - val_loss: 0.6111 - val_accuracy: 0.6560\n",
      "Epoch 130/300\n",
      "1603/1603 [==============================] - 0s 165us/sample - loss: 0.4514 - accuracy: 0.8104 - val_loss: 0.6111 - val_accuracy: 0.6560\n",
      "Epoch 131/300\n",
      "1603/1603 [==============================] - 0s 175us/sample - loss: 0.4467 - accuracy: 0.8066 - val_loss: 0.6111 - val_accuracy: 0.6560\n",
      "Epoch 132/300\n",
      "1603/1603 [==============================] - 0s 180us/sample - loss: 0.4467 - accuracy: 0.8116 - val_loss: 0.6111 - val_accuracy: 0.6560\n",
      "Epoch 133/300\n",
      "1603/1603 [==============================] - 0s 169us/sample - loss: 0.4460 - accuracy: 0.8097 - val_loss: 0.6111 - val_accuracy: 0.6583\n",
      "Epoch 134/300\n",
      "1603/1603 [==============================] - 0s 181us/sample - loss: 0.4451 - accuracy: 0.8203 - val_loss: 0.6111 - val_accuracy: 0.6583\n",
      "Epoch 00134: early stopping\n",
      "197/197 [==============================] - 0s 107us/sample - loss: 1.2462 - accuracy: 0.2690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [24:15, 747.66s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:05<00:05,  5.87s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.28s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "8it [00:00, 69.87it/s]\u001b[A\n",
      "11it [00:00, 49.17it/s]\u001b[A\n",
      "17it [00:00, 50.85it/s]\u001b[A\n",
      "21it [00:00, 41.22it/s]\u001b[A\n",
      "25it [00:00, 36.24it/s]\u001b[A\n",
      "29it [00:00, 36.23it/s]\u001b[A\n",
      "33it [00:00, 36.77it/s]\u001b[A\n",
      "38it [00:00, 37.74it/s]\u001b[A\n",
      "43it [00:01, 39.44it/s]\u001b[A\n",
      "47it [00:01, 36.71it/s]\u001b[A\n",
      "51it [00:01, 35.59it/s]\u001b[A\n",
      "55it [00:01, 35.94it/s]\u001b[A\n",
      "59it [00:01, 34.34it/s]\u001b[A\n",
      "63it [00:01, 33.45it/s]\u001b[A\n",
      "72it [00:01, 38.32it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 72/72 [00:00<00:00, 1181.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 504.8515625 steps, validate for 135.546875 steps\n",
      "Epoch 1/300\n",
      "505/504 [==============================] - 15s 30ms/step - loss: 0.7381 - accuracy: 0.5268 - val_loss: 0.6886 - val_accuracy: 0.5726\n",
      "Epoch 2/300\n",
      "505/504 [==============================] - 14s 27ms/step - loss: 0.6604 - accuracy: 0.6014 - val_loss: 0.6814 - val_accuracy: 0.5832\n",
      "Epoch 3/300\n",
      "505/504 [==============================] - 14s 27ms/step - loss: 0.6442 - accuracy: 0.6237 - val_loss: 0.6763 - val_accuracy: 0.5907\n",
      "Epoch 4/300\n",
      "505/504 [==============================] - 14s 27ms/step - loss: 0.6335 - accuracy: 0.6359 - val_loss: 0.6730 - val_accuracy: 0.5968\n",
      "Epoch 5/300\n",
      "505/504 [==============================] - 14s 27ms/step - loss: 0.6246 - accuracy: 0.6466 - val_loss: 0.6705 - val_accuracy: 0.6024\n",
      "Epoch 6/300\n",
      "505/504 [==============================] - 14s 27ms/step - loss: 0.6165 - accuracy: 0.6554 - val_loss: 0.6721 - val_accuracy: 0.6006\n",
      "Epoch 7/300\n",
      "505/504 [==============================] - 14s 27ms/step - loss: 0.6093 - accuracy: 0.6627 - val_loss: 0.6706 - val_accuracy: 0.6030\n",
      "Epoch 8/300\n",
      "505/504 [==============================] - 14s 27ms/step - loss: 0.6029 - accuracy: 0.6693 - val_loss: 0.6698 - val_accuracy: 0.6063\n",
      "Epoch 9/300\n",
      "505/504 [==============================] - 14s 27ms/step - loss: 0.5969 - accuracy: 0.6756 - val_loss: 0.6680 - val_accuracy: 0.6081\n",
      "Epoch 10/300\n",
      "505/504 [==============================] - 14s 27ms/step - loss: 0.5912 - accuracy: 0.6803 - val_loss: 0.6739 - val_accuracy: 0.6054\n",
      "Epoch 11/300\n",
      "505/504 [==============================] - 14s 27ms/step - loss: 0.5858 - accuracy: 0.6847 - val_loss: 0.6698 - val_accuracy: 0.6078\n",
      "Epoch 12/300\n",
      "505/504 [==============================] - 14s 27ms/step - loss: 0.5807 - accuracy: 0.6899 - val_loss: 0.6703 - val_accuracy: 0.6104\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 504.8515625 steps, validate for 135.546875 steps\n",
      "Epoch 1/300\n",
      "505/504 [==============================] - 33s 66ms/step - loss: 0.5720 - accuracy: 0.6987 - val_loss: 0.7123 - val_accuracy: 0.5604\n",
      "Epoch 2/300\n",
      "505/504 [==============================] - 32s 63ms/step - loss: 0.5539 - accuracy: 0.7163 - val_loss: 0.6835 - val_accuracy: 0.6179\n",
      "Epoch 3/300\n",
      "505/504 [==============================] - 32s 64ms/step - loss: 0.5395 - accuracy: 0.7288 - val_loss: 0.6913 - val_accuracy: 0.6050\n",
      "Epoch 4/300\n",
      "505/504 [==============================] - 32s 63ms/step - loss: 0.5257 - accuracy: 0.7412 - val_loss: 0.6800 - val_accuracy: 0.6139\n",
      "Epoch 5/300\n",
      "505/504 [==============================] - 32s 63ms/step - loss: 0.5135 - accuracy: 0.7521 - val_loss: 0.6948 - val_accuracy: 0.5978\n",
      "Epoch 6/300\n",
      "505/504 [==============================] - 32s 63ms/step - loss: 0.5014 - accuracy: 0.7623 - val_loss: 0.6802 - val_accuracy: 0.6176\n",
      "Epoch 7/300\n",
      "505/504 [==============================] - 32s 63ms/step - loss: 0.4903 - accuracy: 0.7734 - val_loss: 0.6857 - val_accuracy: 0.6111\n",
      "Epoch 00007: early stopping\n",
      "364/364 [==============================] - 0s 789us/sample - loss: 1.1358 - accuracy: 0.2802\n",
      "349/349 [==============================] - 0s 204us/sample - loss: 1.0025 - accuracy: 0.3324\n",
      "342/342 [==============================] - 0s 226us/sample - loss: 0.8944 - accuracy: 0.4123\n",
      "334/334 [==============================] - 0s 211us/sample - loss: 0.9159 - accuracy: 0.3952\n",
      "327/327 [==============================] - 0s 227us/sample - loss: 0.9297 - accuracy: 0.4190\n",
      "323/323 [==============================] - 0s 238us/sample - loss: 0.8845 - accuracy: 0.4489\n",
      "314/314 [==============================] - 0s 249us/sample - loss: 0.8921 - accuracy: 0.4395\n",
      "307/307 [==============================] - 0s 256us/sample - loss: 0.8747 - accuracy: 0.4430\n",
      "301/301 [==============================] - 0s 239us/sample - loss: 0.8580 - accuracy: 0.4651\n",
      "296/296 [==============================] - 0s 236us/sample - loss: 0.8841 - accuracy: 0.4189\n",
      "290/290 [==============================] - 0s 227us/sample - loss: 0.9220 - accuracy: 0.4103\n",
      "288/288 [==============================] - 0s 878us/sample - loss: 0.8864 - accuracy: 0.4479\n",
      "286/286 [==============================] - 0s 215us/sample - loss: 0.8565 - accuracy: 0.4580\n",
      "286/286 [==============================] - 0s 231us/sample - loss: 0.8320 - accuracy: 0.4965\n",
      "280/280 [==============================] - 0s 219us/sample - loss: 0.8905 - accuracy: 0.4000\n",
      "280/280 [==============================] - 0s 244us/sample - loss: 0.8947 - accuracy: 0.4464\n",
      "276/276 [==============================] - 0s 228us/sample - loss: 0.8924 - accuracy: 0.4348\n",
      "274/274 [==============================] - 0s 220us/sample - loss: 0.9259 - accuracy: 0.3832\n",
      "272/272 [==============================] - 0s 221us/sample - loss: 0.9532 - accuracy: 0.3897\n",
      "271/271 [==============================] - 0s 250us/sample - loss: 0.8857 - accuracy: 0.4022\n",
      "266/266 [==============================] - 0s 219us/sample - loss: 0.9725 - accuracy: 0.4023\n",
      "264/264 [==============================] - 0s 231us/sample - loss: 0.9307 - accuracy: 0.4318\n",
      "263/263 [==============================] - 0s 214us/sample - loss: 0.9025 - accuracy: 0.4068\n",
      "260/260 [==============================] - 0s 222us/sample - loss: 0.8636 - accuracy: 0.4192\n",
      "258/258 [==============================] - 0s 244us/sample - loss: 0.9163 - accuracy: 0.4225\n",
      "258/258 [==============================] - 0s 249us/sample - loss: 0.9402 - accuracy: 0.4070\n",
      "258/258 [==============================] - 0s 232us/sample - loss: 0.8636 - accuracy: 0.4457\n",
      "254/254 [==============================] - 0s 207us/sample - loss: 0.9454 - accuracy: 0.3976\n",
      "252/252 [==============================] - 0s 214us/sample - loss: 0.9274 - accuracy: 0.4087\n",
      "249/249 [==============================] - 0s 223us/sample - loss: 0.8922 - accuracy: 0.4337\n",
      "250/250 [==============================] - 0s 223us/sample - loss: 0.9459 - accuracy: 0.4240\n",
      "246/246 [==============================] - 0s 265us/sample - loss: 0.9735 - accuracy: 0.4065\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 1585 samples, validate on 431 samples\n",
      "Epoch 1/300\n",
      "1585/1585 [==============================] - 2s 1ms/sample - loss: 0.7175 - accuracy: 0.5205 - val_loss: 0.6912 - val_accuracy: 0.5545\n",
      "Epoch 2/300\n",
      "1585/1585 [==============================] - 0s 179us/sample - loss: 0.7112 - accuracy: 0.5211 - val_loss: 0.6872 - val_accuracy: 0.5592\n",
      "Epoch 3/300\n",
      "1585/1585 [==============================] - 0s 171us/sample - loss: 0.6991 - accuracy: 0.5489 - val_loss: 0.6845 - val_accuracy: 0.5754\n",
      "Epoch 4/300\n",
      "1585/1585 [==============================] - 0s 174us/sample - loss: 0.6956 - accuracy: 0.5685 - val_loss: 0.6822 - val_accuracy: 0.5800\n",
      "Epoch 5/300\n",
      "1585/1585 [==============================] - 0s 177us/sample - loss: 0.6911 - accuracy: 0.5703 - val_loss: 0.6803 - val_accuracy: 0.5847\n",
      "Epoch 6/300\n",
      "1585/1585 [==============================] - 0s 173us/sample - loss: 0.6868 - accuracy: 0.5817 - val_loss: 0.6786 - val_accuracy: 0.5870\n",
      "Epoch 7/300\n",
      "1585/1585 [==============================] - 0s 178us/sample - loss: 0.6813 - accuracy: 0.5785 - val_loss: 0.6770 - val_accuracy: 0.5963\n",
      "Epoch 8/300\n",
      "1585/1585 [==============================] - 0s 173us/sample - loss: 0.6798 - accuracy: 0.5861 - val_loss: 0.6756 - val_accuracy: 0.6032\n",
      "Epoch 9/300\n",
      "1585/1585 [==============================] - 0s 175us/sample - loss: 0.6784 - accuracy: 0.5811 - val_loss: 0.6743 - val_accuracy: 0.6056\n",
      "Epoch 10/300\n",
      "1585/1585 [==============================] - 0s 165us/sample - loss: 0.6685 - accuracy: 0.5937 - val_loss: 0.6731 - val_accuracy: 0.6102\n",
      "Epoch 11/300\n",
      "1585/1585 [==============================] - 0s 165us/sample - loss: 0.6680 - accuracy: 0.5918 - val_loss: 0.6719 - val_accuracy: 0.6102\n",
      "Epoch 12/300\n",
      "1585/1585 [==============================] - 0s 158us/sample - loss: 0.6696 - accuracy: 0.6095 - val_loss: 0.6708 - val_accuracy: 0.6195\n",
      "Epoch 13/300\n",
      "1585/1585 [==============================] - 0s 166us/sample - loss: 0.6644 - accuracy: 0.5987 - val_loss: 0.6698 - val_accuracy: 0.6195\n",
      "Epoch 14/300\n",
      "1585/1585 [==============================] - 0s 180us/sample - loss: 0.6656 - accuracy: 0.5779 - val_loss: 0.6688 - val_accuracy: 0.6195\n",
      "Epoch 15/300\n",
      "1585/1585 [==============================] - 0s 167us/sample - loss: 0.6576 - accuracy: 0.6189 - val_loss: 0.6678 - val_accuracy: 0.6195\n",
      "Epoch 16/300\n",
      "1585/1585 [==============================] - 0s 177us/sample - loss: 0.6569 - accuracy: 0.6088 - val_loss: 0.6669 - val_accuracy: 0.6218\n",
      "Epoch 17/300\n",
      "1585/1585 [==============================] - 0s 175us/sample - loss: 0.6572 - accuracy: 0.6170 - val_loss: 0.6660 - val_accuracy: 0.6218\n",
      "Epoch 18/300\n",
      "1585/1585 [==============================] - 0s 185us/sample - loss: 0.6521 - accuracy: 0.6221 - val_loss: 0.6652 - val_accuracy: 0.6218\n",
      "Epoch 19/300\n",
      "1585/1585 [==============================] - 0s 174us/sample - loss: 0.6516 - accuracy: 0.6290 - val_loss: 0.6645 - val_accuracy: 0.6218\n",
      "Epoch 20/300\n",
      "1585/1585 [==============================] - 0s 185us/sample - loss: 0.6482 - accuracy: 0.6221 - val_loss: 0.6636 - val_accuracy: 0.6195\n",
      "Epoch 21/300\n",
      "1585/1585 [==============================] - 0s 174us/sample - loss: 0.6497 - accuracy: 0.6227 - val_loss: 0.6628 - val_accuracy: 0.6195\n",
      "Epoch 22/300\n",
      "1585/1585 [==============================] - 0s 189us/sample - loss: 0.6447 - accuracy: 0.6315 - val_loss: 0.6621 - val_accuracy: 0.6195\n",
      "Epoch 23/300\n",
      "1585/1585 [==============================] - 0s 187us/sample - loss: 0.6443 - accuracy: 0.6189 - val_loss: 0.6613 - val_accuracy: 0.6241\n",
      "Epoch 24/300\n",
      "1585/1585 [==============================] - 0s 172us/sample - loss: 0.6446 - accuracy: 0.6259 - val_loss: 0.6605 - val_accuracy: 0.6241\n",
      "Epoch 25/300\n",
      "1585/1585 [==============================] - 0s 177us/sample - loss: 0.6369 - accuracy: 0.6290 - val_loss: 0.6598 - val_accuracy: 0.6218\n",
      "Epoch 26/300\n",
      "1585/1585 [==============================] - 0s 175us/sample - loss: 0.6380 - accuracy: 0.6404 - val_loss: 0.6592 - val_accuracy: 0.6241\n",
      "Epoch 27/300\n",
      "1585/1585 [==============================] - 0s 165us/sample - loss: 0.6314 - accuracy: 0.6328 - val_loss: 0.6585 - val_accuracy: 0.6241\n",
      "Epoch 28/300\n",
      "1585/1585 [==============================] - 0s 162us/sample - loss: 0.6307 - accuracy: 0.6391 - val_loss: 0.6579 - val_accuracy: 0.6265\n",
      "Epoch 29/300\n",
      "1585/1585 [==============================] - 0s 166us/sample - loss: 0.6303 - accuracy: 0.6517 - val_loss: 0.6573 - val_accuracy: 0.6218\n",
      "Epoch 30/300\n",
      "1585/1585 [==============================] - 0s 176us/sample - loss: 0.6288 - accuracy: 0.6498 - val_loss: 0.6567 - val_accuracy: 0.6218\n",
      "Epoch 31/300\n",
      "1585/1585 [==============================] - 0s 170us/sample - loss: 0.6307 - accuracy: 0.6448 - val_loss: 0.6560 - val_accuracy: 0.6265\n",
      "Epoch 32/300\n",
      "1585/1585 [==============================] - 0s 173us/sample - loss: 0.6294 - accuracy: 0.6423 - val_loss: 0.6554 - val_accuracy: 0.6288\n",
      "Epoch 33/300\n",
      "1585/1585 [==============================] - 0s 180us/sample - loss: 0.6204 - accuracy: 0.6618 - val_loss: 0.6548 - val_accuracy: 0.6288\n",
      "Epoch 34/300\n",
      "1585/1585 [==============================] - 0s 185us/sample - loss: 0.6240 - accuracy: 0.6549 - val_loss: 0.6543 - val_accuracy: 0.6311\n",
      "Epoch 35/300\n",
      "1585/1585 [==============================] - 0s 192us/sample - loss: 0.6173 - accuracy: 0.6656 - val_loss: 0.6537 - val_accuracy: 0.6334\n",
      "Epoch 36/300\n",
      "1585/1585 [==============================] - 0s 182us/sample - loss: 0.6188 - accuracy: 0.6536 - val_loss: 0.6532 - val_accuracy: 0.6334\n",
      "Epoch 37/300\n",
      "1585/1585 [==============================] - 0s 172us/sample - loss: 0.6163 - accuracy: 0.6580 - val_loss: 0.6526 - val_accuracy: 0.6334\n",
      "Epoch 38/300\n",
      "1585/1585 [==============================] - 0s 180us/sample - loss: 0.6143 - accuracy: 0.6599 - val_loss: 0.6520 - val_accuracy: 0.6334\n",
      "Epoch 39/300\n",
      "1585/1585 [==============================] - 0s 190us/sample - loss: 0.6123 - accuracy: 0.6789 - val_loss: 0.6514 - val_accuracy: 0.6334\n",
      "Epoch 40/300\n",
      "1585/1585 [==============================] - 0s 191us/sample - loss: 0.6125 - accuracy: 0.6562 - val_loss: 0.6509 - val_accuracy: 0.6311\n",
      "Epoch 41/300\n",
      "1585/1585 [==============================] - 0s 186us/sample - loss: 0.6069 - accuracy: 0.6662 - val_loss: 0.6504 - val_accuracy: 0.6288\n",
      "Epoch 42/300\n",
      "1585/1585 [==============================] - 0s 199us/sample - loss: 0.6106 - accuracy: 0.6669 - val_loss: 0.6499 - val_accuracy: 0.6265\n",
      "Epoch 43/300\n",
      "1585/1585 [==============================] - 0s 179us/sample - loss: 0.6034 - accuracy: 0.6719 - val_loss: 0.6494 - val_accuracy: 0.6265\n",
      "Epoch 44/300\n",
      "1585/1585 [==============================] - 0s 181us/sample - loss: 0.6067 - accuracy: 0.6644 - val_loss: 0.6489 - val_accuracy: 0.6241\n",
      "Epoch 45/300\n",
      "1585/1585 [==============================] - 0s 171us/sample - loss: 0.6040 - accuracy: 0.6700 - val_loss: 0.6484 - val_accuracy: 0.6218\n",
      "Epoch 46/300\n",
      "1585/1585 [==============================] - 0s 177us/sample - loss: 0.6057 - accuracy: 0.6656 - val_loss: 0.6479 - val_accuracy: 0.6195\n",
      "Epoch 47/300\n",
      "1585/1585 [==============================] - 0s 202us/sample - loss: 0.6012 - accuracy: 0.6801 - val_loss: 0.6474 - val_accuracy: 0.6195\n",
      "Epoch 48/300\n",
      "1585/1585 [==============================] - 0s 169us/sample - loss: 0.5979 - accuracy: 0.6833 - val_loss: 0.6470 - val_accuracy: 0.6172\n",
      "Epoch 49/300\n",
      "1585/1585 [==============================] - 0s 169us/sample - loss: 0.5975 - accuracy: 0.6770 - val_loss: 0.6464 - val_accuracy: 0.6195\n",
      "Epoch 50/300\n",
      "1585/1585 [==============================] - 0s 174us/sample - loss: 0.5963 - accuracy: 0.6896 - val_loss: 0.6459 - val_accuracy: 0.6172\n",
      "Epoch 51/300\n",
      "1585/1585 [==============================] - 0s 175us/sample - loss: 0.5896 - accuracy: 0.6890 - val_loss: 0.6455 - val_accuracy: 0.6195\n",
      "Epoch 52/300\n",
      "1585/1585 [==============================] - 0s 171us/sample - loss: 0.5912 - accuracy: 0.6883 - val_loss: 0.6450 - val_accuracy: 0.6195\n",
      "Epoch 53/300\n",
      "1585/1585 [==============================] - 0s 173us/sample - loss: 0.5897 - accuracy: 0.6890 - val_loss: 0.6446 - val_accuracy: 0.6195\n",
      "Epoch 54/300\n",
      "1585/1585 [==============================] - 0s 178us/sample - loss: 0.5844 - accuracy: 0.6934 - val_loss: 0.6442 - val_accuracy: 0.6172\n",
      "Epoch 55/300\n",
      "1585/1585 [==============================] - 0s 173us/sample - loss: 0.5845 - accuracy: 0.6991 - val_loss: 0.6437 - val_accuracy: 0.6172\n",
      "Epoch 56/300\n",
      "1585/1585 [==============================] - 0s 182us/sample - loss: 0.5825 - accuracy: 0.7148 - val_loss: 0.6433 - val_accuracy: 0.6195\n",
      "Epoch 57/300\n",
      "1585/1585 [==============================] - 0s 178us/sample - loss: 0.5810 - accuracy: 0.7079 - val_loss: 0.6429 - val_accuracy: 0.6195\n",
      "Epoch 58/300\n",
      "1585/1585 [==============================] - 0s 176us/sample - loss: 0.5803 - accuracy: 0.7110 - val_loss: 0.6424 - val_accuracy: 0.6172\n",
      "Epoch 59/300\n",
      "1585/1585 [==============================] - 0s 171us/sample - loss: 0.5833 - accuracy: 0.7060 - val_loss: 0.6420 - val_accuracy: 0.6195\n",
      "Epoch 60/300\n",
      "1585/1585 [==============================] - 0s 181us/sample - loss: 0.5725 - accuracy: 0.7066 - val_loss: 0.6417 - val_accuracy: 0.6241\n",
      "Epoch 61/300\n",
      "1585/1585 [==============================] - 0s 165us/sample - loss: 0.5716 - accuracy: 0.7205 - val_loss: 0.6412 - val_accuracy: 0.6311\n",
      "Epoch 62/300\n",
      "1585/1585 [==============================] - 0s 167us/sample - loss: 0.5729 - accuracy: 0.7123 - val_loss: 0.6408 - val_accuracy: 0.6311\n",
      "Epoch 63/300\n",
      "1585/1585 [==============================] - 0s 161us/sample - loss: 0.5726 - accuracy: 0.7161 - val_loss: 0.6404 - val_accuracy: 0.6311\n",
      "Epoch 64/300\n",
      "1585/1585 [==============================] - 0s 164us/sample - loss: 0.5737 - accuracy: 0.7129 - val_loss: 0.6399 - val_accuracy: 0.6288\n",
      "Epoch 65/300\n",
      "1585/1585 [==============================] - 0s 169us/sample - loss: 0.5705 - accuracy: 0.7110 - val_loss: 0.6396 - val_accuracy: 0.6288\n",
      "Epoch 66/300\n",
      "1585/1585 [==============================] - 0s 160us/sample - loss: 0.5660 - accuracy: 0.7211 - val_loss: 0.6392 - val_accuracy: 0.6311\n",
      "Epoch 67/300\n",
      "1585/1585 [==============================] - 0s 159us/sample - loss: 0.5652 - accuracy: 0.7300 - val_loss: 0.6388 - val_accuracy: 0.6311\n",
      "Epoch 68/300\n",
      "1585/1585 [==============================] - 0s 176us/sample - loss: 0.5583 - accuracy: 0.7180 - val_loss: 0.6385 - val_accuracy: 0.6311\n",
      "Epoch 69/300\n",
      "1585/1585 [==============================] - 0s 164us/sample - loss: 0.5611 - accuracy: 0.7211 - val_loss: 0.6381 - val_accuracy: 0.6311\n",
      "Epoch 70/300\n",
      "1585/1585 [==============================] - 0s 161us/sample - loss: 0.5600 - accuracy: 0.7274 - val_loss: 0.6377 - val_accuracy: 0.6288\n",
      "Epoch 71/300\n",
      "1585/1585 [==============================] - 0s 169us/sample - loss: 0.5623 - accuracy: 0.7142 - val_loss: 0.6373 - val_accuracy: 0.6288\n",
      "Epoch 72/300\n",
      "1585/1585 [==============================] - 0s 172us/sample - loss: 0.5615 - accuracy: 0.7293 - val_loss: 0.6369 - val_accuracy: 0.6265\n",
      "Epoch 73/300\n",
      "1585/1585 [==============================] - 0s 172us/sample - loss: 0.5527 - accuracy: 0.7262 - val_loss: 0.6365 - val_accuracy: 0.6265\n",
      "Epoch 74/300\n",
      "1585/1585 [==============================] - 0s 173us/sample - loss: 0.5531 - accuracy: 0.7300 - val_loss: 0.6362 - val_accuracy: 0.6265\n",
      "Epoch 75/300\n",
      "1585/1585 [==============================] - 0s 169us/sample - loss: 0.5499 - accuracy: 0.7344 - val_loss: 0.6358 - val_accuracy: 0.6288\n",
      "Epoch 76/300\n",
      "1585/1585 [==============================] - 0s 170us/sample - loss: 0.5497 - accuracy: 0.7300 - val_loss: 0.6354 - val_accuracy: 0.6265\n",
      "Epoch 77/300\n",
      "1585/1585 [==============================] - 0s 166us/sample - loss: 0.5478 - accuracy: 0.7369 - val_loss: 0.6350 - val_accuracy: 0.6265\n",
      "Epoch 78/300\n",
      "1585/1585 [==============================] - 0s 179us/sample - loss: 0.5418 - accuracy: 0.7388 - val_loss: 0.6347 - val_accuracy: 0.6265\n",
      "Epoch 79/300\n",
      "1585/1585 [==============================] - 0s 171us/sample - loss: 0.5448 - accuracy: 0.7331 - val_loss: 0.6344 - val_accuracy: 0.6265\n",
      "Epoch 80/300\n",
      "1585/1585 [==============================] - 0s 163us/sample - loss: 0.5459 - accuracy: 0.7363 - val_loss: 0.6340 - val_accuracy: 0.6241\n",
      "Epoch 81/300\n",
      "1585/1585 [==============================] - 0s 168us/sample - loss: 0.5428 - accuracy: 0.7413 - val_loss: 0.6336 - val_accuracy: 0.6241\n",
      "Epoch 82/300\n",
      "1585/1585 [==============================] - 0s 174us/sample - loss: 0.5329 - accuracy: 0.7558 - val_loss: 0.6332 - val_accuracy: 0.6265\n",
      "Epoch 83/300\n",
      "1585/1585 [==============================] - 0s 181us/sample - loss: 0.5389 - accuracy: 0.7426 - val_loss: 0.6329 - val_accuracy: 0.6265\n",
      "Epoch 84/300\n",
      "1585/1585 [==============================] - 0s 172us/sample - loss: 0.5322 - accuracy: 0.7603 - val_loss: 0.6327 - val_accuracy: 0.6265\n",
      "Epoch 85/300\n",
      "1585/1585 [==============================] - 0s 179us/sample - loss: 0.5320 - accuracy: 0.7533 - val_loss: 0.6324 - val_accuracy: 0.6265\n",
      "Epoch 86/300\n",
      "1585/1585 [==============================] - 0s 193us/sample - loss: 0.5332 - accuracy: 0.7407 - val_loss: 0.6320 - val_accuracy: 0.6265\n",
      "Epoch 87/300\n",
      "1585/1585 [==============================] - 0s 177us/sample - loss: 0.5330 - accuracy: 0.7451 - val_loss: 0.6317 - val_accuracy: 0.6265\n",
      "Epoch 88/300\n",
      "1585/1585 [==============================] - 0s 174us/sample - loss: 0.5328 - accuracy: 0.7502 - val_loss: 0.6313 - val_accuracy: 0.6288\n",
      "Epoch 89/300\n",
      "1585/1585 [==============================] - 0s 173us/sample - loss: 0.5255 - accuracy: 0.7577 - val_loss: 0.6311 - val_accuracy: 0.6311\n",
      "Epoch 90/300\n",
      "1585/1585 [==============================] - 0s 185us/sample - loss: 0.5225 - accuracy: 0.7609 - val_loss: 0.6308 - val_accuracy: 0.6311\n",
      "Epoch 91/300\n",
      "1585/1585 [==============================] - 0s 175us/sample - loss: 0.5225 - accuracy: 0.7584 - val_loss: 0.6305 - val_accuracy: 0.6334\n",
      "Epoch 92/300\n",
      "1585/1585 [==============================] - 0s 171us/sample - loss: 0.5173 - accuracy: 0.7634 - val_loss: 0.6301 - val_accuracy: 0.6357\n",
      "Epoch 93/300\n",
      "1585/1585 [==============================] - 0s 160us/sample - loss: 0.5166 - accuracy: 0.7666 - val_loss: 0.6298 - val_accuracy: 0.6381\n",
      "Epoch 94/300\n",
      "1585/1585 [==============================] - 0s 168us/sample - loss: 0.5159 - accuracy: 0.7672 - val_loss: 0.6297 - val_accuracy: 0.6381\n",
      "Epoch 95/300\n",
      "1585/1585 [==============================] - 0s 183us/sample - loss: 0.5184 - accuracy: 0.7647 - val_loss: 0.6294 - val_accuracy: 0.6381\n",
      "Epoch 96/300\n",
      "1585/1585 [==============================] - 0s 172us/sample - loss: 0.5125 - accuracy: 0.7628 - val_loss: 0.6291 - val_accuracy: 0.6381\n",
      "Epoch 97/300\n",
      "1585/1585 [==============================] - 0s 173us/sample - loss: 0.5075 - accuracy: 0.7685 - val_loss: 0.6290 - val_accuracy: 0.6381\n",
      "Epoch 98/300\n",
      "1585/1585 [==============================] - 0s 167us/sample - loss: 0.5056 - accuracy: 0.7760 - val_loss: 0.6286 - val_accuracy: 0.6357\n",
      "Epoch 99/300\n",
      "1585/1585 [==============================] - 0s 176us/sample - loss: 0.5087 - accuracy: 0.7710 - val_loss: 0.6284 - val_accuracy: 0.6357\n",
      "Epoch 100/300\n",
      "1585/1585 [==============================] - 0s 181us/sample - loss: 0.5010 - accuracy: 0.7779 - val_loss: 0.6282 - val_accuracy: 0.6381\n",
      "Epoch 101/300\n",
      "1585/1585 [==============================] - 0s 179us/sample - loss: 0.5008 - accuracy: 0.7722 - val_loss: 0.6279 - val_accuracy: 0.6404\n",
      "Epoch 102/300\n",
      "1585/1585 [==============================] - 0s 175us/sample - loss: 0.5044 - accuracy: 0.7729 - val_loss: 0.6277 - val_accuracy: 0.6404\n",
      "Epoch 103/300\n",
      "1585/1585 [==============================] - 0s 176us/sample - loss: 0.5033 - accuracy: 0.7672 - val_loss: 0.6275 - val_accuracy: 0.6427\n",
      "Epoch 104/300\n",
      "1585/1585 [==============================] - 0s 185us/sample - loss: 0.4955 - accuracy: 0.7830 - val_loss: 0.6273 - val_accuracy: 0.6427\n",
      "Epoch 105/300\n",
      "1585/1585 [==============================] - 0s 177us/sample - loss: 0.5027 - accuracy: 0.7754 - val_loss: 0.6271 - val_accuracy: 0.6427\n",
      "Epoch 106/300\n",
      "1585/1585 [==============================] - 0s 166us/sample - loss: 0.4974 - accuracy: 0.7735 - val_loss: 0.6270 - val_accuracy: 0.6427\n",
      "Epoch 107/300\n",
      "1585/1585 [==============================] - 0s 171us/sample - loss: 0.4882 - accuracy: 0.7842 - val_loss: 0.6268 - val_accuracy: 0.6427\n",
      "Epoch 108/300\n",
      "1585/1585 [==============================] - 0s 172us/sample - loss: 0.4889 - accuracy: 0.7836 - val_loss: 0.6266 - val_accuracy: 0.6427\n",
      "Epoch 109/300\n",
      "1585/1585 [==============================] - 0s 183us/sample - loss: 0.4882 - accuracy: 0.7817 - val_loss: 0.6264 - val_accuracy: 0.6427\n",
      "Epoch 110/300\n",
      "1585/1585 [==============================] - 0s 171us/sample - loss: 0.4843 - accuracy: 0.7855 - val_loss: 0.6262 - val_accuracy: 0.6427\n",
      "Epoch 111/300\n",
      "1585/1585 [==============================] - 0s 167us/sample - loss: 0.4865 - accuracy: 0.7811 - val_loss: 0.6260 - val_accuracy: 0.6427\n",
      "Epoch 112/300\n",
      "1585/1585 [==============================] - 0s 174us/sample - loss: 0.4833 - accuracy: 0.7868 - val_loss: 0.6257 - val_accuracy: 0.6427\n",
      "Epoch 113/300\n",
      "1585/1585 [==============================] - 0s 168us/sample - loss: 0.4822 - accuracy: 0.7893 - val_loss: 0.6254 - val_accuracy: 0.6450\n",
      "Epoch 114/300\n",
      "1585/1585 [==============================] - 0s 180us/sample - loss: 0.4846 - accuracy: 0.7849 - val_loss: 0.6252 - val_accuracy: 0.6427\n",
      "Epoch 115/300\n",
      "1585/1585 [==============================] - 0s 165us/sample - loss: 0.4812 - accuracy: 0.7880 - val_loss: 0.6251 - val_accuracy: 0.6427\n",
      "Epoch 116/300\n",
      "1585/1585 [==============================] - 0s 174us/sample - loss: 0.4774 - accuracy: 0.7981 - val_loss: 0.6250 - val_accuracy: 0.6473\n",
      "Epoch 117/300\n",
      "1585/1585 [==============================] - 0s 169us/sample - loss: 0.4775 - accuracy: 0.7962 - val_loss: 0.6248 - val_accuracy: 0.6473\n",
      "Epoch 118/300\n",
      "1585/1585 [==============================] - 0s 165us/sample - loss: 0.4701 - accuracy: 0.7924 - val_loss: 0.6246 - val_accuracy: 0.6473\n",
      "Epoch 119/300\n",
      "1585/1585 [==============================] - 0s 190us/sample - loss: 0.4732 - accuracy: 0.7968 - val_loss: 0.6247 - val_accuracy: 0.6450\n",
      "Epoch 120/300\n",
      "1585/1585 [==============================] - 0s 186us/sample - loss: 0.4714 - accuracy: 0.7924 - val_loss: 0.6245 - val_accuracy: 0.6450\n",
      "Epoch 121/300\n",
      "1585/1585 [==============================] - 0s 178us/sample - loss: 0.4647 - accuracy: 0.8025 - val_loss: 0.6245 - val_accuracy: 0.6450\n",
      "Epoch 122/300\n",
      "1585/1585 [==============================] - 0s 180us/sample - loss: 0.4594 - accuracy: 0.8076 - val_loss: 0.6243 - val_accuracy: 0.6473\n",
      "Epoch 123/300\n",
      "1585/1585 [==============================] - 0s 178us/sample - loss: 0.4641 - accuracy: 0.8006 - val_loss: 0.6241 - val_accuracy: 0.6473\n",
      "Epoch 124/300\n",
      "1585/1585 [==============================] - 0s 174us/sample - loss: 0.4621 - accuracy: 0.8057 - val_loss: 0.6242 - val_accuracy: 0.6450\n",
      "Epoch 125/300\n",
      "1585/1585 [==============================] - 0s 171us/sample - loss: 0.4548 - accuracy: 0.8082 - val_loss: 0.6242 - val_accuracy: 0.6450\n",
      "Epoch 126/300\n",
      "1585/1585 [==============================] - 0s 189us/sample - loss: 0.4566 - accuracy: 0.8063 - val_loss: 0.6241 - val_accuracy: 0.6450\n",
      "Epoch 00126: early stopping\n",
      "223/223 [==============================] - 0s 110us/sample - loss: 0.7981 - accuracy: 0.5874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [36:40, 746.95s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:06<00:06,  6.21s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.68s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "6it [00:00, 46.91it/s]\u001b[A\n",
      "12it [00:00, 48.10it/s]\u001b[A\n",
      "16it [00:00, 40.82it/s]\u001b[A\n",
      "20it [00:00, 40.06it/s]\u001b[A\n",
      "24it [00:00, 39.05it/s]\u001b[A\n",
      "28it [00:00, 34.16it/s]\u001b[A\n",
      "32it [00:00, 35.42it/s]\u001b[A\n",
      "38it [00:00, 37.76it/s]\u001b[A\n",
      "44it [00:01, 40.55it/s]\u001b[A\n",
      "49it [00:01, 40.77it/s]\u001b[A\n",
      "54it [00:01, 41.02it/s]\u001b[A\n",
      "59it [00:01, 38.32it/s]\u001b[A\n",
      "63it [00:01, 32.03it/s]\u001b[A\n",
      "67it [00:01, 29.37it/s]\u001b[A\n",
      "72it [00:01, 37.12it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 72/72 [00:00<00:00, 2024.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 514.75 steps, validate for 136.2890625 steps\n",
      "Epoch 1/300\n",
      "515/514 [==============================] - 15s 30ms/step - loss: 0.7245 - accuracy: 0.5589 - val_loss: 0.6753 - val_accuracy: 0.5823\n",
      "Epoch 2/300\n",
      "515/514 [==============================] - 14s 27ms/step - loss: 0.6391 - accuracy: 0.6257 - val_loss: 0.6575 - val_accuracy: 0.6064\n",
      "Epoch 3/300\n",
      "515/514 [==============================] - 14s 27ms/step - loss: 0.6222 - accuracy: 0.6458 - val_loss: 0.6531 - val_accuracy: 0.6136\n",
      "Epoch 4/300\n",
      "515/514 [==============================] - 14s 27ms/step - loss: 0.6105 - accuracy: 0.6575 - val_loss: 0.6452 - val_accuracy: 0.6222\n",
      "Epoch 5/300\n",
      "515/514 [==============================] - 14s 27ms/step - loss: 0.6007 - accuracy: 0.6674 - val_loss: 0.6435 - val_accuracy: 0.6288\n",
      "Epoch 6/300\n",
      "515/514 [==============================] - 14s 27ms/step - loss: 0.5921 - accuracy: 0.6760 - val_loss: 0.6386 - val_accuracy: 0.6311\n",
      "Epoch 7/300\n",
      "515/514 [==============================] - 14s 27ms/step - loss: 0.5843 - accuracy: 0.6847 - val_loss: 0.6381 - val_accuracy: 0.6357\n",
      "Epoch 8/300\n",
      "515/514 [==============================] - 14s 27ms/step - loss: 0.5767 - accuracy: 0.6919 - val_loss: 0.6404 - val_accuracy: 0.6339\n",
      "Epoch 9/300\n",
      "515/514 [==============================] - 14s 27ms/step - loss: 0.5702 - accuracy: 0.6976 - val_loss: 0.6391 - val_accuracy: 0.6347\n",
      "Epoch 10/300\n",
      "515/514 [==============================] - 14s 27ms/step - loss: 0.5639 - accuracy: 0.7021 - val_loss: 0.6376 - val_accuracy: 0.6378\n",
      "Epoch 11/300\n",
      "515/514 [==============================] - 14s 27ms/step - loss: 0.5580 - accuracy: 0.7075 - val_loss: 0.6400 - val_accuracy: 0.6385\n",
      "Epoch 12/300\n",
      "515/514 [==============================] - 14s 27ms/step - loss: 0.5526 - accuracy: 0.7111 - val_loss: 0.6438 - val_accuracy: 0.6377\n",
      "Epoch 13/300\n",
      "515/514 [==============================] - 14s 27ms/step - loss: 0.5474 - accuracy: 0.7163 - val_loss: 0.6425 - val_accuracy: 0.6385\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 514.75 steps, validate for 136.2890625 steps\n",
      "Epoch 1/300\n",
      "515/514 [==============================] - 34s 66ms/step - loss: 0.5394 - accuracy: 0.7213 - val_loss: 0.6450 - val_accuracy: 0.6336\n",
      "Epoch 2/300\n",
      "515/514 [==============================] - 32s 63ms/step - loss: 0.5195 - accuracy: 0.7400 - val_loss: 0.6441 - val_accuracy: 0.6382\n",
      "Epoch 3/300\n",
      "515/514 [==============================] - 32s 63ms/step - loss: 0.5044 - accuracy: 0.7524 - val_loss: 0.6547 - val_accuracy: 0.6333\n",
      "Epoch 4/300\n",
      "515/514 [==============================] - 32s 63ms/step - loss: 0.4904 - accuracy: 0.7633 - val_loss: 0.7210 - val_accuracy: 0.5987\n",
      "Epoch 5/300\n",
      "515/514 [==============================] - 32s 63ms/step - loss: 0.4778 - accuracy: 0.7734 - val_loss: 0.6588 - val_accuracy: 0.6296\n",
      "Epoch 00005: early stopping\n",
      "306/306 [==============================] - 0s 873us/sample - loss: 1.3720 - accuracy: 0.3301\n",
      "287/287 [==============================] - 0s 191us/sample - loss: 1.1531 - accuracy: 0.3798\n",
      "283/283 [==============================] - 0s 198us/sample - loss: 1.1142 - accuracy: 0.3852\n",
      "281/281 [==============================] - 0s 196us/sample - loss: 1.1701 - accuracy: 0.3416\n",
      "273/273 [==============================] - 0s 189us/sample - loss: 1.1395 - accuracy: 0.3480\n",
      "266/266 [==============================] - 0s 193us/sample - loss: 1.2162 - accuracy: 0.3120\n",
      "265/265 [==============================] - 0s 198us/sample - loss: 1.1723 - accuracy: 0.3736\n",
      "262/262 [==============================] - 0s 241us/sample - loss: 1.2548 - accuracy: 0.3206\n",
      "254/254 [==============================] - 0s 228us/sample - loss: 1.1779 - accuracy: 0.3425\n",
      "248/248 [==============================] - 0s 216us/sample - loss: 1.2160 - accuracy: 0.3589\n",
      "245/245 [==============================] - 0s 210us/sample - loss: 1.2649 - accuracy: 0.3796\n",
      "247/247 [==============================] - 0s 221us/sample - loss: 1.2732 - accuracy: 0.3563\n",
      "243/243 [==============================] - 0s 218us/sample - loss: 1.3401 - accuracy: 0.3663\n",
      "243/243 [==============================] - 0s 222us/sample - loss: 1.2577 - accuracy: 0.3374\n",
      "242/242 [==============================] - 0s 236us/sample - loss: 1.2252 - accuracy: 0.3471\n",
      "243/243 [==============================] - 0s 227us/sample - loss: 1.2664 - accuracy: 0.3663\n",
      "237/237 [==============================] - 0s 263us/sample - loss: 1.2898 - accuracy: 0.3333\n",
      "240/240 [==============================] - 0s 229us/sample - loss: 1.2691 - accuracy: 0.3417\n",
      "235/235 [==============================] - 0s 240us/sample - loss: 1.3488 - accuracy: 0.3362\n",
      "232/232 [==============================] - 0s 253us/sample - loss: 1.2558 - accuracy: 0.3491\n",
      "232/232 [==============================] - 0s 218us/sample - loss: 1.3069 - accuracy: 0.3405\n",
      "227/227 [==============================] - 0s 225us/sample - loss: 1.3052 - accuracy: 0.3656\n",
      "224/224 [==============================] - 0s 887us/sample - loss: 1.3396 - accuracy: 0.3795\n",
      "223/223 [==============================] - 0s 258us/sample - loss: 1.3373 - accuracy: 0.3363\n",
      "223/223 [==============================] - 0s 247us/sample - loss: 1.2819 - accuracy: 0.3453\n",
      "219/219 [==============================] - 0s 259us/sample - loss: 1.2556 - accuracy: 0.3333\n",
      "220/220 [==============================] - 0s 245us/sample - loss: 1.2416 - accuracy: 0.3682\n",
      "215/215 [==============================] - 0s 217us/sample - loss: 1.2050 - accuracy: 0.3535\n",
      "216/216 [==============================] - 0s 212us/sample - loss: 1.2219 - accuracy: 0.3611\n",
      "216/216 [==============================] - 0s 209us/sample - loss: 1.3374 - accuracy: 0.2963\n",
      "215/215 [==============================] - 0s 221us/sample - loss: 1.3700 - accuracy: 0.2837\n",
      "214/214 [==============================] - 0s 216us/sample - loss: 1.3118 - accuracy: 0.3411\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 1609 samples, validate on 433 samples\n",
      "Epoch 1/300\n",
      "1609/1609 [==============================] - 2s 1ms/sample - loss: 0.7143 - accuracy: 0.4941 - val_loss: 0.7083 - val_accuracy: 0.5242\n",
      "Epoch 2/300\n",
      "1609/1609 [==============================] - 0s 180us/sample - loss: 0.7002 - accuracy: 0.5227 - val_loss: 0.7024 - val_accuracy: 0.5427\n",
      "Epoch 3/300\n",
      "1609/1609 [==============================] - 0s 172us/sample - loss: 0.6949 - accuracy: 0.5475 - val_loss: 0.6981 - val_accuracy: 0.5427\n",
      "Epoch 4/300\n",
      "1609/1609 [==============================] - 0s 166us/sample - loss: 0.6856 - accuracy: 0.5575 - val_loss: 0.6945 - val_accuracy: 0.5427\n",
      "Epoch 5/300\n",
      "1609/1609 [==============================] - 0s 164us/sample - loss: 0.6783 - accuracy: 0.5656 - val_loss: 0.6912 - val_accuracy: 0.5543\n",
      "Epoch 6/300\n",
      "1609/1609 [==============================] - 0s 160us/sample - loss: 0.6749 - accuracy: 0.5855 - val_loss: 0.6883 - val_accuracy: 0.5589\n",
      "Epoch 7/300\n",
      "1609/1609 [==============================] - 0s 171us/sample - loss: 0.6675 - accuracy: 0.5792 - val_loss: 0.6857 - val_accuracy: 0.5612\n",
      "Epoch 8/300\n",
      "1609/1609 [==============================] - 0s 164us/sample - loss: 0.6698 - accuracy: 0.5861 - val_loss: 0.6834 - val_accuracy: 0.5774\n",
      "Epoch 9/300\n",
      "1609/1609 [==============================] - 0s 173us/sample - loss: 0.6653 - accuracy: 0.5942 - val_loss: 0.6812 - val_accuracy: 0.5774\n",
      "Epoch 10/300\n",
      "1609/1609 [==============================] - 0s 161us/sample - loss: 0.6620 - accuracy: 0.6053 - val_loss: 0.6791 - val_accuracy: 0.5820\n",
      "Epoch 11/300\n",
      "1609/1609 [==============================] - 0s 153us/sample - loss: 0.6569 - accuracy: 0.6209 - val_loss: 0.6772 - val_accuracy: 0.5843\n",
      "Epoch 12/300\n",
      "1609/1609 [==============================] - 0s 157us/sample - loss: 0.6574 - accuracy: 0.6140 - val_loss: 0.6754 - val_accuracy: 0.5912\n",
      "Epoch 13/300\n",
      "1609/1609 [==============================] - 0s 160us/sample - loss: 0.6537 - accuracy: 0.6091 - val_loss: 0.6737 - val_accuracy: 0.5935\n",
      "Epoch 14/300\n",
      "1609/1609 [==============================] - 0s 167us/sample - loss: 0.6473 - accuracy: 0.6277 - val_loss: 0.6720 - val_accuracy: 0.6028\n",
      "Epoch 15/300\n",
      "1609/1609 [==============================] - 0s 167us/sample - loss: 0.6478 - accuracy: 0.6265 - val_loss: 0.6704 - val_accuracy: 0.6028\n",
      "Epoch 16/300\n",
      "1609/1609 [==============================] - 0s 167us/sample - loss: 0.6452 - accuracy: 0.6414 - val_loss: 0.6689 - val_accuracy: 0.6074\n",
      "Epoch 17/300\n",
      "1609/1609 [==============================] - 0s 174us/sample - loss: 0.6451 - accuracy: 0.6240 - val_loss: 0.6674 - val_accuracy: 0.6074\n",
      "Epoch 18/300\n",
      "1609/1609 [==============================] - 0s 159us/sample - loss: 0.6419 - accuracy: 0.6290 - val_loss: 0.6660 - val_accuracy: 0.6120\n",
      "Epoch 19/300\n",
      "1609/1609 [==============================] - 0s 163us/sample - loss: 0.6389 - accuracy: 0.6352 - val_loss: 0.6646 - val_accuracy: 0.6143\n",
      "Epoch 20/300\n",
      "1609/1609 [==============================] - 0s 177us/sample - loss: 0.6325 - accuracy: 0.6457 - val_loss: 0.6632 - val_accuracy: 0.6143\n",
      "Epoch 21/300\n",
      "1609/1609 [==============================] - 0s 172us/sample - loss: 0.6305 - accuracy: 0.6464 - val_loss: 0.6619 - val_accuracy: 0.6143\n",
      "Epoch 22/300\n",
      "1609/1609 [==============================] - 0s 179us/sample - loss: 0.6326 - accuracy: 0.6513 - val_loss: 0.6606 - val_accuracy: 0.6143\n",
      "Epoch 23/300\n",
      "1609/1609 [==============================] - 0s 177us/sample - loss: 0.6264 - accuracy: 0.6656 - val_loss: 0.6593 - val_accuracy: 0.6143\n",
      "Epoch 24/300\n",
      "1609/1609 [==============================] - 0s 181us/sample - loss: 0.6204 - accuracy: 0.6712 - val_loss: 0.6581 - val_accuracy: 0.6166\n",
      "Epoch 25/300\n",
      "1609/1609 [==============================] - 0s 166us/sample - loss: 0.6204 - accuracy: 0.6725 - val_loss: 0.6568 - val_accuracy: 0.6189\n",
      "Epoch 26/300\n",
      "1609/1609 [==============================] - 0s 167us/sample - loss: 0.6216 - accuracy: 0.6544 - val_loss: 0.6557 - val_accuracy: 0.6212\n",
      "Epoch 27/300\n",
      "1609/1609 [==============================] - 0s 168us/sample - loss: 0.6156 - accuracy: 0.6706 - val_loss: 0.6545 - val_accuracy: 0.6212\n",
      "Epoch 28/300\n",
      "1609/1609 [==============================] - 0s 179us/sample - loss: 0.6184 - accuracy: 0.6631 - val_loss: 0.6533 - val_accuracy: 0.6212\n",
      "Epoch 29/300\n",
      "1609/1609 [==============================] - 0s 162us/sample - loss: 0.6157 - accuracy: 0.6756 - val_loss: 0.6523 - val_accuracy: 0.6259\n",
      "Epoch 30/300\n",
      "1609/1609 [==============================] - 0s 166us/sample - loss: 0.6111 - accuracy: 0.6756 - val_loss: 0.6511 - val_accuracy: 0.6282\n",
      "Epoch 31/300\n",
      "1609/1609 [==============================] - 0s 167us/sample - loss: 0.6096 - accuracy: 0.6818 - val_loss: 0.6500 - val_accuracy: 0.6282\n",
      "Epoch 32/300\n",
      "1609/1609 [==============================] - 0s 161us/sample - loss: 0.6084 - accuracy: 0.6805 - val_loss: 0.6489 - val_accuracy: 0.6282\n",
      "Epoch 33/300\n",
      "1609/1609 [==============================] - 0s 161us/sample - loss: 0.6076 - accuracy: 0.6743 - val_loss: 0.6478 - val_accuracy: 0.6305\n",
      "Epoch 34/300\n",
      "1609/1609 [==============================] - 0s 181us/sample - loss: 0.5989 - accuracy: 0.7011 - val_loss: 0.6468 - val_accuracy: 0.6305\n",
      "Epoch 35/300\n",
      "1609/1609 [==============================] - 0s 167us/sample - loss: 0.5993 - accuracy: 0.7004 - val_loss: 0.6457 - val_accuracy: 0.6305\n",
      "Epoch 36/300\n",
      "1609/1609 [==============================] - 0s 172us/sample - loss: 0.6018 - accuracy: 0.6874 - val_loss: 0.6447 - val_accuracy: 0.6328\n",
      "Epoch 37/300\n",
      "1609/1609 [==============================] - 0s 170us/sample - loss: 0.5979 - accuracy: 0.6930 - val_loss: 0.6436 - val_accuracy: 0.6351\n",
      "Epoch 38/300\n",
      "1609/1609 [==============================] - 0s 160us/sample - loss: 0.5938 - accuracy: 0.7035 - val_loss: 0.6426 - val_accuracy: 0.6374\n",
      "Epoch 39/300\n",
      "1609/1609 [==============================] - 0s 180us/sample - loss: 0.5939 - accuracy: 0.6992 - val_loss: 0.6415 - val_accuracy: 0.6351\n",
      "Epoch 40/300\n",
      "1609/1609 [==============================] - 0s 186us/sample - loss: 0.5912 - accuracy: 0.7035 - val_loss: 0.6405 - val_accuracy: 0.6374\n",
      "Epoch 41/300\n",
      "1609/1609 [==============================] - 0s 179us/sample - loss: 0.5843 - accuracy: 0.7073 - val_loss: 0.6395 - val_accuracy: 0.6374\n",
      "Epoch 42/300\n",
      "1609/1609 [==============================] - 0s 181us/sample - loss: 0.5868 - accuracy: 0.7079 - val_loss: 0.6385 - val_accuracy: 0.6397\n",
      "Epoch 43/300\n",
      "1609/1609 [==============================] - 0s 185us/sample - loss: 0.5875 - accuracy: 0.7079 - val_loss: 0.6375 - val_accuracy: 0.6397\n",
      "Epoch 44/300\n",
      "1609/1609 [==============================] - 0s 198us/sample - loss: 0.5816 - accuracy: 0.7185 - val_loss: 0.6365 - val_accuracy: 0.6397\n",
      "Epoch 45/300\n",
      "1609/1609 [==============================] - 0s 171us/sample - loss: 0.5809 - accuracy: 0.7073 - val_loss: 0.6355 - val_accuracy: 0.6374\n",
      "Epoch 46/300\n",
      "1609/1609 [==============================] - 0s 168us/sample - loss: 0.5771 - accuracy: 0.7259 - val_loss: 0.6346 - val_accuracy: 0.6374\n",
      "Epoch 47/300\n",
      "1609/1609 [==============================] - 0s 173us/sample - loss: 0.5726 - accuracy: 0.7166 - val_loss: 0.6336 - val_accuracy: 0.6420\n",
      "Epoch 48/300\n",
      "1609/1609 [==============================] - 0s 188us/sample - loss: 0.5720 - accuracy: 0.7228 - val_loss: 0.6326 - val_accuracy: 0.6443\n",
      "Epoch 49/300\n",
      "1609/1609 [==============================] - 0s 174us/sample - loss: 0.5712 - accuracy: 0.7222 - val_loss: 0.6317 - val_accuracy: 0.6467\n",
      "Epoch 50/300\n",
      "1609/1609 [==============================] - 0s 181us/sample - loss: 0.5716 - accuracy: 0.7216 - val_loss: 0.6307 - val_accuracy: 0.6467\n",
      "Epoch 51/300\n",
      "1609/1609 [==============================] - 0s 166us/sample - loss: 0.5691 - accuracy: 0.7228 - val_loss: 0.6298 - val_accuracy: 0.6467\n",
      "Epoch 52/300\n",
      "1609/1609 [==============================] - 0s 165us/sample - loss: 0.5625 - accuracy: 0.7390 - val_loss: 0.6288 - val_accuracy: 0.6513\n",
      "Epoch 53/300\n",
      "1609/1609 [==============================] - 0s 172us/sample - loss: 0.5641 - accuracy: 0.7303 - val_loss: 0.6279 - val_accuracy: 0.6536\n",
      "Epoch 54/300\n",
      "1609/1609 [==============================] - 0s 158us/sample - loss: 0.5612 - accuracy: 0.7383 - val_loss: 0.6269 - val_accuracy: 0.6536\n",
      "Epoch 55/300\n",
      "1609/1609 [==============================] - 0s 180us/sample - loss: 0.5606 - accuracy: 0.7328 - val_loss: 0.6260 - val_accuracy: 0.6559\n",
      "Epoch 56/300\n",
      "1609/1609 [==============================] - 0s 183us/sample - loss: 0.5556 - accuracy: 0.7408 - val_loss: 0.6250 - val_accuracy: 0.6582\n",
      "Epoch 57/300\n",
      "1609/1609 [==============================] - 0s 187us/sample - loss: 0.5564 - accuracy: 0.7352 - val_loss: 0.6241 - val_accuracy: 0.6582\n",
      "Epoch 58/300\n",
      "1609/1609 [==============================] - 0s 166us/sample - loss: 0.5500 - accuracy: 0.7340 - val_loss: 0.6232 - val_accuracy: 0.6582\n",
      "Epoch 59/300\n",
      "1609/1609 [==============================] - 0s 168us/sample - loss: 0.5536 - accuracy: 0.7452 - val_loss: 0.6222 - val_accuracy: 0.6559\n",
      "Epoch 60/300\n",
      "1609/1609 [==============================] - 0s 183us/sample - loss: 0.5488 - accuracy: 0.7452 - val_loss: 0.6213 - val_accuracy: 0.6536\n",
      "Epoch 61/300\n",
      "1609/1609 [==============================] - 0s 176us/sample - loss: 0.5480 - accuracy: 0.7446 - val_loss: 0.6204 - val_accuracy: 0.6536\n",
      "Epoch 62/300\n",
      "1609/1609 [==============================] - 0s 172us/sample - loss: 0.5430 - accuracy: 0.7489 - val_loss: 0.6195 - val_accuracy: 0.6582\n",
      "Epoch 63/300\n",
      "1609/1609 [==============================] - 0s 178us/sample - loss: 0.5420 - accuracy: 0.7533 - val_loss: 0.6186 - val_accuracy: 0.6605\n",
      "Epoch 64/300\n",
      "1609/1609 [==============================] - 0s 160us/sample - loss: 0.5395 - accuracy: 0.7446 - val_loss: 0.6177 - val_accuracy: 0.6628\n",
      "Epoch 65/300\n",
      "1609/1609 [==============================] - 0s 161us/sample - loss: 0.5356 - accuracy: 0.7495 - val_loss: 0.6168 - val_accuracy: 0.6651\n",
      "Epoch 66/300\n",
      "1609/1609 [==============================] - 0s 157us/sample - loss: 0.5373 - accuracy: 0.7508 - val_loss: 0.6158 - val_accuracy: 0.6674\n",
      "Epoch 67/300\n",
      "1609/1609 [==============================] - 0s 167us/sample - loss: 0.5328 - accuracy: 0.7508 - val_loss: 0.6149 - val_accuracy: 0.6674\n",
      "Epoch 68/300\n",
      "1609/1609 [==============================] - 0s 165us/sample - loss: 0.5346 - accuracy: 0.7439 - val_loss: 0.6141 - val_accuracy: 0.6697\n",
      "Epoch 69/300\n",
      "1609/1609 [==============================] - 0s 157us/sample - loss: 0.5306 - accuracy: 0.7576 - val_loss: 0.6132 - val_accuracy: 0.6697\n",
      "Epoch 70/300\n",
      "1609/1609 [==============================] - 0s 170us/sample - loss: 0.5298 - accuracy: 0.7539 - val_loss: 0.6123 - val_accuracy: 0.6721\n",
      "Epoch 71/300\n",
      "1609/1609 [==============================] - 0s 177us/sample - loss: 0.5241 - accuracy: 0.7620 - val_loss: 0.6115 - val_accuracy: 0.6721\n",
      "Epoch 72/300\n",
      "1609/1609 [==============================] - 0s 171us/sample - loss: 0.5223 - accuracy: 0.7632 - val_loss: 0.6106 - val_accuracy: 0.6697\n",
      "Epoch 73/300\n",
      "1609/1609 [==============================] - 0s 184us/sample - loss: 0.5199 - accuracy: 0.7657 - val_loss: 0.6097 - val_accuracy: 0.6721\n",
      "Epoch 74/300\n",
      "1609/1609 [==============================] - 0s 163us/sample - loss: 0.5190 - accuracy: 0.7620 - val_loss: 0.6089 - val_accuracy: 0.6721\n",
      "Epoch 75/300\n",
      "1609/1609 [==============================] - 0s 169us/sample - loss: 0.5166 - accuracy: 0.7669 - val_loss: 0.6080 - val_accuracy: 0.6721\n",
      "Epoch 76/300\n",
      "1609/1609 [==============================] - 0s 162us/sample - loss: 0.5148 - accuracy: 0.7769 - val_loss: 0.6072 - val_accuracy: 0.6697\n",
      "Epoch 77/300\n",
      "1609/1609 [==============================] - 0s 169us/sample - loss: 0.5088 - accuracy: 0.7657 - val_loss: 0.6063 - val_accuracy: 0.6721\n",
      "Epoch 78/300\n",
      "1609/1609 [==============================] - 0s 166us/sample - loss: 0.5087 - accuracy: 0.7775 - val_loss: 0.6055 - val_accuracy: 0.6744\n",
      "Epoch 79/300\n",
      "1609/1609 [==============================] - 0s 168us/sample - loss: 0.5059 - accuracy: 0.7750 - val_loss: 0.6047 - val_accuracy: 0.6767\n",
      "Epoch 80/300\n",
      "1609/1609 [==============================] - 0s 174us/sample - loss: 0.5045 - accuracy: 0.7756 - val_loss: 0.6039 - val_accuracy: 0.6767\n",
      "Epoch 81/300\n",
      "1609/1609 [==============================] - 0s 173us/sample - loss: 0.5020 - accuracy: 0.7763 - val_loss: 0.6031 - val_accuracy: 0.6790\n",
      "Epoch 82/300\n",
      "1609/1609 [==============================] - 0s 170us/sample - loss: 0.4998 - accuracy: 0.7800 - val_loss: 0.6022 - val_accuracy: 0.6790\n",
      "Epoch 83/300\n",
      "1609/1609 [==============================] - 0s 166us/sample - loss: 0.4988 - accuracy: 0.7887 - val_loss: 0.6014 - val_accuracy: 0.6790\n",
      "Epoch 84/300\n",
      "1609/1609 [==============================] - 0s 173us/sample - loss: 0.4964 - accuracy: 0.7924 - val_loss: 0.6006 - val_accuracy: 0.6790\n",
      "Epoch 85/300\n",
      "1609/1609 [==============================] - 0s 163us/sample - loss: 0.4922 - accuracy: 0.7918 - val_loss: 0.5998 - val_accuracy: 0.6790\n",
      "Epoch 86/300\n",
      "1609/1609 [==============================] - 0s 163us/sample - loss: 0.4882 - accuracy: 0.7974 - val_loss: 0.5990 - val_accuracy: 0.6813\n",
      "Epoch 87/300\n",
      "1609/1609 [==============================] - 0s 170us/sample - loss: 0.4904 - accuracy: 0.7856 - val_loss: 0.5981 - val_accuracy: 0.6813\n",
      "Epoch 88/300\n",
      "1609/1609 [==============================] - 0s 186us/sample - loss: 0.4854 - accuracy: 0.7874 - val_loss: 0.5974 - val_accuracy: 0.6813\n",
      "Epoch 89/300\n",
      "1609/1609 [==============================] - 0s 171us/sample - loss: 0.4824 - accuracy: 0.7974 - val_loss: 0.5966 - val_accuracy: 0.6813\n",
      "Epoch 90/300\n",
      "1609/1609 [==============================] - 0s 164us/sample - loss: 0.4776 - accuracy: 0.7949 - val_loss: 0.5959 - val_accuracy: 0.6767\n",
      "Epoch 91/300\n",
      "1609/1609 [==============================] - 0s 161us/sample - loss: 0.4768 - accuracy: 0.7937 - val_loss: 0.5950 - val_accuracy: 0.6721\n",
      "Epoch 92/300\n",
      "1609/1609 [==============================] - 0s 160us/sample - loss: 0.4766 - accuracy: 0.7943 - val_loss: 0.5943 - val_accuracy: 0.6674\n",
      "Epoch 93/300\n",
      "1609/1609 [==============================] - 0s 171us/sample - loss: 0.4725 - accuracy: 0.8036 - val_loss: 0.5934 - val_accuracy: 0.6674\n",
      "Epoch 94/300\n",
      "1609/1609 [==============================] - 0s 175us/sample - loss: 0.4685 - accuracy: 0.8024 - val_loss: 0.5927 - val_accuracy: 0.6674\n",
      "Epoch 95/300\n",
      "1609/1609 [==============================] - 0s 163us/sample - loss: 0.4705 - accuracy: 0.8061 - val_loss: 0.5920 - val_accuracy: 0.6651\n",
      "Epoch 96/300\n",
      "1609/1609 [==============================] - 0s 163us/sample - loss: 0.4654 - accuracy: 0.8073 - val_loss: 0.5912 - val_accuracy: 0.6628\n",
      "Epoch 97/300\n",
      "1609/1609 [==============================] - 0s 163us/sample - loss: 0.4609 - accuracy: 0.8117 - val_loss: 0.5906 - val_accuracy: 0.6651\n",
      "Epoch 98/300\n",
      "1609/1609 [==============================] - 0s 177us/sample - loss: 0.4617 - accuracy: 0.8073 - val_loss: 0.5898 - val_accuracy: 0.6651\n",
      "Epoch 99/300\n",
      "1609/1609 [==============================] - 0s 189us/sample - loss: 0.4575 - accuracy: 0.8173 - val_loss: 0.5892 - val_accuracy: 0.6721\n",
      "Epoch 100/300\n",
      "1609/1609 [==============================] - 0s 189us/sample - loss: 0.4563 - accuracy: 0.8198 - val_loss: 0.5884 - val_accuracy: 0.6721\n",
      "Epoch 101/300\n",
      "1609/1609 [==============================] - 0s 185us/sample - loss: 0.4562 - accuracy: 0.8073 - val_loss: 0.5877 - val_accuracy: 0.6721\n",
      "Epoch 102/300\n",
      "1609/1609 [==============================] - 0s 203us/sample - loss: 0.4497 - accuracy: 0.8167 - val_loss: 0.5871 - val_accuracy: 0.6744\n",
      "Epoch 103/300\n",
      "1609/1609 [==============================] - 0s 187us/sample - loss: 0.4483 - accuracy: 0.8154 - val_loss: 0.5866 - val_accuracy: 0.6721\n",
      "Epoch 104/300\n",
      "1609/1609 [==============================] - 0s 186us/sample - loss: 0.4444 - accuracy: 0.8235 - val_loss: 0.5859 - val_accuracy: 0.6674\n",
      "Epoch 105/300\n",
      "1609/1609 [==============================] - 0s 187us/sample - loss: 0.4417 - accuracy: 0.8229 - val_loss: 0.5852 - val_accuracy: 0.6721\n",
      "Epoch 106/300\n",
      "1609/1609 [==============================] - 0s 175us/sample - loss: 0.4377 - accuracy: 0.8191 - val_loss: 0.5847 - val_accuracy: 0.6744\n",
      "Epoch 107/300\n",
      "1609/1609 [==============================] - 0s 172us/sample - loss: 0.4430 - accuracy: 0.8198 - val_loss: 0.5840 - val_accuracy: 0.6744\n",
      "Epoch 108/300\n",
      "1609/1609 [==============================] - 0s 177us/sample - loss: 0.4363 - accuracy: 0.8266 - val_loss: 0.5834 - val_accuracy: 0.6790\n",
      "Epoch 109/300\n",
      "1609/1609 [==============================] - 0s 187us/sample - loss: 0.4323 - accuracy: 0.8204 - val_loss: 0.5828 - val_accuracy: 0.6813\n",
      "Epoch 110/300\n",
      "1609/1609 [==============================] - 0s 175us/sample - loss: 0.4307 - accuracy: 0.8179 - val_loss: 0.5822 - val_accuracy: 0.6790\n",
      "Epoch 111/300\n",
      "1609/1609 [==============================] - 0s 166us/sample - loss: 0.4262 - accuracy: 0.8210 - val_loss: 0.5816 - val_accuracy: 0.6813\n",
      "Epoch 112/300\n",
      "1609/1609 [==============================] - 0s 182us/sample - loss: 0.4221 - accuracy: 0.8297 - val_loss: 0.5811 - val_accuracy: 0.6836\n",
      "Epoch 113/300\n",
      "1609/1609 [==============================] - 0s 167us/sample - loss: 0.4236 - accuracy: 0.8322 - val_loss: 0.5805 - val_accuracy: 0.6813\n",
      "Epoch 114/300\n",
      "1609/1609 [==============================] - 0s 163us/sample - loss: 0.4215 - accuracy: 0.8353 - val_loss: 0.5800 - val_accuracy: 0.6836\n",
      "Epoch 115/300\n",
      "1609/1609 [==============================] - 0s 174us/sample - loss: 0.4170 - accuracy: 0.8297 - val_loss: 0.5796 - val_accuracy: 0.6836\n",
      "Epoch 116/300\n",
      "1609/1609 [==============================] - 0s 171us/sample - loss: 0.4136 - accuracy: 0.8409 - val_loss: 0.5791 - val_accuracy: 0.6859\n",
      "Epoch 117/300\n",
      "1609/1609 [==============================] - 0s 175us/sample - loss: 0.4109 - accuracy: 0.8341 - val_loss: 0.5787 - val_accuracy: 0.6859\n",
      "Epoch 118/300\n",
      "1609/1609 [==============================] - 0s 179us/sample - loss: 0.4084 - accuracy: 0.8434 - val_loss: 0.5783 - val_accuracy: 0.6836\n",
      "Epoch 119/300\n",
      "1609/1609 [==============================] - 0s 194us/sample - loss: 0.4057 - accuracy: 0.8421 - val_loss: 0.5779 - val_accuracy: 0.6859\n",
      "Epoch 120/300\n",
      "1609/1609 [==============================] - 0s 172us/sample - loss: 0.4039 - accuracy: 0.8415 - val_loss: 0.5776 - val_accuracy: 0.6905\n",
      "Epoch 121/300\n",
      "1609/1609 [==============================] - 0s 165us/sample - loss: 0.3994 - accuracy: 0.8403 - val_loss: 0.5774 - val_accuracy: 0.6928\n",
      "Epoch 122/300\n",
      "1609/1609 [==============================] - 0s 189us/sample - loss: 0.3971 - accuracy: 0.8459 - val_loss: 0.5771 - val_accuracy: 0.6952\n",
      "Epoch 123/300\n",
      "1609/1609 [==============================] - 0s 169us/sample - loss: 0.3957 - accuracy: 0.8614 - val_loss: 0.5769 - val_accuracy: 0.6952\n",
      "Epoch 124/300\n",
      "1609/1609 [==============================] - 0s 162us/sample - loss: 0.3921 - accuracy: 0.8496 - val_loss: 0.5767 - val_accuracy: 0.6952\n",
      "Epoch 125/300\n",
      "1609/1609 [==============================] - 0s 159us/sample - loss: 0.3918 - accuracy: 0.8452 - val_loss: 0.5764 - val_accuracy: 0.6928\n",
      "Epoch 126/300\n",
      "1609/1609 [==============================] - 0s 163us/sample - loss: 0.3902 - accuracy: 0.8496 - val_loss: 0.5760 - val_accuracy: 0.6952\n",
      "Epoch 127/300\n",
      "1609/1609 [==============================] - 0s 182us/sample - loss: 0.3900 - accuracy: 0.8558 - val_loss: 0.5758 - val_accuracy: 0.6928\n",
      "Epoch 128/300\n",
      "1609/1609 [==============================] - 0s 179us/sample - loss: 0.3886 - accuracy: 0.8539 - val_loss: 0.5758 - val_accuracy: 0.6928\n",
      "Epoch 129/300\n",
      "1609/1609 [==============================] - 0s 177us/sample - loss: 0.3809 - accuracy: 0.8620 - val_loss: 0.5757 - val_accuracy: 0.6952\n",
      "Epoch 130/300\n",
      "1609/1609 [==============================] - 0s 175us/sample - loss: 0.3761 - accuracy: 0.8564 - val_loss: 0.5756 - val_accuracy: 0.6952\n",
      "Epoch 131/300\n",
      "1609/1609 [==============================] - 0s 175us/sample - loss: 0.3788 - accuracy: 0.8515 - val_loss: 0.5755 - val_accuracy: 0.6975\n",
      "Epoch 132/300\n",
      "1609/1609 [==============================] - 0s 164us/sample - loss: 0.3694 - accuracy: 0.8633 - val_loss: 0.5755 - val_accuracy: 0.6905\n",
      "Epoch 133/300\n",
      "1609/1609 [==============================] - 0s 183us/sample - loss: 0.3714 - accuracy: 0.8614 - val_loss: 0.5755 - val_accuracy: 0.6905\n",
      "Epoch 134/300\n",
      "1609/1609 [==============================] - 0s 194us/sample - loss: 0.3711 - accuracy: 0.8608 - val_loss: 0.5756 - val_accuracy: 0.6882\n",
      "Epoch 00134: early stopping\n",
      "197/197 [==============================] - 0s 114us/sample - loss: 1.2952 - accuracy: 0.3503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [48:31, 735.90s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:05<00:05,  5.99s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.39s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "6it [00:00, 45.68it/s]\u001b[A\n",
      "11it [00:00, 46.03it/s]\u001b[A\n",
      "15it [00:00, 43.73it/s]\u001b[A\n",
      "18it [00:00, 37.33it/s]\u001b[A\n",
      "22it [00:00, 38.05it/s]\u001b[A\n",
      "26it [00:00, 34.77it/s]\u001b[A\n",
      "31it [00:00, 37.92it/s]\u001b[A\n",
      "35it [00:00, 37.76it/s]\u001b[A\n",
      "41it [00:01, 39.75it/s]\u001b[A\n",
      "45it [00:01, 38.22it/s]\u001b[A\n",
      "50it [00:01, 37.76it/s]\u001b[A\n",
      "55it [00:01, 37.70it/s]\u001b[A\n",
      "59it [00:01, 36.16it/s]\u001b[A\n",
      "63it [00:01, 32.43it/s]\u001b[A\n",
      "67it [00:01, 33.24it/s]\u001b[A\n",
      "72it [00:01, 37.73it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 72/72 [00:00<00:00, 2158.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 507.4296875 steps, validate for 135.421875 steps\n",
      "Epoch 1/300\n",
      "508/507 [==============================] - 15s 30ms/step - loss: 0.6914 - accuracy: 0.5708 - val_loss: 0.6758 - val_accuracy: 0.5922\n",
      "Epoch 2/300\n",
      "508/507 [==============================] - 14s 27ms/step - loss: 0.6530 - accuracy: 0.6138 - val_loss: 0.6641 - val_accuracy: 0.6076\n",
      "Epoch 3/300\n",
      "508/507 [==============================] - 14s 27ms/step - loss: 0.6369 - accuracy: 0.6337 - val_loss: 0.6547 - val_accuracy: 0.6199\n",
      "Epoch 4/300\n",
      "508/507 [==============================] - 14s 27ms/step - loss: 0.6251 - accuracy: 0.6465 - val_loss: 0.6503 - val_accuracy: 0.6244\n",
      "Epoch 5/300\n",
      "508/507 [==============================] - 14s 27ms/step - loss: 0.6151 - accuracy: 0.6570 - val_loss: 0.6479 - val_accuracy: 0.6317\n",
      "Epoch 6/300\n",
      "508/507 [==============================] - 14s 27ms/step - loss: 0.6065 - accuracy: 0.6663 - val_loss: 0.6473 - val_accuracy: 0.6293\n",
      "Epoch 7/300\n",
      "508/507 [==============================] - 14s 27ms/step - loss: 0.5991 - accuracy: 0.6732 - val_loss: 0.6436 - val_accuracy: 0.6362\n",
      "Epoch 8/300\n",
      "508/507 [==============================] - 14s 27ms/step - loss: 0.5921 - accuracy: 0.6789 - val_loss: 0.6448 - val_accuracy: 0.6378\n",
      "Epoch 9/300\n",
      "508/507 [==============================] - 14s 27ms/step - loss: 0.5858 - accuracy: 0.6846 - val_loss: 0.6474 - val_accuracy: 0.6328\n",
      "Epoch 10/300\n",
      "508/507 [==============================] - 14s 27ms/step - loss: 0.5802 - accuracy: 0.6893 - val_loss: 0.6456 - val_accuracy: 0.6375\n",
      "Epoch 00010: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 507.4296875 steps, validate for 135.421875 steps\n",
      "Epoch 1/300\n",
      "508/507 [==============================] - 33s 66ms/step - loss: 0.5701 - accuracy: 0.6996 - val_loss: 0.6741 - val_accuracy: 0.6184\n",
      "Epoch 2/300\n",
      "508/507 [==============================] - 32s 63ms/step - loss: 0.5502 - accuracy: 0.7189 - val_loss: 0.6547 - val_accuracy: 0.6337\n",
      "Epoch 3/300\n",
      "508/507 [==============================] - 32s 63ms/step - loss: 0.5345 - accuracy: 0.7326 - val_loss: 0.6564 - val_accuracy: 0.6377\n",
      "Epoch 4/300\n",
      "508/507 [==============================] - 32s 63ms/step - loss: 0.5206 - accuracy: 0.7427 - val_loss: 0.6461 - val_accuracy: 0.6390\n",
      "Epoch 5/300\n",
      "508/507 [==============================] - 32s 63ms/step - loss: 0.5078 - accuracy: 0.7548 - val_loss: 0.6473 - val_accuracy: 0.6369\n",
      "Epoch 6/300\n",
      "508/507 [==============================] - 32s 63ms/step - loss: 0.4953 - accuracy: 0.7661 - val_loss: 0.6390 - val_accuracy: 0.6501\n",
      "Epoch 7/300\n",
      "508/507 [==============================] - 32s 63ms/step - loss: 0.4838 - accuracy: 0.7749 - val_loss: 0.6637 - val_accuracy: 0.6217\n",
      "Epoch 8/300\n",
      "508/507 [==============================] - 32s 63ms/step - loss: 0.4722 - accuracy: 0.7829 - val_loss: 0.6544 - val_accuracy: 0.6468\n",
      "Epoch 9/300\n",
      "508/507 [==============================] - 32s 63ms/step - loss: 0.4607 - accuracy: 0.7920 - val_loss: 0.6530 - val_accuracy: 0.6395\n",
      "Epoch 00009: early stopping\n",
      "360/360 [==============================] - 0s 856us/sample - loss: 1.1909 - accuracy: 0.2750\n",
      "335/335 [==============================] - 0s 218us/sample - loss: 1.1654 - accuracy: 0.2925\n",
      "327/327 [==============================] - 0s 205us/sample - loss: 1.1729 - accuracy: 0.2630\n",
      "320/320 [==============================] - 0s 722us/sample - loss: 1.1299 - accuracy: 0.3000\n",
      "312/312 [==============================] - 0s 196us/sample - loss: 1.0908 - accuracy: 0.3686\n",
      "307/307 [==============================] - 0s 226us/sample - loss: 1.0693 - accuracy: 0.3648\n",
      "304/304 [==============================] - 0s 268us/sample - loss: 1.0863 - accuracy: 0.3651\n",
      "297/297 [==============================] - 0s 224us/sample - loss: 1.0488 - accuracy: 0.3636\n",
      "297/297 [==============================] - 0s 229us/sample - loss: 1.0573 - accuracy: 0.3569\n",
      "291/291 [==============================] - 0s 257us/sample - loss: 1.0571 - accuracy: 0.3677\n",
      "284/284 [==============================] - 0s 233us/sample - loss: 1.0674 - accuracy: 0.3521\n",
      "283/283 [==============================] - 0s 215us/sample - loss: 1.0496 - accuracy: 0.3428\n",
      "282/282 [==============================] - 0s 221us/sample - loss: 1.0586 - accuracy: 0.3475\n",
      "277/277 [==============================] - 0s 219us/sample - loss: 1.0001 - accuracy: 0.3863\n",
      "279/279 [==============================] - 0s 244us/sample - loss: 1.0524 - accuracy: 0.3477\n",
      "270/270 [==============================] - 0s 216us/sample - loss: 1.0179 - accuracy: 0.4037\n",
      "265/265 [==============================] - 0s 213us/sample - loss: 1.0196 - accuracy: 0.4113\n",
      "266/266 [==============================] - 0s 221us/sample - loss: 1.0040 - accuracy: 0.4173\n",
      "266/266 [==============================] - 0s 213us/sample - loss: 0.9795 - accuracy: 0.4436\n",
      "264/264 [==============================] - 0s 232us/sample - loss: 1.0611 - accuracy: 0.4091\n",
      "258/258 [==============================] - 0s 226us/sample - loss: 1.0768 - accuracy: 0.3992\n",
      "255/255 [==============================] - 0s 221us/sample - loss: 1.0165 - accuracy: 0.3686\n",
      "255/255 [==============================] - 0s 234us/sample - loss: 1.0150 - accuracy: 0.4118\n",
      "254/254 [==============================] - 0s 211us/sample - loss: 0.9907 - accuracy: 0.4213\n",
      "246/246 [==============================] - 0s 210us/sample - loss: 1.0143 - accuracy: 0.3780\n",
      "242/242 [==============================] - 0s 220us/sample - loss: 0.9907 - accuracy: 0.4421\n",
      "242/242 [==============================] - 0s 233us/sample - loss: 1.0048 - accuracy: 0.4215\n",
      "240/240 [==============================] - 0s 229us/sample - loss: 1.0263 - accuracy: 0.4083\n",
      "238/238 [==============================] - 0s 219us/sample - loss: 1.0226 - accuracy: 0.4202\n",
      "239/239 [==============================] - 0s 245us/sample - loss: 1.0895 - accuracy: 0.3975\n",
      "235/235 [==============================] - 0s 244us/sample - loss: 1.0672 - accuracy: 0.3532\n",
      "234/234 [==============================] - 0s 227us/sample - loss: 1.1204 - accuracy: 0.3504\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 1591 samples, validate on 433 samples\n",
      "Epoch 1/300\n",
      "1591/1591 [==============================] - 2s 1ms/sample - loss: 0.7094 - accuracy: 0.5248 - val_loss: 0.6792 - val_accuracy: 0.5704\n",
      "Epoch 2/300\n",
      "1591/1591 [==============================] - 0s 168us/sample - loss: 0.6927 - accuracy: 0.5519 - val_loss: 0.6723 - val_accuracy: 0.5935\n",
      "Epoch 3/300\n",
      "1591/1591 [==============================] - 0s 160us/sample - loss: 0.6882 - accuracy: 0.5575 - val_loss: 0.6671 - val_accuracy: 0.6143\n",
      "Epoch 4/300\n",
      "1591/1591 [==============================] - 0s 168us/sample - loss: 0.6748 - accuracy: 0.5845 - val_loss: 0.6630 - val_accuracy: 0.6259\n",
      "Epoch 5/300\n",
      "1591/1591 [==============================] - 0s 171us/sample - loss: 0.6762 - accuracy: 0.5852 - val_loss: 0.6592 - val_accuracy: 0.6282\n",
      "Epoch 6/300\n",
      "1591/1591 [==============================] - 0s 177us/sample - loss: 0.6627 - accuracy: 0.6065 - val_loss: 0.6560 - val_accuracy: 0.6282\n",
      "Epoch 7/300\n",
      "1591/1591 [==============================] - 0s 165us/sample - loss: 0.6535 - accuracy: 0.6172 - val_loss: 0.6532 - val_accuracy: 0.6305\n",
      "Epoch 8/300\n",
      "1591/1591 [==============================] - 0s 161us/sample - loss: 0.6514 - accuracy: 0.6147 - val_loss: 0.6505 - val_accuracy: 0.6328\n",
      "Epoch 9/300\n",
      "1591/1591 [==============================] - 0s 173us/sample - loss: 0.6501 - accuracy: 0.6254 - val_loss: 0.6480 - val_accuracy: 0.6351\n",
      "Epoch 10/300\n",
      "1591/1591 [==============================] - 0s 187us/sample - loss: 0.6467 - accuracy: 0.6323 - val_loss: 0.6457 - val_accuracy: 0.6467\n",
      "Epoch 11/300\n",
      "1591/1591 [==============================] - 0s 182us/sample - loss: 0.6458 - accuracy: 0.6216 - val_loss: 0.6434 - val_accuracy: 0.6582\n",
      "Epoch 12/300\n",
      "1591/1591 [==============================] - 0s 170us/sample - loss: 0.6378 - accuracy: 0.6499 - val_loss: 0.6414 - val_accuracy: 0.6605\n",
      "Epoch 13/300\n",
      "1591/1591 [==============================] - 0s 174us/sample - loss: 0.6403 - accuracy: 0.6499 - val_loss: 0.6393 - val_accuracy: 0.6628\n",
      "Epoch 14/300\n",
      "1591/1591 [==============================] - 0s 176us/sample - loss: 0.6349 - accuracy: 0.6493 - val_loss: 0.6374 - val_accuracy: 0.6651\n",
      "Epoch 15/300\n",
      "1591/1591 [==============================] - 0s 170us/sample - loss: 0.6293 - accuracy: 0.6549 - val_loss: 0.6356 - val_accuracy: 0.6674\n",
      "Epoch 16/300\n",
      "1591/1591 [==============================] - 0s 162us/sample - loss: 0.6270 - accuracy: 0.6631 - val_loss: 0.6338 - val_accuracy: 0.6813\n",
      "Epoch 17/300\n",
      "1591/1591 [==============================] - 0s 170us/sample - loss: 0.6253 - accuracy: 0.6631 - val_loss: 0.6321 - val_accuracy: 0.6744\n",
      "Epoch 18/300\n",
      "1591/1591 [==============================] - 0s 179us/sample - loss: 0.6202 - accuracy: 0.6744 - val_loss: 0.6304 - val_accuracy: 0.6697\n",
      "Epoch 19/300\n",
      "1591/1591 [==============================] - 0s 177us/sample - loss: 0.6156 - accuracy: 0.6788 - val_loss: 0.6288 - val_accuracy: 0.6697\n",
      "Epoch 20/300\n",
      "1591/1591 [==============================] - 0s 174us/sample - loss: 0.6146 - accuracy: 0.6813 - val_loss: 0.6272 - val_accuracy: 0.6767\n",
      "Epoch 21/300\n",
      "1591/1591 [==============================] - 0s 166us/sample - loss: 0.6103 - accuracy: 0.6939 - val_loss: 0.6256 - val_accuracy: 0.6767\n",
      "Epoch 22/300\n",
      "1591/1591 [==============================] - 0s 170us/sample - loss: 0.6085 - accuracy: 0.6933 - val_loss: 0.6241 - val_accuracy: 0.6790\n",
      "Epoch 23/300\n",
      "1591/1591 [==============================] - 0s 164us/sample - loss: 0.6070 - accuracy: 0.6933 - val_loss: 0.6226 - val_accuracy: 0.6767\n",
      "Epoch 24/300\n",
      "1591/1591 [==============================] - 0s 164us/sample - loss: 0.6016 - accuracy: 0.6977 - val_loss: 0.6211 - val_accuracy: 0.6767\n",
      "Epoch 25/300\n",
      "1591/1591 [==============================] - 0s 167us/sample - loss: 0.5999 - accuracy: 0.6996 - val_loss: 0.6197 - val_accuracy: 0.6767\n",
      "Epoch 26/300\n",
      "1591/1591 [==============================] - 0s 164us/sample - loss: 0.5972 - accuracy: 0.7002 - val_loss: 0.6184 - val_accuracy: 0.6767\n",
      "Epoch 27/300\n",
      "1591/1591 [==============================] - 0s 166us/sample - loss: 0.5975 - accuracy: 0.6933 - val_loss: 0.6170 - val_accuracy: 0.6767\n",
      "Epoch 28/300\n",
      "1591/1591 [==============================] - 0s 174us/sample - loss: 0.5936 - accuracy: 0.7102 - val_loss: 0.6156 - val_accuracy: 0.6790\n",
      "Epoch 29/300\n",
      "1591/1591 [==============================] - 0s 172us/sample - loss: 0.5877 - accuracy: 0.7178 - val_loss: 0.6143 - val_accuracy: 0.6813\n",
      "Epoch 30/300\n",
      "1591/1591 [==============================] - 0s 172us/sample - loss: 0.5890 - accuracy: 0.7121 - val_loss: 0.6131 - val_accuracy: 0.6836\n",
      "Epoch 31/300\n",
      "1591/1591 [==============================] - 0s 167us/sample - loss: 0.5858 - accuracy: 0.7109 - val_loss: 0.6118 - val_accuracy: 0.6859\n",
      "Epoch 32/300\n",
      "1591/1591 [==============================] - 0s 158us/sample - loss: 0.5862 - accuracy: 0.7121 - val_loss: 0.6105 - val_accuracy: 0.6836\n",
      "Epoch 33/300\n",
      "1591/1591 [==============================] - 0s 166us/sample - loss: 0.5804 - accuracy: 0.7153 - val_loss: 0.6092 - val_accuracy: 0.6882\n",
      "Epoch 34/300\n",
      "1591/1591 [==============================] - 0s 161us/sample - loss: 0.5764 - accuracy: 0.7146 - val_loss: 0.6080 - val_accuracy: 0.6882\n",
      "Epoch 35/300\n",
      "1591/1591 [==============================] - 0s 164us/sample - loss: 0.5777 - accuracy: 0.7115 - val_loss: 0.6067 - val_accuracy: 0.6905\n",
      "Epoch 36/300\n",
      "1591/1591 [==============================] - 0s 169us/sample - loss: 0.5772 - accuracy: 0.7203 - val_loss: 0.6055 - val_accuracy: 0.6928\n",
      "Epoch 37/300\n",
      "1591/1591 [==============================] - 0s 167us/sample - loss: 0.5679 - accuracy: 0.7341 - val_loss: 0.6043 - val_accuracy: 0.6952\n",
      "Epoch 38/300\n",
      "1591/1591 [==============================] - 0s 168us/sample - loss: 0.5741 - accuracy: 0.7316 - val_loss: 0.6031 - val_accuracy: 0.6928\n",
      "Epoch 39/300\n",
      "1591/1591 [==============================] - 0s 170us/sample - loss: 0.5686 - accuracy: 0.7486 - val_loss: 0.6019 - val_accuracy: 0.6952\n",
      "Epoch 40/300\n",
      "1591/1591 [==============================] - 0s 179us/sample - loss: 0.5688 - accuracy: 0.7291 - val_loss: 0.6008 - val_accuracy: 0.6975\n",
      "Epoch 41/300\n",
      "1591/1591 [==============================] - 0s 176us/sample - loss: 0.5682 - accuracy: 0.7291 - val_loss: 0.5996 - val_accuracy: 0.6975\n",
      "Epoch 42/300\n",
      "1591/1591 [==============================] - 0s 166us/sample - loss: 0.5639 - accuracy: 0.7379 - val_loss: 0.5985 - val_accuracy: 0.6952\n",
      "Epoch 43/300\n",
      "1591/1591 [==============================] - 0s 176us/sample - loss: 0.5629 - accuracy: 0.7360 - val_loss: 0.5973 - val_accuracy: 0.6975\n",
      "Epoch 44/300\n",
      "1591/1591 [==============================] - 0s 193us/sample - loss: 0.5520 - accuracy: 0.7542 - val_loss: 0.5962 - val_accuracy: 0.6975\n",
      "Epoch 45/300\n",
      "1591/1591 [==============================] - 0s 180us/sample - loss: 0.5494 - accuracy: 0.7536 - val_loss: 0.5952 - val_accuracy: 0.6952\n",
      "Epoch 46/300\n",
      "1591/1591 [==============================] - 0s 171us/sample - loss: 0.5525 - accuracy: 0.7480 - val_loss: 0.5940 - val_accuracy: 0.6975\n",
      "Epoch 47/300\n",
      "1591/1591 [==============================] - 0s 174us/sample - loss: 0.5533 - accuracy: 0.7498 - val_loss: 0.5929 - val_accuracy: 0.6975\n",
      "Epoch 48/300\n",
      "1591/1591 [==============================] - 0s 193us/sample - loss: 0.5485 - accuracy: 0.7536 - val_loss: 0.5918 - val_accuracy: 0.6975\n",
      "Epoch 49/300\n",
      "1591/1591 [==============================] - 0s 166us/sample - loss: 0.5443 - accuracy: 0.7599 - val_loss: 0.5908 - val_accuracy: 0.6975\n",
      "Epoch 50/300\n",
      "1591/1591 [==============================] - 0s 212us/sample - loss: 0.5433 - accuracy: 0.7524 - val_loss: 0.5897 - val_accuracy: 0.6998\n",
      "Epoch 51/300\n",
      "1591/1591 [==============================] - 0s 169us/sample - loss: 0.5378 - accuracy: 0.7630 - val_loss: 0.5886 - val_accuracy: 0.6998\n",
      "Epoch 52/300\n",
      "1591/1591 [==============================] - 0s 176us/sample - loss: 0.5364 - accuracy: 0.7687 - val_loss: 0.5876 - val_accuracy: 0.6998\n",
      "Epoch 53/300\n",
      "1591/1591 [==============================] - 0s 184us/sample - loss: 0.5373 - accuracy: 0.7568 - val_loss: 0.5865 - val_accuracy: 0.6998\n",
      "Epoch 54/300\n",
      "1591/1591 [==============================] - 0s 181us/sample - loss: 0.5354 - accuracy: 0.7649 - val_loss: 0.5855 - val_accuracy: 0.6952\n",
      "Epoch 55/300\n",
      "1591/1591 [==============================] - 0s 180us/sample - loss: 0.5302 - accuracy: 0.7643 - val_loss: 0.5844 - val_accuracy: 0.6952\n",
      "Epoch 56/300\n",
      "1591/1591 [==============================] - 0s 182us/sample - loss: 0.5269 - accuracy: 0.7662 - val_loss: 0.5834 - val_accuracy: 0.6998\n",
      "Epoch 57/300\n",
      "1591/1591 [==============================] - 0s 181us/sample - loss: 0.5262 - accuracy: 0.7693 - val_loss: 0.5823 - val_accuracy: 0.6975\n",
      "Epoch 58/300\n",
      "1591/1591 [==============================] - 0s 169us/sample - loss: 0.5238 - accuracy: 0.7750 - val_loss: 0.5813 - val_accuracy: 0.6975\n",
      "Epoch 59/300\n",
      "1591/1591 [==============================] - 0s 174us/sample - loss: 0.5219 - accuracy: 0.7674 - val_loss: 0.5803 - val_accuracy: 0.6975\n",
      "Epoch 60/300\n",
      "1591/1591 [==============================] - 0s 178us/sample - loss: 0.5163 - accuracy: 0.7825 - val_loss: 0.5793 - val_accuracy: 0.6998\n",
      "Epoch 61/300\n",
      "1591/1591 [==============================] - 0s 176us/sample - loss: 0.5176 - accuracy: 0.7819 - val_loss: 0.5783 - val_accuracy: 0.6998\n",
      "Epoch 62/300\n",
      "1591/1591 [==============================] - 0s 175us/sample - loss: 0.5178 - accuracy: 0.7693 - val_loss: 0.5773 - val_accuracy: 0.7021\n",
      "Epoch 63/300\n",
      "1591/1591 [==============================] - 0s 177us/sample - loss: 0.5167 - accuracy: 0.7800 - val_loss: 0.5764 - val_accuracy: 0.6998\n",
      "Epoch 64/300\n",
      "1591/1591 [==============================] - 0s 181us/sample - loss: 0.5125 - accuracy: 0.7838 - val_loss: 0.5754 - val_accuracy: 0.6998\n",
      "Epoch 65/300\n",
      "1591/1591 [==============================] - 0s 165us/sample - loss: 0.5107 - accuracy: 0.7850 - val_loss: 0.5745 - val_accuracy: 0.6975\n",
      "Epoch 66/300\n",
      "1591/1591 [==============================] - 0s 156us/sample - loss: 0.5107 - accuracy: 0.7806 - val_loss: 0.5735 - val_accuracy: 0.6975\n",
      "Epoch 67/300\n",
      "1591/1591 [==============================] - 0s 179us/sample - loss: 0.5078 - accuracy: 0.7932 - val_loss: 0.5725 - val_accuracy: 0.6975\n",
      "Epoch 68/300\n",
      "1591/1591 [==============================] - 0s 192us/sample - loss: 0.5021 - accuracy: 0.7838 - val_loss: 0.5716 - val_accuracy: 0.6975\n",
      "Epoch 69/300\n",
      "1591/1591 [==============================] - 0s 170us/sample - loss: 0.5019 - accuracy: 0.7888 - val_loss: 0.5707 - val_accuracy: 0.6952\n",
      "Epoch 70/300\n",
      "1591/1591 [==============================] - 0s 179us/sample - loss: 0.5026 - accuracy: 0.7844 - val_loss: 0.5698 - val_accuracy: 0.6952\n",
      "Epoch 71/300\n",
      "1591/1591 [==============================] - 0s 178us/sample - loss: 0.4961 - accuracy: 0.7894 - val_loss: 0.5689 - val_accuracy: 0.6928\n",
      "Epoch 72/300\n",
      "1591/1591 [==============================] - 0s 167us/sample - loss: 0.4922 - accuracy: 0.7957 - val_loss: 0.5680 - val_accuracy: 0.6905\n",
      "Epoch 73/300\n",
      "1591/1591 [==============================] - 0s 171us/sample - loss: 0.4928 - accuracy: 0.7938 - val_loss: 0.5671 - val_accuracy: 0.6882\n",
      "Epoch 74/300\n",
      "1591/1591 [==============================] - 0s 174us/sample - loss: 0.4910 - accuracy: 0.7970 - val_loss: 0.5663 - val_accuracy: 0.6882\n",
      "Epoch 75/300\n",
      "1591/1591 [==============================] - 0s 178us/sample - loss: 0.4834 - accuracy: 0.8064 - val_loss: 0.5654 - val_accuracy: 0.6882\n",
      "Epoch 76/300\n",
      "1591/1591 [==============================] - 0s 193us/sample - loss: 0.4878 - accuracy: 0.7894 - val_loss: 0.5646 - val_accuracy: 0.6882\n",
      "Epoch 77/300\n",
      "1591/1591 [==============================] - 0s 204us/sample - loss: 0.4830 - accuracy: 0.7989 - val_loss: 0.5638 - val_accuracy: 0.6882\n",
      "Epoch 78/300\n",
      "1591/1591 [==============================] - 0s 197us/sample - loss: 0.4802 - accuracy: 0.8033 - val_loss: 0.5630 - val_accuracy: 0.6905\n",
      "Epoch 79/300\n",
      "1591/1591 [==============================] - 0s 192us/sample - loss: 0.4748 - accuracy: 0.8190 - val_loss: 0.5621 - val_accuracy: 0.6882\n",
      "Epoch 80/300\n",
      "1591/1591 [==============================] - 0s 172us/sample - loss: 0.4738 - accuracy: 0.8058 - val_loss: 0.5613 - val_accuracy: 0.6882\n",
      "Epoch 81/300\n",
      "1591/1591 [==============================] - 0s 175us/sample - loss: 0.4729 - accuracy: 0.8089 - val_loss: 0.5605 - val_accuracy: 0.6905\n",
      "Epoch 82/300\n",
      "1591/1591 [==============================] - 0s 188us/sample - loss: 0.4703 - accuracy: 0.8070 - val_loss: 0.5598 - val_accuracy: 0.6905\n",
      "Epoch 83/300\n",
      "1591/1591 [==============================] - 0s 168us/sample - loss: 0.4622 - accuracy: 0.8202 - val_loss: 0.5590 - val_accuracy: 0.6905\n",
      "Epoch 84/300\n",
      "1591/1591 [==============================] - 0s 166us/sample - loss: 0.4657 - accuracy: 0.8070 - val_loss: 0.5583 - val_accuracy: 0.6882\n",
      "Epoch 85/300\n",
      "1591/1591 [==============================] - 0s 184us/sample - loss: 0.4567 - accuracy: 0.8265 - val_loss: 0.5576 - val_accuracy: 0.6882\n",
      "Epoch 86/300\n",
      "1591/1591 [==============================] - 0s 172us/sample - loss: 0.4589 - accuracy: 0.8114 - val_loss: 0.5569 - val_accuracy: 0.6905\n",
      "Epoch 87/300\n",
      "1591/1591 [==============================] - 0s 187us/sample - loss: 0.4564 - accuracy: 0.8196 - val_loss: 0.5562 - val_accuracy: 0.6905\n",
      "Epoch 88/300\n",
      "1591/1591 [==============================] - 0s 178us/sample - loss: 0.4555 - accuracy: 0.8184 - val_loss: 0.5556 - val_accuracy: 0.6905\n",
      "Epoch 89/300\n",
      "1591/1591 [==============================] - 0s 180us/sample - loss: 0.4523 - accuracy: 0.8089 - val_loss: 0.5550 - val_accuracy: 0.6928\n",
      "Epoch 90/300\n",
      "1591/1591 [==============================] - 0s 169us/sample - loss: 0.4516 - accuracy: 0.8228 - val_loss: 0.5543 - val_accuracy: 0.6928\n",
      "Epoch 91/300\n",
      "1591/1591 [==============================] - 0s 174us/sample - loss: 0.4481 - accuracy: 0.8297 - val_loss: 0.5538 - val_accuracy: 0.6928\n",
      "Epoch 92/300\n",
      "1591/1591 [==============================] - 0s 181us/sample - loss: 0.4473 - accuracy: 0.8240 - val_loss: 0.5532 - val_accuracy: 0.6928\n",
      "Epoch 93/300\n",
      "1591/1591 [==============================] - 0s 188us/sample - loss: 0.4439 - accuracy: 0.8303 - val_loss: 0.5526 - val_accuracy: 0.6975\n",
      "Epoch 94/300\n",
      "1591/1591 [==============================] - 0s 185us/sample - loss: 0.4433 - accuracy: 0.8290 - val_loss: 0.5521 - val_accuracy: 0.6975\n",
      "Epoch 95/300\n",
      "1591/1591 [==============================] - 0s 174us/sample - loss: 0.4384 - accuracy: 0.8259 - val_loss: 0.5516 - val_accuracy: 0.6952\n",
      "Epoch 96/300\n",
      "1591/1591 [==============================] - 0s 165us/sample - loss: 0.4391 - accuracy: 0.8234 - val_loss: 0.5511 - val_accuracy: 0.6975\n",
      "Epoch 97/300\n",
      "1591/1591 [==============================] - 0s 178us/sample - loss: 0.4370 - accuracy: 0.8297 - val_loss: 0.5507 - val_accuracy: 0.6998\n",
      "Epoch 98/300\n",
      "1591/1591 [==============================] - 0s 185us/sample - loss: 0.4340 - accuracy: 0.8328 - val_loss: 0.5502 - val_accuracy: 0.6998\n",
      "Epoch 99/300\n",
      "1591/1591 [==============================] - 0s 166us/sample - loss: 0.4329 - accuracy: 0.8259 - val_loss: 0.5498 - val_accuracy: 0.6952\n",
      "Epoch 100/300\n",
      "1591/1591 [==============================] - 0s 166us/sample - loss: 0.4312 - accuracy: 0.8253 - val_loss: 0.5494 - val_accuracy: 0.6952\n",
      "Epoch 101/300\n",
      "1591/1591 [==============================] - 0s 166us/sample - loss: 0.4263 - accuracy: 0.8322 - val_loss: 0.5490 - val_accuracy: 0.6975\n",
      "Epoch 102/300\n",
      "1591/1591 [==============================] - 0s 173us/sample - loss: 0.4212 - accuracy: 0.8448 - val_loss: 0.5486 - val_accuracy: 0.6998\n",
      "Epoch 103/300\n",
      "1591/1591 [==============================] - 0s 171us/sample - loss: 0.4233 - accuracy: 0.8322 - val_loss: 0.5483 - val_accuracy: 0.6998\n",
      "Epoch 104/300\n",
      "1591/1591 [==============================] - 0s 164us/sample - loss: 0.4181 - accuracy: 0.8360 - val_loss: 0.5480 - val_accuracy: 0.6998\n",
      "Epoch 105/300\n",
      "1591/1591 [==============================] - 0s 180us/sample - loss: 0.4170 - accuracy: 0.8347 - val_loss: 0.5477 - val_accuracy: 0.6998\n",
      "Epoch 106/300\n",
      "1591/1591 [==============================] - 0s 178us/sample - loss: 0.4176 - accuracy: 0.8334 - val_loss: 0.5474 - val_accuracy: 0.6998\n",
      "Epoch 107/300\n",
      "1591/1591 [==============================] - 0s 168us/sample - loss: 0.4107 - accuracy: 0.8429 - val_loss: 0.5472 - val_accuracy: 0.7021\n",
      "Epoch 108/300\n",
      "1591/1591 [==============================] - 0s 162us/sample - loss: 0.4103 - accuracy: 0.8435 - val_loss: 0.5469 - val_accuracy: 0.7021\n",
      "Epoch 109/300\n",
      "1591/1591 [==============================] - 0s 165us/sample - loss: 0.4089 - accuracy: 0.8435 - val_loss: 0.5467 - val_accuracy: 0.7044\n",
      "Epoch 110/300\n",
      "1591/1591 [==============================] - 0s 163us/sample - loss: 0.4000 - accuracy: 0.8504 - val_loss: 0.5464 - val_accuracy: 0.7044\n",
      "Epoch 111/300\n",
      "1591/1591 [==============================] - 0s 176us/sample - loss: 0.4042 - accuracy: 0.8448 - val_loss: 0.5463 - val_accuracy: 0.7021\n",
      "Epoch 112/300\n",
      "1591/1591 [==============================] - 0s 167us/sample - loss: 0.4018 - accuracy: 0.8510 - val_loss: 0.5460 - val_accuracy: 0.7021\n",
      "Epoch 113/300\n",
      "1591/1591 [==============================] - 0s 179us/sample - loss: 0.4012 - accuracy: 0.8536 - val_loss: 0.5459 - val_accuracy: 0.7021\n",
      "Epoch 114/300\n",
      "1591/1591 [==============================] - 0s 167us/sample - loss: 0.3957 - accuracy: 0.8536 - val_loss: 0.5457 - val_accuracy: 0.7044\n",
      "Epoch 115/300\n",
      "1591/1591 [==============================] - 0s 160us/sample - loss: 0.3909 - accuracy: 0.8510 - val_loss: 0.5456 - val_accuracy: 0.7044\n",
      "Epoch 116/300\n",
      "1591/1591 [==============================] - 0s 167us/sample - loss: 0.3903 - accuracy: 0.8485 - val_loss: 0.5455 - val_accuracy: 0.7067\n",
      "Epoch 117/300\n",
      "1591/1591 [==============================] - 0s 174us/sample - loss: 0.3898 - accuracy: 0.8561 - val_loss: 0.5454 - val_accuracy: 0.7067\n",
      "Epoch 118/300\n",
      "1591/1591 [==============================] - 0s 167us/sample - loss: 0.3892 - accuracy: 0.8598 - val_loss: 0.5454 - val_accuracy: 0.7090\n",
      "Epoch 119/300\n",
      "1591/1591 [==============================] - 0s 176us/sample - loss: 0.3869 - accuracy: 0.8542 - val_loss: 0.5453 - val_accuracy: 0.7090\n",
      "Epoch 120/300\n",
      "1591/1591 [==============================] - 0s 180us/sample - loss: 0.3867 - accuracy: 0.8542 - val_loss: 0.5453 - val_accuracy: 0.7090\n",
      "Epoch 121/300\n",
      "1591/1591 [==============================] - 0s 173us/sample - loss: 0.3832 - accuracy: 0.8592 - val_loss: 0.5454 - val_accuracy: 0.7136\n",
      "Epoch 122/300\n",
      "1591/1591 [==============================] - 0s 174us/sample - loss: 0.3794 - accuracy: 0.8580 - val_loss: 0.5453 - val_accuracy: 0.7159\n",
      "Epoch 123/300\n",
      "1591/1591 [==============================] - 0s 164us/sample - loss: 0.3793 - accuracy: 0.8592 - val_loss: 0.5454 - val_accuracy: 0.7182\n",
      "Epoch 124/300\n",
      "1591/1591 [==============================] - 0s 172us/sample - loss: 0.3752 - accuracy: 0.8630 - val_loss: 0.5455 - val_accuracy: 0.7159\n",
      "Epoch 125/300\n",
      "1591/1591 [==============================] - 0s 168us/sample - loss: 0.3753 - accuracy: 0.8548 - val_loss: 0.5456 - val_accuracy: 0.7159\n",
      "Epoch 00125: early stopping\n",
      "215/215 [==============================] - 0s 80us/sample - loss: 1.0483 - accuracy: 0.4558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [1:01:36, 739.32s/it]\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:06<00:06,  6.29s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.50s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "8it [00:00, 77.07it/s]\u001b[A\n",
      "14it [00:00, 67.96it/s]\u001b[A\n",
      "18it [00:00, 54.77it/s]\u001b[A\n",
      "23it [00:00, 46.63it/s]\u001b[A\n",
      "27it [00:00, 41.07it/s]\u001b[A\n",
      "32it [00:00, 42.29it/s]\u001b[A\n",
      "38it [00:00, 42.76it/s]\u001b[A\n",
      "43it [00:00, 43.62it/s]\u001b[A\n",
      "48it [00:01, 38.80it/s]\u001b[A\n",
      "52it [00:01, 38.60it/s]\u001b[A\n",
      "57it [00:01, 40.04it/s]\u001b[A\n",
      "61it [00:01, 34.44it/s]\u001b[A\n",
      "66it [00:01, 35.62it/s]\u001b[A\n",
      "72it [00:01, 41.53it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 72/72 [00:00<00:00, 1442.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 494.9296875 steps, validate for 132.765625 steps\n",
      "Epoch 1/300\n",
      "495/494 [==============================] - 15s 30ms/step - loss: 0.6618 - accuracy: 0.6025 - val_loss: 0.6674 - val_accuracy: 0.5987\n",
      "Epoch 2/300\n",
      "495/494 [==============================] - 13s 27ms/step - loss: 0.6226 - accuracy: 0.6444 - val_loss: 0.6479 - val_accuracy: 0.6264\n",
      "Epoch 3/300\n",
      "495/494 [==============================] - 14s 27ms/step - loss: 0.6065 - accuracy: 0.6613 - val_loss: 0.6379 - val_accuracy: 0.6408\n",
      "Epoch 4/300\n",
      "495/494 [==============================] - 13s 27ms/step - loss: 0.5954 - accuracy: 0.6728 - val_loss: 0.6371 - val_accuracy: 0.6419\n",
      "Epoch 5/300\n",
      "495/494 [==============================] - 14s 27ms/step - loss: 0.5859 - accuracy: 0.6838 - val_loss: 0.6307 - val_accuracy: 0.6480\n",
      "Epoch 6/300\n",
      "495/494 [==============================] - 13s 27ms/step - loss: 0.5774 - accuracy: 0.6926 - val_loss: 0.6290 - val_accuracy: 0.6509\n",
      "Epoch 7/300\n",
      "495/494 [==============================] - 14s 27ms/step - loss: 0.5697 - accuracy: 0.6980 - val_loss: 0.6291 - val_accuracy: 0.6558\n",
      "Epoch 8/300\n",
      "495/494 [==============================] - 13s 27ms/step - loss: 0.5627 - accuracy: 0.7042 - val_loss: 0.6260 - val_accuracy: 0.6533\n",
      "Epoch 9/300\n",
      "495/494 [==============================] - 13s 27ms/step - loss: 0.5560 - accuracy: 0.7093 - val_loss: 0.6285 - val_accuracy: 0.6533\n",
      "Epoch 10/300\n",
      "495/494 [==============================] - 13s 27ms/step - loss: 0.5497 - accuracy: 0.7138 - val_loss: 0.6249 - val_accuracy: 0.6555\n",
      "Epoch 11/300\n",
      "495/494 [==============================] - 14s 27ms/step - loss: 0.5437 - accuracy: 0.7198 - val_loss: 0.6259 - val_accuracy: 0.6566\n",
      "Epoch 12/300\n",
      "495/494 [==============================] - 13s 27ms/step - loss: 0.5378 - accuracy: 0.7243 - val_loss: 0.6286 - val_accuracy: 0.6544\n",
      "Epoch 13/300\n",
      "495/494 [==============================] - 14s 27ms/step - loss: 0.5323 - accuracy: 0.7294 - val_loss: 0.6342 - val_accuracy: 0.6519\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 494.9296875 steps, validate for 132.765625 steps\n",
      "Epoch 1/300\n",
      "495/494 [==============================] - 33s 66ms/step - loss: 0.5224 - accuracy: 0.7358 - val_loss: 0.7280 - val_accuracy: 0.6025\n",
      "Epoch 2/300\n",
      "495/494 [==============================] - 31s 63ms/step - loss: 0.5021 - accuracy: 0.7527 - val_loss: 0.6499 - val_accuracy: 0.6508\n",
      "Epoch 3/300\n",
      "495/494 [==============================] - 31s 63ms/step - loss: 0.4865 - accuracy: 0.7660 - val_loss: 0.6262 - val_accuracy: 0.6689\n",
      "Epoch 4/300\n",
      "495/494 [==============================] - 31s 63ms/step - loss: 0.4725 - accuracy: 0.7762 - val_loss: 0.6541 - val_accuracy: 0.6349\n",
      "Epoch 5/300\n",
      "495/494 [==============================] - 31s 63ms/step - loss: 0.4600 - accuracy: 0.7857 - val_loss: 0.6491 - val_accuracy: 0.6466\n",
      "Epoch 6/300\n",
      "495/494 [==============================] - 31s 63ms/step - loss: 0.4473 - accuracy: 0.7958 - val_loss: 0.6367 - val_accuracy: 0.6535\n",
      "Epoch 00006: early stopping\n",
      "421/421 [==============================] - 0s 731us/sample - loss: 1.3749 - accuracy: 0.3610\n",
      "397/397 [==============================] - 0s 220us/sample - loss: 1.3056 - accuracy: 0.3904\n",
      "389/389 [==============================] - 0s 213us/sample - loss: 1.3337 - accuracy: 0.3599\n",
      "381/381 [==============================] - 0s 200us/sample - loss: 1.3649 - accuracy: 0.3570\n",
      "375/375 [==============================] - 0s 231us/sample - loss: 1.3636 - accuracy: 0.3760\n",
      "369/369 [==============================] - 0s 232us/sample - loss: 1.4117 - accuracy: 0.3740\n",
      "366/366 [==============================] - 0s 227us/sample - loss: 1.4394 - accuracy: 0.4044\n",
      "357/357 [==============================] - 0s 216us/sample - loss: 1.4140 - accuracy: 0.3697\n",
      "355/355 [==============================] - 0s 232us/sample - loss: 1.4392 - accuracy: 0.3944\n",
      "347/347 [==============================] - 0s 242us/sample - loss: 1.3918 - accuracy: 0.3919\n",
      "343/343 [==============================] - 0s 229us/sample - loss: 1.4343 - accuracy: 0.4140\n",
      "339/339 [==============================] - 0s 243us/sample - loss: 1.4632 - accuracy: 0.3658\n",
      "335/335 [==============================] - 0s 258us/sample - loss: 1.4736 - accuracy: 0.3851\n",
      "338/338 [==============================] - 0s 239us/sample - loss: 1.4810 - accuracy: 0.3757\n",
      "330/330 [==============================] - 0s 239us/sample - loss: 1.4119 - accuracy: 0.3545\n",
      "330/330 [==============================] - 0s 255us/sample - loss: 1.3993 - accuracy: 0.3970\n",
      "332/332 [==============================] - 0s 229us/sample - loss: 1.4659 - accuracy: 0.4127\n",
      "327/327 [==============================] - 0s 216us/sample - loss: 1.4612 - accuracy: 0.3700\n",
      "324/324 [==============================] - 0s 231us/sample - loss: 1.4397 - accuracy: 0.4012\n",
      "322/322 [==============================] - 0s 222us/sample - loss: 1.4845 - accuracy: 0.3975\n",
      "321/321 [==============================] - 0s 243us/sample - loss: 1.5583 - accuracy: 0.3645\n",
      "320/320 [==============================] - 0s 964us/sample - loss: 1.4651 - accuracy: 0.3656\n",
      "313/313 [==============================] - 0s 219us/sample - loss: 1.6023 - accuracy: 0.3546\n",
      "315/315 [==============================] - 0s 213us/sample - loss: 1.4923 - accuracy: 0.3683\n",
      "309/309 [==============================] - 0s 219us/sample - loss: 1.5500 - accuracy: 0.3625\n",
      "308/308 [==============================] - 0s 215us/sample - loss: 1.6235 - accuracy: 0.3442\n",
      "306/306 [==============================] - 0s 234us/sample - loss: 1.6485 - accuracy: 0.3268\n",
      "301/301 [==============================] - 0s 251us/sample - loss: 1.5400 - accuracy: 0.3488\n",
      "300/300 [==============================] - 0s 248us/sample - loss: 1.5026 - accuracy: 0.3833\n",
      "301/301 [==============================] - 0s 281us/sample - loss: 1.5730 - accuracy: 0.3455\n",
      "296/296 [==============================] - 0s 236us/sample - loss: 1.5922 - accuracy: 0.3412\n",
      "297/297 [==============================] - 0s 240us/sample - loss: 1.5086 - accuracy: 0.3468\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 1545 samples, validate on 423 samples\n",
      "Epoch 1/300\n",
      "1545/1545 [==============================] - 2s 1ms/sample - loss: 0.7641 - accuracy: 0.4421 - val_loss: 0.7361 - val_accuracy: 0.4563\n",
      "Epoch 2/300\n",
      "1545/1545 [==============================] - 0s 176us/sample - loss: 0.7430 - accuracy: 0.4816 - val_loss: 0.7231 - val_accuracy: 0.4657\n",
      "Epoch 3/300\n",
      "1545/1545 [==============================] - 0s 181us/sample - loss: 0.7367 - accuracy: 0.4757 - val_loss: 0.7140 - val_accuracy: 0.4846\n",
      "Epoch 4/300\n",
      "1545/1545 [==============================] - 0s 179us/sample - loss: 0.7208 - accuracy: 0.4945 - val_loss: 0.7069 - val_accuracy: 0.4941\n",
      "Epoch 5/300\n",
      "1545/1545 [==============================] - 0s 195us/sample - loss: 0.7123 - accuracy: 0.5178 - val_loss: 0.7011 - val_accuracy: 0.5106\n",
      "Epoch 6/300\n",
      "1545/1545 [==============================] - 0s 180us/sample - loss: 0.7013 - accuracy: 0.5476 - val_loss: 0.6960 - val_accuracy: 0.5201\n",
      "Epoch 7/300\n",
      "1545/1545 [==============================] - 0s 188us/sample - loss: 0.6938 - accuracy: 0.5450 - val_loss: 0.6916 - val_accuracy: 0.5319\n",
      "Epoch 8/300\n",
      "1545/1545 [==============================] - 0s 190us/sample - loss: 0.6886 - accuracy: 0.5586 - val_loss: 0.6875 - val_accuracy: 0.5414\n",
      "Epoch 9/300\n",
      "1545/1545 [==============================] - 0s 178us/sample - loss: 0.6881 - accuracy: 0.5670 - val_loss: 0.6838 - val_accuracy: 0.5390\n",
      "Epoch 10/300\n",
      "1545/1545 [==============================] - 0s 204us/sample - loss: 0.6797 - accuracy: 0.5786 - val_loss: 0.6804 - val_accuracy: 0.5414\n",
      "Epoch 11/300\n",
      "1545/1545 [==============================] - 0s 190us/sample - loss: 0.6778 - accuracy: 0.5845 - val_loss: 0.6774 - val_accuracy: 0.5532\n",
      "Epoch 12/300\n",
      "1545/1545 [==============================] - 0s 186us/sample - loss: 0.6770 - accuracy: 0.5832 - val_loss: 0.6745 - val_accuracy: 0.5745\n",
      "Epoch 13/300\n",
      "1545/1545 [==============================] - 0s 202us/sample - loss: 0.6651 - accuracy: 0.6104 - val_loss: 0.6716 - val_accuracy: 0.5816\n",
      "Epoch 14/300\n",
      "1545/1545 [==============================] - 0s 181us/sample - loss: 0.6681 - accuracy: 0.5942 - val_loss: 0.6690 - val_accuracy: 0.5839\n",
      "Epoch 15/300\n",
      "1545/1545 [==============================] - 0s 193us/sample - loss: 0.6627 - accuracy: 0.6110 - val_loss: 0.6666 - val_accuracy: 0.5887\n",
      "Epoch 16/300\n",
      "1545/1545 [==============================] - 0s 190us/sample - loss: 0.6559 - accuracy: 0.6220 - val_loss: 0.6643 - val_accuracy: 0.5887\n",
      "Epoch 17/300\n",
      "1545/1545 [==============================] - 0s 170us/sample - loss: 0.6562 - accuracy: 0.6311 - val_loss: 0.6621 - val_accuracy: 0.5981\n",
      "Epoch 18/300\n",
      "1545/1545 [==============================] - 0s 183us/sample - loss: 0.6512 - accuracy: 0.6291 - val_loss: 0.6600 - val_accuracy: 0.6028\n",
      "Epoch 19/300\n",
      "1545/1545 [==============================] - 0s 176us/sample - loss: 0.6452 - accuracy: 0.6369 - val_loss: 0.6580 - val_accuracy: 0.6052\n",
      "Epoch 20/300\n",
      "1545/1545 [==============================] - 0s 174us/sample - loss: 0.6495 - accuracy: 0.6220 - val_loss: 0.6561 - val_accuracy: 0.6028\n",
      "Epoch 21/300\n",
      "1545/1545 [==============================] - 0s 170us/sample - loss: 0.6405 - accuracy: 0.6537 - val_loss: 0.6542 - val_accuracy: 0.6076\n",
      "Epoch 22/300\n",
      "1545/1545 [==============================] - 0s 170us/sample - loss: 0.6368 - accuracy: 0.6595 - val_loss: 0.6525 - val_accuracy: 0.5981\n",
      "Epoch 23/300\n",
      "1545/1545 [==============================] - 0s 189us/sample - loss: 0.6380 - accuracy: 0.6434 - val_loss: 0.6508 - val_accuracy: 0.6028\n",
      "Epoch 24/300\n",
      "1545/1545 [==============================] - 0s 179us/sample - loss: 0.6322 - accuracy: 0.6531 - val_loss: 0.6492 - val_accuracy: 0.6076\n",
      "Epoch 25/300\n",
      "1545/1545 [==============================] - 0s 181us/sample - loss: 0.6294 - accuracy: 0.6647 - val_loss: 0.6476 - val_accuracy: 0.6099\n",
      "Epoch 26/300\n",
      "1545/1545 [==============================] - 0s 182us/sample - loss: 0.6311 - accuracy: 0.6498 - val_loss: 0.6460 - val_accuracy: 0.6123\n",
      "Epoch 27/300\n",
      "1545/1545 [==============================] - 0s 182us/sample - loss: 0.6240 - accuracy: 0.6809 - val_loss: 0.6446 - val_accuracy: 0.6123\n",
      "Epoch 28/300\n",
      "1545/1545 [==============================] - 0s 195us/sample - loss: 0.6245 - accuracy: 0.6680 - val_loss: 0.6432 - val_accuracy: 0.6170\n",
      "Epoch 29/300\n",
      "1545/1545 [==============================] - 0s 172us/sample - loss: 0.6239 - accuracy: 0.6615 - val_loss: 0.6418 - val_accuracy: 0.6194\n",
      "Epoch 30/300\n",
      "1545/1545 [==============================] - 0s 164us/sample - loss: 0.6203 - accuracy: 0.6874 - val_loss: 0.6405 - val_accuracy: 0.6241\n",
      "Epoch 31/300\n",
      "1545/1545 [==============================] - 0s 185us/sample - loss: 0.6133 - accuracy: 0.6874 - val_loss: 0.6392 - val_accuracy: 0.6241\n",
      "Epoch 32/300\n",
      "1545/1545 [==============================] - 0s 176us/sample - loss: 0.6156 - accuracy: 0.6816 - val_loss: 0.6379 - val_accuracy: 0.6265\n",
      "Epoch 33/300\n",
      "1545/1545 [==============================] - 0s 166us/sample - loss: 0.6145 - accuracy: 0.6803 - val_loss: 0.6366 - val_accuracy: 0.6312\n",
      "Epoch 34/300\n",
      "1545/1545 [==============================] - 0s 210us/sample - loss: 0.6114 - accuracy: 0.6887 - val_loss: 0.6353 - val_accuracy: 0.6383\n",
      "Epoch 35/300\n",
      "1545/1545 [==============================] - 0s 223us/sample - loss: 0.6128 - accuracy: 0.6848 - val_loss: 0.6342 - val_accuracy: 0.6430\n",
      "Epoch 36/300\n",
      "1545/1545 [==============================] - 0s 192us/sample - loss: 0.6063 - accuracy: 0.6874 - val_loss: 0.6330 - val_accuracy: 0.6478\n",
      "Epoch 37/300\n",
      "1545/1545 [==============================] - 0s 185us/sample - loss: 0.6017 - accuracy: 0.7029 - val_loss: 0.6319 - val_accuracy: 0.6501\n",
      "Epoch 38/300\n",
      "1545/1545 [==============================] - 0s 179us/sample - loss: 0.6002 - accuracy: 0.6964 - val_loss: 0.6308 - val_accuracy: 0.6501\n",
      "Epoch 39/300\n",
      "1545/1545 [==============================] - 0s 199us/sample - loss: 0.6046 - accuracy: 0.6880 - val_loss: 0.6297 - val_accuracy: 0.6478\n",
      "Epoch 40/300\n",
      "1545/1545 [==============================] - 0s 191us/sample - loss: 0.5978 - accuracy: 0.7016 - val_loss: 0.6286 - val_accuracy: 0.6430\n",
      "Epoch 41/300\n",
      "1545/1545 [==============================] - 0s 174us/sample - loss: 0.5937 - accuracy: 0.6932 - val_loss: 0.6275 - val_accuracy: 0.6501\n",
      "Epoch 42/300\n",
      "1545/1545 [==============================] - 0s 183us/sample - loss: 0.5921 - accuracy: 0.7061 - val_loss: 0.6265 - val_accuracy: 0.6525\n",
      "Epoch 43/300\n",
      "1545/1545 [==============================] - 0s 181us/sample - loss: 0.5957 - accuracy: 0.6990 - val_loss: 0.6254 - val_accuracy: 0.6501\n",
      "Epoch 44/300\n",
      "1545/1545 [==============================] - 0s 175us/sample - loss: 0.5887 - accuracy: 0.7223 - val_loss: 0.6244 - val_accuracy: 0.6525\n",
      "Epoch 45/300\n",
      "1545/1545 [==============================] - 0s 185us/sample - loss: 0.5849 - accuracy: 0.7081 - val_loss: 0.6235 - val_accuracy: 0.6525\n",
      "Epoch 46/300\n",
      "1545/1545 [==============================] - 0s 172us/sample - loss: 0.5816 - accuracy: 0.7236 - val_loss: 0.6225 - val_accuracy: 0.6548\n",
      "Epoch 47/300\n",
      "1545/1545 [==============================] - 0s 175us/sample - loss: 0.5878 - accuracy: 0.7107 - val_loss: 0.6215 - val_accuracy: 0.6548\n",
      "Epoch 48/300\n",
      "1545/1545 [==============================] - 0s 174us/sample - loss: 0.5799 - accuracy: 0.7256 - val_loss: 0.6206 - val_accuracy: 0.6572\n",
      "Epoch 49/300\n",
      "1545/1545 [==============================] - 0s 169us/sample - loss: 0.5797 - accuracy: 0.7294 - val_loss: 0.6197 - val_accuracy: 0.6548\n",
      "Epoch 50/300\n",
      "1545/1545 [==============================] - 0s 180us/sample - loss: 0.5782 - accuracy: 0.7256 - val_loss: 0.6187 - val_accuracy: 0.6572\n",
      "Epoch 51/300\n",
      "1545/1545 [==============================] - 0s 173us/sample - loss: 0.5769 - accuracy: 0.7236 - val_loss: 0.6178 - val_accuracy: 0.6525\n",
      "Epoch 52/300\n",
      "1545/1545 [==============================] - 0s 182us/sample - loss: 0.5771 - accuracy: 0.7314 - val_loss: 0.6169 - val_accuracy: 0.6525\n",
      "Epoch 53/300\n",
      "1545/1545 [==============================] - 0s 178us/sample - loss: 0.5742 - accuracy: 0.7243 - val_loss: 0.6160 - val_accuracy: 0.6525\n",
      "Epoch 54/300\n",
      "1545/1545 [==============================] - 0s 182us/sample - loss: 0.5742 - accuracy: 0.7223 - val_loss: 0.6152 - val_accuracy: 0.6525\n",
      "Epoch 55/300\n",
      "1545/1545 [==============================] - 0s 184us/sample - loss: 0.5695 - accuracy: 0.7307 - val_loss: 0.6143 - val_accuracy: 0.6501\n",
      "Epoch 56/300\n",
      "1545/1545 [==============================] - 0s 169us/sample - loss: 0.5682 - accuracy: 0.7417 - val_loss: 0.6134 - val_accuracy: 0.6501\n",
      "Epoch 57/300\n",
      "1545/1545 [==============================] - 0s 162us/sample - loss: 0.5664 - accuracy: 0.7398 - val_loss: 0.6126 - val_accuracy: 0.6501\n",
      "Epoch 58/300\n",
      "1545/1545 [==============================] - 0s 168us/sample - loss: 0.5654 - accuracy: 0.7379 - val_loss: 0.6118 - val_accuracy: 0.6501\n",
      "Epoch 59/300\n",
      "1545/1545 [==============================] - 0s 165us/sample - loss: 0.5634 - accuracy: 0.7340 - val_loss: 0.6109 - val_accuracy: 0.6525\n",
      "Epoch 60/300\n",
      "1545/1545 [==============================] - 0s 164us/sample - loss: 0.5582 - accuracy: 0.7482 - val_loss: 0.6100 - val_accuracy: 0.6501\n",
      "Epoch 61/300\n",
      "1545/1545 [==============================] - 0s 174us/sample - loss: 0.5614 - accuracy: 0.7411 - val_loss: 0.6092 - val_accuracy: 0.6572\n",
      "Epoch 62/300\n",
      "1545/1545 [==============================] - 0s 164us/sample - loss: 0.5645 - accuracy: 0.7379 - val_loss: 0.6084 - val_accuracy: 0.6548\n",
      "Epoch 63/300\n",
      "1545/1545 [==============================] - 0s 171us/sample - loss: 0.5573 - accuracy: 0.7405 - val_loss: 0.6076 - val_accuracy: 0.6572\n",
      "Epoch 64/300\n",
      "1545/1545 [==============================] - 0s 165us/sample - loss: 0.5588 - accuracy: 0.7463 - val_loss: 0.6068 - val_accuracy: 0.6572\n",
      "Epoch 65/300\n",
      "1545/1545 [==============================] - 0s 158us/sample - loss: 0.5579 - accuracy: 0.7340 - val_loss: 0.6061 - val_accuracy: 0.6548\n",
      "Epoch 66/300\n",
      "1545/1545 [==============================] - 0s 158us/sample - loss: 0.5525 - accuracy: 0.7405 - val_loss: 0.6053 - val_accuracy: 0.6548\n",
      "Epoch 67/300\n",
      "1545/1545 [==============================] - 0s 164us/sample - loss: 0.5494 - accuracy: 0.7560 - val_loss: 0.6045 - val_accuracy: 0.6548\n",
      "Epoch 68/300\n",
      "1545/1545 [==============================] - 0s 171us/sample - loss: 0.5506 - accuracy: 0.7521 - val_loss: 0.6037 - val_accuracy: 0.6596\n",
      "Epoch 69/300\n",
      "1545/1545 [==============================] - 0s 161us/sample - loss: 0.5422 - accuracy: 0.7644 - val_loss: 0.6030 - val_accuracy: 0.6572\n",
      "Epoch 70/300\n",
      "1545/1545 [==============================] - 0s 162us/sample - loss: 0.5466 - accuracy: 0.7540 - val_loss: 0.6022 - val_accuracy: 0.6619\n",
      "Epoch 71/300\n",
      "1545/1545 [==============================] - 0s 163us/sample - loss: 0.5443 - accuracy: 0.7618 - val_loss: 0.6015 - val_accuracy: 0.6643\n",
      "Epoch 72/300\n",
      "1545/1545 [==============================] - 0s 159us/sample - loss: 0.5392 - accuracy: 0.7631 - val_loss: 0.6007 - val_accuracy: 0.6667\n",
      "Epoch 73/300\n",
      "1545/1545 [==============================] - 0s 162us/sample - loss: 0.5419 - accuracy: 0.7521 - val_loss: 0.5999 - val_accuracy: 0.6690\n",
      "Epoch 74/300\n",
      "1545/1545 [==============================] - 0s 159us/sample - loss: 0.5395 - accuracy: 0.7663 - val_loss: 0.5992 - val_accuracy: 0.6690\n",
      "Epoch 75/300\n",
      "1545/1545 [==============================] - 0s 159us/sample - loss: 0.5365 - accuracy: 0.7612 - val_loss: 0.5985 - val_accuracy: 0.6690\n",
      "Epoch 76/300\n",
      "1545/1545 [==============================] - 0s 165us/sample - loss: 0.5310 - accuracy: 0.7773 - val_loss: 0.5978 - val_accuracy: 0.6667\n",
      "Epoch 77/300\n",
      "1545/1545 [==============================] - 0s 165us/sample - loss: 0.5345 - accuracy: 0.7657 - val_loss: 0.5970 - val_accuracy: 0.6667\n",
      "Epoch 78/300\n",
      "1545/1545 [==============================] - 0s 169us/sample - loss: 0.5305 - accuracy: 0.7735 - val_loss: 0.5963 - val_accuracy: 0.6690\n",
      "Epoch 79/300\n",
      "1545/1545 [==============================] - 0s 164us/sample - loss: 0.5257 - accuracy: 0.7715 - val_loss: 0.5956 - val_accuracy: 0.6714\n",
      "Epoch 80/300\n",
      "1545/1545 [==============================] - 0s 165us/sample - loss: 0.5259 - accuracy: 0.7761 - val_loss: 0.5949 - val_accuracy: 0.6714\n",
      "Epoch 81/300\n",
      "1545/1545 [==============================] - 0s 166us/sample - loss: 0.5289 - accuracy: 0.7644 - val_loss: 0.5942 - val_accuracy: 0.6714\n",
      "Epoch 82/300\n",
      "1545/1545 [==============================] - 0s 168us/sample - loss: 0.5217 - accuracy: 0.7670 - val_loss: 0.5934 - val_accuracy: 0.6738\n",
      "Epoch 83/300\n",
      "1545/1545 [==============================] - 0s 171us/sample - loss: 0.5257 - accuracy: 0.7754 - val_loss: 0.5928 - val_accuracy: 0.6738\n",
      "Epoch 84/300\n",
      "1545/1545 [==============================] - 0s 167us/sample - loss: 0.5191 - accuracy: 0.7851 - val_loss: 0.5921 - val_accuracy: 0.6738\n",
      "Epoch 85/300\n",
      "1545/1545 [==============================] - 0s 166us/sample - loss: 0.5195 - accuracy: 0.7793 - val_loss: 0.5913 - val_accuracy: 0.6738\n",
      "Epoch 86/300\n",
      "1545/1545 [==============================] - 0s 166us/sample - loss: 0.5141 - accuracy: 0.7754 - val_loss: 0.5907 - val_accuracy: 0.6738\n",
      "Epoch 87/300\n",
      "1545/1545 [==============================] - 0s 157us/sample - loss: 0.5161 - accuracy: 0.7799 - val_loss: 0.5900 - val_accuracy: 0.6738\n",
      "Epoch 88/300\n",
      "1545/1545 [==============================] - 0s 161us/sample - loss: 0.5136 - accuracy: 0.7812 - val_loss: 0.5893 - val_accuracy: 0.6738\n",
      "Epoch 89/300\n",
      "1545/1545 [==============================] - 0s 171us/sample - loss: 0.5146 - accuracy: 0.7793 - val_loss: 0.5886 - val_accuracy: 0.6738\n",
      "Epoch 90/300\n",
      "1545/1545 [==============================] - 0s 166us/sample - loss: 0.5091 - accuracy: 0.7786 - val_loss: 0.5879 - val_accuracy: 0.6738\n",
      "Epoch 91/300\n",
      "1545/1545 [==============================] - 0s 169us/sample - loss: 0.5044 - accuracy: 0.7896 - val_loss: 0.5872 - val_accuracy: 0.6761\n",
      "Epoch 92/300\n",
      "1545/1545 [==============================] - 0s 208us/sample - loss: 0.5063 - accuracy: 0.7773 - val_loss: 0.5865 - val_accuracy: 0.6761\n",
      "Epoch 93/300\n",
      "1545/1545 [==============================] - 0s 210us/sample - loss: 0.5032 - accuracy: 0.7935 - val_loss: 0.5858 - val_accuracy: 0.6761\n",
      "Epoch 94/300\n",
      "1545/1545 [==============================] - 0s 171us/sample - loss: 0.5042 - accuracy: 0.7955 - val_loss: 0.5852 - val_accuracy: 0.6761\n",
      "Epoch 95/300\n",
      "1545/1545 [==============================] - 0s 180us/sample - loss: 0.5025 - accuracy: 0.7890 - val_loss: 0.5845 - val_accuracy: 0.6761\n",
      "Epoch 96/300\n",
      "1545/1545 [==============================] - 0s 171us/sample - loss: 0.4993 - accuracy: 0.7961 - val_loss: 0.5838 - val_accuracy: 0.6785\n",
      "Epoch 97/300\n",
      "1545/1545 [==============================] - 0s 181us/sample - loss: 0.4978 - accuracy: 0.7896 - val_loss: 0.5832 - val_accuracy: 0.6809\n",
      "Epoch 98/300\n",
      "1545/1545 [==============================] - 0s 192us/sample - loss: 0.4915 - accuracy: 0.8000 - val_loss: 0.5825 - val_accuracy: 0.6809\n",
      "Epoch 99/300\n",
      "1545/1545 [==============================] - 0s 183us/sample - loss: 0.4977 - accuracy: 0.7909 - val_loss: 0.5819 - val_accuracy: 0.6856\n",
      "Epoch 100/300\n",
      "1545/1545 [==============================] - 0s 177us/sample - loss: 0.4914 - accuracy: 0.7955 - val_loss: 0.5812 - val_accuracy: 0.6856\n",
      "Epoch 101/300\n",
      "1545/1545 [==============================] - 0s 194us/sample - loss: 0.4871 - accuracy: 0.8019 - val_loss: 0.5806 - val_accuracy: 0.6879\n",
      "Epoch 102/300\n",
      "1545/1545 [==============================] - 0s 172us/sample - loss: 0.4891 - accuracy: 0.7929 - val_loss: 0.5799 - val_accuracy: 0.6856\n",
      "Epoch 103/300\n",
      "1545/1545 [==============================] - 0s 176us/sample - loss: 0.4854 - accuracy: 0.8019 - val_loss: 0.5792 - val_accuracy: 0.6809\n",
      "Epoch 104/300\n",
      "1545/1545 [==============================] - 0s 173us/sample - loss: 0.4834 - accuracy: 0.8026 - val_loss: 0.5786 - val_accuracy: 0.6856\n",
      "Epoch 105/300\n",
      "1545/1545 [==============================] - 0s 172us/sample - loss: 0.4805 - accuracy: 0.8019 - val_loss: 0.5780 - val_accuracy: 0.6903\n",
      "Epoch 106/300\n",
      "1545/1545 [==============================] - 0s 172us/sample - loss: 0.4825 - accuracy: 0.8078 - val_loss: 0.5773 - val_accuracy: 0.6903\n",
      "Epoch 107/300\n",
      "1545/1545 [==============================] - 0s 177us/sample - loss: 0.4770 - accuracy: 0.8032 - val_loss: 0.5767 - val_accuracy: 0.6903\n",
      "Epoch 108/300\n",
      "1545/1545 [==============================] - 0s 179us/sample - loss: 0.4721 - accuracy: 0.8071 - val_loss: 0.5761 - val_accuracy: 0.6903\n",
      "Epoch 109/300\n",
      "1545/1545 [==============================] - 0s 175us/sample - loss: 0.4729 - accuracy: 0.7968 - val_loss: 0.5755 - val_accuracy: 0.6903\n",
      "Epoch 110/300\n",
      "1545/1545 [==============================] - 0s 178us/sample - loss: 0.4767 - accuracy: 0.8078 - val_loss: 0.5749 - val_accuracy: 0.6950\n",
      "Epoch 111/300\n",
      "1545/1545 [==============================] - 0s 160us/sample - loss: 0.4673 - accuracy: 0.8084 - val_loss: 0.5743 - val_accuracy: 0.6927\n",
      "Epoch 112/300\n",
      "1545/1545 [==============================] - 0s 169us/sample - loss: 0.4709 - accuracy: 0.8052 - val_loss: 0.5736 - val_accuracy: 0.6950\n",
      "Epoch 113/300\n",
      "1545/1545 [==============================] - 0s 160us/sample - loss: 0.4687 - accuracy: 0.8019 - val_loss: 0.5730 - val_accuracy: 0.6950\n",
      "Epoch 114/300\n",
      "1545/1545 [==============================] - 0s 157us/sample - loss: 0.4631 - accuracy: 0.8104 - val_loss: 0.5725 - val_accuracy: 0.6950\n",
      "Epoch 115/300\n",
      "1545/1545 [==============================] - 0s 196us/sample - loss: 0.4631 - accuracy: 0.8155 - val_loss: 0.5719 - val_accuracy: 0.6950\n",
      "Epoch 116/300\n",
      "1545/1545 [==============================] - 0s 170us/sample - loss: 0.4606 - accuracy: 0.8136 - val_loss: 0.5712 - val_accuracy: 0.6950\n",
      "Epoch 117/300\n",
      "1545/1545 [==============================] - 0s 188us/sample - loss: 0.4542 - accuracy: 0.8188 - val_loss: 0.5707 - val_accuracy: 0.6950\n",
      "Epoch 118/300\n",
      "1545/1545 [==============================] - 0s 187us/sample - loss: 0.4523 - accuracy: 0.8220 - val_loss: 0.5701 - val_accuracy: 0.6950\n",
      "Epoch 119/300\n",
      "1545/1545 [==============================] - 0s 192us/sample - loss: 0.4533 - accuracy: 0.8207 - val_loss: 0.5696 - val_accuracy: 0.6974\n",
      "Epoch 120/300\n",
      "1545/1545 [==============================] - 0s 195us/sample - loss: 0.4520 - accuracy: 0.8265 - val_loss: 0.5690 - val_accuracy: 0.6974\n",
      "Epoch 121/300\n",
      "1545/1545 [==============================] - 0s 160us/sample - loss: 0.4491 - accuracy: 0.8259 - val_loss: 0.5685 - val_accuracy: 0.6974\n",
      "Epoch 122/300\n",
      "1545/1545 [==============================] - 0s 170us/sample - loss: 0.4514 - accuracy: 0.8175 - val_loss: 0.5679 - val_accuracy: 0.6974\n",
      "Epoch 123/300\n",
      "1545/1545 [==============================] - 0s 167us/sample - loss: 0.4454 - accuracy: 0.8188 - val_loss: 0.5674 - val_accuracy: 0.6974\n",
      "Epoch 124/300\n",
      "1545/1545 [==============================] - 0s 160us/sample - loss: 0.4431 - accuracy: 0.8272 - val_loss: 0.5669 - val_accuracy: 0.6974\n",
      "Epoch 125/300\n",
      "1545/1545 [==============================] - 0s 162us/sample - loss: 0.4418 - accuracy: 0.8227 - val_loss: 0.5663 - val_accuracy: 0.6974\n",
      "Epoch 126/300\n",
      "1545/1545 [==============================] - 0s 161us/sample - loss: 0.4390 - accuracy: 0.8304 - val_loss: 0.5659 - val_accuracy: 0.6974\n",
      "Epoch 127/300\n",
      "1545/1545 [==============================] - 0s 169us/sample - loss: 0.4393 - accuracy: 0.8317 - val_loss: 0.5653 - val_accuracy: 0.6974\n",
      "Epoch 128/300\n",
      "1545/1545 [==============================] - 0s 190us/sample - loss: 0.4380 - accuracy: 0.8337 - val_loss: 0.5648 - val_accuracy: 0.6998\n",
      "Epoch 129/300\n",
      "1545/1545 [==============================] - 0s 181us/sample - loss: 0.4344 - accuracy: 0.8311 - val_loss: 0.5644 - val_accuracy: 0.6950\n",
      "Epoch 130/300\n",
      "1545/1545 [==============================] - 0s 169us/sample - loss: 0.4361 - accuracy: 0.8356 - val_loss: 0.5639 - val_accuracy: 0.6950\n",
      "Epoch 131/300\n",
      "1545/1545 [==============================] - 0s 167us/sample - loss: 0.4282 - accuracy: 0.8421 - val_loss: 0.5635 - val_accuracy: 0.6950\n",
      "Epoch 132/300\n",
      "1545/1545 [==============================] - 0s 177us/sample - loss: 0.4245 - accuracy: 0.8401 - val_loss: 0.5630 - val_accuracy: 0.6974\n",
      "Epoch 133/300\n",
      "1545/1545 [==============================] - 0s 162us/sample - loss: 0.4240 - accuracy: 0.8447 - val_loss: 0.5625 - val_accuracy: 0.6974\n",
      "Epoch 134/300\n",
      "1545/1545 [==============================] - 0s 159us/sample - loss: 0.4212 - accuracy: 0.8408 - val_loss: 0.5620 - val_accuracy: 0.6974\n",
      "Epoch 135/300\n",
      "1545/1545 [==============================] - 0s 165us/sample - loss: 0.4162 - accuracy: 0.8434 - val_loss: 0.5616 - val_accuracy: 0.6974\n",
      "Epoch 136/300\n",
      "1545/1545 [==============================] - 0s 163us/sample - loss: 0.4185 - accuracy: 0.8447 - val_loss: 0.5612 - val_accuracy: 0.6974\n",
      "Epoch 137/300\n",
      "1545/1545 [==============================] - 0s 163us/sample - loss: 0.4163 - accuracy: 0.8356 - val_loss: 0.5608 - val_accuracy: 0.7021\n",
      "Epoch 138/300\n",
      "1545/1545 [==============================] - 0s 186us/sample - loss: 0.4117 - accuracy: 0.8511 - val_loss: 0.5603 - val_accuracy: 0.7021\n",
      "Epoch 139/300\n",
      "1545/1545 [==============================] - 0s 171us/sample - loss: 0.4146 - accuracy: 0.8401 - val_loss: 0.5599 - val_accuracy: 0.7069\n",
      "Epoch 140/300\n",
      "1545/1545 [==============================] - 0s 166us/sample - loss: 0.4110 - accuracy: 0.8492 - val_loss: 0.5595 - val_accuracy: 0.7069\n",
      "Epoch 141/300\n",
      "1545/1545 [==============================] - 0s 172us/sample - loss: 0.4092 - accuracy: 0.8440 - val_loss: 0.5592 - val_accuracy: 0.7045\n",
      "Epoch 142/300\n",
      "1545/1545 [==============================] - 0s 188us/sample - loss: 0.3996 - accuracy: 0.8557 - val_loss: 0.5588 - val_accuracy: 0.7069\n",
      "Epoch 143/300\n",
      "1545/1545 [==============================] - 0s 192us/sample - loss: 0.3982 - accuracy: 0.8479 - val_loss: 0.5584 - val_accuracy: 0.7045\n",
      "Epoch 144/300\n",
      "1545/1545 [==============================] - 0s 188us/sample - loss: 0.4014 - accuracy: 0.8544 - val_loss: 0.5581 - val_accuracy: 0.7069\n",
      "Epoch 145/300\n",
      "1545/1545 [==============================] - 0s 182us/sample - loss: 0.4004 - accuracy: 0.8408 - val_loss: 0.5578 - val_accuracy: 0.7045\n",
      "Epoch 146/300\n",
      "1545/1545 [==============================] - 0s 178us/sample - loss: 0.3941 - accuracy: 0.8557 - val_loss: 0.5574 - val_accuracy: 0.7021\n",
      "Epoch 147/300\n",
      "1545/1545 [==============================] - 0s 212us/sample - loss: 0.3942 - accuracy: 0.8505 - val_loss: 0.5571 - val_accuracy: 0.7021\n",
      "Epoch 148/300\n",
      "1545/1545 [==============================] - 0s 169us/sample - loss: 0.3888 - accuracy: 0.8615 - val_loss: 0.5569 - val_accuracy: 0.7021\n",
      "Epoch 149/300\n",
      "1545/1545 [==============================] - 0s 186us/sample - loss: 0.3919 - accuracy: 0.8479 - val_loss: 0.5566 - val_accuracy: 0.7021\n",
      "Epoch 150/300\n",
      "1545/1545 [==============================] - 0s 171us/sample - loss: 0.3897 - accuracy: 0.8570 - val_loss: 0.5564 - val_accuracy: 0.7021\n",
      "Epoch 151/300\n",
      "1545/1545 [==============================] - 0s 164us/sample - loss: 0.3914 - accuracy: 0.8492 - val_loss: 0.5561 - val_accuracy: 0.7045\n",
      "Epoch 152/300\n",
      "1545/1545 [==============================] - 0s 178us/sample - loss: 0.3821 - accuracy: 0.8563 - val_loss: 0.5559 - val_accuracy: 0.7045\n",
      "Epoch 153/300\n",
      "1545/1545 [==============================] - 0s 176us/sample - loss: 0.3781 - accuracy: 0.8608 - val_loss: 0.5558 - val_accuracy: 0.7021\n",
      "Epoch 154/300\n",
      "1545/1545 [==============================] - 0s 161us/sample - loss: 0.3788 - accuracy: 0.8537 - val_loss: 0.5556 - val_accuracy: 0.7021\n",
      "Epoch 155/300\n",
      "1545/1545 [==============================] - 0s 175us/sample - loss: 0.3807 - accuracy: 0.8576 - val_loss: 0.5555 - val_accuracy: 0.7045\n",
      "Epoch 156/300\n",
      "1545/1545 [==============================] - 0s 174us/sample - loss: 0.3732 - accuracy: 0.8602 - val_loss: 0.5554 - val_accuracy: 0.7045\n",
      "Epoch 157/300\n",
      "1545/1545 [==============================] - 0s 199us/sample - loss: 0.3701 - accuracy: 0.8706 - val_loss: 0.5553 - val_accuracy: 0.7021\n",
      "Epoch 158/300\n",
      "1545/1545 [==============================] - 0s 192us/sample - loss: 0.3682 - accuracy: 0.8641 - val_loss: 0.5552 - val_accuracy: 0.7021\n",
      "Epoch 159/300\n",
      "1545/1545 [==============================] - 0s 170us/sample - loss: 0.3661 - accuracy: 0.8667 - val_loss: 0.5551 - val_accuracy: 0.7021\n",
      "Epoch 160/300\n",
      "1545/1545 [==============================] - 0s 198us/sample - loss: 0.3700 - accuracy: 0.8647 - val_loss: 0.5551 - val_accuracy: 0.7069\n",
      "Epoch 161/300\n",
      "1545/1545 [==============================] - 0s 174us/sample - loss: 0.3634 - accuracy: 0.8660 - val_loss: 0.5551 - val_accuracy: 0.7069\n",
      "Epoch 162/300\n",
      "1545/1545 [==============================] - 0s 181us/sample - loss: 0.3633 - accuracy: 0.8654 - val_loss: 0.5551 - val_accuracy: 0.7092\n",
      "Epoch 163/300\n",
      "1545/1545 [==============================] - 0s 183us/sample - loss: 0.3574 - accuracy: 0.8725 - val_loss: 0.5551 - val_accuracy: 0.7045\n",
      "Epoch 00163: early stopping\n",
      "271/271 [==============================] - 0s 120us/sample - loss: 1.4842 - accuracy: 0.2804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [12:16, 736.16s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:05<00:05,  5.92s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.42s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "8it [00:00, 72.02it/s]\u001b[A\n",
      "11it [00:00, 47.89it/s]\u001b[A\n",
      "15it [00:00, 43.28it/s]\u001b[A\n",
      "18it [00:00, 35.36it/s]\u001b[A\n",
      "23it [00:00, 38.22it/s]\u001b[A\n",
      "27it [00:00, 36.04it/s]\u001b[A\n",
      "32it [00:00, 37.04it/s]\u001b[A\n",
      "38it [00:00, 38.84it/s]\u001b[A\n",
      "43it [00:01, 40.69it/s]\u001b[A\n",
      "47it [00:01, 38.22it/s]\u001b[A\n",
      "51it [00:01, 37.93it/s]\u001b[A\n",
      "56it [00:01, 39.69it/s]\u001b[A\n",
      "60it [00:01, 37.03it/s]\u001b[A\n",
      "64it [00:01, 35.09it/s]\u001b[A\n",
      "72it [00:01, 39.19it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 72/72 [00:00<00:00, 1801.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 511.171875 steps, validate for 138.0859375 steps\n",
      "Epoch 1/300\n",
      "512/511 [==============================] - 15s 30ms/step - loss: 0.6907 - accuracy: 0.5690 - val_loss: 0.6848 - val_accuracy: 0.5856\n",
      "Epoch 2/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.6444 - accuracy: 0.6241 - val_loss: 0.6714 - val_accuracy: 0.6027\n",
      "Epoch 3/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.6270 - accuracy: 0.6469 - val_loss: 0.6647 - val_accuracy: 0.6118\n",
      "Epoch 4/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.6146 - accuracy: 0.6608 - val_loss: 0.6634 - val_accuracy: 0.6110\n",
      "Epoch 5/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.6047 - accuracy: 0.6697 - val_loss: 0.6560 - val_accuracy: 0.6179\n",
      "Epoch 6/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.5960 - accuracy: 0.6776 - val_loss: 0.6557 - val_accuracy: 0.6203\n",
      "Epoch 7/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.5885 - accuracy: 0.6844 - val_loss: 0.6535 - val_accuracy: 0.6248\n",
      "Epoch 8/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.5816 - accuracy: 0.6902 - val_loss: 0.6484 - val_accuracy: 0.6288\n",
      "Epoch 9/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.5754 - accuracy: 0.6953 - val_loss: 0.6550 - val_accuracy: 0.6230\n",
      "Epoch 10/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.5693 - accuracy: 0.7011 - val_loss: 0.6568 - val_accuracy: 0.6257\n",
      "Epoch 11/300\n",
      "512/511 [==============================] - 14s 27ms/step - loss: 0.5639 - accuracy: 0.7034 - val_loss: 0.6540 - val_accuracy: 0.6292\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 511.171875 steps, validate for 138.0859375 steps\n",
      "Epoch 1/300\n",
      "512/511 [==============================] - 34s 66ms/step - loss: 0.5539 - accuracy: 0.7133 - val_loss: 0.6901 - val_accuracy: 0.6116\n",
      "Epoch 2/300\n",
      "512/511 [==============================] - 32s 63ms/step - loss: 0.5336 - accuracy: 0.7321 - val_loss: 0.6956 - val_accuracy: 0.6076\n",
      "Epoch 3/300\n",
      "512/511 [==============================] - 32s 63ms/step - loss: 0.5177 - accuracy: 0.7425 - val_loss: 0.7086 - val_accuracy: 0.6068\n",
      "Epoch 4/300\n",
      "512/511 [==============================] - 32s 63ms/step - loss: 0.5037 - accuracy: 0.7557 - val_loss: 0.6685 - val_accuracy: 0.6263\n",
      "Epoch 5/300\n",
      "512/511 [==============================] - 32s 63ms/step - loss: 0.4904 - accuracy: 0.7665 - val_loss: 0.6644 - val_accuracy: 0.6293\n",
      "Epoch 6/300\n",
      "512/511 [==============================] - 32s 63ms/step - loss: 0.4777 - accuracy: 0.7752 - val_loss: 0.6849 - val_accuracy: 0.6263\n",
      "Epoch 7/300\n",
      "512/511 [==============================] - 32s 63ms/step - loss: 0.4655 - accuracy: 0.7846 - val_loss: 0.6934 - val_accuracy: 0.6299\n",
      "Epoch 8/300\n",
      "512/511 [==============================] - 32s 63ms/step - loss: 0.4539 - accuracy: 0.7924 - val_loss: 0.6596 - val_accuracy: 0.6363\n",
      "Epoch 9/300\n",
      "512/511 [==============================] - 32s 63ms/step - loss: 0.4421 - accuracy: 0.8030 - val_loss: 0.6959 - val_accuracy: 0.6286\n",
      "Epoch 10/300\n",
      "512/511 [==============================] - 32s 63ms/step - loss: 0.4314 - accuracy: 0.8081 - val_loss: 0.6589 - val_accuracy: 0.6390\n",
      "Epoch 11/300\n",
      "512/511 [==============================] - 32s 63ms/step - loss: 0.4205 - accuracy: 0.8168 - val_loss: 0.6782 - val_accuracy: 0.6369\n",
      "Epoch 12/300\n",
      "512/511 [==============================] - 32s 63ms/step - loss: 0.4106 - accuracy: 0.8246 - val_loss: 0.7025 - val_accuracy: 0.6324\n",
      "Epoch 13/300\n",
      "512/511 [==============================] - 32s 63ms/step - loss: 0.4006 - accuracy: 0.8283 - val_loss: 0.6944 - val_accuracy: 0.6228\n",
      "Epoch 00013: early stopping\n",
      "312/312 [==============================] - 0s 825us/sample - loss: 0.9007 - accuracy: 0.4423\n",
      "296/296 [==============================] - 0s 215us/sample - loss: 0.9609 - accuracy: 0.4122\n",
      "290/290 [==============================] - 0s 227us/sample - loss: 0.9754 - accuracy: 0.4000\n",
      "285/285 [==============================] - 0s 198us/sample - loss: 0.9700 - accuracy: 0.4105\n",
      "279/279 [==============================] - 0s 228us/sample - loss: 0.9746 - accuracy: 0.4086\n",
      "272/272 [==============================] - 0s 204us/sample - loss: 1.0323 - accuracy: 0.4375\n",
      "270/270 [==============================] - 0s 269us/sample - loss: 1.0383 - accuracy: 0.4296\n",
      "269/269 [==============================] - 0s 248us/sample - loss: 1.0040 - accuracy: 0.3755\n",
      "263/263 [==============================] - 0s 255us/sample - loss: 1.0078 - accuracy: 0.4183\n",
      "262/262 [==============================] - 0s 271us/sample - loss: 1.0373 - accuracy: 0.3817\n",
      "261/261 [==============================] - 0s 218us/sample - loss: 1.0663 - accuracy: 0.3525\n",
      "254/254 [==============================] - 0s 235us/sample - loss: 1.0526 - accuracy: 0.3701\n",
      "252/252 [==============================] - 0s 277us/sample - loss: 1.0400 - accuracy: 0.3611\n",
      "249/249 [==============================] - 0s 276us/sample - loss: 1.0635 - accuracy: 0.4056\n",
      "251/251 [==============================] - 0s 217us/sample - loss: 1.0130 - accuracy: 0.4462\n",
      "247/247 [==============================] - 0s 221us/sample - loss: 0.9986 - accuracy: 0.4008\n",
      "246/246 [==============================] - 0s 237us/sample - loss: 1.0061 - accuracy: 0.4472\n",
      "243/243 [==============================] - 0s 261us/sample - loss: 1.0087 - accuracy: 0.3909\n",
      "242/242 [==============================] - 0s 248us/sample - loss: 0.9634 - accuracy: 0.4339\n",
      "236/236 [==============================] - 0s 236us/sample - loss: 0.9564 - accuracy: 0.4110\n",
      "234/234 [==============================] - 0s 297us/sample - loss: 0.8972 - accuracy: 0.4744\n",
      "230/230 [==============================] - 0s 230us/sample - loss: 0.8709 - accuracy: 0.4783\n",
      "231/231 [==============================] - 0s 233us/sample - loss: 0.9346 - accuracy: 0.4892\n",
      "228/228 [==============================] - 0s 229us/sample - loss: 0.9180 - accuracy: 0.4474\n",
      "227/227 [==============================] - 0s 244us/sample - loss: 1.0184 - accuracy: 0.4097\n",
      "227/227 [==============================] - 0s 235us/sample - loss: 0.9748 - accuracy: 0.4405\n",
      "221/221 [==============================] - 0s 220us/sample - loss: 0.9546 - accuracy: 0.4842\n",
      "226/226 [==============================] - 0s 230us/sample - loss: 1.0215 - accuracy: 0.4248\n",
      "230/230 [==============================] - 0s 239us/sample - loss: 0.9510 - accuracy: 0.4565\n",
      "226/226 [==============================] - 0s 276us/sample - loss: 0.9595 - accuracy: 0.4513\n",
      "223/223 [==============================] - 0s 211us/sample - loss: 1.0252 - accuracy: 0.3901\n",
      "222/222 [==============================] - 0s 225us/sample - loss: 1.0652 - accuracy: 0.4009\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 1593 samples, validate on 449 samples\n",
      "Epoch 1/300\n",
      "1593/1593 [==============================] - 3s 2ms/sample - loss: 0.6722 - accuracy: 0.5851 - val_loss: 0.6777 - val_accuracy: 0.5523\n",
      "Epoch 2/300\n",
      "1593/1593 [==============================] - 0s 185us/sample - loss: 0.6661 - accuracy: 0.5844 - val_loss: 0.6726 - val_accuracy: 0.5702\n",
      "Epoch 3/300\n",
      "1593/1593 [==============================] - 0s 177us/sample - loss: 0.6538 - accuracy: 0.6146 - val_loss: 0.6687 - val_accuracy: 0.5835\n",
      "Epoch 4/300\n",
      "1593/1593 [==============================] - 0s 178us/sample - loss: 0.6502 - accuracy: 0.6208 - val_loss: 0.6655 - val_accuracy: 0.5924\n",
      "Epoch 5/300\n",
      "1593/1593 [==============================] - 0s 179us/sample - loss: 0.6380 - accuracy: 0.6566 - val_loss: 0.6628 - val_accuracy: 0.5991\n",
      "Epoch 6/300\n",
      "1593/1593 [==============================] - 0s 171us/sample - loss: 0.6370 - accuracy: 0.6403 - val_loss: 0.6603 - val_accuracy: 0.5991\n",
      "Epoch 7/300\n",
      "1593/1593 [==============================] - 0s 167us/sample - loss: 0.6322 - accuracy: 0.6585 - val_loss: 0.6580 - val_accuracy: 0.5991\n",
      "Epoch 8/300\n",
      "1593/1593 [==============================] - 0s 172us/sample - loss: 0.6261 - accuracy: 0.6673 - val_loss: 0.6559 - val_accuracy: 0.6013\n",
      "Epoch 9/300\n",
      "1593/1593 [==============================] - 0s 184us/sample - loss: 0.6250 - accuracy: 0.6660 - val_loss: 0.6539 - val_accuracy: 0.6125\n",
      "Epoch 10/300\n",
      "1593/1593 [==============================] - 0s 190us/sample - loss: 0.6145 - accuracy: 0.6805 - val_loss: 0.6521 - val_accuracy: 0.6192\n",
      "Epoch 11/300\n",
      "1593/1593 [==============================] - 0s 185us/sample - loss: 0.6117 - accuracy: 0.6899 - val_loss: 0.6503 - val_accuracy: 0.6192\n",
      "Epoch 12/300\n",
      "1593/1593 [==============================] - 0s 174us/sample - loss: 0.6118 - accuracy: 0.6880 - val_loss: 0.6486 - val_accuracy: 0.6214\n",
      "Epoch 13/300\n",
      "1593/1593 [==============================] - 0s 175us/sample - loss: 0.6119 - accuracy: 0.6717 - val_loss: 0.6470 - val_accuracy: 0.6214\n",
      "Epoch 14/300\n",
      "1593/1593 [==============================] - 0s 183us/sample - loss: 0.6009 - accuracy: 0.6974 - val_loss: 0.6455 - val_accuracy: 0.6214\n",
      "Epoch 15/300\n",
      "1593/1593 [==============================] - 0s 184us/sample - loss: 0.5972 - accuracy: 0.6955 - val_loss: 0.6440 - val_accuracy: 0.6281\n",
      "Epoch 16/300\n",
      "1593/1593 [==============================] - 0s 190us/sample - loss: 0.5929 - accuracy: 0.7137 - val_loss: 0.6426 - val_accuracy: 0.6303\n",
      "Epoch 17/300\n",
      "1593/1593 [==============================] - 0s 181us/sample - loss: 0.5954 - accuracy: 0.7031 - val_loss: 0.6411 - val_accuracy: 0.6325\n",
      "Epoch 18/300\n",
      "1593/1593 [==============================] - 0s 167us/sample - loss: 0.5896 - accuracy: 0.7194 - val_loss: 0.6398 - val_accuracy: 0.6303\n",
      "Epoch 19/300\n",
      "1593/1593 [==============================] - 0s 190us/sample - loss: 0.5881 - accuracy: 0.7163 - val_loss: 0.6385 - val_accuracy: 0.6303\n",
      "Epoch 20/300\n",
      "1593/1593 [==============================] - 0s 191us/sample - loss: 0.5859 - accuracy: 0.7131 - val_loss: 0.6372 - val_accuracy: 0.6258\n",
      "Epoch 21/300\n",
      "1593/1593 [==============================] - 0s 184us/sample - loss: 0.5819 - accuracy: 0.7250 - val_loss: 0.6359 - val_accuracy: 0.6281\n",
      "Epoch 22/300\n",
      "1593/1593 [==============================] - 0s 183us/sample - loss: 0.5802 - accuracy: 0.7294 - val_loss: 0.6347 - val_accuracy: 0.6303\n",
      "Epoch 23/300\n",
      "1593/1593 [==============================] - 0s 209us/sample - loss: 0.5757 - accuracy: 0.7376 - val_loss: 0.6335 - val_accuracy: 0.6303\n",
      "Epoch 24/300\n",
      "1593/1593 [==============================] - 0s 181us/sample - loss: 0.5767 - accuracy: 0.7282 - val_loss: 0.6323 - val_accuracy: 0.6303\n",
      "Epoch 25/300\n",
      "1593/1593 [==============================] - 0s 198us/sample - loss: 0.5734 - accuracy: 0.7263 - val_loss: 0.6312 - val_accuracy: 0.6303\n",
      "Epoch 26/300\n",
      "1593/1593 [==============================] - 0s 177us/sample - loss: 0.5698 - accuracy: 0.7420 - val_loss: 0.6300 - val_accuracy: 0.6281\n",
      "Epoch 27/300\n",
      "1593/1593 [==============================] - 0s 168us/sample - loss: 0.5663 - accuracy: 0.7276 - val_loss: 0.6289 - val_accuracy: 0.6303\n",
      "Epoch 28/300\n",
      "1593/1593 [==============================] - 0s 164us/sample - loss: 0.5623 - accuracy: 0.7451 - val_loss: 0.6278 - val_accuracy: 0.6303\n",
      "Epoch 29/300\n",
      "1593/1593 [==============================] - 0s 170us/sample - loss: 0.5620 - accuracy: 0.7458 - val_loss: 0.6268 - val_accuracy: 0.6347\n",
      "Epoch 30/300\n",
      "1593/1593 [==============================] - 0s 165us/sample - loss: 0.5560 - accuracy: 0.7395 - val_loss: 0.6256 - val_accuracy: 0.6370\n",
      "Epoch 31/300\n",
      "1593/1593 [==============================] - 0s 157us/sample - loss: 0.5533 - accuracy: 0.7420 - val_loss: 0.6246 - val_accuracy: 0.6347\n",
      "Epoch 32/300\n",
      "1593/1593 [==============================] - 0s 168us/sample - loss: 0.5557 - accuracy: 0.7426 - val_loss: 0.6236 - val_accuracy: 0.6370\n",
      "Epoch 33/300\n",
      "1593/1593 [==============================] - 0s 157us/sample - loss: 0.5499 - accuracy: 0.7527 - val_loss: 0.6225 - val_accuracy: 0.6370\n",
      "Epoch 34/300\n",
      "1593/1593 [==============================] - 0s 163us/sample - loss: 0.5466 - accuracy: 0.7627 - val_loss: 0.6216 - val_accuracy: 0.6370\n",
      "Epoch 35/300\n",
      "1593/1593 [==============================] - 0s 172us/sample - loss: 0.5447 - accuracy: 0.7602 - val_loss: 0.6206 - val_accuracy: 0.6370\n",
      "Epoch 36/300\n",
      "1593/1593 [==============================] - 0s 166us/sample - loss: 0.5385 - accuracy: 0.7759 - val_loss: 0.6196 - val_accuracy: 0.6370\n",
      "Epoch 37/300\n",
      "1593/1593 [==============================] - 0s 161us/sample - loss: 0.5385 - accuracy: 0.7577 - val_loss: 0.6186 - val_accuracy: 0.6370\n",
      "Epoch 38/300\n",
      "1593/1593 [==============================] - 0s 160us/sample - loss: 0.5344 - accuracy: 0.7690 - val_loss: 0.6177 - val_accuracy: 0.6370\n",
      "Epoch 39/300\n",
      "1593/1593 [==============================] - 0s 160us/sample - loss: 0.5359 - accuracy: 0.7702 - val_loss: 0.6167 - val_accuracy: 0.6370\n",
      "Epoch 40/300\n",
      "1593/1593 [==============================] - 0s 158us/sample - loss: 0.5303 - accuracy: 0.7753 - val_loss: 0.6158 - val_accuracy: 0.6347\n",
      "Epoch 41/300\n",
      "1593/1593 [==============================] - 0s 163us/sample - loss: 0.5292 - accuracy: 0.7671 - val_loss: 0.6149 - val_accuracy: 0.6414\n",
      "Epoch 42/300\n",
      "1593/1593 [==============================] - 0s 171us/sample - loss: 0.5258 - accuracy: 0.7652 - val_loss: 0.6139 - val_accuracy: 0.6459\n",
      "Epoch 43/300\n",
      "1593/1593 [==============================] - 0s 165us/sample - loss: 0.5235 - accuracy: 0.7822 - val_loss: 0.6131 - val_accuracy: 0.6459\n",
      "Epoch 44/300\n",
      "1593/1593 [==============================] - 0s 166us/sample - loss: 0.5182 - accuracy: 0.7878 - val_loss: 0.6122 - val_accuracy: 0.6459\n",
      "Epoch 45/300\n",
      "1593/1593 [==============================] - 0s 186us/sample - loss: 0.5213 - accuracy: 0.7778 - val_loss: 0.6113 - val_accuracy: 0.6414\n",
      "Epoch 46/300\n",
      "1593/1593 [==============================] - 0s 167us/sample - loss: 0.5174 - accuracy: 0.7728 - val_loss: 0.6105 - val_accuracy: 0.6392\n",
      "Epoch 47/300\n",
      "1593/1593 [==============================] - 0s 177us/sample - loss: 0.5148 - accuracy: 0.7866 - val_loss: 0.6096 - val_accuracy: 0.6414\n",
      "Epoch 48/300\n",
      "1593/1593 [==============================] - 0s 175us/sample - loss: 0.5133 - accuracy: 0.7797 - val_loss: 0.6088 - val_accuracy: 0.6414\n",
      "Epoch 49/300\n",
      "1593/1593 [==============================] - 0s 208us/sample - loss: 0.5085 - accuracy: 0.7922 - val_loss: 0.6080 - val_accuracy: 0.6414\n",
      "Epoch 50/300\n",
      "1593/1593 [==============================] - 0s 164us/sample - loss: 0.5069 - accuracy: 0.7966 - val_loss: 0.6072 - val_accuracy: 0.6414\n",
      "Epoch 51/300\n",
      "1593/1593 [==============================] - 0s 168us/sample - loss: 0.5036 - accuracy: 0.7910 - val_loss: 0.6064 - val_accuracy: 0.6414\n",
      "Epoch 52/300\n",
      "1593/1593 [==============================] - 0s 183us/sample - loss: 0.5011 - accuracy: 0.8016 - val_loss: 0.6056 - val_accuracy: 0.6414\n",
      "Epoch 53/300\n",
      "1593/1593 [==============================] - 0s 174us/sample - loss: 0.4986 - accuracy: 0.7928 - val_loss: 0.6048 - val_accuracy: 0.6459\n",
      "Epoch 54/300\n",
      "1593/1593 [==============================] - 0s 167us/sample - loss: 0.4969 - accuracy: 0.7997 - val_loss: 0.6041 - val_accuracy: 0.6437\n",
      "Epoch 55/300\n",
      "1593/1593 [==============================] - 0s 181us/sample - loss: 0.4924 - accuracy: 0.7972 - val_loss: 0.6033 - val_accuracy: 0.6459\n",
      "Epoch 56/300\n",
      "1593/1593 [==============================] - 0s 175us/sample - loss: 0.4898 - accuracy: 0.8067 - val_loss: 0.6026 - val_accuracy: 0.6437\n",
      "Epoch 57/300\n",
      "1593/1593 [==============================] - 0s 171us/sample - loss: 0.4884 - accuracy: 0.8085 - val_loss: 0.6018 - val_accuracy: 0.6459\n",
      "Epoch 58/300\n",
      "1593/1593 [==============================] - 0s 169us/sample - loss: 0.4867 - accuracy: 0.8029 - val_loss: 0.6011 - val_accuracy: 0.6503\n",
      "Epoch 59/300\n",
      "1593/1593 [==============================] - 0s 161us/sample - loss: 0.4825 - accuracy: 0.8173 - val_loss: 0.6004 - val_accuracy: 0.6503\n",
      "Epoch 60/300\n",
      "1593/1593 [==============================] - 0s 169us/sample - loss: 0.4815 - accuracy: 0.8060 - val_loss: 0.5997 - val_accuracy: 0.6526\n",
      "Epoch 61/300\n",
      "1593/1593 [==============================] - 0s 177us/sample - loss: 0.4708 - accuracy: 0.8286 - val_loss: 0.5990 - val_accuracy: 0.6548\n",
      "Epoch 62/300\n",
      "1593/1593 [==============================] - 0s 174us/sample - loss: 0.4768 - accuracy: 0.8217 - val_loss: 0.5983 - val_accuracy: 0.6548\n",
      "Epoch 63/300\n",
      "1593/1593 [==============================] - 0s 163us/sample - loss: 0.4711 - accuracy: 0.8236 - val_loss: 0.5977 - val_accuracy: 0.6548\n",
      "Epoch 64/300\n",
      "1593/1593 [==============================] - 0s 170us/sample - loss: 0.4707 - accuracy: 0.8236 - val_loss: 0.5970 - val_accuracy: 0.6570\n",
      "Epoch 65/300\n",
      "1593/1593 [==============================] - 0s 164us/sample - loss: 0.4633 - accuracy: 0.8280 - val_loss: 0.5964 - val_accuracy: 0.6592\n",
      "Epoch 66/300\n",
      "1593/1593 [==============================] - 0s 161us/sample - loss: 0.4652 - accuracy: 0.8211 - val_loss: 0.5957 - val_accuracy: 0.6637\n",
      "Epoch 67/300\n",
      "1593/1593 [==============================] - 0s 164us/sample - loss: 0.4599 - accuracy: 0.8242 - val_loss: 0.5951 - val_accuracy: 0.6637\n",
      "Epoch 68/300\n",
      "1593/1593 [==============================] - 0s 169us/sample - loss: 0.4582 - accuracy: 0.8368 - val_loss: 0.5945 - val_accuracy: 0.6637\n",
      "Epoch 69/300\n",
      "1593/1593 [==============================] - 0s 165us/sample - loss: 0.4568 - accuracy: 0.8198 - val_loss: 0.5939 - val_accuracy: 0.6637\n",
      "Epoch 70/300\n",
      "1593/1593 [==============================] - 0s 166us/sample - loss: 0.4537 - accuracy: 0.8355 - val_loss: 0.5934 - val_accuracy: 0.6637\n",
      "Epoch 71/300\n",
      "1593/1593 [==============================] - 0s 182us/sample - loss: 0.4486 - accuracy: 0.8293 - val_loss: 0.5928 - val_accuracy: 0.6637\n",
      "Epoch 72/300\n",
      "1593/1593 [==============================] - 0s 175us/sample - loss: 0.4489 - accuracy: 0.8412 - val_loss: 0.5923 - val_accuracy: 0.6615\n",
      "Epoch 73/300\n",
      "1593/1593 [==============================] - 0s 155us/sample - loss: 0.4487 - accuracy: 0.8399 - val_loss: 0.5917 - val_accuracy: 0.6637\n",
      "Epoch 74/300\n",
      "1593/1593 [==============================] - 0s 176us/sample - loss: 0.4478 - accuracy: 0.8280 - val_loss: 0.5912 - val_accuracy: 0.6637\n",
      "Epoch 75/300\n",
      "1593/1593 [==============================] - 0s 189us/sample - loss: 0.4383 - accuracy: 0.8424 - val_loss: 0.5907 - val_accuracy: 0.6615\n",
      "Epoch 76/300\n",
      "1593/1593 [==============================] - 0s 178us/sample - loss: 0.4372 - accuracy: 0.8374 - val_loss: 0.5902 - val_accuracy: 0.6637\n",
      "Epoch 77/300\n",
      "1593/1593 [==============================] - 0s 181us/sample - loss: 0.4355 - accuracy: 0.8412 - val_loss: 0.5897 - val_accuracy: 0.6659\n",
      "Epoch 78/300\n",
      "1593/1593 [==============================] - 0s 181us/sample - loss: 0.4347 - accuracy: 0.8362 - val_loss: 0.5892 - val_accuracy: 0.6615\n",
      "Epoch 79/300\n",
      "1593/1593 [==============================] - 0s 179us/sample - loss: 0.4345 - accuracy: 0.8468 - val_loss: 0.5888 - val_accuracy: 0.6682\n",
      "Epoch 80/300\n",
      "1593/1593 [==============================] - 0s 162us/sample - loss: 0.4293 - accuracy: 0.8437 - val_loss: 0.5883 - val_accuracy: 0.6682\n",
      "Epoch 81/300\n",
      "1593/1593 [==============================] - 0s 166us/sample - loss: 0.4239 - accuracy: 0.8512 - val_loss: 0.5880 - val_accuracy: 0.6704\n",
      "Epoch 82/300\n",
      "1593/1593 [==============================] - 0s 156us/sample - loss: 0.4194 - accuracy: 0.8544 - val_loss: 0.5875 - val_accuracy: 0.6748\n",
      "Epoch 83/300\n",
      "1593/1593 [==============================] - 0s 182us/sample - loss: 0.4185 - accuracy: 0.8487 - val_loss: 0.5871 - val_accuracy: 0.6748\n",
      "Epoch 84/300\n",
      "1593/1593 [==============================] - 0s 170us/sample - loss: 0.4152 - accuracy: 0.8544 - val_loss: 0.5867 - val_accuracy: 0.6704\n",
      "Epoch 85/300\n",
      "1593/1593 [==============================] - 0s 179us/sample - loss: 0.4167 - accuracy: 0.8544 - val_loss: 0.5864 - val_accuracy: 0.6704\n",
      "Epoch 86/300\n",
      "1593/1593 [==============================] - 0s 175us/sample - loss: 0.4122 - accuracy: 0.8550 - val_loss: 0.5861 - val_accuracy: 0.6704\n",
      "Epoch 87/300\n",
      "1593/1593 [==============================] - 0s 159us/sample - loss: 0.4086 - accuracy: 0.8581 - val_loss: 0.5858 - val_accuracy: 0.6704\n",
      "Epoch 88/300\n",
      "1593/1593 [==============================] - 0s 166us/sample - loss: 0.4019 - accuracy: 0.8562 - val_loss: 0.5855 - val_accuracy: 0.6704\n",
      "Epoch 89/300\n",
      "1593/1593 [==============================] - 0s 171us/sample - loss: 0.4037 - accuracy: 0.8644 - val_loss: 0.5853 - val_accuracy: 0.6726\n",
      "Epoch 90/300\n",
      "1593/1593 [==============================] - 0s 176us/sample - loss: 0.4012 - accuracy: 0.8669 - val_loss: 0.5850 - val_accuracy: 0.6726\n",
      "Epoch 91/300\n",
      "1593/1593 [==============================] - 0s 163us/sample - loss: 0.3980 - accuracy: 0.8657 - val_loss: 0.5848 - val_accuracy: 0.6726\n",
      "Epoch 92/300\n",
      "1593/1593 [==============================] - 0s 159us/sample - loss: 0.3998 - accuracy: 0.8544 - val_loss: 0.5846 - val_accuracy: 0.6726\n",
      "Epoch 93/300\n",
      "1593/1593 [==============================] - 0s 172us/sample - loss: 0.3944 - accuracy: 0.8650 - val_loss: 0.5844 - val_accuracy: 0.6726\n",
      "Epoch 94/300\n",
      "1593/1593 [==============================] - 0s 190us/sample - loss: 0.3876 - accuracy: 0.8751 - val_loss: 0.5842 - val_accuracy: 0.6726\n",
      "Epoch 95/300\n",
      "1593/1593 [==============================] - 0s 169us/sample - loss: 0.3862 - accuracy: 0.8707 - val_loss: 0.5841 - val_accuracy: 0.6726\n",
      "Epoch 96/300\n",
      "1593/1593 [==============================] - 0s 164us/sample - loss: 0.3838 - accuracy: 0.8619 - val_loss: 0.5839 - val_accuracy: 0.6726\n",
      "Epoch 97/300\n",
      "1593/1593 [==============================] - 0s 166us/sample - loss: 0.3744 - accuracy: 0.8820 - val_loss: 0.5839 - val_accuracy: 0.6748\n",
      "Epoch 98/300\n",
      "1593/1593 [==============================] - 0s 156us/sample - loss: 0.3813 - accuracy: 0.8694 - val_loss: 0.5838 - val_accuracy: 0.6726\n",
      "Epoch 99/300\n",
      "1593/1593 [==============================] - 0s 158us/sample - loss: 0.3746 - accuracy: 0.8713 - val_loss: 0.5837 - val_accuracy: 0.6726\n",
      "Epoch 100/300\n",
      "1593/1593 [==============================] - 0s 180us/sample - loss: 0.3723 - accuracy: 0.8832 - val_loss: 0.5837 - val_accuracy: 0.6726\n",
      "Epoch 101/300\n",
      "1593/1593 [==============================] - 0s 183us/sample - loss: 0.3689 - accuracy: 0.8776 - val_loss: 0.5837 - val_accuracy: 0.6704\n",
      "Epoch 102/300\n",
      "1593/1593 [==============================] - 0s 170us/sample - loss: 0.3646 - accuracy: 0.8832 - val_loss: 0.5838 - val_accuracy: 0.6704\n",
      "Epoch 103/300\n",
      "1593/1593 [==============================] - 0s 180us/sample - loss: 0.3671 - accuracy: 0.8757 - val_loss: 0.5838 - val_accuracy: 0.6704\n",
      "Epoch 00103: early stopping\n",
      "197/197 [==============================] - 0s 116us/sample - loss: 1.3374 - accuracy: 0.2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [27:45, 794.16s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:06<00:06,  6.07s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.56s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "8it [00:00, 68.86it/s]\u001b[A\n",
      "11it [00:00, 46.31it/s]\u001b[A\n",
      "16it [00:00, 45.43it/s]\u001b[A\n",
      "20it [00:00, 38.52it/s]\u001b[A\n",
      "23it [00:00, 34.54it/s]\u001b[A\n",
      "26it [00:00, 31.52it/s]\u001b[A\n",
      "30it [00:00, 32.14it/s]\u001b[A\n",
      "35it [00:00, 35.57it/s]\u001b[A\n",
      "39it [00:01, 35.22it/s]\u001b[A\n",
      "44it [00:01, 36.35it/s]\u001b[A\n",
      "48it [00:01, 32.27it/s]\u001b[A\n",
      "52it [00:01, 33.37it/s]\u001b[A\n",
      "57it [00:01, 36.05it/s]\u001b[A\n",
      "61it [00:01, 32.03it/s]\u001b[A\n",
      "66it [00:01, 33.85it/s]\u001b[A\n",
      "72it [00:01, 36.66it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 72/72 [00:00<00:00, 2103.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 505.4296875 steps, validate for 134.96875 steps\n",
      "Epoch 1/300\n",
      "506/505 [==============================] - 15s 30ms/step - loss: 0.7036 - accuracy: 0.5699 - val_loss: 0.6912 - val_accuracy: 0.5723\n",
      "Epoch 2/300\n",
      "506/505 [==============================] - 14s 27ms/step - loss: 0.6625 - accuracy: 0.5999 - val_loss: 0.6840 - val_accuracy: 0.5811\n",
      "Epoch 3/300\n",
      "506/505 [==============================] - 14s 27ms/step - loss: 0.6466 - accuracy: 0.6197 - val_loss: 0.6734 - val_accuracy: 0.5948\n",
      "Epoch 4/300\n",
      "506/505 [==============================] - 14s 27ms/step - loss: 0.6356 - accuracy: 0.6335 - val_loss: 0.6712 - val_accuracy: 0.5969\n",
      "Epoch 5/300\n",
      "506/505 [==============================] - 14s 27ms/step - loss: 0.6263 - accuracy: 0.6454 - val_loss: 0.6693 - val_accuracy: 0.5987\n",
      "Epoch 6/300\n",
      "506/505 [==============================] - 14s 27ms/step - loss: 0.6184 - accuracy: 0.6524 - val_loss: 0.6685 - val_accuracy: 0.5967\n",
      "Epoch 7/300\n",
      "506/505 [==============================] - 14s 27ms/step - loss: 0.6110 - accuracy: 0.6606 - val_loss: 0.6661 - val_accuracy: 0.6037\n",
      "Epoch 8/300\n",
      "506/505 [==============================] - 14s 28ms/step - loss: 0.6044 - accuracy: 0.6678 - val_loss: 0.6653 - val_accuracy: 0.6021\n",
      "Epoch 9/300\n",
      "506/505 [==============================] - 14s 27ms/step - loss: 0.5979 - accuracy: 0.6747 - val_loss: 0.6684 - val_accuracy: 0.6014\n",
      "Epoch 10/300\n",
      "506/505 [==============================] - 14s 27ms/step - loss: 0.5920 - accuracy: 0.6798 - val_loss: 0.6727 - val_accuracy: 0.5973\n",
      "Epoch 11/300\n",
      "506/505 [==============================] - 14s 27ms/step - loss: 0.5860 - accuracy: 0.6862 - val_loss: 0.6687 - val_accuracy: 0.6050\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 505.4296875 steps, validate for 134.96875 steps\n",
      "Epoch 1/300\n",
      "506/505 [==============================] - 33s 65ms/step - loss: 0.5764 - accuracy: 0.6937 - val_loss: 0.6767 - val_accuracy: 0.6112\n",
      "Epoch 2/300\n",
      "506/505 [==============================] - 32s 63ms/step - loss: 0.5570 - accuracy: 0.7128 - val_loss: 0.6879 - val_accuracy: 0.5957\n",
      "Epoch 3/300\n",
      "506/505 [==============================] - 32s 63ms/step - loss: 0.5410 - accuracy: 0.7277 - val_loss: 0.6734 - val_accuracy: 0.6162\n",
      "Epoch 4/300\n",
      "506/505 [==============================] - 32s 63ms/step - loss: 0.5265 - accuracy: 0.7406 - val_loss: 0.6938 - val_accuracy: 0.5997\n",
      "Epoch 5/300\n",
      "506/505 [==============================] - 32s 63ms/step - loss: 0.5136 - accuracy: 0.7504 - val_loss: 0.6915 - val_accuracy: 0.6102\n",
      "Epoch 6/300\n",
      "506/505 [==============================] - 32s 63ms/step - loss: 0.5006 - accuracy: 0.7609 - val_loss: 0.6786 - val_accuracy: 0.6137\n",
      "Epoch 00006: early stopping\n",
      "364/364 [==============================] - 0s 760us/sample - loss: 1.0645 - accuracy: 0.3077\n",
      "349/349 [==============================] - 0s 209us/sample - loss: 0.9813 - accuracy: 0.3209\n",
      "342/342 [==============================] - 0s 230us/sample - loss: 0.8948 - accuracy: 0.4152\n",
      "334/334 [==============================] - 0s 205us/sample - loss: 0.8591 - accuracy: 0.4401\n",
      "327/327 [==============================] - 0s 219us/sample - loss: 0.8329 - accuracy: 0.4832\n",
      "323/323 [==============================] - 0s 226us/sample - loss: 0.8622 - accuracy: 0.4675\n",
      "314/314 [==============================] - 0s 224us/sample - loss: 0.7968 - accuracy: 0.4968\n",
      "307/307 [==============================] - 0s 225us/sample - loss: 0.7644 - accuracy: 0.5375\n",
      "301/301 [==============================] - 0s 259us/sample - loss: 0.7202 - accuracy: 0.5814\n",
      "296/296 [==============================] - 0s 256us/sample - loss: 0.7327 - accuracy: 0.5642\n",
      "290/290 [==============================] - 0s 260us/sample - loss: 0.7438 - accuracy: 0.5414\n",
      "288/288 [==============================] - 0s 955us/sample - loss: 0.7450 - accuracy: 0.5868\n",
      "286/286 [==============================] - 0s 233us/sample - loss: 0.7328 - accuracy: 0.5664\n",
      "286/286 [==============================] - 0s 219us/sample - loss: 0.7455 - accuracy: 0.5664\n",
      "280/280 [==============================] - 0s 244us/sample - loss: 0.7714 - accuracy: 0.5429\n",
      "280/280 [==============================] - 0s 248us/sample - loss: 0.7710 - accuracy: 0.5679\n",
      "276/276 [==============================] - 0s 255us/sample - loss: 0.7937 - accuracy: 0.5471\n",
      "274/274 [==============================] - 0s 268us/sample - loss: 0.8272 - accuracy: 0.5000\n",
      "272/272 [==============================] - 0s 287us/sample - loss: 0.8055 - accuracy: 0.5221\n",
      "271/271 [==============================] - 0s 216us/sample - loss: 0.7972 - accuracy: 0.4760\n",
      "266/266 [==============================] - 0s 254us/sample - loss: 0.8192 - accuracy: 0.5414\n",
      "264/264 [==============================] - 0s 253us/sample - loss: 0.7970 - accuracy: 0.5189\n",
      "263/263 [==============================] - 0s 222us/sample - loss: 0.7960 - accuracy: 0.5247\n",
      "260/260 [==============================] - 0s 266us/sample - loss: 0.7806 - accuracy: 0.5231\n",
      "258/258 [==============================] - 0s 249us/sample - loss: 0.7581 - accuracy: 0.5465\n",
      "258/258 [==============================] - 0s 247us/sample - loss: 0.7817 - accuracy: 0.5233\n",
      "258/258 [==============================] - 0s 234us/sample - loss: 0.7251 - accuracy: 0.5775\n",
      "254/254 [==============================] - 0s 218us/sample - loss: 0.7666 - accuracy: 0.5551\n",
      "252/252 [==============================] - 0s 221us/sample - loss: 0.7929 - accuracy: 0.5476\n",
      "249/249 [==============================] - 0s 228us/sample - loss: 0.7411 - accuracy: 0.5663\n",
      "250/250 [==============================] - 0s 255us/sample - loss: 0.8072 - accuracy: 0.4960\n",
      "246/246 [==============================] - 0s 243us/sample - loss: 0.8075 - accuracy: 0.5122\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 1580 samples, validate on 436 samples\n",
      "Epoch 1/300\n",
      "1580/1580 [==============================] - 2s 1ms/sample - loss: 0.7079 - accuracy: 0.5076 - val_loss: 0.6952 - val_accuracy: 0.5252\n",
      "Epoch 2/300\n",
      "1580/1580 [==============================] - 0s 173us/sample - loss: 0.7053 - accuracy: 0.5120 - val_loss: 0.6887 - val_accuracy: 0.5321\n",
      "Epoch 3/300\n",
      "1580/1580 [==============================] - 0s 175us/sample - loss: 0.6895 - accuracy: 0.5411 - val_loss: 0.6845 - val_accuracy: 0.5505\n",
      "Epoch 4/300\n",
      "1580/1580 [==============================] - 0s 178us/sample - loss: 0.6837 - accuracy: 0.5513 - val_loss: 0.6810 - val_accuracy: 0.5550\n",
      "Epoch 5/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.6803 - accuracy: 0.5468 - val_loss: 0.6781 - val_accuracy: 0.5596\n",
      "Epoch 6/300\n",
      "1580/1580 [==============================] - 0s 173us/sample - loss: 0.6743 - accuracy: 0.5614 - val_loss: 0.6756 - val_accuracy: 0.5711\n",
      "Epoch 7/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.6697 - accuracy: 0.5899 - val_loss: 0.6735 - val_accuracy: 0.5872\n",
      "Epoch 8/300\n",
      "1580/1580 [==============================] - 0s 169us/sample - loss: 0.6650 - accuracy: 0.5924 - val_loss: 0.6713 - val_accuracy: 0.5872\n",
      "Epoch 9/300\n",
      "1580/1580 [==============================] - 0s 172us/sample - loss: 0.6648 - accuracy: 0.5842 - val_loss: 0.6696 - val_accuracy: 0.5986\n",
      "Epoch 10/300\n",
      "1580/1580 [==============================] - 0s 170us/sample - loss: 0.6686 - accuracy: 0.5816 - val_loss: 0.6679 - val_accuracy: 0.5917\n",
      "Epoch 11/300\n",
      "1580/1580 [==============================] - 0s 170us/sample - loss: 0.6598 - accuracy: 0.5975 - val_loss: 0.6664 - val_accuracy: 0.6032\n",
      "Epoch 12/300\n",
      "1580/1580 [==============================] - 0s 173us/sample - loss: 0.6597 - accuracy: 0.5949 - val_loss: 0.6648 - val_accuracy: 0.6055\n",
      "Epoch 13/300\n",
      "1580/1580 [==============================] - 0s 173us/sample - loss: 0.6567 - accuracy: 0.6082 - val_loss: 0.6634 - val_accuracy: 0.6055\n",
      "Epoch 14/300\n",
      "1580/1580 [==============================] - 0s 167us/sample - loss: 0.6524 - accuracy: 0.6241 - val_loss: 0.6619 - val_accuracy: 0.5986\n",
      "Epoch 15/300\n",
      "1580/1580 [==============================] - 0s 167us/sample - loss: 0.6492 - accuracy: 0.6114 - val_loss: 0.6606 - val_accuracy: 0.6032\n",
      "Epoch 16/300\n",
      "1580/1580 [==============================] - 0s 162us/sample - loss: 0.6487 - accuracy: 0.6165 - val_loss: 0.6595 - val_accuracy: 0.6009\n",
      "Epoch 17/300\n",
      "1580/1580 [==============================] - 0s 185us/sample - loss: 0.6456 - accuracy: 0.6184 - val_loss: 0.6583 - val_accuracy: 0.6055\n",
      "Epoch 18/300\n",
      "1580/1580 [==============================] - 0s 187us/sample - loss: 0.6410 - accuracy: 0.6297 - val_loss: 0.6573 - val_accuracy: 0.6124\n",
      "Epoch 19/300\n",
      "1580/1580 [==============================] - 0s 188us/sample - loss: 0.6372 - accuracy: 0.6259 - val_loss: 0.6562 - val_accuracy: 0.6124\n",
      "Epoch 20/300\n",
      "1580/1580 [==============================] - 0s 190us/sample - loss: 0.6412 - accuracy: 0.6272 - val_loss: 0.6552 - val_accuracy: 0.6124\n",
      "Epoch 21/300\n",
      "1580/1580 [==============================] - 0s 168us/sample - loss: 0.6378 - accuracy: 0.6418 - val_loss: 0.6543 - val_accuracy: 0.6078\n",
      "Epoch 22/300\n",
      "1580/1580 [==============================] - 0s 186us/sample - loss: 0.6371 - accuracy: 0.6297 - val_loss: 0.6533 - val_accuracy: 0.6101\n",
      "Epoch 23/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.6370 - accuracy: 0.6373 - val_loss: 0.6523 - val_accuracy: 0.6147\n",
      "Epoch 24/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.6358 - accuracy: 0.6494 - val_loss: 0.6514 - val_accuracy: 0.6170\n",
      "Epoch 25/300\n",
      "1580/1580 [==============================] - 0s 175us/sample - loss: 0.6273 - accuracy: 0.6487 - val_loss: 0.6506 - val_accuracy: 0.6216\n",
      "Epoch 26/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.6282 - accuracy: 0.6475 - val_loss: 0.6497 - val_accuracy: 0.6284\n",
      "Epoch 27/300\n",
      "1580/1580 [==============================] - 0s 199us/sample - loss: 0.6293 - accuracy: 0.6506 - val_loss: 0.6489 - val_accuracy: 0.6330\n",
      "Epoch 28/300\n",
      "1580/1580 [==============================] - 0s 200us/sample - loss: 0.6292 - accuracy: 0.6532 - val_loss: 0.6480 - val_accuracy: 0.6353\n",
      "Epoch 29/300\n",
      "1580/1580 [==============================] - 0s 182us/sample - loss: 0.6255 - accuracy: 0.6709 - val_loss: 0.6472 - val_accuracy: 0.6376\n",
      "Epoch 30/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.6231 - accuracy: 0.6601 - val_loss: 0.6464 - val_accuracy: 0.6399\n",
      "Epoch 31/300\n",
      "1580/1580 [==============================] - 0s 174us/sample - loss: 0.6215 - accuracy: 0.6684 - val_loss: 0.6456 - val_accuracy: 0.6399\n",
      "Epoch 32/300\n",
      "1580/1580 [==============================] - 0s 177us/sample - loss: 0.6256 - accuracy: 0.6595 - val_loss: 0.6448 - val_accuracy: 0.6376\n",
      "Epoch 33/300\n",
      "1580/1580 [==============================] - 0s 192us/sample - loss: 0.6185 - accuracy: 0.6753 - val_loss: 0.6441 - val_accuracy: 0.6399\n",
      "Epoch 34/300\n",
      "1580/1580 [==============================] - 0s 174us/sample - loss: 0.6199 - accuracy: 0.6557 - val_loss: 0.6433 - val_accuracy: 0.6422\n",
      "Epoch 35/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.6143 - accuracy: 0.6709 - val_loss: 0.6427 - val_accuracy: 0.6445\n",
      "Epoch 36/300\n",
      "1580/1580 [==============================] - 0s 169us/sample - loss: 0.6127 - accuracy: 0.6772 - val_loss: 0.6420 - val_accuracy: 0.6445\n",
      "Epoch 37/300\n",
      "1580/1580 [==============================] - 0s 175us/sample - loss: 0.6151 - accuracy: 0.6810 - val_loss: 0.6412 - val_accuracy: 0.6445\n",
      "Epoch 38/300\n",
      "1580/1580 [==============================] - 0s 173us/sample - loss: 0.6106 - accuracy: 0.6728 - val_loss: 0.6406 - val_accuracy: 0.6445\n",
      "Epoch 39/300\n",
      "1580/1580 [==============================] - 0s 166us/sample - loss: 0.6127 - accuracy: 0.6652 - val_loss: 0.6400 - val_accuracy: 0.6468\n",
      "Epoch 40/300\n",
      "1580/1580 [==============================] - 0s 174us/sample - loss: 0.6141 - accuracy: 0.6741 - val_loss: 0.6393 - val_accuracy: 0.6422\n",
      "Epoch 41/300\n",
      "1580/1580 [==============================] - 0s 169us/sample - loss: 0.6073 - accuracy: 0.6759 - val_loss: 0.6386 - val_accuracy: 0.6468\n",
      "Epoch 42/300\n",
      "1580/1580 [==============================] - 0s 162us/sample - loss: 0.6062 - accuracy: 0.6842 - val_loss: 0.6380 - val_accuracy: 0.6468\n",
      "Epoch 43/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.6084 - accuracy: 0.6703 - val_loss: 0.6373 - val_accuracy: 0.6445\n",
      "Epoch 44/300\n",
      "1580/1580 [==============================] - 0s 182us/sample - loss: 0.6035 - accuracy: 0.6854 - val_loss: 0.6367 - val_accuracy: 0.6445\n",
      "Epoch 45/300\n",
      "1580/1580 [==============================] - 0s 200us/sample - loss: 0.6012 - accuracy: 0.6854 - val_loss: 0.6361 - val_accuracy: 0.6445\n",
      "Epoch 46/300\n",
      "1580/1580 [==============================] - 0s 195us/sample - loss: 0.5984 - accuracy: 0.6968 - val_loss: 0.6355 - val_accuracy: 0.6468\n",
      "Epoch 47/300\n",
      "1580/1580 [==============================] - 0s 180us/sample - loss: 0.5997 - accuracy: 0.6918 - val_loss: 0.6349 - val_accuracy: 0.6468\n",
      "Epoch 48/300\n",
      "1580/1580 [==============================] - 0s 180us/sample - loss: 0.6011 - accuracy: 0.6861 - val_loss: 0.6343 - val_accuracy: 0.6468\n",
      "Epoch 49/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.5976 - accuracy: 0.7063 - val_loss: 0.6337 - val_accuracy: 0.6445\n",
      "Epoch 50/300\n",
      "1580/1580 [==============================] - 0s 163us/sample - loss: 0.5899 - accuracy: 0.6981 - val_loss: 0.6331 - val_accuracy: 0.6422\n",
      "Epoch 51/300\n",
      "1580/1580 [==============================] - 0s 188us/sample - loss: 0.5960 - accuracy: 0.6899 - val_loss: 0.6326 - val_accuracy: 0.6399\n",
      "Epoch 52/300\n",
      "1580/1580 [==============================] - 0s 194us/sample - loss: 0.5918 - accuracy: 0.7133 - val_loss: 0.6320 - val_accuracy: 0.6399\n",
      "Epoch 53/300\n",
      "1580/1580 [==============================] - 0s 197us/sample - loss: 0.5921 - accuracy: 0.7025 - val_loss: 0.6314 - val_accuracy: 0.6376\n",
      "Epoch 54/300\n",
      "1580/1580 [==============================] - 0s 168us/sample - loss: 0.5947 - accuracy: 0.6880 - val_loss: 0.6309 - val_accuracy: 0.6399\n",
      "Epoch 55/300\n",
      "1580/1580 [==============================] - 0s 180us/sample - loss: 0.5886 - accuracy: 0.7000 - val_loss: 0.6303 - val_accuracy: 0.6399\n",
      "Epoch 56/300\n",
      "1580/1580 [==============================] - 0s 160us/sample - loss: 0.5900 - accuracy: 0.7063 - val_loss: 0.6298 - val_accuracy: 0.6422\n",
      "Epoch 57/300\n",
      "1580/1580 [==============================] - 0s 160us/sample - loss: 0.5863 - accuracy: 0.7032 - val_loss: 0.6293 - val_accuracy: 0.6468\n",
      "Epoch 58/300\n",
      "1580/1580 [==============================] - 0s 176us/sample - loss: 0.5811 - accuracy: 0.7127 - val_loss: 0.6288 - val_accuracy: 0.6468\n",
      "Epoch 59/300\n",
      "1580/1580 [==============================] - 0s 187us/sample - loss: 0.5819 - accuracy: 0.7171 - val_loss: 0.6283 - val_accuracy: 0.6468\n",
      "Epoch 60/300\n",
      "1580/1580 [==============================] - 0s 195us/sample - loss: 0.5812 - accuracy: 0.7146 - val_loss: 0.6277 - val_accuracy: 0.6445\n",
      "Epoch 61/300\n",
      "1580/1580 [==============================] - 0s 185us/sample - loss: 0.5861 - accuracy: 0.6987 - val_loss: 0.6272 - val_accuracy: 0.6468\n",
      "Epoch 62/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.5793 - accuracy: 0.7203 - val_loss: 0.6267 - val_accuracy: 0.6468\n",
      "Epoch 63/300\n",
      "1580/1580 [==============================] - 0s 162us/sample - loss: 0.5750 - accuracy: 0.7177 - val_loss: 0.6263 - val_accuracy: 0.6491\n",
      "Epoch 64/300\n",
      "1580/1580 [==============================] - 0s 167us/sample - loss: 0.5812 - accuracy: 0.7120 - val_loss: 0.6257 - val_accuracy: 0.6491\n",
      "Epoch 65/300\n",
      "1580/1580 [==============================] - 0s 169us/sample - loss: 0.5809 - accuracy: 0.7076 - val_loss: 0.6252 - val_accuracy: 0.6491\n",
      "Epoch 66/300\n",
      "1580/1580 [==============================] - 0s 162us/sample - loss: 0.5700 - accuracy: 0.7184 - val_loss: 0.6247 - val_accuracy: 0.6537\n",
      "Epoch 67/300\n",
      "1580/1580 [==============================] - 0s 165us/sample - loss: 0.5710 - accuracy: 0.7177 - val_loss: 0.6242 - val_accuracy: 0.6537\n",
      "Epoch 68/300\n",
      "1580/1580 [==============================] - 0s 176us/sample - loss: 0.5715 - accuracy: 0.7165 - val_loss: 0.6238 - val_accuracy: 0.6537\n",
      "Epoch 69/300\n",
      "1580/1580 [==============================] - 0s 174us/sample - loss: 0.5743 - accuracy: 0.7184 - val_loss: 0.6232 - val_accuracy: 0.6537\n",
      "Epoch 70/300\n",
      "1580/1580 [==============================] - 0s 167us/sample - loss: 0.5668 - accuracy: 0.7304 - val_loss: 0.6228 - val_accuracy: 0.6537\n",
      "Epoch 71/300\n",
      "1580/1580 [==============================] - 0s 200us/sample - loss: 0.5642 - accuracy: 0.7228 - val_loss: 0.6223 - val_accuracy: 0.6583\n",
      "Epoch 72/300\n",
      "1580/1580 [==============================] - 0s 186us/sample - loss: 0.5658 - accuracy: 0.7291 - val_loss: 0.6219 - val_accuracy: 0.6583\n",
      "Epoch 73/300\n",
      "1580/1580 [==============================] - 0s 186us/sample - loss: 0.5642 - accuracy: 0.7354 - val_loss: 0.6215 - val_accuracy: 0.6583\n",
      "Epoch 74/300\n",
      "1580/1580 [==============================] - 0s 188us/sample - loss: 0.5661 - accuracy: 0.7114 - val_loss: 0.6210 - val_accuracy: 0.6583\n",
      "Epoch 75/300\n",
      "1580/1580 [==============================] - 0s 175us/sample - loss: 0.5613 - accuracy: 0.7354 - val_loss: 0.6205 - val_accuracy: 0.6606\n",
      "Epoch 76/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.5584 - accuracy: 0.7297 - val_loss: 0.6201 - val_accuracy: 0.6628\n",
      "Epoch 77/300\n",
      "1580/1580 [==============================] - 0s 193us/sample - loss: 0.5548 - accuracy: 0.7323 - val_loss: 0.6197 - val_accuracy: 0.6628\n",
      "Epoch 78/300\n",
      "1580/1580 [==============================] - 0s 180us/sample - loss: 0.5536 - accuracy: 0.7380 - val_loss: 0.6193 - val_accuracy: 0.6628\n",
      "Epoch 79/300\n",
      "1580/1580 [==============================] - 0s 177us/sample - loss: 0.5576 - accuracy: 0.7316 - val_loss: 0.6188 - val_accuracy: 0.6628\n",
      "Epoch 80/300\n",
      "1580/1580 [==============================] - 0s 182us/sample - loss: 0.5531 - accuracy: 0.7494 - val_loss: 0.6184 - val_accuracy: 0.6628\n",
      "Epoch 81/300\n",
      "1580/1580 [==============================] - 0s 168us/sample - loss: 0.5525 - accuracy: 0.7437 - val_loss: 0.6180 - val_accuracy: 0.6606\n",
      "Epoch 82/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.5517 - accuracy: 0.7329 - val_loss: 0.6175 - val_accuracy: 0.6606\n",
      "Epoch 83/300\n",
      "1580/1580 [==============================] - 0s 192us/sample - loss: 0.5491 - accuracy: 0.7411 - val_loss: 0.6171 - val_accuracy: 0.6583\n",
      "Epoch 84/300\n",
      "1580/1580 [==============================] - 0s 181us/sample - loss: 0.5458 - accuracy: 0.7443 - val_loss: 0.6166 - val_accuracy: 0.6583\n",
      "Epoch 85/300\n",
      "1580/1580 [==============================] - 0s 168us/sample - loss: 0.5461 - accuracy: 0.7310 - val_loss: 0.6162 - val_accuracy: 0.6560\n",
      "Epoch 86/300\n",
      "1580/1580 [==============================] - 0s 167us/sample - loss: 0.5458 - accuracy: 0.7380 - val_loss: 0.6158 - val_accuracy: 0.6537\n",
      "Epoch 87/300\n",
      "1580/1580 [==============================] - 0s 168us/sample - loss: 0.5459 - accuracy: 0.7494 - val_loss: 0.6154 - val_accuracy: 0.6537\n",
      "Epoch 88/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.5424 - accuracy: 0.7443 - val_loss: 0.6150 - val_accuracy: 0.6514\n",
      "Epoch 89/300\n",
      "1580/1580 [==============================] - 0s 188us/sample - loss: 0.5441 - accuracy: 0.7392 - val_loss: 0.6146 - val_accuracy: 0.6514\n",
      "Epoch 90/300\n",
      "1580/1580 [==============================] - 0s 174us/sample - loss: 0.5467 - accuracy: 0.7373 - val_loss: 0.6142 - val_accuracy: 0.6514\n",
      "Epoch 91/300\n",
      "1580/1580 [==============================] - 0s 178us/sample - loss: 0.5409 - accuracy: 0.7494 - val_loss: 0.6138 - val_accuracy: 0.6491\n",
      "Epoch 92/300\n",
      "1580/1580 [==============================] - 0s 188us/sample - loss: 0.5387 - accuracy: 0.7399 - val_loss: 0.6134 - val_accuracy: 0.6560\n",
      "Epoch 93/300\n",
      "1580/1580 [==============================] - 0s 175us/sample - loss: 0.5354 - accuracy: 0.7481 - val_loss: 0.6130 - val_accuracy: 0.6537\n",
      "Epoch 94/300\n",
      "1580/1580 [==============================] - 0s 185us/sample - loss: 0.5351 - accuracy: 0.7399 - val_loss: 0.6126 - val_accuracy: 0.6537\n",
      "Epoch 95/300\n",
      "1580/1580 [==============================] - 0s 184us/sample - loss: 0.5295 - accuracy: 0.7525 - val_loss: 0.6122 - val_accuracy: 0.6537\n",
      "Epoch 96/300\n",
      "1580/1580 [==============================] - 0s 173us/sample - loss: 0.5320 - accuracy: 0.7481 - val_loss: 0.6118 - val_accuracy: 0.6537\n",
      "Epoch 97/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.5285 - accuracy: 0.7570 - val_loss: 0.6114 - val_accuracy: 0.6537\n",
      "Epoch 98/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.5286 - accuracy: 0.7494 - val_loss: 0.6110 - val_accuracy: 0.6583\n",
      "Epoch 99/300\n",
      "1580/1580 [==============================] - 0s 163us/sample - loss: 0.5278 - accuracy: 0.7551 - val_loss: 0.6106 - val_accuracy: 0.6583\n",
      "Epoch 100/300\n",
      "1580/1580 [==============================] - 0s 174us/sample - loss: 0.5219 - accuracy: 0.7646 - val_loss: 0.6103 - val_accuracy: 0.6583\n",
      "Epoch 101/300\n",
      "1580/1580 [==============================] - 0s 172us/sample - loss: 0.5229 - accuracy: 0.7570 - val_loss: 0.6099 - val_accuracy: 0.6606\n",
      "Epoch 102/300\n",
      "1580/1580 [==============================] - 0s 163us/sample - loss: 0.5252 - accuracy: 0.7544 - val_loss: 0.6096 - val_accuracy: 0.6606\n",
      "Epoch 103/300\n",
      "1580/1580 [==============================] - 0s 167us/sample - loss: 0.5183 - accuracy: 0.7601 - val_loss: 0.6093 - val_accuracy: 0.6606\n",
      "Epoch 104/300\n",
      "1580/1580 [==============================] - 0s 182us/sample - loss: 0.5241 - accuracy: 0.7487 - val_loss: 0.6090 - val_accuracy: 0.6606\n",
      "Epoch 105/300\n",
      "1580/1580 [==============================] - 0s 178us/sample - loss: 0.5134 - accuracy: 0.7684 - val_loss: 0.6087 - val_accuracy: 0.6606\n",
      "Epoch 106/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.5148 - accuracy: 0.7658 - val_loss: 0.6083 - val_accuracy: 0.6606\n",
      "Epoch 107/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.5099 - accuracy: 0.7715 - val_loss: 0.6080 - val_accuracy: 0.6628\n",
      "Epoch 108/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.5109 - accuracy: 0.7671 - val_loss: 0.6076 - val_accuracy: 0.6628\n",
      "Epoch 109/300\n",
      "1580/1580 [==============================] - 0s 190us/sample - loss: 0.5148 - accuracy: 0.7633 - val_loss: 0.6073 - val_accuracy: 0.6651\n",
      "Epoch 110/300\n",
      "1580/1580 [==============================] - 0s 170us/sample - loss: 0.5137 - accuracy: 0.7690 - val_loss: 0.6070 - val_accuracy: 0.6628\n",
      "Epoch 111/300\n",
      "1580/1580 [==============================] - 0s 169us/sample - loss: 0.5060 - accuracy: 0.7741 - val_loss: 0.6066 - val_accuracy: 0.6628\n",
      "Epoch 112/300\n",
      "1580/1580 [==============================] - 0s 184us/sample - loss: 0.5065 - accuracy: 0.7766 - val_loss: 0.6063 - val_accuracy: 0.6651\n",
      "Epoch 113/300\n",
      "1580/1580 [==============================] - 0s 183us/sample - loss: 0.5054 - accuracy: 0.7722 - val_loss: 0.6059 - val_accuracy: 0.6651\n",
      "Epoch 114/300\n",
      "1580/1580 [==============================] - 0s 180us/sample - loss: 0.5071 - accuracy: 0.7646 - val_loss: 0.6057 - val_accuracy: 0.6697\n",
      "Epoch 115/300\n",
      "1580/1580 [==============================] - 0s 178us/sample - loss: 0.5010 - accuracy: 0.7709 - val_loss: 0.6054 - val_accuracy: 0.6697\n",
      "Epoch 116/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.5035 - accuracy: 0.7703 - val_loss: 0.6051 - val_accuracy: 0.6720\n",
      "Epoch 117/300\n",
      "1580/1580 [==============================] - 0s 172us/sample - loss: 0.4972 - accuracy: 0.7842 - val_loss: 0.6048 - val_accuracy: 0.6743\n",
      "Epoch 118/300\n",
      "1580/1580 [==============================] - 0s 172us/sample - loss: 0.4973 - accuracy: 0.7791 - val_loss: 0.6045 - val_accuracy: 0.6743\n",
      "Epoch 119/300\n",
      "1580/1580 [==============================] - 0s 189us/sample - loss: 0.4965 - accuracy: 0.7772 - val_loss: 0.6043 - val_accuracy: 0.6743\n",
      "Epoch 120/300\n",
      "1580/1580 [==============================] - 0s 181us/sample - loss: 0.4931 - accuracy: 0.7766 - val_loss: 0.6041 - val_accuracy: 0.6743\n",
      "Epoch 121/300\n",
      "1580/1580 [==============================] - 0s 175us/sample - loss: 0.4963 - accuracy: 0.7734 - val_loss: 0.6039 - val_accuracy: 0.6720\n",
      "Epoch 122/300\n",
      "1580/1580 [==============================] - 0s 195us/sample - loss: 0.4912 - accuracy: 0.7873 - val_loss: 0.6037 - val_accuracy: 0.6697\n",
      "Epoch 123/300\n",
      "1580/1580 [==============================] - 0s 198us/sample - loss: 0.4892 - accuracy: 0.7848 - val_loss: 0.6034 - val_accuracy: 0.6720\n",
      "Epoch 124/300\n",
      "1580/1580 [==============================] - 0s 199us/sample - loss: 0.4897 - accuracy: 0.7816 - val_loss: 0.6032 - val_accuracy: 0.6697\n",
      "Epoch 125/300\n",
      "1580/1580 [==============================] - 0s 173us/sample - loss: 0.4860 - accuracy: 0.7842 - val_loss: 0.6030 - val_accuracy: 0.6720\n",
      "Epoch 126/300\n",
      "1580/1580 [==============================] - 0s 187us/sample - loss: 0.4882 - accuracy: 0.7842 - val_loss: 0.6029 - val_accuracy: 0.6743\n",
      "Epoch 127/300\n",
      "1580/1580 [==============================] - 0s 185us/sample - loss: 0.4845 - accuracy: 0.7772 - val_loss: 0.6027 - val_accuracy: 0.6766\n",
      "Epoch 128/300\n",
      "1580/1580 [==============================] - 0s 170us/sample - loss: 0.4838 - accuracy: 0.7835 - val_loss: 0.6027 - val_accuracy: 0.6789\n",
      "Epoch 129/300\n",
      "1580/1580 [==============================] - 0s 169us/sample - loss: 0.4729 - accuracy: 0.7930 - val_loss: 0.6025 - val_accuracy: 0.6766\n",
      "Epoch 130/300\n",
      "1580/1580 [==============================] - 0s 181us/sample - loss: 0.4713 - accuracy: 0.7975 - val_loss: 0.6025 - val_accuracy: 0.6766\n",
      "Epoch 131/300\n",
      "1580/1580 [==============================] - 0s 172us/sample - loss: 0.4765 - accuracy: 0.7930 - val_loss: 0.6023 - val_accuracy: 0.6766\n",
      "Epoch 132/300\n",
      "1580/1580 [==============================] - 0s 177us/sample - loss: 0.4774 - accuracy: 0.7848 - val_loss: 0.6022 - val_accuracy: 0.6766\n",
      "Epoch 133/300\n",
      "1580/1580 [==============================] - 0s 167us/sample - loss: 0.4720 - accuracy: 0.7911 - val_loss: 0.6021 - val_accuracy: 0.6766\n",
      "Epoch 134/300\n",
      "1580/1580 [==============================] - 0s 170us/sample - loss: 0.4691 - accuracy: 0.8013 - val_loss: 0.6021 - val_accuracy: 0.6766\n",
      "Epoch 135/300\n",
      "1580/1580 [==============================] - 0s 167us/sample - loss: 0.4693 - accuracy: 0.7943 - val_loss: 0.6021 - val_accuracy: 0.6766\n",
      "Epoch 136/300\n",
      "1580/1580 [==============================] - 0s 160us/sample - loss: 0.4683 - accuracy: 0.7930 - val_loss: 0.6021 - val_accuracy: 0.6766\n",
      "Epoch 137/300\n",
      "1580/1580 [==============================] - 0s 167us/sample - loss: 0.4629 - accuracy: 0.8013 - val_loss: 0.6021 - val_accuracy: 0.6766\n",
      "Epoch 138/300\n",
      "1580/1580 [==============================] - 0s 172us/sample - loss: 0.4630 - accuracy: 0.7994 - val_loss: 0.6020 - val_accuracy: 0.6766\n",
      "Epoch 139/300\n",
      "1580/1580 [==============================] - 0s 158us/sample - loss: 0.4574 - accuracy: 0.8070 - val_loss: 0.6021 - val_accuracy: 0.6766\n",
      "Epoch 140/300\n",
      "1580/1580 [==============================] - 0s 172us/sample - loss: 0.4586 - accuracy: 0.8089 - val_loss: 0.6021 - val_accuracy: 0.6743\n",
      "Epoch 141/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.4572 - accuracy: 0.8019 - val_loss: 0.6022 - val_accuracy: 0.6766\n",
      "Epoch 00141: early stopping\n",
      "223/223 [==============================] - 0s 96us/sample - loss: 0.6720 - accuracy: 0.6278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [39:37, 769.36s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:06<00:06,  6.37s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.71s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "6it [00:00, 48.65it/s]\u001b[A\n",
      "12it [00:00, 49.99it/s]\u001b[A\n",
      "16it [00:00, 38.33it/s]\u001b[A\n",
      "21it [00:00, 39.86it/s]\u001b[A\n",
      "25it [00:00, 39.06it/s]\u001b[A\n",
      "29it [00:00, 31.51it/s]\u001b[A\n",
      "33it [00:00, 32.31it/s]\u001b[A\n",
      "38it [00:01, 34.86it/s]\u001b[A\n",
      "42it [00:01, 35.65it/s]\u001b[A\n",
      "46it [00:01, 31.58it/s]\u001b[A\n",
      "50it [00:01, 32.33it/s]\u001b[A\n",
      "55it [00:01, 33.45it/s]\u001b[A\n",
      "59it [00:01, 33.49it/s]\u001b[A\n",
      "63it [00:01, 32.12it/s]\u001b[A\n",
      "72it [00:02, 35.40it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 72/72 [00:00<00:00, 2336.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 512.5703125 steps, validate for 138.46875 steps\n",
      "Epoch 1/300\n",
      "513/512 [==============================] - 15s 29ms/step - loss: 0.6798 - accuracy: 0.5834 - val_loss: 0.6621 - val_accuracy: 0.6004\n",
      "Epoch 2/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.6384 - accuracy: 0.6280 - val_loss: 0.6537 - val_accuracy: 0.6107\n",
      "Epoch 3/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.6225 - accuracy: 0.6452 - val_loss: 0.6469 - val_accuracy: 0.6199\n",
      "Epoch 4/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.6107 - accuracy: 0.6581 - val_loss: 0.6418 - val_accuracy: 0.6249\n",
      "Epoch 5/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.6010 - accuracy: 0.6679 - val_loss: 0.6400 - val_accuracy: 0.6282\n",
      "Epoch 6/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.5924 - accuracy: 0.6759 - val_loss: 0.6383 - val_accuracy: 0.6293\n",
      "Epoch 7/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.5848 - accuracy: 0.6829 - val_loss: 0.6361 - val_accuracy: 0.6329\n",
      "Epoch 8/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.5780 - accuracy: 0.6888 - val_loss: 0.6363 - val_accuracy: 0.6339\n",
      "Epoch 9/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.5716 - accuracy: 0.6957 - val_loss: 0.6358 - val_accuracy: 0.6351\n",
      "Epoch 10/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.5654 - accuracy: 0.7011 - val_loss: 0.6375 - val_accuracy: 0.6334\n",
      "Epoch 11/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.5599 - accuracy: 0.7053 - val_loss: 0.6390 - val_accuracy: 0.6323\n",
      "Epoch 12/300\n",
      "513/512 [==============================] - 14s 27ms/step - loss: 0.5544 - accuracy: 0.7110 - val_loss: 0.6365 - val_accuracy: 0.6368\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 512.5703125 steps, validate for 138.46875 steps\n",
      "Epoch 1/300\n",
      "513/512 [==============================] - 34s 66ms/step - loss: 0.5449 - accuracy: 0.7189 - val_loss: 0.6459 - val_accuracy: 0.6361\n",
      "Epoch 2/300\n",
      "513/512 [==============================] - 32s 63ms/step - loss: 0.5245 - accuracy: 0.7380 - val_loss: 0.6655 - val_accuracy: 0.6226\n",
      "Epoch 3/300\n",
      "513/512 [==============================] - 32s 63ms/step - loss: 0.5088 - accuracy: 0.7491 - val_loss: 0.6480 - val_accuracy: 0.6494\n",
      "Epoch 4/300\n",
      "513/512 [==============================] - 32s 63ms/step - loss: 0.4947 - accuracy: 0.7616 - val_loss: 0.6435 - val_accuracy: 0.6414\n",
      "Epoch 5/300\n",
      "513/512 [==============================] - 32s 63ms/step - loss: 0.4813 - accuracy: 0.7712 - val_loss: 0.6400 - val_accuracy: 0.6496\n",
      "Epoch 6/300\n",
      "513/512 [==============================] - 32s 63ms/step - loss: 0.4690 - accuracy: 0.7818 - val_loss: 0.6510 - val_accuracy: 0.6308\n",
      "Epoch 7/300\n",
      "513/512 [==============================] - 32s 63ms/step - loss: 0.4579 - accuracy: 0.7885 - val_loss: 0.6665 - val_accuracy: 0.6395\n",
      "Epoch 8/300\n",
      "513/512 [==============================] - 33s 63ms/step - loss: 0.4464 - accuracy: 0.7982 - val_loss: 0.6739 - val_accuracy: 0.6162\n",
      "Epoch 00008: early stopping\n",
      "306/306 [==============================] - 0s 914us/sample - loss: 1.3499 - accuracy: 0.3595\n",
      "287/287 [==============================] - 0s 197us/sample - loss: 1.1517 - accuracy: 0.4042\n",
      "283/283 [==============================] - 0s 202us/sample - loss: 1.0943 - accuracy: 0.4311\n",
      "281/281 [==============================] - 0s 222us/sample - loss: 1.1353 - accuracy: 0.3488\n",
      "273/273 [==============================] - 0s 203us/sample - loss: 1.0943 - accuracy: 0.3846\n",
      "266/266 [==============================] - 0s 260us/sample - loss: 1.0755 - accuracy: 0.4173\n",
      "265/265 [==============================] - 0s 234us/sample - loss: 1.0195 - accuracy: 0.4528\n",
      "262/262 [==============================] - 0s 234us/sample - loss: 1.1709 - accuracy: 0.3817\n",
      "254/254 [==============================] - 0s 235us/sample - loss: 1.1719 - accuracy: 0.3858\n",
      "248/248 [==============================] - 0s 248us/sample - loss: 1.1805 - accuracy: 0.4073\n",
      "245/245 [==============================] - 0s 218us/sample - loss: 1.1780 - accuracy: 0.3959\n",
      "247/247 [==============================] - 0s 218us/sample - loss: 1.2238 - accuracy: 0.3927\n",
      "243/243 [==============================] - 0s 219us/sample - loss: 1.2448 - accuracy: 0.3951\n",
      "243/243 [==============================] - 0s 244us/sample - loss: 1.1140 - accuracy: 0.4198\n",
      "242/242 [==============================] - 0s 214us/sample - loss: 1.1504 - accuracy: 0.3554\n",
      "243/243 [==============================] - 0s 223us/sample - loss: 1.1479 - accuracy: 0.4156\n",
      "237/237 [==============================] - 0s 230us/sample - loss: 1.0995 - accuracy: 0.4051\n",
      "240/240 [==============================] - 0s 218us/sample - loss: 1.1465 - accuracy: 0.3583\n",
      "235/235 [==============================] - 0s 216us/sample - loss: 1.2005 - accuracy: 0.3745\n",
      "232/232 [==============================] - 0s 248us/sample - loss: 1.1017 - accuracy: 0.3664\n",
      "232/232 [==============================] - 0s 238us/sample - loss: 1.2531 - accuracy: 0.3578\n",
      "227/227 [==============================] - 0s 230us/sample - loss: 1.2281 - accuracy: 0.3612\n",
      "224/224 [==============================] - 0s 1ms/sample - loss: 1.2554 - accuracy: 0.3527\n",
      "223/223 [==============================] - 0s 221us/sample - loss: 1.2701 - accuracy: 0.3453\n",
      "223/223 [==============================] - 0s 214us/sample - loss: 1.1783 - accuracy: 0.3857\n",
      "219/219 [==============================] - 0s 249us/sample - loss: 1.2037 - accuracy: 0.3744\n",
      "220/220 [==============================] - 0s 221us/sample - loss: 1.1610 - accuracy: 0.4091\n",
      "215/215 [==============================] - 0s 225us/sample - loss: 1.1718 - accuracy: 0.4326\n",
      "216/216 [==============================] - 0s 246us/sample - loss: 1.1444 - accuracy: 0.4120\n",
      "216/216 [==============================] - 0s 246us/sample - loss: 1.2249 - accuracy: 0.3704\n",
      "215/215 [==============================] - 0s 216us/sample - loss: 1.2867 - accuracy: 0.3163\n",
      "214/214 [==============================] - 0s 220us/sample - loss: 1.2461 - accuracy: 0.3925\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 1596 samples, validate on 446 samples\n",
      "Epoch 1/300\n",
      "1596/1596 [==============================] - 2s 1ms/sample - loss: 0.6781 - accuracy: 0.5576 - val_loss: 0.6870 - val_accuracy: 0.5561\n",
      "Epoch 2/300\n",
      "1596/1596 [==============================] - 0s 196us/sample - loss: 0.6695 - accuracy: 0.5777 - val_loss: 0.6832 - val_accuracy: 0.5583\n",
      "Epoch 3/300\n",
      "1596/1596 [==============================] - 0s 184us/sample - loss: 0.6637 - accuracy: 0.5902 - val_loss: 0.6803 - val_accuracy: 0.5628\n",
      "Epoch 4/300\n",
      "1596/1596 [==============================] - 0s 190us/sample - loss: 0.6551 - accuracy: 0.6015 - val_loss: 0.6780 - val_accuracy: 0.5605\n",
      "Epoch 5/300\n",
      "1596/1596 [==============================] - 0s 179us/sample - loss: 0.6514 - accuracy: 0.5990 - val_loss: 0.6759 - val_accuracy: 0.5673\n",
      "Epoch 6/300\n",
      "1596/1596 [==============================] - 0s 191us/sample - loss: 0.6553 - accuracy: 0.6009 - val_loss: 0.6742 - val_accuracy: 0.5673\n",
      "Epoch 7/300\n",
      "1596/1596 [==============================] - 0s 168us/sample - loss: 0.6470 - accuracy: 0.6159 - val_loss: 0.6725 - val_accuracy: 0.5762\n",
      "Epoch 8/300\n",
      "1596/1596 [==============================] - 0s 170us/sample - loss: 0.6425 - accuracy: 0.6109 - val_loss: 0.6709 - val_accuracy: 0.5807\n",
      "Epoch 9/300\n",
      "1596/1596 [==============================] - 0s 180us/sample - loss: 0.6359 - accuracy: 0.6366 - val_loss: 0.6696 - val_accuracy: 0.5830\n",
      "Epoch 10/300\n",
      "1596/1596 [==============================] - 0s 163us/sample - loss: 0.6324 - accuracy: 0.6222 - val_loss: 0.6681 - val_accuracy: 0.5830\n",
      "Epoch 11/300\n",
      "1596/1596 [==============================] - 0s 170us/sample - loss: 0.6334 - accuracy: 0.6447 - val_loss: 0.6669 - val_accuracy: 0.5919\n",
      "Epoch 12/300\n",
      "1596/1596 [==============================] - 0s 174us/sample - loss: 0.6258 - accuracy: 0.6410 - val_loss: 0.6656 - val_accuracy: 0.5964\n",
      "Epoch 13/300\n",
      "1596/1596 [==============================] - 0s 174us/sample - loss: 0.6199 - accuracy: 0.6554 - val_loss: 0.6645 - val_accuracy: 0.5964\n",
      "Epoch 14/300\n",
      "1596/1596 [==============================] - 0s 186us/sample - loss: 0.6313 - accuracy: 0.6303 - val_loss: 0.6633 - val_accuracy: 0.6031\n",
      "Epoch 15/300\n",
      "1596/1596 [==============================] - 0s 176us/sample - loss: 0.6187 - accuracy: 0.6523 - val_loss: 0.6622 - val_accuracy: 0.6054\n",
      "Epoch 16/300\n",
      "1596/1596 [==============================] - 0s 168us/sample - loss: 0.6216 - accuracy: 0.6548 - val_loss: 0.6611 - val_accuracy: 0.6031\n",
      "Epoch 17/300\n",
      "1596/1596 [==============================] - 0s 179us/sample - loss: 0.6185 - accuracy: 0.6454 - val_loss: 0.6600 - val_accuracy: 0.6031\n",
      "Epoch 18/300\n",
      "1596/1596 [==============================] - 0s 173us/sample - loss: 0.6087 - accuracy: 0.6736 - val_loss: 0.6590 - val_accuracy: 0.6054\n",
      "Epoch 19/300\n",
      "1596/1596 [==============================] - 0s 177us/sample - loss: 0.6130 - accuracy: 0.6548 - val_loss: 0.6580 - val_accuracy: 0.6076\n",
      "Epoch 20/300\n",
      "1596/1596 [==============================] - 0s 179us/sample - loss: 0.6125 - accuracy: 0.6685 - val_loss: 0.6571 - val_accuracy: 0.6121\n",
      "Epoch 21/300\n",
      "1596/1596 [==============================] - 0s 179us/sample - loss: 0.6103 - accuracy: 0.6692 - val_loss: 0.6562 - val_accuracy: 0.6143\n",
      "Epoch 22/300\n",
      "1596/1596 [==============================] - 0s 171us/sample - loss: 0.6040 - accuracy: 0.6698 - val_loss: 0.6552 - val_accuracy: 0.6166\n",
      "Epoch 23/300\n",
      "1596/1596 [==============================] - 0s 229us/sample - loss: 0.6079 - accuracy: 0.6585 - val_loss: 0.6543 - val_accuracy: 0.6188\n",
      "Epoch 24/300\n",
      "1596/1596 [==============================] - 0s 208us/sample - loss: 0.6036 - accuracy: 0.6792 - val_loss: 0.6534 - val_accuracy: 0.6188\n",
      "Epoch 25/300\n",
      "1596/1596 [==============================] - 0s 176us/sample - loss: 0.5994 - accuracy: 0.6905 - val_loss: 0.6525 - val_accuracy: 0.6211\n",
      "Epoch 26/300\n",
      "1596/1596 [==============================] - 0s 180us/sample - loss: 0.6010 - accuracy: 0.6748 - val_loss: 0.6517 - val_accuracy: 0.6233\n",
      "Epoch 27/300\n",
      "1596/1596 [==============================] - 0s 172us/sample - loss: 0.5939 - accuracy: 0.6773 - val_loss: 0.6509 - val_accuracy: 0.6256\n",
      "Epoch 28/300\n",
      "1596/1596 [==============================] - 0s 185us/sample - loss: 0.6005 - accuracy: 0.6836 - val_loss: 0.6500 - val_accuracy: 0.6278\n",
      "Epoch 29/300\n",
      "1596/1596 [==============================] - 0s 174us/sample - loss: 0.5894 - accuracy: 0.7024 - val_loss: 0.6491 - val_accuracy: 0.6323\n",
      "Epoch 30/300\n",
      "1596/1596 [==============================] - 0s 178us/sample - loss: 0.5911 - accuracy: 0.6855 - val_loss: 0.6483 - val_accuracy: 0.6390\n",
      "Epoch 31/300\n",
      "1596/1596 [==============================] - 0s 200us/sample - loss: 0.5908 - accuracy: 0.6855 - val_loss: 0.6475 - val_accuracy: 0.6390\n",
      "Epoch 32/300\n",
      "1596/1596 [==============================] - 0s 178us/sample - loss: 0.5855 - accuracy: 0.6880 - val_loss: 0.6467 - val_accuracy: 0.6390\n",
      "Epoch 33/300\n",
      "1596/1596 [==============================] - 0s 180us/sample - loss: 0.5842 - accuracy: 0.7011 - val_loss: 0.6459 - val_accuracy: 0.6368\n",
      "Epoch 34/300\n",
      "1596/1596 [==============================] - 0s 177us/sample - loss: 0.5781 - accuracy: 0.6974 - val_loss: 0.6451 - val_accuracy: 0.6368\n",
      "Epoch 35/300\n",
      "1596/1596 [==============================] - 0s 187us/sample - loss: 0.5818 - accuracy: 0.6986 - val_loss: 0.6443 - val_accuracy: 0.6390\n",
      "Epoch 36/300\n",
      "1596/1596 [==============================] - 0s 184us/sample - loss: 0.5765 - accuracy: 0.7155 - val_loss: 0.6436 - val_accuracy: 0.6390\n",
      "Epoch 37/300\n",
      "1596/1596 [==============================] - 0s 175us/sample - loss: 0.5746 - accuracy: 0.7074 - val_loss: 0.6428 - val_accuracy: 0.6390\n",
      "Epoch 38/300\n",
      "1596/1596 [==============================] - 0s 188us/sample - loss: 0.5750 - accuracy: 0.7061 - val_loss: 0.6420 - val_accuracy: 0.6390\n",
      "Epoch 39/300\n",
      "1596/1596 [==============================] - 0s 177us/sample - loss: 0.5701 - accuracy: 0.7180 - val_loss: 0.6413 - val_accuracy: 0.6413\n",
      "Epoch 40/300\n",
      "1596/1596 [==============================] - 0s 188us/sample - loss: 0.5710 - accuracy: 0.7124 - val_loss: 0.6405 - val_accuracy: 0.6435\n",
      "Epoch 41/300\n",
      "1596/1596 [==============================] - 0s 186us/sample - loss: 0.5689 - accuracy: 0.7124 - val_loss: 0.6397 - val_accuracy: 0.6413\n",
      "Epoch 42/300\n",
      "1596/1596 [==============================] - 0s 186us/sample - loss: 0.5661 - accuracy: 0.7168 - val_loss: 0.6390 - val_accuracy: 0.6480\n",
      "Epoch 43/300\n",
      "1596/1596 [==============================] - 0s 178us/sample - loss: 0.5646 - accuracy: 0.7237 - val_loss: 0.6382 - val_accuracy: 0.6480\n",
      "Epoch 44/300\n",
      "1596/1596 [==============================] - 0s 185us/sample - loss: 0.5649 - accuracy: 0.7143 - val_loss: 0.6375 - val_accuracy: 0.6502\n",
      "Epoch 45/300\n",
      "1596/1596 [==============================] - 0s 171us/sample - loss: 0.5610 - accuracy: 0.7281 - val_loss: 0.6367 - val_accuracy: 0.6525\n",
      "Epoch 46/300\n",
      "1596/1596 [==============================] - 0s 172us/sample - loss: 0.5588 - accuracy: 0.7312 - val_loss: 0.6359 - val_accuracy: 0.6525\n",
      "Epoch 47/300\n",
      "1596/1596 [==============================] - 0s 176us/sample - loss: 0.5567 - accuracy: 0.7212 - val_loss: 0.6352 - val_accuracy: 0.6525\n",
      "Epoch 48/300\n",
      "1596/1596 [==============================] - 0s 189us/sample - loss: 0.5530 - accuracy: 0.7306 - val_loss: 0.6344 - val_accuracy: 0.6525\n",
      "Epoch 49/300\n",
      "1596/1596 [==============================] - 0s 182us/sample - loss: 0.5567 - accuracy: 0.7299 - val_loss: 0.6337 - val_accuracy: 0.6547\n",
      "Epoch 50/300\n",
      "1596/1596 [==============================] - 0s 177us/sample - loss: 0.5496 - accuracy: 0.7481 - val_loss: 0.6330 - val_accuracy: 0.6525\n",
      "Epoch 51/300\n",
      "1596/1596 [==============================] - 0s 178us/sample - loss: 0.5463 - accuracy: 0.7387 - val_loss: 0.6323 - val_accuracy: 0.6525\n",
      "Epoch 52/300\n",
      "1596/1596 [==============================] - 0s 174us/sample - loss: 0.5497 - accuracy: 0.7356 - val_loss: 0.6315 - val_accuracy: 0.6592\n",
      "Epoch 53/300\n",
      "1596/1596 [==============================] - 0s 173us/sample - loss: 0.5450 - accuracy: 0.7481 - val_loss: 0.6308 - val_accuracy: 0.6637\n",
      "Epoch 54/300\n",
      "1596/1596 [==============================] - 0s 173us/sample - loss: 0.5417 - accuracy: 0.7487 - val_loss: 0.6301 - val_accuracy: 0.6614\n",
      "Epoch 55/300\n",
      "1596/1596 [==============================] - 0s 197us/sample - loss: 0.5421 - accuracy: 0.7406 - val_loss: 0.6294 - val_accuracy: 0.6592\n",
      "Epoch 56/300\n",
      "1596/1596 [==============================] - 0s 192us/sample - loss: 0.5415 - accuracy: 0.7419 - val_loss: 0.6287 - val_accuracy: 0.6592\n",
      "Epoch 57/300\n",
      "1596/1596 [==============================] - 0s 181us/sample - loss: 0.5376 - accuracy: 0.7462 - val_loss: 0.6280 - val_accuracy: 0.6592\n",
      "Epoch 58/300\n",
      "1596/1596 [==============================] - 0s 167us/sample - loss: 0.5368 - accuracy: 0.7500 - val_loss: 0.6273 - val_accuracy: 0.6614\n",
      "Epoch 59/300\n",
      "1596/1596 [==============================] - 0s 164us/sample - loss: 0.5314 - accuracy: 0.7600 - val_loss: 0.6266 - val_accuracy: 0.6592\n",
      "Epoch 60/300\n",
      "1596/1596 [==============================] - 0s 176us/sample - loss: 0.5312 - accuracy: 0.7638 - val_loss: 0.6259 - val_accuracy: 0.6592\n",
      "Epoch 61/300\n",
      "1596/1596 [==============================] - 0s 167us/sample - loss: 0.5282 - accuracy: 0.7594 - val_loss: 0.6252 - val_accuracy: 0.6592\n",
      "Epoch 62/300\n",
      "1596/1596 [==============================] - 0s 184us/sample - loss: 0.5302 - accuracy: 0.7538 - val_loss: 0.6246 - val_accuracy: 0.6614\n",
      "Epoch 63/300\n",
      "1596/1596 [==============================] - 0s 160us/sample - loss: 0.5258 - accuracy: 0.7563 - val_loss: 0.6238 - val_accuracy: 0.6614\n",
      "Epoch 64/300\n",
      "1596/1596 [==============================] - 0s 176us/sample - loss: 0.5192 - accuracy: 0.7644 - val_loss: 0.6232 - val_accuracy: 0.6637\n",
      "Epoch 65/300\n",
      "1596/1596 [==============================] - 0s 180us/sample - loss: 0.5239 - accuracy: 0.7657 - val_loss: 0.6225 - val_accuracy: 0.6637\n",
      "Epoch 66/300\n",
      "1596/1596 [==============================] - 0s 177us/sample - loss: 0.5203 - accuracy: 0.7531 - val_loss: 0.6218 - val_accuracy: 0.6637\n",
      "Epoch 67/300\n",
      "1596/1596 [==============================] - 0s 180us/sample - loss: 0.5119 - accuracy: 0.7813 - val_loss: 0.6212 - val_accuracy: 0.6637\n",
      "Epoch 68/300\n",
      "1596/1596 [==============================] - 0s 179us/sample - loss: 0.5129 - accuracy: 0.7719 - val_loss: 0.6205 - val_accuracy: 0.6637\n",
      "Epoch 69/300\n",
      "1596/1596 [==============================] - 0s 176us/sample - loss: 0.5082 - accuracy: 0.7845 - val_loss: 0.6198 - val_accuracy: 0.6637\n",
      "Epoch 70/300\n",
      "1596/1596 [==============================] - 0s 175us/sample - loss: 0.5132 - accuracy: 0.7707 - val_loss: 0.6191 - val_accuracy: 0.6637\n",
      "Epoch 71/300\n",
      "1596/1596 [==============================] - 0s 171us/sample - loss: 0.5072 - accuracy: 0.7807 - val_loss: 0.6185 - val_accuracy: 0.6614\n",
      "Epoch 72/300\n",
      "1596/1596 [==============================] - 0s 169us/sample - loss: 0.5063 - accuracy: 0.7838 - val_loss: 0.6178 - val_accuracy: 0.6659\n",
      "Epoch 73/300\n",
      "1596/1596 [==============================] - 0s 171us/sample - loss: 0.5075 - accuracy: 0.7851 - val_loss: 0.6172 - val_accuracy: 0.6659\n",
      "Epoch 74/300\n",
      "1596/1596 [==============================] - 0s 167us/sample - loss: 0.5046 - accuracy: 0.7738 - val_loss: 0.6165 - val_accuracy: 0.6659\n",
      "Epoch 75/300\n",
      "1596/1596 [==============================] - 0s 171us/sample - loss: 0.4958 - accuracy: 0.7863 - val_loss: 0.6159 - val_accuracy: 0.6682\n",
      "Epoch 76/300\n",
      "1596/1596 [==============================] - 0s 163us/sample - loss: 0.4968 - accuracy: 0.7857 - val_loss: 0.6153 - val_accuracy: 0.6704\n",
      "Epoch 77/300\n",
      "1596/1596 [==============================] - 0s 180us/sample - loss: 0.4952 - accuracy: 0.7820 - val_loss: 0.6146 - val_accuracy: 0.6704\n",
      "Epoch 78/300\n",
      "1596/1596 [==============================] - 0s 182us/sample - loss: 0.4907 - accuracy: 0.7995 - val_loss: 0.6140 - val_accuracy: 0.6704\n",
      "Epoch 79/300\n",
      "1596/1596 [==============================] - 0s 162us/sample - loss: 0.4917 - accuracy: 0.7876 - val_loss: 0.6133 - val_accuracy: 0.6749\n",
      "Epoch 80/300\n",
      "1596/1596 [==============================] - 0s 157us/sample - loss: 0.4847 - accuracy: 0.7945 - val_loss: 0.6128 - val_accuracy: 0.6726\n",
      "Epoch 81/300\n",
      "1596/1596 [==============================] - 0s 164us/sample - loss: 0.4873 - accuracy: 0.7995 - val_loss: 0.6122 - val_accuracy: 0.6726\n",
      "Epoch 82/300\n",
      "1596/1596 [==============================] - 0s 157us/sample - loss: 0.4876 - accuracy: 0.7914 - val_loss: 0.6115 - val_accuracy: 0.6726\n",
      "Epoch 83/300\n",
      "1596/1596 [==============================] - 0s 154us/sample - loss: 0.4829 - accuracy: 0.7932 - val_loss: 0.6109 - val_accuracy: 0.6749\n",
      "Epoch 84/300\n",
      "1596/1596 [==============================] - 0s 185us/sample - loss: 0.4830 - accuracy: 0.7932 - val_loss: 0.6103 - val_accuracy: 0.6771\n",
      "Epoch 85/300\n",
      "1596/1596 [==============================] - 0s 164us/sample - loss: 0.4733 - accuracy: 0.8145 - val_loss: 0.6098 - val_accuracy: 0.6771\n",
      "Epoch 86/300\n",
      "1596/1596 [==============================] - 0s 176us/sample - loss: 0.4708 - accuracy: 0.8139 - val_loss: 0.6092 - val_accuracy: 0.6771\n",
      "Epoch 87/300\n",
      "1596/1596 [==============================] - 0s 164us/sample - loss: 0.4712 - accuracy: 0.8145 - val_loss: 0.6086 - val_accuracy: 0.6771\n",
      "Epoch 88/300\n",
      "1596/1596 [==============================] - 0s 178us/sample - loss: 0.4727 - accuracy: 0.8026 - val_loss: 0.6081 - val_accuracy: 0.6771\n",
      "Epoch 89/300\n",
      "1596/1596 [==============================] - 0s 186us/sample - loss: 0.4686 - accuracy: 0.8064 - val_loss: 0.6075 - val_accuracy: 0.6794\n",
      "Epoch 90/300\n",
      "1596/1596 [==============================] - 0s 173us/sample - loss: 0.4653 - accuracy: 0.8083 - val_loss: 0.6070 - val_accuracy: 0.6794\n",
      "Epoch 91/300\n",
      "1596/1596 [==============================] - 0s 159us/sample - loss: 0.4640 - accuracy: 0.8158 - val_loss: 0.6064 - val_accuracy: 0.6839\n",
      "Epoch 92/300\n",
      "1596/1596 [==============================] - 0s 180us/sample - loss: 0.4604 - accuracy: 0.8133 - val_loss: 0.6059 - val_accuracy: 0.6861\n",
      "Epoch 93/300\n",
      "1596/1596 [==============================] - 0s 170us/sample - loss: 0.4591 - accuracy: 0.8102 - val_loss: 0.6053 - val_accuracy: 0.6839\n",
      "Epoch 94/300\n",
      "1596/1596 [==============================] - 0s 172us/sample - loss: 0.4518 - accuracy: 0.8208 - val_loss: 0.6048 - val_accuracy: 0.6861\n",
      "Epoch 95/300\n",
      "1596/1596 [==============================] - 0s 163us/sample - loss: 0.4578 - accuracy: 0.8183 - val_loss: 0.6043 - val_accuracy: 0.6883\n",
      "Epoch 96/300\n",
      "1596/1596 [==============================] - 0s 170us/sample - loss: 0.4464 - accuracy: 0.8308 - val_loss: 0.6039 - val_accuracy: 0.6883\n",
      "Epoch 97/300\n",
      "1596/1596 [==============================] - 0s 166us/sample - loss: 0.4509 - accuracy: 0.8202 - val_loss: 0.6034 - val_accuracy: 0.6883\n",
      "Epoch 98/300\n",
      "1596/1596 [==============================] - 0s 171us/sample - loss: 0.4456 - accuracy: 0.8283 - val_loss: 0.6029 - val_accuracy: 0.6906\n",
      "Epoch 99/300\n",
      "1596/1596 [==============================] - 0s 162us/sample - loss: 0.4442 - accuracy: 0.8208 - val_loss: 0.6024 - val_accuracy: 0.6951\n",
      "Epoch 100/300\n",
      "1596/1596 [==============================] - 0s 161us/sample - loss: 0.4428 - accuracy: 0.8321 - val_loss: 0.6020 - val_accuracy: 0.6951\n",
      "Epoch 101/300\n",
      "1596/1596 [==============================] - 0s 164us/sample - loss: 0.4363 - accuracy: 0.8321 - val_loss: 0.6016 - val_accuracy: 0.6951\n",
      "Epoch 102/300\n",
      "1596/1596 [==============================] - 0s 158us/sample - loss: 0.4299 - accuracy: 0.8471 - val_loss: 0.6012 - val_accuracy: 0.6951\n",
      "Epoch 103/300\n",
      "1596/1596 [==============================] - 0s 168us/sample - loss: 0.4324 - accuracy: 0.8333 - val_loss: 0.6007 - val_accuracy: 0.6951\n",
      "Epoch 104/300\n",
      "1596/1596 [==============================] - 0s 177us/sample - loss: 0.4307 - accuracy: 0.8321 - val_loss: 0.6003 - val_accuracy: 0.6951\n",
      "Epoch 105/300\n",
      "1596/1596 [==============================] - 0s 162us/sample - loss: 0.4319 - accuracy: 0.8277 - val_loss: 0.5999 - val_accuracy: 0.6951\n",
      "Epoch 106/300\n",
      "1596/1596 [==============================] - 0s 158us/sample - loss: 0.4222 - accuracy: 0.8427 - val_loss: 0.5995 - val_accuracy: 0.6951\n",
      "Epoch 107/300\n",
      "1596/1596 [==============================] - 0s 168us/sample - loss: 0.4213 - accuracy: 0.8402 - val_loss: 0.5991 - val_accuracy: 0.6951\n",
      "Epoch 108/300\n",
      "1596/1596 [==============================] - 0s 168us/sample - loss: 0.4212 - accuracy: 0.8434 - val_loss: 0.5987 - val_accuracy: 0.6951\n",
      "Epoch 109/300\n",
      "1596/1596 [==============================] - 0s 167us/sample - loss: 0.4194 - accuracy: 0.8434 - val_loss: 0.5984 - val_accuracy: 0.6951\n",
      "Epoch 110/300\n",
      "1596/1596 [==============================] - 0s 164us/sample - loss: 0.4172 - accuracy: 0.8515 - val_loss: 0.5981 - val_accuracy: 0.6973\n",
      "Epoch 111/300\n",
      "1596/1596 [==============================] - 0s 173us/sample - loss: 0.4083 - accuracy: 0.8490 - val_loss: 0.5979 - val_accuracy: 0.6951\n",
      "Epoch 112/300\n",
      "1596/1596 [==============================] - 0s 169us/sample - loss: 0.4071 - accuracy: 0.8534 - val_loss: 0.5975 - val_accuracy: 0.6973\n",
      "Epoch 113/300\n",
      "1596/1596 [==============================] - 0s 168us/sample - loss: 0.4075 - accuracy: 0.8521 - val_loss: 0.5972 - val_accuracy: 0.6973\n",
      "Epoch 114/300\n",
      "1596/1596 [==============================] - 0s 174us/sample - loss: 0.4008 - accuracy: 0.8578 - val_loss: 0.5969 - val_accuracy: 0.6973\n",
      "Epoch 115/300\n",
      "1596/1596 [==============================] - 0s 167us/sample - loss: 0.4003 - accuracy: 0.8496 - val_loss: 0.5968 - val_accuracy: 0.6951\n",
      "Epoch 116/300\n",
      "1596/1596 [==============================] - 0s 167us/sample - loss: 0.3989 - accuracy: 0.8565 - val_loss: 0.5965 - val_accuracy: 0.6951\n",
      "Epoch 117/300\n",
      "1596/1596 [==============================] - 0s 167us/sample - loss: 0.3948 - accuracy: 0.8571 - val_loss: 0.5963 - val_accuracy: 0.6951\n",
      "Epoch 118/300\n",
      "1596/1596 [==============================] - 0s 170us/sample - loss: 0.3902 - accuracy: 0.8628 - val_loss: 0.5962 - val_accuracy: 0.6928\n",
      "Epoch 119/300\n",
      "1596/1596 [==============================] - 0s 181us/sample - loss: 0.3925 - accuracy: 0.8559 - val_loss: 0.5960 - val_accuracy: 0.6951\n",
      "Epoch 120/300\n",
      "1596/1596 [==============================] - 0s 176us/sample - loss: 0.3866 - accuracy: 0.8647 - val_loss: 0.5959 - val_accuracy: 0.6928\n",
      "Epoch 121/300\n",
      "1596/1596 [==============================] - 0s 179us/sample - loss: 0.3860 - accuracy: 0.8697 - val_loss: 0.5958 - val_accuracy: 0.6906\n",
      "Epoch 122/300\n",
      "1596/1596 [==============================] - 0s 178us/sample - loss: 0.3759 - accuracy: 0.8734 - val_loss: 0.5956 - val_accuracy: 0.6883\n",
      "Epoch 123/300\n",
      "1596/1596 [==============================] - 0s 174us/sample - loss: 0.3775 - accuracy: 0.8659 - val_loss: 0.5956 - val_accuracy: 0.6906\n",
      "Epoch 124/300\n",
      "1596/1596 [==============================] - 0s 176us/sample - loss: 0.3806 - accuracy: 0.8603 - val_loss: 0.5956 - val_accuracy: 0.6906\n",
      "Epoch 125/300\n",
      "1596/1596 [==============================] - 0s 167us/sample - loss: 0.3691 - accuracy: 0.8778 - val_loss: 0.5955 - val_accuracy: 0.6906\n",
      "Epoch 126/300\n",
      "1596/1596 [==============================] - 0s 183us/sample - loss: 0.3724 - accuracy: 0.8665 - val_loss: 0.5956 - val_accuracy: 0.6906\n",
      "Epoch 127/300\n",
      "1596/1596 [==============================] - 0s 181us/sample - loss: 0.3654 - accuracy: 0.8734 - val_loss: 0.5955 - val_accuracy: 0.6928\n",
      "Epoch 128/300\n",
      "1596/1596 [==============================] - 0s 177us/sample - loss: 0.3685 - accuracy: 0.8697 - val_loss: 0.5956 - val_accuracy: 0.6928\n",
      "Epoch 129/300\n",
      "1596/1596 [==============================] - 0s 176us/sample - loss: 0.3660 - accuracy: 0.8703 - val_loss: 0.5957 - val_accuracy: 0.6928\n",
      "Epoch 130/300\n",
      "1596/1596 [==============================] - 0s 171us/sample - loss: 0.3612 - accuracy: 0.8772 - val_loss: 0.5958 - val_accuracy: 0.6951\n",
      "Epoch 00130: early stopping\n",
      "197/197 [==============================] - 0s 113us/sample - loss: 1.2466 - accuracy: 0.3249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [52:49, 776.11s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:05<00:05,  5.32s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.29s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "6it [00:00, 53.09it/s]\u001b[A\n",
      "12it [00:00, 52.81it/s]\u001b[A\n",
      "16it [00:00, 43.11it/s]\u001b[A\n",
      "21it [00:00, 42.44it/s]\u001b[A\n",
      "25it [00:00, 35.69it/s]\u001b[A\n",
      "29it [00:00, 33.74it/s]\u001b[A\n",
      "33it [00:00, 34.58it/s]\u001b[A\n",
      "38it [00:00, 37.27it/s]\u001b[A\n",
      "43it [00:01, 39.92it/s]\u001b[A\n",
      "47it [00:01, 37.03it/s]\u001b[A\n",
      "51it [00:01, 32.94it/s]\u001b[A\n",
      "55it [00:01, 34.18it/s]\u001b[A\n",
      "59it [00:01, 33.31it/s]\u001b[A\n",
      "63it [00:01, 33.02it/s]\u001b[A\n",
      "72it [00:01, 37.14it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 72/72 [00:00<00:00, 2232.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 506.0625 steps, validate for 136.7890625 steps\n",
      "Epoch 1/300\n",
      "507/506 [==============================] - 15s 30ms/step - loss: 0.6916 - accuracy: 0.5672 - val_loss: 0.6717 - val_accuracy: 0.5928\n",
      "Epoch 2/300\n",
      "507/506 [==============================] - 14s 27ms/step - loss: 0.6498 - accuracy: 0.6181 - val_loss: 0.6641 - val_accuracy: 0.6064\n",
      "Epoch 3/300\n",
      "507/506 [==============================] - 14s 27ms/step - loss: 0.6329 - accuracy: 0.6392 - val_loss: 0.6562 - val_accuracy: 0.6159\n",
      "Epoch 4/300\n",
      "507/506 [==============================] - 14s 27ms/step - loss: 0.6206 - accuracy: 0.6534 - val_loss: 0.6535 - val_accuracy: 0.6208\n",
      "Epoch 5/300\n",
      "507/506 [==============================] - 14s 27ms/step - loss: 0.6104 - accuracy: 0.6633 - val_loss: 0.6523 - val_accuracy: 0.6261\n",
      "Epoch 6/300\n",
      "507/506 [==============================] - 14s 27ms/step - loss: 0.6020 - accuracy: 0.6709 - val_loss: 0.6531 - val_accuracy: 0.6172\n",
      "Epoch 7/300\n",
      "507/506 [==============================] - 14s 27ms/step - loss: 0.5944 - accuracy: 0.6790 - val_loss: 0.6502 - val_accuracy: 0.6248\n",
      "Epoch 8/300\n",
      "507/506 [==============================] - 14s 27ms/step - loss: 0.5875 - accuracy: 0.6839 - val_loss: 0.6505 - val_accuracy: 0.6262\n",
      "Epoch 9/300\n",
      "507/506 [==============================] - 14s 27ms/step - loss: 0.5813 - accuracy: 0.6890 - val_loss: 0.6536 - val_accuracy: 0.6188\n",
      "Epoch 10/300\n",
      "507/506 [==============================] - 14s 27ms/step - loss: 0.5757 - accuracy: 0.6950 - val_loss: 0.6556 - val_accuracy: 0.6179\n",
      "Epoch 00010: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 506.0625 steps, validate for 136.7890625 steps\n",
      "Epoch 1/300\n",
      "507/506 [==============================] - 33s 66ms/step - loss: 0.5661 - accuracy: 0.7037 - val_loss: 0.6726 - val_accuracy: 0.6036\n",
      "Epoch 2/300\n",
      "507/506 [==============================] - 32s 63ms/step - loss: 0.5455 - accuracy: 0.7219 - val_loss: 0.6572 - val_accuracy: 0.6314\n",
      "Epoch 3/300\n",
      "507/506 [==============================] - 32s 63ms/step - loss: 0.5293 - accuracy: 0.7357 - val_loss: 0.6540 - val_accuracy: 0.6220\n",
      "Epoch 4/300\n",
      "507/506 [==============================] - 32s 62ms/step - loss: 0.5147 - accuracy: 0.7478 - val_loss: 0.6626 - val_accuracy: 0.6212\n",
      "Epoch 5/300\n",
      "507/506 [==============================] - 32s 63ms/step - loss: 0.5006 - accuracy: 0.7580 - val_loss: 0.6771 - val_accuracy: 0.6189\n",
      "Epoch 6/300\n",
      "507/506 [==============================] - 32s 63ms/step - loss: 0.4877 - accuracy: 0.7692 - val_loss: 0.6523 - val_accuracy: 0.6325\n",
      "Epoch 7/300\n",
      "507/506 [==============================] - 32s 63ms/step - loss: 0.4761 - accuracy: 0.7770 - val_loss: 0.6617 - val_accuracy: 0.6341\n",
      "Epoch 8/300\n",
      "507/506 [==============================] - 32s 63ms/step - loss: 0.4643 - accuracy: 0.7859 - val_loss: 0.6610 - val_accuracy: 0.6301\n",
      "Epoch 9/300\n",
      "507/506 [==============================] - 32s 63ms/step - loss: 0.4533 - accuracy: 0.7952 - val_loss: 0.6615 - val_accuracy: 0.6306\n",
      "Epoch 00009: early stopping\n",
      "360/360 [==============================] - 0s 712us/sample - loss: 0.9591 - accuracy: 0.4250\n",
      "335/335 [==============================] - 0s 212us/sample - loss: 0.9086 - accuracy: 0.4149\n",
      "327/327 [==============================] - 0s 213us/sample - loss: 0.8802 - accuracy: 0.4618\n",
      "320/320 [==============================] - 0s 672us/sample - loss: 0.8883 - accuracy: 0.4375\n",
      "312/312 [==============================] - 0s 201us/sample - loss: 0.8953 - accuracy: 0.4359\n",
      "307/307 [==============================] - 0s 239us/sample - loss: 0.8905 - accuracy: 0.4169\n",
      "304/304 [==============================] - 0s 259us/sample - loss: 0.8719 - accuracy: 0.4539\n",
      "297/297 [==============================] - 0s 257us/sample - loss: 0.8723 - accuracy: 0.4411\n",
      "297/297 [==============================] - 0s 223us/sample - loss: 0.8533 - accuracy: 0.4377\n",
      "291/291 [==============================] - 0s 236us/sample - loss: 0.8849 - accuracy: 0.4777\n",
      "284/284 [==============================] - 0s 249us/sample - loss: 0.9010 - accuracy: 0.4542\n",
      "283/283 [==============================] - 0s 211us/sample - loss: 0.8951 - accuracy: 0.4452\n",
      "282/282 [==============================] - 0s 212us/sample - loss: 0.8539 - accuracy: 0.4539\n",
      "277/277 [==============================] - 0s 213us/sample - loss: 0.8291 - accuracy: 0.4693\n",
      "279/279 [==============================] - 0s 210us/sample - loss: 0.8585 - accuracy: 0.4803\n",
      "270/270 [==============================] - 0s 227us/sample - loss: 0.8508 - accuracy: 0.4889\n",
      "265/265 [==============================] - 0s 257us/sample - loss: 0.8638 - accuracy: 0.4868\n",
      "266/266 [==============================] - 0s 232us/sample - loss: 0.8367 - accuracy: 0.5038\n",
      "266/266 [==============================] - 0s 215us/sample - loss: 0.8367 - accuracy: 0.5226\n",
      "264/264 [==============================] - 0s 214us/sample - loss: 0.8514 - accuracy: 0.4848\n",
      "258/258 [==============================] - 0s 215us/sample - loss: 0.8579 - accuracy: 0.4767\n",
      "255/255 [==============================] - 0s 216us/sample - loss: 0.8532 - accuracy: 0.4549\n",
      "255/255 [==============================] - 0s 208us/sample - loss: 0.8120 - accuracy: 0.5176\n",
      "254/254 [==============================] - 0s 239us/sample - loss: 0.8306 - accuracy: 0.4961\n",
      "246/246 [==============================] - 0s 222us/sample - loss: 0.8472 - accuracy: 0.5203\n",
      "242/242 [==============================] - 0s 237us/sample - loss: 0.8534 - accuracy: 0.5289\n",
      "242/242 [==============================] - 0s 275us/sample - loss: 0.8266 - accuracy: 0.4876\n",
      "240/240 [==============================] - 0s 244us/sample - loss: 0.8156 - accuracy: 0.5167\n",
      "238/238 [==============================] - 0s 236us/sample - loss: 0.8053 - accuracy: 0.5042\n",
      "239/239 [==============================] - 0s 242us/sample - loss: 0.8897 - accuracy: 0.4603\n",
      "235/235 [==============================] - 0s 237us/sample - loss: 0.8492 - accuracy: 0.4851\n",
      "234/234 [==============================] - 0s 226us/sample - loss: 0.8411 - accuracy: 0.5000\n",
      "Saved_feature_train\n",
      "Saved_feature_test\n",
      "Saved_feature_validation\n",
      "Train on 1580 samples, validate on 444 samples\n",
      "Epoch 1/300\n",
      "1580/1580 [==============================] - 2s 1ms/sample - loss: 0.7434 - accuracy: 0.4715 - val_loss: 0.7079 - val_accuracy: 0.5158\n",
      "Epoch 2/300\n",
      "1580/1580 [==============================] - 0s 186us/sample - loss: 0.7203 - accuracy: 0.5108 - val_loss: 0.7012 - val_accuracy: 0.5248\n",
      "Epoch 3/300\n",
      "1580/1580 [==============================] - 0s 177us/sample - loss: 0.7081 - accuracy: 0.5215 - val_loss: 0.6963 - val_accuracy: 0.5473\n",
      "Epoch 4/300\n",
      "1580/1580 [==============================] - 0s 169us/sample - loss: 0.7080 - accuracy: 0.5120 - val_loss: 0.6925 - val_accuracy: 0.5563\n",
      "Epoch 5/300\n",
      "1580/1580 [==============================] - 0s 172us/sample - loss: 0.6977 - accuracy: 0.5367 - val_loss: 0.6889 - val_accuracy: 0.5608\n",
      "Epoch 6/300\n",
      "1580/1580 [==============================] - 0s 178us/sample - loss: 0.6902 - accuracy: 0.5449 - val_loss: 0.6860 - val_accuracy: 0.5586\n",
      "Epoch 7/300\n",
      "1580/1580 [==============================] - 0s 182us/sample - loss: 0.6807 - accuracy: 0.5563 - val_loss: 0.6832 - val_accuracy: 0.5586\n",
      "Epoch 8/300\n",
      "1580/1580 [==============================] - 0s 170us/sample - loss: 0.6781 - accuracy: 0.5728 - val_loss: 0.6807 - val_accuracy: 0.5653\n",
      "Epoch 9/300\n",
      "1580/1580 [==============================] - 0s 188us/sample - loss: 0.6738 - accuracy: 0.5728 - val_loss: 0.6783 - val_accuracy: 0.5743\n",
      "Epoch 10/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.6740 - accuracy: 0.5690 - val_loss: 0.6762 - val_accuracy: 0.5788\n",
      "Epoch 11/300\n",
      "1580/1580 [==============================] - 0s 184us/sample - loss: 0.6651 - accuracy: 0.5949 - val_loss: 0.6740 - val_accuracy: 0.5811\n",
      "Epoch 12/300\n",
      "1580/1580 [==============================] - 0s 184us/sample - loss: 0.6648 - accuracy: 0.5823 - val_loss: 0.6721 - val_accuracy: 0.5811\n",
      "Epoch 13/300\n",
      "1580/1580 [==============================] - 0s 190us/sample - loss: 0.6593 - accuracy: 0.5924 - val_loss: 0.6702 - val_accuracy: 0.5923\n",
      "Epoch 14/300\n",
      "1580/1580 [==============================] - 0s 187us/sample - loss: 0.6561 - accuracy: 0.6044 - val_loss: 0.6684 - val_accuracy: 0.5991\n",
      "Epoch 15/300\n",
      "1580/1580 [==============================] - 0s 191us/sample - loss: 0.6490 - accuracy: 0.6190 - val_loss: 0.6666 - val_accuracy: 0.6059\n",
      "Epoch 16/300\n",
      "1580/1580 [==============================] - 0s 194us/sample - loss: 0.6487 - accuracy: 0.6133 - val_loss: 0.6650 - val_accuracy: 0.6059\n",
      "Epoch 17/300\n",
      "1580/1580 [==============================] - 0s 170us/sample - loss: 0.6443 - accuracy: 0.6247 - val_loss: 0.6633 - val_accuracy: 0.6104\n",
      "Epoch 18/300\n",
      "1580/1580 [==============================] - 0s 167us/sample - loss: 0.6385 - accuracy: 0.6310 - val_loss: 0.6617 - val_accuracy: 0.6126\n",
      "Epoch 19/300\n",
      "1580/1580 [==============================] - 0s 184us/sample - loss: 0.6401 - accuracy: 0.6310 - val_loss: 0.6603 - val_accuracy: 0.6081\n",
      "Epoch 20/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.6359 - accuracy: 0.6411 - val_loss: 0.6587 - val_accuracy: 0.6149\n",
      "Epoch 21/300\n",
      "1580/1580 [==============================] - 0s 173us/sample - loss: 0.6341 - accuracy: 0.6392 - val_loss: 0.6573 - val_accuracy: 0.6149\n",
      "Epoch 22/300\n",
      "1580/1580 [==============================] - 0s 180us/sample - loss: 0.6313 - accuracy: 0.6405 - val_loss: 0.6558 - val_accuracy: 0.6171\n",
      "Epoch 23/300\n",
      "1580/1580 [==============================] - 0s 170us/sample - loss: 0.6221 - accuracy: 0.6684 - val_loss: 0.6545 - val_accuracy: 0.6216\n",
      "Epoch 24/300\n",
      "1580/1580 [==============================] - 0s 172us/sample - loss: 0.6223 - accuracy: 0.6475 - val_loss: 0.6532 - val_accuracy: 0.6261\n",
      "Epoch 25/300\n",
      "1580/1580 [==============================] - 0s 174us/sample - loss: 0.6198 - accuracy: 0.6652 - val_loss: 0.6518 - val_accuracy: 0.6261\n",
      "Epoch 26/300\n",
      "1580/1580 [==============================] - 0s 185us/sample - loss: 0.6185 - accuracy: 0.6677 - val_loss: 0.6505 - val_accuracy: 0.6284\n",
      "Epoch 27/300\n",
      "1580/1580 [==============================] - 0s 181us/sample - loss: 0.6146 - accuracy: 0.6804 - val_loss: 0.6492 - val_accuracy: 0.6261\n",
      "Epoch 28/300\n",
      "1580/1580 [==============================] - 0s 177us/sample - loss: 0.6129 - accuracy: 0.6816 - val_loss: 0.6480 - val_accuracy: 0.6284\n",
      "Epoch 29/300\n",
      "1580/1580 [==============================] - 0s 174us/sample - loss: 0.6048 - accuracy: 0.6943 - val_loss: 0.6467 - val_accuracy: 0.6329\n",
      "Epoch 30/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.6082 - accuracy: 0.6741 - val_loss: 0.6455 - val_accuracy: 0.6351\n",
      "Epoch 31/300\n",
      "1580/1580 [==============================] - 0s 174us/sample - loss: 0.6087 - accuracy: 0.6785 - val_loss: 0.6443 - val_accuracy: 0.6351\n",
      "Epoch 32/300\n",
      "1580/1580 [==============================] - 0s 187us/sample - loss: 0.5994 - accuracy: 0.6937 - val_loss: 0.6432 - val_accuracy: 0.6374\n",
      "Epoch 33/300\n",
      "1580/1580 [==============================] - 0s 168us/sample - loss: 0.5985 - accuracy: 0.7006 - val_loss: 0.6420 - val_accuracy: 0.6374\n",
      "Epoch 34/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.5952 - accuracy: 0.6924 - val_loss: 0.6408 - val_accuracy: 0.6374\n",
      "Epoch 35/300\n",
      "1580/1580 [==============================] - 0s 163us/sample - loss: 0.5971 - accuracy: 0.6975 - val_loss: 0.6397 - val_accuracy: 0.6351\n",
      "Epoch 36/300\n",
      "1580/1580 [==============================] - 0s 173us/sample - loss: 0.5939 - accuracy: 0.7057 - val_loss: 0.6385 - val_accuracy: 0.6419\n",
      "Epoch 37/300\n",
      "1580/1580 [==============================] - 0s 185us/sample - loss: 0.5947 - accuracy: 0.7057 - val_loss: 0.6374 - val_accuracy: 0.6532\n",
      "Epoch 38/300\n",
      "1580/1580 [==============================] - 0s 194us/sample - loss: 0.5906 - accuracy: 0.7038 - val_loss: 0.6363 - val_accuracy: 0.6554\n",
      "Epoch 39/300\n",
      "1580/1580 [==============================] - 0s 210us/sample - loss: 0.5815 - accuracy: 0.7297 - val_loss: 0.6351 - val_accuracy: 0.6554\n",
      "Epoch 40/300\n",
      "1580/1580 [==============================] - 0s 186us/sample - loss: 0.5843 - accuracy: 0.7095 - val_loss: 0.6341 - val_accuracy: 0.6599\n",
      "Epoch 41/300\n",
      "1580/1580 [==============================] - 0s 183us/sample - loss: 0.5760 - accuracy: 0.7266 - val_loss: 0.6330 - val_accuracy: 0.6599\n",
      "Epoch 42/300\n",
      "1580/1580 [==============================] - 0s 170us/sample - loss: 0.5802 - accuracy: 0.7177 - val_loss: 0.6319 - val_accuracy: 0.6577\n",
      "Epoch 43/300\n",
      "1580/1580 [==============================] - 0s 180us/sample - loss: 0.5727 - accuracy: 0.7266 - val_loss: 0.6309 - val_accuracy: 0.6644\n",
      "Epoch 44/300\n",
      "1580/1580 [==============================] - 0s 170us/sample - loss: 0.5713 - accuracy: 0.7272 - val_loss: 0.6298 - val_accuracy: 0.6734\n",
      "Epoch 45/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.5717 - accuracy: 0.7361 - val_loss: 0.6288 - val_accuracy: 0.6734\n",
      "Epoch 46/300\n",
      "1580/1580 [==============================] - 0s 168us/sample - loss: 0.5681 - accuracy: 0.7329 - val_loss: 0.6278 - val_accuracy: 0.6757\n",
      "Epoch 47/300\n",
      "1580/1580 [==============================] - 0s 165us/sample - loss: 0.5659 - accuracy: 0.7348 - val_loss: 0.6268 - val_accuracy: 0.6824\n",
      "Epoch 48/300\n",
      "1580/1580 [==============================] - 0s 216us/sample - loss: 0.5629 - accuracy: 0.7418 - val_loss: 0.6258 - val_accuracy: 0.6802\n",
      "Epoch 49/300\n",
      "1580/1580 [==============================] - 0s 175us/sample - loss: 0.5628 - accuracy: 0.7411 - val_loss: 0.6248 - val_accuracy: 0.6802\n",
      "Epoch 50/300\n",
      "1580/1580 [==============================] - 0s 185us/sample - loss: 0.5594 - accuracy: 0.7544 - val_loss: 0.6238 - val_accuracy: 0.6779\n",
      "Epoch 51/300\n",
      "1580/1580 [==============================] - 0s 175us/sample - loss: 0.5567 - accuracy: 0.7538 - val_loss: 0.6228 - val_accuracy: 0.6734\n",
      "Epoch 52/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.5551 - accuracy: 0.7519 - val_loss: 0.6219 - val_accuracy: 0.6734\n",
      "Epoch 53/300\n",
      "1580/1580 [==============================] - 0s 189us/sample - loss: 0.5463 - accuracy: 0.7563 - val_loss: 0.6208 - val_accuracy: 0.6757\n",
      "Epoch 54/300\n",
      "1580/1580 [==============================] - 0s 186us/sample - loss: 0.5510 - accuracy: 0.7525 - val_loss: 0.6199 - val_accuracy: 0.6734\n",
      "Epoch 55/300\n",
      "1580/1580 [==============================] - 0s 196us/sample - loss: 0.5486 - accuracy: 0.7582 - val_loss: 0.6190 - val_accuracy: 0.6757\n",
      "Epoch 56/300\n",
      "1580/1580 [==============================] - 0s 189us/sample - loss: 0.5454 - accuracy: 0.7576 - val_loss: 0.6180 - val_accuracy: 0.6779\n",
      "Epoch 57/300\n",
      "1580/1580 [==============================] - 0s 195us/sample - loss: 0.5423 - accuracy: 0.7715 - val_loss: 0.6171 - val_accuracy: 0.6779\n",
      "Epoch 58/300\n",
      "1580/1580 [==============================] - 0s 192us/sample - loss: 0.5380 - accuracy: 0.7759 - val_loss: 0.6161 - val_accuracy: 0.6824\n",
      "Epoch 59/300\n",
      "1580/1580 [==============================] - 0s 180us/sample - loss: 0.5384 - accuracy: 0.7690 - val_loss: 0.6152 - val_accuracy: 0.6824\n",
      "Epoch 60/300\n",
      "1580/1580 [==============================] - 0s 169us/sample - loss: 0.5388 - accuracy: 0.7665 - val_loss: 0.6142 - val_accuracy: 0.6847\n",
      "Epoch 61/300\n",
      "1580/1580 [==============================] - 0s 167us/sample - loss: 0.5302 - accuracy: 0.7835 - val_loss: 0.6133 - val_accuracy: 0.6847\n",
      "Epoch 62/300\n",
      "1580/1580 [==============================] - 0s 168us/sample - loss: 0.5301 - accuracy: 0.7810 - val_loss: 0.6124 - val_accuracy: 0.6847\n",
      "Epoch 63/300\n",
      "1580/1580 [==============================] - 0s 178us/sample - loss: 0.5281 - accuracy: 0.7766 - val_loss: 0.6114 - val_accuracy: 0.6847\n",
      "Epoch 64/300\n",
      "1580/1580 [==============================] - 0s 185us/sample - loss: 0.5273 - accuracy: 0.7709 - val_loss: 0.6105 - val_accuracy: 0.6892\n",
      "Epoch 65/300\n",
      "1580/1580 [==============================] - 0s 178us/sample - loss: 0.5285 - accuracy: 0.7861 - val_loss: 0.6096 - val_accuracy: 0.6892\n",
      "Epoch 66/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.5228 - accuracy: 0.7848 - val_loss: 0.6087 - val_accuracy: 0.6892\n",
      "Epoch 67/300\n",
      "1580/1580 [==============================] - 0s 169us/sample - loss: 0.5168 - accuracy: 0.7766 - val_loss: 0.6078 - val_accuracy: 0.6937\n",
      "Epoch 68/300\n",
      "1580/1580 [==============================] - 0s 182us/sample - loss: 0.5162 - accuracy: 0.7918 - val_loss: 0.6069 - val_accuracy: 0.6959\n",
      "Epoch 69/300\n",
      "1580/1580 [==============================] - 0s 175us/sample - loss: 0.5167 - accuracy: 0.7905 - val_loss: 0.6060 - val_accuracy: 0.6982\n",
      "Epoch 70/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.5131 - accuracy: 0.7816 - val_loss: 0.6052 - val_accuracy: 0.7005\n",
      "Epoch 71/300\n",
      "1580/1580 [==============================] - 0s 181us/sample - loss: 0.5119 - accuracy: 0.7880 - val_loss: 0.6043 - val_accuracy: 0.6982\n",
      "Epoch 72/300\n",
      "1580/1580 [==============================] - 0s 183us/sample - loss: 0.5097 - accuracy: 0.7867 - val_loss: 0.6035 - val_accuracy: 0.6982\n",
      "Epoch 73/300\n",
      "1580/1580 [==============================] - 0s 195us/sample - loss: 0.5031 - accuracy: 0.7949 - val_loss: 0.6027 - val_accuracy: 0.7005\n",
      "Epoch 74/300\n",
      "1580/1580 [==============================] - 0s 167us/sample - loss: 0.5026 - accuracy: 0.8038 - val_loss: 0.6018 - val_accuracy: 0.7005\n",
      "Epoch 75/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.5005 - accuracy: 0.7962 - val_loss: 0.6010 - val_accuracy: 0.7005\n",
      "Epoch 76/300\n",
      "1580/1580 [==============================] - 0s 175us/sample - loss: 0.4994 - accuracy: 0.7962 - val_loss: 0.6002 - val_accuracy: 0.7027\n",
      "Epoch 77/300\n",
      "1580/1580 [==============================] - 0s 174us/sample - loss: 0.4980 - accuracy: 0.7861 - val_loss: 0.5994 - val_accuracy: 0.7027\n",
      "Epoch 78/300\n",
      "1580/1580 [==============================] - 0s 169us/sample - loss: 0.4927 - accuracy: 0.8108 - val_loss: 0.5986 - val_accuracy: 0.7005\n",
      "Epoch 79/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.4906 - accuracy: 0.8127 - val_loss: 0.5978 - val_accuracy: 0.7005\n",
      "Epoch 80/300\n",
      "1580/1580 [==============================] - 0s 169us/sample - loss: 0.4895 - accuracy: 0.8013 - val_loss: 0.5970 - val_accuracy: 0.7005\n",
      "Epoch 81/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.4877 - accuracy: 0.7975 - val_loss: 0.5962 - val_accuracy: 0.7005\n",
      "Epoch 82/300\n",
      "1580/1580 [==============================] - 0s 175us/sample - loss: 0.4854 - accuracy: 0.8139 - val_loss: 0.5954 - val_accuracy: 0.7005\n",
      "Epoch 83/300\n",
      "1580/1580 [==============================] - 0s 179us/sample - loss: 0.4836 - accuracy: 0.8108 - val_loss: 0.5946 - val_accuracy: 0.7005\n",
      "Epoch 84/300\n",
      "1580/1580 [==============================] - 0s 181us/sample - loss: 0.4819 - accuracy: 0.8127 - val_loss: 0.5939 - val_accuracy: 0.7005\n",
      "Epoch 85/300\n",
      "1580/1580 [==============================] - 0s 182us/sample - loss: 0.4759 - accuracy: 0.8089 - val_loss: 0.5931 - val_accuracy: 0.7005\n",
      "Epoch 86/300\n",
      "1580/1580 [==============================] - 0s 169us/sample - loss: 0.4768 - accuracy: 0.8133 - val_loss: 0.5924 - val_accuracy: 0.7027\n",
      "Epoch 87/300\n",
      "1580/1580 [==============================] - 0s 178us/sample - loss: 0.4768 - accuracy: 0.8120 - val_loss: 0.5917 - val_accuracy: 0.7027\n",
      "Epoch 88/300\n",
      "1580/1580 [==============================] - 0s 173us/sample - loss: 0.4677 - accuracy: 0.8285 - val_loss: 0.5910 - val_accuracy: 0.7050\n",
      "Epoch 89/300\n",
      "1580/1580 [==============================] - 0s 162us/sample - loss: 0.4703 - accuracy: 0.8177 - val_loss: 0.5903 - val_accuracy: 0.7072\n",
      "Epoch 90/300\n",
      "1580/1580 [==============================] - 0s 186us/sample - loss: 0.4672 - accuracy: 0.8114 - val_loss: 0.5896 - val_accuracy: 0.7095\n",
      "Epoch 91/300\n",
      "1580/1580 [==============================] - 0s 181us/sample - loss: 0.4661 - accuracy: 0.8234 - val_loss: 0.5889 - val_accuracy: 0.7095\n",
      "Epoch 92/300\n",
      "1580/1580 [==============================] - 0s 173us/sample - loss: 0.4613 - accuracy: 0.8241 - val_loss: 0.5882 - val_accuracy: 0.7095\n",
      "Epoch 93/300\n",
      "1580/1580 [==============================] - 0s 180us/sample - loss: 0.4563 - accuracy: 0.8291 - val_loss: 0.5875 - val_accuracy: 0.7117\n",
      "Epoch 94/300\n",
      "1580/1580 [==============================] - 0s 165us/sample - loss: 0.4583 - accuracy: 0.8247 - val_loss: 0.5869 - val_accuracy: 0.7117\n",
      "Epoch 95/300\n",
      "1580/1580 [==============================] - 0s 173us/sample - loss: 0.4570 - accuracy: 0.8323 - val_loss: 0.5862 - val_accuracy: 0.7117\n",
      "Epoch 96/300\n",
      "1580/1580 [==============================] - 0s 184us/sample - loss: 0.4524 - accuracy: 0.8253 - val_loss: 0.5856 - val_accuracy: 0.7140\n",
      "Epoch 97/300\n",
      "1580/1580 [==============================] - 0s 172us/sample - loss: 0.4537 - accuracy: 0.8241 - val_loss: 0.5850 - val_accuracy: 0.7140\n",
      "Epoch 98/300\n",
      "1580/1580 [==============================] - 0s 169us/sample - loss: 0.4497 - accuracy: 0.8278 - val_loss: 0.5844 - val_accuracy: 0.7117\n",
      "Epoch 99/300\n",
      "1580/1580 [==============================] - 0s 167us/sample - loss: 0.4448 - accuracy: 0.8304 - val_loss: 0.5838 - val_accuracy: 0.7162\n",
      "Epoch 100/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.4430 - accuracy: 0.8354 - val_loss: 0.5832 - val_accuracy: 0.7185\n",
      "Epoch 101/300\n",
      "1580/1580 [==============================] - 0s 166us/sample - loss: 0.4424 - accuracy: 0.8278 - val_loss: 0.5826 - val_accuracy: 0.7185\n",
      "Epoch 102/300\n",
      "1580/1580 [==============================] - 0s 175us/sample - loss: 0.4396 - accuracy: 0.8386 - val_loss: 0.5821 - val_accuracy: 0.7162\n",
      "Epoch 103/300\n",
      "1580/1580 [==============================] - 0s 177us/sample - loss: 0.4398 - accuracy: 0.8310 - val_loss: 0.5815 - val_accuracy: 0.7185\n",
      "Epoch 104/300\n",
      "1580/1580 [==============================] - 0s 174us/sample - loss: 0.4361 - accuracy: 0.8373 - val_loss: 0.5810 - val_accuracy: 0.7162\n",
      "Epoch 105/300\n",
      "1580/1580 [==============================] - 0s 193us/sample - loss: 0.4331 - accuracy: 0.8380 - val_loss: 0.5805 - val_accuracy: 0.7185\n",
      "Epoch 106/300\n",
      "1580/1580 [==============================] - 0s 175us/sample - loss: 0.4285 - accuracy: 0.8335 - val_loss: 0.5800 - val_accuracy: 0.7162\n",
      "Epoch 107/300\n",
      "1580/1580 [==============================] - 0s 163us/sample - loss: 0.4295 - accuracy: 0.8437 - val_loss: 0.5796 - val_accuracy: 0.7162\n",
      "Epoch 108/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.4312 - accuracy: 0.8392 - val_loss: 0.5791 - val_accuracy: 0.7162\n",
      "Epoch 109/300\n",
      "1580/1580 [==============================] - 0s 181us/sample - loss: 0.4248 - accuracy: 0.8392 - val_loss: 0.5787 - val_accuracy: 0.7207\n",
      "Epoch 110/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.4236 - accuracy: 0.8411 - val_loss: 0.5782 - val_accuracy: 0.7230\n",
      "Epoch 111/300\n",
      "1580/1580 [==============================] - 0s 177us/sample - loss: 0.4210 - accuracy: 0.8462 - val_loss: 0.5778 - val_accuracy: 0.7252\n",
      "Epoch 112/300\n",
      "1580/1580 [==============================] - 0s 165us/sample - loss: 0.4171 - accuracy: 0.8475 - val_loss: 0.5774 - val_accuracy: 0.7252\n",
      "Epoch 113/300\n",
      "1580/1580 [==============================] - 0s 167us/sample - loss: 0.4192 - accuracy: 0.8386 - val_loss: 0.5770 - val_accuracy: 0.7252\n",
      "Epoch 114/300\n",
      "1580/1580 [==============================] - 0s 160us/sample - loss: 0.4129 - accuracy: 0.8475 - val_loss: 0.5767 - val_accuracy: 0.7252\n",
      "Epoch 115/300\n",
      "1580/1580 [==============================] - 0s 157us/sample - loss: 0.4082 - accuracy: 0.8532 - val_loss: 0.5763 - val_accuracy: 0.7252\n",
      "Epoch 116/300\n",
      "1580/1580 [==============================] - 0s 158us/sample - loss: 0.4090 - accuracy: 0.8538 - val_loss: 0.5759 - val_accuracy: 0.7230\n",
      "Epoch 117/300\n",
      "1580/1580 [==============================] - 0s 158us/sample - loss: 0.4082 - accuracy: 0.8532 - val_loss: 0.5756 - val_accuracy: 0.7230\n",
      "Epoch 118/300\n",
      "1580/1580 [==============================] - 0s 156us/sample - loss: 0.4072 - accuracy: 0.8532 - val_loss: 0.5753 - val_accuracy: 0.7230\n",
      "Epoch 119/300\n",
      "1580/1580 [==============================] - 0s 166us/sample - loss: 0.4035 - accuracy: 0.8487 - val_loss: 0.5751 - val_accuracy: 0.7230\n",
      "Epoch 120/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.4009 - accuracy: 0.8481 - val_loss: 0.5748 - val_accuracy: 0.7207\n",
      "Epoch 121/300\n",
      "1580/1580 [==============================] - 0s 199us/sample - loss: 0.3959 - accuracy: 0.8551 - val_loss: 0.5745 - val_accuracy: 0.7207\n",
      "Epoch 122/300\n",
      "1580/1580 [==============================] - 0s 187us/sample - loss: 0.3953 - accuracy: 0.8595 - val_loss: 0.5743 - val_accuracy: 0.7207\n",
      "Epoch 123/300\n",
      "1580/1580 [==============================] - 0s 180us/sample - loss: 0.3934 - accuracy: 0.8601 - val_loss: 0.5741 - val_accuracy: 0.7207\n",
      "Epoch 124/300\n",
      "1580/1580 [==============================] - 0s 176us/sample - loss: 0.3955 - accuracy: 0.8475 - val_loss: 0.5739 - val_accuracy: 0.7207\n",
      "Epoch 125/300\n",
      "1580/1580 [==============================] - 0s 170us/sample - loss: 0.3901 - accuracy: 0.8563 - val_loss: 0.5737 - val_accuracy: 0.7252\n",
      "Epoch 126/300\n",
      "1580/1580 [==============================] - 0s 161us/sample - loss: 0.3875 - accuracy: 0.8595 - val_loss: 0.5734 - val_accuracy: 0.7230\n",
      "Epoch 127/300\n",
      "1580/1580 [==============================] - 0s 158us/sample - loss: 0.3843 - accuracy: 0.8658 - val_loss: 0.5732 - val_accuracy: 0.7230\n",
      "Epoch 128/300\n",
      "1580/1580 [==============================] - 0s 155us/sample - loss: 0.3834 - accuracy: 0.8627 - val_loss: 0.5732 - val_accuracy: 0.7207\n",
      "Epoch 129/300\n",
      "1580/1580 [==============================] - 0s 165us/sample - loss: 0.3785 - accuracy: 0.8627 - val_loss: 0.5730 - val_accuracy: 0.7207\n",
      "Epoch 130/300\n",
      "1580/1580 [==============================] - 0s 155us/sample - loss: 0.3764 - accuracy: 0.8747 - val_loss: 0.5729 - val_accuracy: 0.7185\n",
      "Epoch 131/300\n",
      "1580/1580 [==============================] - 0s 165us/sample - loss: 0.3784 - accuracy: 0.8690 - val_loss: 0.5728 - val_accuracy: 0.7207\n",
      "Epoch 132/300\n",
      "1580/1580 [==============================] - 0s 162us/sample - loss: 0.3737 - accuracy: 0.8703 - val_loss: 0.5727 - val_accuracy: 0.7207\n",
      "Epoch 133/300\n",
      "1580/1580 [==============================] - 0s 161us/sample - loss: 0.3711 - accuracy: 0.8690 - val_loss: 0.5727 - val_accuracy: 0.7207\n",
      "Epoch 134/300\n",
      "1580/1580 [==============================] - 0s 160us/sample - loss: 0.3697 - accuracy: 0.8703 - val_loss: 0.5727 - val_accuracy: 0.7207\n",
      "Epoch 135/300\n",
      "1580/1580 [==============================] - 0s 172us/sample - loss: 0.3651 - accuracy: 0.8753 - val_loss: 0.5727 - val_accuracy: 0.7207\n",
      "Epoch 136/300\n",
      "1580/1580 [==============================] - 0s 171us/sample - loss: 0.3638 - accuracy: 0.8747 - val_loss: 0.5728 - val_accuracy: 0.7207\n",
      "Epoch 137/300\n",
      "1580/1580 [==============================] - 0s 164us/sample - loss: 0.3661 - accuracy: 0.8658 - val_loss: 0.5728 - val_accuracy: 0.7230\n",
      "Epoch 00137: early stopping\n",
      "215/215 [==============================] - 0s 86us/sample - loss: 0.9800 - accuracy: 0.4233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [1:05:58, 791.79s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for num_ix, rand_num in enumerate(rand):\n",
    "    for index_t_well, _ in tqdm.tqdm(enumerate(tot_well)):\n",
    "\n",
    "        time_points = list(map(str, range(1,97,3)))\n",
    "\n",
    "        new_time = []\n",
    "        for i in time_points:\n",
    "            r = '_' + i + '.'\n",
    "            new_time.append(r)\n",
    "\n",
    "\n",
    "\n",
    "        path_test = '/home/jovyan/DATA_MASTER_PROJECT/Check_DIFF_T0_T97/{}_cropped/'.format(a)\n",
    "\n",
    "        # NAME OF THE WELLS CORRESPONDING TO THE FRUG THAT YOU WANT IN THE TEST SET \n",
    "\n",
    "        wells_drug = [tot_well[index_t_well][0], tot_well[index_t_well][1]] \n",
    "\n",
    "        test = []\n",
    "\n",
    "        for _,_, filenames in os.walk(path_test):\n",
    "\n",
    "            for filename in sorted(filenames, key = natural_keys):\n",
    "\n",
    "                for w in wells_drug:\n",
    "                    for t in new_time:\n",
    "                        if '{}'.format(w) in filename and '{}tiff'.format(t) in filename:\n",
    "                            test.append(filename)\n",
    "\n",
    "        groups_list = ['{}'.format(a), '{}'.format(b)]\n",
    "\n",
    "        train = []\n",
    "\n",
    "        validation = []\n",
    "\n",
    "        group_compounds = []\n",
    "\n",
    "        for group in tqdm.tqdm(groups_list):\n",
    "\n",
    "            pa = '/home/jovyan/DATA_MASTER_PROJECT/Check_DIFF_T0_T97/{}_cropped/'.format(group)\n",
    "\n",
    "            for _,_, filenames in os.walk(pa):\n",
    "\n",
    "                for filename in sorted(filenames, key = natural_keys):\n",
    "\n",
    "                    for t in new_time:\n",
    "\n",
    "                        if '_{}-'.format(wells_drug[0]) not in filename and '_{}-'.format(wells_drug[1]) not in filename and '{}tiff'.format(t) in filename:\n",
    "\n",
    "                            group_compounds.append(filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        name =sorted(group_compounds)\n",
    "\n",
    "\n",
    "        well = []\n",
    "        for i in name:\n",
    "            well.append(i.split('_id')[0])\n",
    "\n",
    "        well_name = list(set(well))\n",
    "\n",
    "        well_name = sorted(well_name)\n",
    "\n",
    "        l = []\n",
    "        for ix, _ in enumerate(well_name):\n",
    "            n = []\n",
    "            for i in name:\n",
    "                if well_name[ix] in i:\n",
    "                    n.append(i)\n",
    "            l.append(n)\n",
    "\n",
    "\n",
    "        tot_list = []\n",
    "\n",
    "        for ix, i in tqdm.tqdm(enumerate(l)):\n",
    "\n",
    "\n",
    "            id_n = []\n",
    "            for j in l[ix]:\n",
    "                id_n.append(j.split('_time')[0].split('_id_')[1])\n",
    "\n",
    "            id_name = list(set(id_n))\n",
    "\n",
    "            l1 = []\n",
    "            for ixd, _ in enumerate(id_name):\n",
    "                n1 = []\n",
    "                for na in l[ix]:\n",
    "                    if 'id_{}_time'.format(id_name[ixd]) in na:\n",
    "                        n1.append(na)\n",
    "                l1.append(n1)\n",
    "\n",
    "            tot_list.append(l1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        tra = []\n",
    "\n",
    "        val = []\n",
    "\n",
    "        for ie in tqdm.tqdm((range(len(tot_list)))):\n",
    "\n",
    "            f_list = tot_list[ie]\n",
    "\n",
    "            li = list(range((len(f_list))))\n",
    "\n",
    "            f, s = train_test_split(li, test_size=0.2, random_state=rand_num)\n",
    "\n",
    "\n",
    "            for i in f:\n",
    "\n",
    "                tra.append(f_list[i])\n",
    "\n",
    "            for v1 in s:\n",
    "                val.append(f_list[v1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        train = [i for sub in tra for i in sub]\n",
    "\n",
    "        validation = [i for sub in val for i in sub]\n",
    "\n",
    "\n",
    "        x_train = loadImages(train)\n",
    "        y_train = make_labels(train)\n",
    "\n",
    "\n",
    "\n",
    "        x_val = loadImages(validation)\n",
    "        y_val = make_labels(validation)\n",
    "\n",
    "\n",
    "\n",
    "        x_train = resize(x_train)\n",
    "\n",
    "\n",
    "        x_val = resize(x_val)\n",
    "\n",
    "\n",
    "        weights = class_weight.compute_class_weight('balanced', np.unique(y_train),y_train)\n",
    "\n",
    "\n",
    "        x_train = preprocess_input(x_train)\n",
    "\n",
    "        x_val = preprocess_input(x_val)\n",
    "\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=3)\n",
    "\n",
    "        pretrained_model = VGG16(weights='imagenet',include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "        base_model = Model(inputs=pretrained_model.input, outputs=pretrained_model.get_layer('block3_pool').output)\n",
    "\n",
    "        batch_size = 128\n",
    "\n",
    "        datagen = ImageDataGenerator()\n",
    "\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "        train_gen = datagen.flow(x_train, y_train,batch_size=batch_size )\n",
    "\n",
    "        dat_val = ImageDataGenerator()\n",
    "\n",
    "        dat_val.fit(x_val)\n",
    "\n",
    "        val_gen = dat_val.flow(x_val, y_val,batch_size=batch_size)\n",
    "\n",
    "        m4 = Sequential()\n",
    "        m4.add(base_model)\n",
    "\n",
    "\n",
    "        m4.add(BatchNormalization())\n",
    "        m4.add(GlobalAveragePooling2D())\n",
    "        m4.add(Dense(64, activation='relu'))\n",
    "        m4.add(BatchNormalization())\n",
    "        m4.add(Activation('relu'))\n",
    "        m4.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "        base_model.trainable = False\n",
    "\n",
    "        opt = keras.optimizers.Adam(lr=1e-4)\n",
    "\n",
    "        m4.compile(loss= keras.losses.binary_crossentropy, optimizer=opt, metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "        epochs = 300\n",
    "\n",
    "        m4_h = m4.fit(train_gen,\n",
    "                        steps_per_epoch=(len(x_train)/batch_size),\n",
    "                        callbacks = [es],\n",
    "                        epochs=epochs,\n",
    "                        validation_data = (val_gen), \n",
    "                        validation_steps = (len(x_val)/batch_size),\n",
    "                        class_weight = weights,\n",
    "                         verbose = 1)\n",
    "\n",
    "        base_model.trainable = True\n",
    "\n",
    "        opt = keras.optimizers.Adam(lr=1e-5)\n",
    "\n",
    "        m4.compile(loss= keras.losses.binary_crossentropy, optimizer=opt, metrics = ['accuracy'])\n",
    "\n",
    "        epochs = 300\n",
    "\n",
    "        m4_h = m4.fit(train_gen,\n",
    "                        steps_per_epoch=(len(x_train)/batch_size),\n",
    "                        callbacks = [es],\n",
    "                        epochs=epochs,\n",
    "                        validation_data = val_gen, \n",
    "                        validation_steps = (len(x_val)/batch_size),\n",
    "                        class_weight = weights,\n",
    "                        verbose = 1)\n",
    "\n",
    "        l = []\n",
    "        for t in new_time:\n",
    "            for i in test:\n",
    "                if t in i:\n",
    "                    l.append((i))\n",
    "\n",
    "\n",
    "        grouped = {}\n",
    "        for elem in l:\n",
    "            key = elem.split('.tiff')[0].split('_')[5]\n",
    "            grouped.setdefault(key, []).append(elem)\n",
    "        grouped = grouped.values()\n",
    "\n",
    "        test_data = list(grouped)\n",
    "\n",
    "        r = []\n",
    "\n",
    "        for ix ,_ in enumerate(test_data):\n",
    "            r.append(time_step_acc(test_data[ix],m4))\n",
    "\n",
    "        plt.plot(time_points,r)\n",
    "        plt.savefig('/home/jovyan/{}_accuracy.png'.format(string_well[index_t_well]))\n",
    "\n",
    "        tot_results_accuracy.append(r)\n",
    "        \n",
    "        for i, layer in enumerate(m4.layers):\n",
    "            layer._name = 'layer_' + str(i)\n",
    "\n",
    "\n",
    "\n",
    "        lstm_model = Model(inputs=m4.input, outputs=m4.get_layer('layer_4').output)\n",
    "\n",
    "        data_name = [train,test,validation]\n",
    "\n",
    "        feat_name = ['train', 'test', 'validation']\n",
    "\n",
    "        for index_name, _ in enumerate(data_name):\n",
    "\n",
    "            path =  data_name[index_name]\n",
    "\n",
    "            name_well = []\n",
    "\n",
    "            for i in path:\n",
    "                name_well.append(i.split('_id')[0])\n",
    "\n",
    "            wells = list(set(name_well))\n",
    "            wells\n",
    "\n",
    "            for w in wells:\n",
    "\n",
    "                time = []\n",
    "\n",
    "\n",
    "                for filename in sorted(path, key = natural_keys):\n",
    "                    if w in filename: #PAY ATTENTION ID THE IMAGE IS A TIFF OR PNG IMAGE #########\n",
    "                        time.append(filename)\n",
    "\n",
    "                data_id = {}\n",
    "                n_id = []\n",
    "                w_n = []\n",
    "\n",
    "                for i in time:\n",
    "                    t = i.split('_id_')[1].split('time_')[0]\n",
    "                    f = i.split('_id_')[0].split('time_')[0]\n",
    "                    n_id.append(t)\n",
    "                    w_n.append(f)\n",
    "\n",
    "                id_cell = set(n_id)\n",
    "\n",
    "\n",
    "                for ix, i in enumerate(sorted(id_cell, key = natural_keys)):\n",
    "\n",
    "                    id_name = []\n",
    "                    dict_1 = {}\n",
    "\n",
    "                    for t in time:\n",
    "                        if 'id_{}'.format(i) in t:\n",
    "                            id_name.append(t)\n",
    "\n",
    "                    d = {'id':id_name}\n",
    "                    data = pd.DataFrame(d)\n",
    "\n",
    "                    dict_1[ix]=data \n",
    "                    data_id.update(dict_1) \n",
    "\n",
    "                delete = [i for i, j in data_id.items() if len(j) < 32] # 9 or the length of time span you are traning on \n",
    "                for i in delete : del data_id[i]\n",
    "\n",
    "                len_id = [i for i, j in data_id.items()]\n",
    "\n",
    "                for le in len_id:    \n",
    "\n",
    "\n",
    "                    e = pd.DataFrame(data_id[le])\n",
    "\n",
    "                    coords = e.values.tolist()\n",
    "                    id_cells = []\n",
    "                    for i in coords:\n",
    "                        for j in i:\n",
    "                            id_cells.append(j)\n",
    "\n",
    "                    x_orig = loadImages(id_cells)\n",
    "                    x_orig = resize(x_orig)\n",
    "\n",
    "                    x_orig = preprocess_input(x_orig)\n",
    "                    output = lstm_model.predict(x_orig)\n",
    "                    np.save('/home/jovyan/DATA_MASTER_PROJECT/LSTM//FEAT_FOLDERS/features_{}/features_well_{}_id_{}.npy'.format(feat_name[index_name],w_n[0], le), output)\n",
    "            print('Saved_feature_{}'.format(feat_name[index_name]))\n",
    "\n",
    "\n",
    "        x_train_lstm = loadImages_LSTM(train_data)\n",
    "        y_train_lstm = make_labels_LSTM(y_tra_path)\n",
    "\n",
    "        x_test_lstm = loadImages_LSTM(tes_data)\n",
    "        y_test_lstm = make_labels_LSTM(y_tes_path)\n",
    "\n",
    "        x_val_lstm = loadImages_LSTM(val_data)\n",
    "        y_val_lstm = make_labels_LSTM(y_val_path)\n",
    "\n",
    "        weights_lstm = class_weight.compute_class_weight('balanced', np.unique(y_train_lstm),y_train_lstm)\n",
    "\n",
    "\n",
    "        m = Sequential()\n",
    "        m.add(LSTM(32, input_shape = (x_train_lstm.shape[1],x_train_lstm.shape[2])))\n",
    "        m.add(Dropout(0.2))\n",
    "        m.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "        opt_lstm = keras.optimizers.Adam(lr=1e-4)\n",
    "\n",
    "        m.compile(loss= keras.losses.binary_crossentropy, optimizer=opt, metrics = ['accuracy'])\n",
    "\n",
    "        epochs = 300\n",
    "\n",
    "        m_h = m.fit(x_train_lstm,y_train_lstm,\n",
    "\n",
    "                         callbacks = [es],\n",
    "\n",
    "                        epochs=epochs,\n",
    "                        validation_data = (x_val_lstm,y_val_lstm), \n",
    "\n",
    "                        class_weight = weights_lstm)\n",
    "\n",
    "\n",
    "        scores_lstm = m.evaluate(x_test_lstm, y_test_lstm)\n",
    "        results_lstm.append([scores_lstm[1]*100, string_well[index_t_well]])\n",
    "\n",
    "        # DELITE FILES IN FEATURE VECTOR FOLDERS\n",
    "\n",
    "        folders = glob.glob('/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/*')\n",
    "\n",
    "        for fo in folders:\n",
    "            file = glob.glob(f'{fo}/*')\n",
    "            for f in file:\n",
    "                os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(41.29738650905589, 'mid'),\n",
       " (47.145385264108576, 'leb'),\n",
       " (35.5723592142264, 'mep'),\n",
       " (29.52169361524284, 'met'),\n",
       " (36.669812677428126, 'oxy')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ACCURACY SCORE AVERAGE FOR CNN\n",
    "cv_s = cv_mean_acc(tot_results_accuracy, string_well)\n",
    "cv_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT OF MEAN ACCURACY FOR EVERY TIME POINT CNN\n",
    "\n",
    "l_drug = string_well*3\n",
    "\n",
    "acc_plot = []\n",
    "\n",
    "for i in tot_results_accuracy:\n",
    "    acc_plot.append(i)\n",
    "\n",
    "cv_plot = list(zip(acc_plot, l_drug))\n",
    "\n",
    "res_plot = sorted(cv_plot, key = lambda x: x[1])\n",
    "\n",
    "a , b = zip(*res_plot)\n",
    "    \n",
    "a = list(a)\n",
    "\n",
    "s = list(np.array_split(a, 5))\n",
    "\n",
    "cv_plot = []\n",
    "\n",
    "for ix, i in enumerate(s):\n",
    "    s1 = list(s[ix])\n",
    "    \n",
    "    cv_plot.append(np.average(s1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i in cv_plot:\n",
    "    \n",
    "    plt.plot(time_points, i)\n",
    "    plt.show\n",
    "    plt.savefig('/home/jovyan/cv_score.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lstm = sorted(results_lstm, key=lambda x: x[1])\n",
    "r_lstm , _ = zip(*results_lstm)\n",
    "    \n",
    "r_lstm = list(r_lstm)\n",
    "\n",
    "re_lstm = list(np.array_split(r_lstm, 5))\n",
    "\n",
    "cv_lstm = []\n",
    "\n",
    "for ix, i in enumerate(re_lstm):\n",
    "    r1 = list(re_lstm[ix])\n",
    "    cv_lstm.append(np.mean(r1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23.35025320450465, 'mid'),\n",
       " (62.03288435935974, 'leb'),\n",
       " (34.01015202204386, 'mep'),\n",
       " (27.429274717966717, 'met'),\n",
       " (43.41085155804952, 'oxy')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_lstm = list(zip(cv_lstm, string_well))\n",
    "cv_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE RUNNING AGAIN\n",
    "\n",
    "folders = glob.glob('/home/jovyan/DATA_MASTER_PROJECT/LSTM/FEAT_FOLDERS/*')\n",
    "\n",
    "for fo in folders:\n",
    "    file = glob.glob(f'{fo}/*')\n",
    "    for f in file:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
