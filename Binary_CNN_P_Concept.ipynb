{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D\n",
    "from tensorflow.keras.layers import MaxPooling2D, MaxPooling3D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import preprocessing\n",
    "import tqdm\n",
    "from numpy import loadtxt\n",
    "from os import *\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(true,preds):\n",
    "    conf_matx = confusion_matrix(true, preds)\n",
    "    sns.heatmap(conf_matx, annot=True,annot_kws={\"size\": 12},fmt='g', cbar=False, cmap=plt.cm.Blues) #'viridis'\n",
    "    #plt.savefig('/home/jovyan/img1.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return conf_matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(model_history, model_name):\n",
    "    fig = plt.figure(figsize=(15,5), facecolor='w')\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.plot(model_history.history['loss'])\n",
    "    ax.plot(model_history.history['val_loss'])\n",
    "    ax.set(title=model_name + ': Model loss', ylabel='Loss', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Val'], loc='upper left')\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.plot(model_history.history['accuracy'])\n",
    "    ax.plot(model_history.history['val_accuracy'])\n",
    "    ax.set(title=model_name + ': Model Accuracy; test='+ str(np.round(model_history.history['val_accuracy'][-1], 3)),\n",
    "           ylabel='Accuracy', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Val'], loc='upper left')\n",
    "    #plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def loadImages(path_data, path_labels):\n",
    "\n",
    "    image_list = []\n",
    "    \n",
    "\n",
    "    for filename in sorted(glob.glob(path_data), key=natural_keys): \n",
    "        im=cv2.imread(filename)\n",
    "        #gray_image = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        imarray = np.array(im)\n",
    "        imarray = imarray.astype('float32')\n",
    "        image_list.append(imarray)\n",
    "\n",
    "    x_orig = np.reshape(image_list, (len(image_list), 90, 90, 3))\n",
    "    \n",
    "    path = path_labels    \n",
    "    labels = pd.read_csv(path, usecols=[\"Type\", \"Category\"],\n",
    "                       sep=\",\" )\n",
    "    y_orig = np.array(labels['Category'])\n",
    "\n",
    "    return x_orig, y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = '/home/jovyan/DATA_MASTER_PROJECT/A549/Prof_of_concept/trained_cropped/*.tiff'\n",
    "train_lab='/home/jovyan/DATA_MASTER_PROJECT/A549/Prof_of_concept/train_labels.csv'\n",
    "\n",
    "\n",
    "test_data='/home/jovyan/DATA_MASTER_PROJECT/A549/Prof_of_concept/test_cropped/*.tiff'\n",
    "test_lab='/home/jovyan/DATA_MASTER_PROJECT/A549/Prof_of_concept/test_leb.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 3171.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((7592, 90, 90, 3), (7592,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_orig_1, y_orig_1 = tqdm.tqdm(loadImages(train_data, train_lab))\n",
    "x_orig_1.shape, y_orig_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_orig_1 = x_orig_1/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6073, 90, 90, 3), (1519, 90, 90, 3), (6073,), (1519,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_1, x_val, y_train_1, y_val = train_test_split(x_orig_1, y_orig_1, test_size=0.2, random_state=999 )\n",
    "x_train_1.shape, x_val.shape, y_train_1.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-831ff8a94019>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_lab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b55222c1f3ac>\u001b[0m in \u001b[0;36mloadImages\u001b[0;34m(path_data, path_labels)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnatural_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m#gray_image = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mimarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_test, y_test = loadImages(test_data, test_lab)\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show n rabdom images to check for quality\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train_1[i], cmap=plt.cm.binary)\n",
    "    #plt.xlabel(class_names[y_orig_1[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train_1, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_val, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = class_weight.compute_class_weight('balanced', np.unique(y_train_1),y_train_1)\n",
    "print('weights = ' + str(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (90,90,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Sequential()\n",
    "m.add(Conv2D(filters=8, kernel_size=3, strides=1, padding='same', activation='relu', input_shape = input_shape))\n",
    "m.add(MaxPooling2D())\n",
    "\n",
    "m.add(Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "m.add(MaxPooling2D())\n",
    "\n",
    "m.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "m.add(MaxPooling2D())\n",
    "\n",
    "m.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "m.add(MaxPooling2D())\n",
    "\n",
    "m.add(Flatten())\n",
    "\n",
    "m.add(Dense(128, activation='relu'))\n",
    "\n",
    "\n",
    "m.add(Dense(3,activation='sigmoid'))\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(loss= binary_crossentropy,\n",
    "              optimizer = Adam(lr=1e-4),\n",
    "             metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 100\n",
    "\n",
    "m_h = m.fit(x_train_1, y_train_1,\n",
    "            epochs=epochs, \n",
    "            callbacks = [es],\n",
    "            class_weight = weights,\n",
    "            validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(m_h, 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976/976 [==============================] - 0s 140us/sample - loss: 0.6552 - accuracy: 0.6240\n",
      "\n",
      "accuracy: 62.40%\n"
     ]
    }
   ],
   "source": [
    "scores = m.evaluate(x_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (m.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = m.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "t= []\n",
    "for i in (test_preds):\n",
    "    if i > 0.5:\n",
    "        t.append(1)\n",
    "    else:\n",
    "        t.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[250, 200],\n",
       "       [167, 359]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_confusion_matrix(y_test, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.56      0.58       450\n",
      "           1       0.64      0.68      0.66       526\n",
      "\n",
      "    accuracy                           0.62       976\n",
      "   macro avg       0.62      0.62      0.62       976\n",
      "weighted avg       0.62      0.62      0.62       976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
